2023-06-01 16:34:36.716: Dataset name: yelp2018
The number of users: 31668
The number of items: 38048
The number of ratings: 1561406
Average actions of users: 49.31
Average actions of items: 41.04
The sparsity of the dataset: 99.870412%
2023-06-01 16:34:36.716: 

NeuRec hyperparameters:
recommender=SGL
config_dir=./conf
gpu_id=1
gpu_mem=0.5
data.input.path=dataset
data.input.dataset=yelp2018
data.column.format=UI
data.convert.separator=','
user_min=0
item_min=0
splitter=given
ratio=0.8
by_time=False
metric=["Precision", "Recall", "NDCG", "MAP", "MRR"]
topk=[20]
group_view=None
rec.evaluate.neg=0
test_batch_size=128
num_thread=8
start_testing_epoch=0
proj_path=./

SGL's hyperparameters:
seed=2021
aug_type=1
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.2
ssl_ratio=0.1
ssl_temp=0.3
ssl_mode=both_side
ssl_loss_type=2
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
init_method=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=50
pretrain=0
save_flag=1

2023-06-01 16:34:40.423: metrics:	Precision@20	Recall@20   	NDCG@20     	MAP@20      	MRR@20      
2023-06-01 16:34:44.857: 		0.00030630  	0.00060534  	0.00047115  	0.00104996  	0.00105193  
2023-06-01 16:36:17.924: [iter 1 : loss : 4.5082 = 0.6930 + 3.8151 + 0.0000, time: 90.216146]
2023-06-01 16:36:22.089: epoch 1:	0.00339463  	0.00724618  	0.00574310  	0.01164315  	0.01242355  
2023-06-01 16:36:22.089: Found a better model.
2023-06-01 16:36:22.089: Save model to file as pretrain.
2023-06-01 16:37:54.260: [iter 2 : loss : 4.5062 = 0.6924 + 3.8138 + 0.0000, time: 89.150896]
2023-06-01 16:37:58.188: epoch 2:	0.00359042  	0.00785274  	0.00602422  	0.01138567  	0.01225949  
2023-06-01 16:37:58.188: Found a better model.
2023-06-01 16:37:58.188: Save model to file as pretrain.
2023-06-01 16:39:30.096: [iter 3 : loss : 4.4959 = 0.6818 + 3.8141 + 0.0000, time: 88.038976]
2023-06-01 16:39:33.820: epoch 3:	0.00532725  	0.01147056  	0.00925263  	0.01685585  	0.01882675  
2023-06-01 16:39:33.820: Found a better model.
2023-06-01 16:39:33.820: Save model to file as pretrain.
2023-06-01 16:41:07.255: [iter 4 : loss : 4.4487 = 0.6319 + 3.8168 + 0.0001, time: 89.751230]
2023-06-01 16:41:11.424: epoch 4:	0.01039685  	0.02282577  	0.01824883  	0.03220793  	0.03622670  
2023-06-01 16:41:11.424: Found a better model.
2023-06-01 16:41:11.424: Save model to file as pretrain.
2023-06-01 16:42:44.828: [iter 5 : loss : 4.3407 = 0.5136 + 3.8268 + 0.0002, time: 89.598867]
2023-06-01 16:42:48.458: epoch 5:	0.01679047  	0.03648309  	0.02941091  	0.05483702  	0.06067302  
2023-06-01 16:42:48.458: Found a better model.
2023-06-01 16:42:48.458: Save model to file as pretrain.
2023-06-01 16:44:21.418: [iter 6 : loss : 4.0952 = 0.2378 + 3.8567 + 0.0006, time: 89.168460]
2023-06-01 16:44:25.632: epoch 6:	0.01898466  	0.04098698  	0.03339710  	0.06396114  	0.07053509  
2023-06-01 16:44:25.632: Found a better model.
2023-06-01 16:44:25.632: Save model to file as pretrain.
2023-06-01 16:45:59.544: [iter 7 : loss : 3.9919 = 0.1331 + 3.8578 + 0.0010, time: 89.994286]
2023-06-01 16:46:03.750: epoch 7:	0.02008337  	0.04310343  	0.03518025  	0.06733654  	0.07409970  
2023-06-01 16:46:03.750: Found a better model.
2023-06-01 16:46:03.750: Save model to file as pretrain.
2023-06-01 16:47:36.757: [iter 8 : loss : 3.9669 = 0.1135 + 3.8522 + 0.0012, time: 89.126777]
2023-06-01 16:47:40.947: epoch 8:	0.02082373  	0.04471743  	0.03655542  	0.07008747  	0.07726395  
2023-06-01 16:47:40.947: Found a better model.
2023-06-01 16:47:40.947: Save model to file as pretrain.
2023-06-01 16:49:14.291: [iter 9 : loss : 3.9517 = 0.1025 + 3.8478 + 0.0014, time: 89.655674]
2023-06-01 16:49:18.727: epoch 9:	0.02132259  	0.04575663  	0.03751159  	0.07214274  	0.07942096  
2023-06-01 16:49:18.727: Found a better model.
2023-06-01 16:49:18.727: Save model to file as pretrain.
2023-06-01 16:50:50.757: [iter 10 : loss : 3.9412 = 0.0951 + 3.8446 + 0.0015, time: 88.221933]
2023-06-01 16:50:54.944: epoch 10:	0.02163201  	0.04649076  	0.03818899  	0.07350576  	0.08105427  
2023-06-01 16:50:54.944: Found a better model.
2023-06-01 16:50:54.944: Save model to file as pretrain.
2023-06-01 16:52:27.966: [iter 11 : loss : 3.9324 = 0.0885 + 3.8422 + 0.0016, time: 89.020177]
2023-06-01 16:52:32.178: epoch 11:	0.02189247  	0.04708499  	0.03869290  	0.07428690  	0.08202862  
2023-06-01 16:52:32.179: Found a better model.
2023-06-01 16:52:32.179: Save model to file as pretrain.
2023-06-01 16:54:04.622: [iter 12 : loss : 3.9258 = 0.0837 + 3.8403 + 0.0018, time: 88.428401]
2023-06-01 16:54:08.759: epoch 12:	0.02217980  	0.04766663  	0.03919684  	0.07508421  	0.08292551  
2023-06-01 16:54:08.759: Found a better model.
2023-06-01 16:54:08.759: Save model to file as pretrain.
2023-06-01 16:55:41.573: [iter 13 : loss : 3.9208 = 0.0801 + 3.8388 + 0.0019, time: 88.898067]
2023-06-01 16:55:45.744: epoch 13:	0.02237080  	0.04822029  	0.03961674  	0.07581540  	0.08395003  
2023-06-01 16:55:45.744: Found a better model.
2023-06-01 16:55:45.744: Save model to file as pretrain.
2023-06-01 16:57:18.586: [iter 14 : loss : 3.9159 = 0.0764 + 3.8375 + 0.0020, time: 89.126208]
2023-06-01 16:57:23.052: epoch 14:	0.02256655  	0.04866041  	0.04000008  	0.07645170  	0.08473485  
2023-06-01 16:57:23.052: Found a better model.
2023-06-01 16:57:23.052: Save model to file as pretrain.
2023-06-01 16:58:55.903: [iter 15 : loss : 3.9117 = 0.0732 + 3.8364 + 0.0021, time: 89.078417]
2023-06-01 16:59:00.035: epoch 15:	0.02271651  	0.04913995  	0.04035818  	0.07706370  	0.08548945  
2023-06-01 16:59:00.035: Found a better model.
2023-06-01 16:59:00.035: Save model to file as pretrain.
2023-06-01 17:00:32.304: [iter 16 : loss : 3.9074 = 0.0698 + 3.8355 + 0.0022, time: 88.417755]
2023-06-01 17:00:36.611: epoch 16:	0.02291859  	0.04967873  	0.04074387  	0.07779728  	0.08607933  
2023-06-01 17:00:36.611: Found a better model.
2023-06-01 17:00:36.611: Save model to file as pretrain.
2023-06-01 17:02:10.589: [iter 17 : loss : 3.9049 = 0.0680 + 3.8346 + 0.0023, time: 89.950172]
2023-06-01 17:02:14.659: epoch 17:	0.02312380  	0.05028047  	0.04115235  	0.07832240  	0.08693714  
2023-06-01 17:02:14.659: Found a better model.
2023-06-01 17:02:14.659: Save model to file as pretrain.
2023-06-01 17:03:46.445: [iter 18 : loss : 3.9014 = 0.0652 + 3.8339 + 0.0024, time: 87.848547]
2023-06-01 17:03:50.541: epoch 18:	0.02320269  	0.05053427  	0.04138560  	0.07898895  	0.08755206  
2023-06-01 17:03:50.542: Found a better model.
2023-06-01 17:03:50.542: Save model to file as pretrain.
2023-06-01 17:05:23.474: [iter 19 : loss : 3.8993 = 0.0636 + 3.8332 + 0.0025, time: 89.188964]
2023-06-01 17:05:27.511: epoch 19:	0.02336844  	0.05091532  	0.04166811  	0.07939849  	0.08809905  
2023-06-01 17:05:27.511: Found a better model.
2023-06-01 17:05:27.511: Save model to file as pretrain.
2023-06-01 17:06:59.903: [iter 20 : loss : 3.8969 = 0.0617 + 3.8326 + 0.0025, time: 88.658643]
2023-06-01 17:07:03.883: epoch 20:	0.02354369  	0.05147294  	0.04202787  	0.07995771  	0.08860679  
2023-06-01 17:07:03.884: Found a better model.
2023-06-01 17:07:03.884: Save model to file as pretrain.
2023-06-01 17:08:37.976: [iter 21 : loss : 3.8943 = 0.0597 + 3.8320 + 0.0026, time: 90.161893]
2023-06-01 17:08:42.156: epoch 21:	0.02371261  	0.05194669  	0.04234415  	0.08037628  	0.08909398  
2023-06-01 17:08:42.157: Found a better model.
2023-06-01 17:08:42.157: Save model to file as pretrain.
2023-06-01 17:10:14.877: [iter 22 : loss : 3.8919 = 0.0577 + 3.8315 + 0.0027, time: 88.904668]
2023-06-01 17:10:18.497: epoch 22:	0.02382942  	0.05216176  	0.04256526  	0.08076718  	0.08953026  
2023-06-01 17:10:18.497: Found a better model.
2023-06-01 17:10:18.497: Save model to file as pretrain.
2023-06-01 17:11:51.418: [iter 23 : loss : 3.8903 = 0.0564 + 3.8310 + 0.0028, time: 89.025208]
2023-06-01 17:11:55.725: epoch 23:	0.02400783  	0.05268893  	0.04298381  	0.08152596  	0.09038956  
2023-06-01 17:11:55.725: Found a better model.
2023-06-01 17:11:55.725: Save model to file as pretrain.
2023-06-01 17:13:27.690: [iter 24 : loss : 3.8889 = 0.0555 + 3.8306 + 0.0029, time: 88.286340]
2023-06-01 17:13:31.145: epoch 24:	0.02399993  	0.05277327  	0.04312015  	0.08191900  	0.09071174  
2023-06-01 17:13:31.145: Found a better model.
2023-06-01 17:13:31.145: Save model to file as pretrain.
2023-06-01 17:15:05.221: [iter 25 : loss : 3.8871 = 0.0540 + 3.8302 + 0.0030, time: 90.286616]
2023-06-01 17:15:09.172: epoch 25:	0.02418938  	0.05305656  	0.04342337  	0.08256659  	0.09145635  
2023-06-01 17:15:09.172: Found a better model.
2023-06-01 17:15:09.172: Save model to file as pretrain.
2023-06-01 17:16:42.458: [iter 26 : loss : 3.8852 = 0.0524 + 3.8298 + 0.0031, time: 89.493336]
2023-06-01 17:16:46.579: epoch 26:	0.02431252  	0.05337366  	0.04367030  	0.08276414  	0.09184964  
2023-06-01 17:16:46.579: Found a better model.
2023-06-01 17:16:46.579: Save model to file as pretrain.
2023-06-01 17:18:19.370: [iter 27 : loss : 3.8836 = 0.0511 + 3.8294 + 0.0031, time: 88.961246]
2023-06-01 17:18:23.631: epoch 27:	0.02436618  	0.05365006  	0.04384465  	0.08289208  	0.09206887  
2023-06-01 17:18:23.631: Found a better model.
2023-06-01 17:18:23.631: Save model to file as pretrain.
2023-06-01 17:19:56.290: [iter 28 : loss : 3.8827 = 0.0504 + 3.8291 + 0.0032, time: 88.467693]
2023-06-01 17:20:00.528: epoch 28:	0.02446407  	0.05394183  	0.04401812  	0.08310067  	0.09234723  
2023-06-01 17:20:00.528: Found a better model.
2023-06-01 17:20:00.528: Save model to file as pretrain.
2023-06-01 17:21:33.503: [iter 29 : loss : 3.8815 = 0.0494 + 3.8288 + 0.0033, time: 89.192796]
2023-06-01 17:21:37.734: epoch 29:	0.02454932  	0.05418720  	0.04419742  	0.08339983  	0.09259911  
2023-06-01 17:21:37.734: Found a better model.
2023-06-01 17:21:37.734: Save model to file as pretrain.
2023-06-01 17:23:11.242: [iter 30 : loss : 3.8802 = 0.0484 + 3.8285 + 0.0034, time: 89.568498]
2023-06-01 17:23:15.190: epoch 30:	0.02454932  	0.05417476  	0.04432889  	0.08397951  	0.09312993  
2023-06-01 17:24:46.995: [iter 31 : loss : 3.8791 = 0.0475 + 3.8282 + 0.0034, time: 89.041440]
2023-06-01 17:24:50.942: epoch 31:	0.02465982  	0.05450151  	0.04452985  	0.08417399  	0.09340186  
2023-06-01 17:24:50.942: Found a better model.
2023-06-01 17:24:50.942: Save model to file as pretrain.
2023-06-01 17:26:22.949: [iter 32 : loss : 3.8781 = 0.0467 + 3.8279 + 0.0035, time: 88.117159]
2023-06-01 17:26:27.109: epoch 32:	0.02472615  	0.05466972  	0.04469806  	0.08458908  	0.09378108  
2023-06-01 17:26:27.109: Found a better model.
2023-06-01 17:26:27.109: Save model to file as pretrain.
2023-06-01 17:27:59.773: [iter 33 : loss : 3.8772 = 0.0460 + 3.8276 + 0.0036, time: 88.874631]
2023-06-01 17:28:03.982: epoch 33:	0.02470088  	0.05464718  	0.04469793  	0.08449660  	0.09370965  
2023-06-01 17:29:35.633: [iter 34 : loss : 3.8764 = 0.0453 + 3.8274 + 0.0037, time: 88.848642]
2023-06-01 17:29:39.614: epoch 34:	0.02481771  	0.05495166  	0.04491683  	0.08481961  	0.09408506  
2023-06-01 17:29:39.614: Found a better model.
2023-06-01 17:29:39.614: Save model to file as pretrain.
2023-06-01 17:31:12.691: [iter 35 : loss : 3.8753 = 0.0444 + 3.8272 + 0.0037, time: 88.971978]
2023-06-01 17:31:16.757: epoch 35:	0.02487612  	0.05511941  	0.04504936  	0.08508235  	0.09426866  
2023-06-01 17:31:16.757: Found a better model.
2023-06-01 17:31:16.758: Save model to file as pretrain.
2023-06-01 17:32:48.430: [iter 36 : loss : 3.8738 = 0.0430 + 3.8269 + 0.0038, time: 87.918814]
2023-06-01 17:32:52.344: epoch 36:	0.02498979  	0.05542667  	0.04520267  	0.08520073  	0.09445291  
2023-06-01 17:32:52.344: Found a better model.
2023-06-01 17:32:52.344: Save model to file as pretrain.
2023-06-01 17:34:25.886: [iter 37 : loss : 3.8735 = 0.0428 + 3.8268 + 0.0039, time: 89.711713]
2023-06-01 17:34:30.122: epoch 37:	0.02500715  	0.05545914  	0.04536316  	0.08564229  	0.09501424  
2023-06-01 17:34:30.122: Found a better model.
2023-06-01 17:34:30.122: Save model to file as pretrain.
2023-06-01 17:36:03.013: [iter 38 : loss : 3.8725 = 0.0420 + 3.8265 + 0.0039, time: 89.098829]
2023-06-01 17:36:07.510: epoch 38:	0.02499450  	0.05535183  	0.04541557  	0.08596768  	0.09546729  
2023-06-01 17:37:39.964: [iter 39 : loss : 3.8716 = 0.0413 + 3.8263 + 0.0040, time: 89.700133]
2023-06-01 17:37:43.981: epoch 39:	0.02513500  	0.05570596  	0.04565138  	0.08600093  	0.09570096  
2023-06-01 17:37:43.981: Found a better model.
2023-06-01 17:37:43.981: Save model to file as pretrain.
2023-06-01 17:39:17.520: [iter 40 : loss : 3.8709 = 0.0407 + 3.8261 + 0.0041, time: 89.490445]
2023-06-01 17:39:21.682: epoch 40:	0.02512395  	0.05570110  	0.04571382  	0.08637659  	0.09602264  
2023-06-01 17:40:54.242: [iter 41 : loss : 3.8704 = 0.0403 + 3.8260 + 0.0041, time: 89.802405]
2023-06-01 17:40:58.368: epoch 41:	0.02523760  	0.05590505  	0.04585315  	0.08638181  	0.09617659  
2023-06-01 17:40:58.368: Found a better model.
2023-06-01 17:40:58.368: Save model to file as pretrain.
2023-06-01 17:42:30.321: [iter 42 : loss : 3.8695 = 0.0395 + 3.8258 + 0.0042, time: 87.992111]
2023-06-01 17:42:34.294: epoch 42:	0.02529287  	0.05610749  	0.04601705  	0.08688137  	0.09660954  
2023-06-01 17:42:34.294: Found a better model.
2023-06-01 17:42:34.294: Save model to file as pretrain.
2023-06-01 17:44:08.431: [iter 43 : loss : 3.8687 = 0.0389 + 3.8256 + 0.0043, time: 90.239988]
2023-06-01 17:44:11.979: epoch 43:	0.02525496  	0.05606482  	0.04601127  	0.08697580  	0.09667252  
2023-06-01 17:45:43.242: [iter 44 : loss : 3.8686 = 0.0388 + 3.8254 + 0.0043, time: 88.503725]
2023-06-01 17:45:47.570: epoch 44:	0.02541126  	0.05642290  	0.04631671  	0.08747740  	0.09736582  
2023-06-01 17:45:47.571: Found a better model.
2023-06-01 17:45:47.571: Save model to file as pretrain.
2023-06-01 17:47:21.041: [iter 45 : loss : 3.8673 = 0.0376 + 3.8253 + 0.0044, time: 89.707050]
2023-06-01 17:47:24.498: epoch 45:	0.02538916  	0.05627725  	0.04629132  	0.08754019  	0.09743793  
2023-06-01 17:48:56.353: [iter 46 : loss : 3.8669 = 0.0373 + 3.8251 + 0.0044, time: 89.090344]
2023-06-01 17:49:00.258: epoch 46:	0.02548074  	0.05654991  	0.04640365  	0.08745319  	0.09735456  
2023-06-01 17:49:00.258: Found a better model.
2023-06-01 17:49:00.258: Save model to file as pretrain.
2023-06-01 17:50:31.095: [iter 47 : loss : 3.8663 = 0.0369 + 3.8250 + 0.0045, time: 87.112450]
2023-06-01 17:50:34.831: epoch 47:	0.02563704  	0.05701814  	0.04665986  	0.08765588  	0.09761632  
2023-06-01 17:50:34.831: Found a better model.
2023-06-01 17:50:34.831: Save model to file as pretrain.
2023-06-01 17:52:08.185: [iter 48 : loss : 3.8656 = 0.0362 + 3.8248 + 0.0046, time: 89.448136]
2023-06-01 17:52:12.366: epoch 48:	0.02573649  	0.05722189  	0.04680902  	0.08781798  	0.09777482  
2023-06-01 17:52:12.366: Found a better model.
2023-06-01 17:52:12.366: Save model to file as pretrain.
2023-06-01 17:53:43.931: [iter 49 : loss : 3.8651 = 0.0358 + 3.8247 + 0.0046, time: 87.553486]
2023-06-01 17:53:48.109: epoch 49:	0.02576332  	0.05738381  	0.04693486  	0.08795583  	0.09807993  
2023-06-01 17:53:48.110: Found a better model.
2023-06-01 17:53:48.110: Save model to file as pretrain.
2023-06-01 17:55:20.833: [iter 50 : loss : 3.8645 = 0.0353 + 3.8245 + 0.0047, time: 88.736976]
2023-06-01 17:55:24.824: epoch 50:	0.02576490  	0.05750981  	0.04703531  	0.08839179  	0.09851359  
2023-06-01 17:55:24.824: Found a better model.
2023-06-01 17:55:24.824: Save model to file as pretrain.
2023-06-01 17:56:56.580: [iter 51 : loss : 3.8637 = 0.0346 + 3.8244 + 0.0047, time: 87.967750]
2023-06-01 17:57:01.116: epoch 51:	0.02573808  	0.05739820  	0.04699044  	0.08843355  	0.09846626  
2023-06-01 17:58:34.134: [iter 52 : loss : 3.8635 = 0.0344 + 3.8243 + 0.0048, time: 90.236585]
2023-06-01 17:58:38.258: epoch 52:	0.02574123  	0.05742444  	0.04702879  	0.08861084  	0.09865631  
2023-06-01 18:00:10.154: [iter 53 : loss : 3.8632 = 0.0342 + 3.8242 + 0.0049, time: 89.069526]
2023-06-01 18:00:14.411: epoch 53:	0.02579648  	0.05755582  	0.04700885  	0.08817426  	0.09831129  
2023-06-01 18:00:14.412: Found a better model.
2023-06-01 18:00:14.412: Save model to file as pretrain.
2023-06-01 18:01:47.699: [iter 54 : loss : 3.8625 = 0.0336 + 3.8240 + 0.0049, time: 89.405883]
2023-06-01 18:01:51.882: epoch 54:	0.02577438  	0.05747773  	0.04703851  	0.08846842  	0.09856509  
2023-06-01 18:03:25.069: [iter 55 : loss : 3.8620 = 0.0332 + 3.8239 + 0.0050, time: 90.377353]
2023-06-01 18:03:29.346: epoch 55:	0.02593382  	0.05780465  	0.04723265  	0.08851278  	0.09878623  
2023-06-01 18:03:29.346: Found a better model.
2023-06-01 18:03:29.346: Save model to file as pretrain.
2023-06-01 18:05:03.108: [iter 56 : loss : 3.8614 = 0.0326 + 3.8238 + 0.0050, time: 89.880795]
2023-06-01 18:05:07.467: epoch 56:	0.02589122  	0.05763065  	0.04730576  	0.08913466  	0.09934748  
2023-06-01 18:06:39.254: [iter 57 : loss : 3.8611 = 0.0324 + 3.8237 + 0.0051, time: 89.007542]
2023-06-01 18:06:43.224: epoch 57:	0.02593384  	0.05767629  	0.04732078  	0.08887810  	0.09931137  
2023-06-01 18:08:16.190: [iter 58 : loss : 3.8604 = 0.0317 + 3.8235 + 0.0051, time: 90.185559]
2023-06-01 18:08:20.167: epoch 58:	0.02597173  	0.05781970  	0.04742819  	0.08925051  	0.09952374  
2023-06-01 18:08:20.167: Found a better model.
2023-06-01 18:08:20.167: Save model to file as pretrain.
2023-06-01 18:09:53.272: [iter 59 : loss : 3.8602 = 0.0315 + 3.8234 + 0.0052, time: 89.053275]
2023-06-01 18:09:57.220: epoch 59:	0.02606488  	0.05797501  	0.04754270  	0.08936582  	0.09952748  
2023-06-01 18:09:57.220: Found a better model.
2023-06-01 18:09:57.220: Save model to file as pretrain.
2023-06-01 18:11:32.975: [iter 60 : loss : 3.8596 = 0.0310 + 3.8233 + 0.0053, time: 91.804699]
2023-06-01 18:11:36.894: epoch 60:	0.02604436  	0.05804197  	0.04765606  	0.08979468  	0.09997576  
2023-06-01 18:11:36.895: Found a better model.
2023-06-01 18:11:36.895: Save model to file as pretrain.
2023-06-01 18:13:11.187: [iter 61 : loss : 3.8593 = 0.0308 + 3.8232 + 0.0053, time: 90.429625]
2023-06-01 18:13:15.325: epoch 61:	0.02608539  	0.05821094  	0.04769112  	0.08988918  	0.09995431  
2023-06-01 18:13:15.325: Found a better model.
2023-06-01 18:13:15.325: Save model to file as pretrain.
2023-06-01 18:14:48.178: [iter 62 : loss : 3.8589 = 0.0305 + 3.8231 + 0.0054, time: 88.963427]
2023-06-01 18:14:51.718: epoch 62:	0.02605222  	0.05812732  	0.04774921  	0.08999012  	0.10042150  
2023-06-01 18:16:24.966: [iter 63 : loss : 3.8588 = 0.0303 + 3.8230 + 0.0054, time: 90.428092]
2023-06-01 18:16:29.037: epoch 63:	0.02608697  	0.05821635  	0.04778631  	0.09007797  	0.10063134  
2023-06-01 18:16:29.038: Found a better model.
2023-06-01 18:16:29.038: Save model to file as pretrain.
2023-06-01 18:18:02.539: [iter 64 : loss : 3.8582 = 0.0298 + 3.8229 + 0.0055, time: 89.589376]
2023-06-01 18:18:06.877: epoch 64:	0.02612012  	0.05824059  	0.04785271  	0.09020493  	0.10075224  
2023-06-01 18:18:06.877: Found a better model.
2023-06-01 18:18:06.877: Save model to file as pretrain.
2023-06-01 18:19:40.533: [iter 65 : loss : 3.8581 = 0.0298 + 3.8228 + 0.0055, time: 89.688514]
2023-06-01 18:19:44.506: epoch 65:	0.02615325  	0.05842783  	0.04801390  	0.09057374  	0.10108720  
2023-06-01 18:19:44.506: Found a better model.
2023-06-01 18:19:44.508: Save model to file as pretrain.
2023-06-01 18:21:17.976: [iter 66 : loss : 3.8575 = 0.0292 + 3.8227 + 0.0056, time: 89.518753]
2023-06-01 18:21:22.303: epoch 66:	0.02616273  	0.05828590  	0.04798147  	0.09039581  	0.10112052  
2023-06-01 18:22:55.470: [iter 67 : loss : 3.8570 = 0.0288 + 3.8226 + 0.0056, time: 90.387023]
2023-06-01 18:22:59.400: epoch 67:	0.02616745  	0.05827865  	0.04794434  	0.09018866  	0.10094927  
2023-06-01 18:24:31.846: [iter 68 : loss : 3.8569 = 0.0287 + 3.8225 + 0.0057, time: 89.630900]
2023-06-01 18:24:35.985: epoch 68:	0.02623691  	0.05836447  	0.04802693  	0.09040255  	0.10106506  
2023-06-01 18:26:08.620: [iter 69 : loss : 3.8565 = 0.0283 + 3.8224 + 0.0057, time: 89.781765]
2023-06-01 18:26:12.732: epoch 69:	0.02628268  	0.05848836  	0.04813147  	0.09059754  	0.10142727  
2023-06-01 18:26:12.733: Found a better model.
2023-06-01 18:26:12.733: Save model to file as pretrain.
2023-06-01 18:27:46.248: [iter 70 : loss : 3.8557 = 0.0275 + 3.8224 + 0.0058, time: 89.663143]
2023-06-01 18:27:50.352: epoch 70:	0.02631268  	0.05857722  	0.04815219  	0.09078731  	0.10147484  
2023-06-01 18:27:50.352: Found a better model.
2023-06-01 18:27:50.352: Save model to file as pretrain.
2023-06-01 18:29:23.885: [iter 71 : loss : 3.8557 = 0.0275 + 3.8223 + 0.0058, time: 89.574811]
2023-06-01 18:29:28.323: epoch 71:	0.02639635  	0.05875575  	0.04826521  	0.09090013  	0.10163133  
2023-06-01 18:29:28.323: Found a better model.
2023-06-01 18:29:28.323: Save model to file as pretrain.
2023-06-01 18:31:01.125: [iter 72 : loss : 3.8555 = 0.0274 + 3.8222 + 0.0059, time: 89.006673]
2023-06-01 18:31:05.277: epoch 72:	0.02639475  	0.05883266  	0.04828118  	0.09094195  	0.10164062  
2023-06-01 18:31:05.277: Found a better model.
2023-06-01 18:31:05.277: Save model to file as pretrain.
2023-06-01 18:32:39.366: [iter 73 : loss : 3.8548 = 0.0268 + 3.8221 + 0.0059, time: 90.209523]
2023-06-01 18:32:43.494: epoch 73:	0.02637584  	0.05871985  	0.04824930  	0.09078901  	0.10150293  
2023-06-01 18:34:16.054: [iter 74 : loss : 3.8549 = 0.0269 + 3.8220 + 0.0060, time: 89.758030]
2023-06-01 18:34:20.176: epoch 74:	0.02648004  	0.05901458  	0.04839002  	0.09098086  	0.10167810  
2023-06-01 18:34:20.176: Found a better model.
2023-06-01 18:34:20.176: Save model to file as pretrain.
2023-06-01 18:35:54.550: [iter 75 : loss : 3.8548 = 0.0268 + 3.8220 + 0.0060, time: 90.495312]
2023-06-01 18:35:58.033: epoch 75:	0.02657477  	0.05911842  	0.04856593  	0.09130789  	0.10208844  
2023-06-01 18:35:58.033: Found a better model.
2023-06-01 18:35:58.033: Save model to file as pretrain.
2023-06-01 18:37:32.388: [iter 76 : loss : 3.8544 = 0.0265 + 3.8219 + 0.0061, time: 90.439980]
2023-06-01 18:37:36.451: epoch 76:	0.02661106  	0.05920803  	0.04861125  	0.09125429  	0.10211631  
2023-06-01 18:37:36.451: Found a better model.
2023-06-01 18:37:36.451: Save model to file as pretrain.
2023-06-01 18:39:10.986: [iter 77 : loss : 3.8539 = 0.0260 + 3.8218 + 0.0061, time: 90.656771]
2023-06-01 18:39:14.930: epoch 77:	0.02656371  	0.05909913  	0.04861089  	0.09164775  	0.10244174  
2023-06-01 18:40:46.724: [iter 78 : loss : 3.8534 = 0.0255 + 3.8217 + 0.0062, time: 88.976756]
2023-06-01 18:40:50.686: epoch 78:	0.02658422  	0.05917919  	0.04857923  	0.09143688  	0.10208764  
2023-06-01 18:42:23.260: [iter 79 : loss : 3.8535 = 0.0257 + 3.8216 + 0.0062, time: 89.780950]
2023-06-01 18:42:27.448: epoch 79:	0.02658579  	0.05920814  	0.04868193  	0.09166387  	0.10235480  
2023-06-01 18:42:27.448: Found a better model.
2023-06-01 18:42:27.448: Save model to file as pretrain.
2023-06-01 18:44:00.194: [iter 80 : loss : 3.8530 = 0.0252 + 3.8216 + 0.0063, time: 88.842966]
2023-06-01 18:44:04.644: epoch 80:	0.02663633  	0.05935472  	0.04876729  	0.09164218  	0.10248289  
2023-06-01 18:44:04.644: Found a better model.
2023-06-01 18:44:04.644: Save model to file as pretrain.
2023-06-01 18:45:37.817: [iter 81 : loss : 3.8528 = 0.0250 + 3.8215 + 0.0063, time: 89.263754]
2023-06-01 18:45:42.092: epoch 81:	0.02662843  	0.05930662  	0.04884169  	0.09193429  	0.10280640  
2023-06-01 18:47:14.504: [iter 82 : loss : 3.8527 = 0.0249 + 3.8214 + 0.0064, time: 89.605414]
2023-06-01 18:47:18.657: epoch 82:	0.02658422  	0.05930796  	0.04879700  	0.09204225  	0.10283819  
2023-06-01 18:48:50.551: [iter 83 : loss : 3.8523 = 0.0245 + 3.8214 + 0.0064, time: 89.098135]
2023-06-01 18:48:54.580: epoch 83:	0.02665211  	0.05930443  	0.04883586  	0.09212980  	0.10292269  
2023-06-01 18:50:27.097: [iter 84 : loss : 3.8523 = 0.0246 + 3.8213 + 0.0065, time: 89.715081]
2023-06-01 18:50:31.322: epoch 84:	0.02663790  	0.05921507  	0.04880364  	0.09192212  	0.10275818  
2023-06-01 18:52:03.956: [iter 85 : loss : 3.8520 = 0.0243 + 3.8212 + 0.0065, time: 89.825016]
2023-06-01 18:52:08.239: epoch 85:	0.02668841  	0.05951923  	0.04901997  	0.09257260  	0.10332058  
2023-06-01 18:52:08.240: Found a better model.
2023-06-01 18:52:08.240: Save model to file as pretrain.
2023-06-01 18:53:41.166: [iter 86 : loss : 3.8516 = 0.0239 + 3.8212 + 0.0065, time: 88.933843]
2023-06-01 18:53:45.444: epoch 86:	0.02666317  	0.05937857  	0.04895284  	0.09226990  	0.10314841  
2023-06-01 18:55:17.444: [iter 87 : loss : 3.8520 = 0.0243 + 3.8211 + 0.0066, time: 89.180585]
2023-06-01 18:55:21.443: epoch 87:	0.02663002  	0.05935023  	0.04895690  	0.09227454  	0.10329238  
2023-06-01 18:56:53.673: [iter 88 : loss : 3.8513 = 0.0236 + 3.8210 + 0.0066, time: 89.435588]
2023-06-01 18:56:57.721: epoch 88:	0.02669316  	0.05955151  	0.04896640  	0.09197083  	0.10302830  
2023-06-01 18:56:57.721: Found a better model.
2023-06-01 18:56:57.721: Save model to file as pretrain.
2023-06-01 18:58:31.538: [iter 89 : loss : 3.8511 = 0.0234 + 3.8210 + 0.0067, time: 89.799926]
2023-06-01 18:58:35.614: epoch 89:	0.02665842  	0.05951369  	0.04900283  	0.09215346  	0.10322458  
2023-06-01 19:00:08.697: [iter 90 : loss : 3.8509 = 0.0233 + 3.8209 + 0.0067, time: 90.252455]
2023-06-01 19:00:12.309: epoch 90:	0.02668050  	0.05949925  	0.04896196  	0.09223490  	0.10315585  
2023-06-01 19:01:44.106: [iter 91 : loss : 3.8508 = 0.0232 + 3.8209 + 0.0068, time: 89.025095]
2023-06-01 19:01:48.068: epoch 91:	0.02667577  	0.05946030  	0.04890695  	0.09186529  	0.10292956  
2023-06-01 19:03:21.111: [iter 92 : loss : 3.8504 = 0.0228 + 3.8208 + 0.0068, time: 90.245041]
2023-06-01 19:03:25.007: epoch 92:	0.02667262  	0.05951215  	0.04889401  	0.09182896  	0.10267957  
2023-06-01 19:04:57.408: [iter 93 : loss : 3.8503 = 0.0227 + 3.8207 + 0.0068, time: 89.613234]
2023-06-01 19:05:01.559: epoch 93:	0.02669473  	0.05954393  	0.04891600  	0.09188750  	0.10264031  
2023-06-01 19:06:34.437: [iter 94 : loss : 3.8500 = 0.0225 + 3.8207 + 0.0069, time: 90.091156]
2023-06-01 19:06:38.356: epoch 94:	0.02679103  	0.05970219  	0.04900762  	0.09179883  	0.10278693  
2023-06-01 19:06:38.356: Found a better model.
2023-06-01 19:06:38.356: Save model to file as pretrain.
2023-06-01 19:08:11.927: [iter 95 : loss : 3.8498 = 0.0222 + 3.8206 + 0.0069, time: 89.610869]
2023-06-01 19:08:15.980: epoch 95:	0.02668839  	0.05953823  	0.04890743  	0.09199297  	0.10277726  
2023-06-01 19:09:48.515: [iter 96 : loss : 3.8496 = 0.0221 + 3.8206 + 0.0070, time: 89.718453]
2023-06-01 19:09:52.542: epoch 96:	0.02675944  	0.05959177  	0.04895511  	0.09205542  	0.10296414  
2023-06-01 19:11:24.400: [iter 97 : loss : 3.8498 = 0.0223 + 3.8205 + 0.0070, time: 89.021053]
2023-06-01 19:11:28.595: epoch 97:	0.02691576  	0.05985017  	0.04913342  	0.09207119  	0.10304932  
2023-06-01 19:11:28.595: Found a better model.
2023-06-01 19:11:28.595: Save model to file as pretrain.
2023-06-01 19:13:02.126: [iter 98 : loss : 3.8494 = 0.0218 + 3.8205 + 0.0070, time: 89.618433]
2023-06-01 19:13:06.384: epoch 98:	0.02684786  	0.05963434  	0.04899869  	0.09201153  	0.10282850  
2023-06-01 19:14:38.819: [iter 99 : loss : 3.8490 = 0.0215 + 3.8204 + 0.0071, time: 89.648571]
2023-06-01 19:14:43.152: epoch 99:	0.02691101  	0.05975288  	0.04908425  	0.09214131  	0.10294435  
2023-06-01 19:16:14.940: [iter 100 : loss : 3.8490 = 0.0215 + 3.8204 + 0.0071, time: 88.952571]
2023-06-01 19:16:19.113: epoch 100:	0.02685259  	0.05977323  	0.04907823  	0.09212089  	0.10301581  
2023-06-01 19:17:51.785: [iter 101 : loss : 3.8488 = 0.0213 + 3.8203 + 0.0072, time: 89.813552]
2023-06-01 19:17:55.892: epoch 101:	0.02684152  	0.05966491  	0.04908407  	0.09235574  	0.10328470  
2023-06-01 19:19:27.624: [iter 102 : loss : 3.8487 = 0.0212 + 3.8203 + 0.0072, time: 88.918821]
2023-06-01 19:19:31.719: epoch 102:	0.02690944  	0.05994878  	0.04917075  	0.09237617  	0.10326440  
2023-06-01 19:19:31.719: Found a better model.
2023-06-01 19:19:31.719: Save model to file as pretrain.
2023-06-01 19:21:05.398: [iter 103 : loss : 3.8486 = 0.0211 + 3.8202 + 0.0072, time: 89.707471]
2023-06-01 19:21:09.495: epoch 103:	0.02687627  	0.05983998  	0.04907023  	0.09221797  	0.10296728  
2023-06-01 19:22:41.289: [iter 104 : loss : 3.8482 = 0.0207 + 3.8202 + 0.0073, time: 89.032094]
2023-06-01 19:22:45.347: epoch 104:	0.02688892  	0.05988405  	0.04907193  	0.09202685  	0.10283131  
2023-06-01 19:24:18.523: [iter 105 : loss : 3.8482 = 0.0207 + 3.8201 + 0.0073, time: 90.321506]
2023-06-01 19:24:21.939: epoch 105:	0.02685260  	0.05980087  	0.04902056  	0.09195401  	0.10270870  
2023-06-01 19:25:53.670: [iter 106 : loss : 3.8477 = 0.0202 + 3.8201 + 0.0074, time: 88.981816]
2023-06-01 19:25:57.847: epoch 106:	0.02686681  	0.05982238  	0.04901607  	0.09180979  	0.10246432  
2023-06-01 19:27:31.135: [iter 107 : loss : 3.8479 = 0.0205 + 3.8201 + 0.0074, time: 90.459446]
2023-06-01 19:27:35.578: epoch 107:	0.02692681  	0.05998681  	0.04914815  	0.09216126  	0.10289418  
2023-06-01 19:27:35.578: Found a better model.
2023-06-01 19:27:35.578: Save model to file as pretrain.
2023-06-01 19:29:08.446: [iter 108 : loss : 3.8476 = 0.0202 + 3.8200 + 0.0074, time: 88.949269]
2023-06-01 19:29:12.590: epoch 108:	0.02700256  	0.06022302  	0.04930077  	0.09237636  	0.10328852  
2023-06-01 19:29:12.590: Found a better model.
2023-06-01 19:29:12.590: Save model to file as pretrain.
2023-06-01 19:30:46.264: [iter 109 : loss : 3.8477 = 0.0203 + 3.8200 + 0.0075, time: 89.783550]
2023-06-01 19:30:50.241: epoch 109:	0.02699784  	0.06003363  	0.04932467  	0.09266432  	0.10355372  
2023-06-01 19:32:22.597: [iter 110 : loss : 3.8474 = 0.0199 + 3.8199 + 0.0075, time: 89.577330]
2023-06-01 19:32:26.795: epoch 110:	0.02700888  	0.06001211  	0.04922151  	0.09231769  	0.10324380  
2023-06-01 19:33:58.111: [iter 111 : loss : 3.8471 = 0.0197 + 3.8199 + 0.0075, time: 88.531727]
2023-06-01 19:34:02.503: epoch 111:	0.02702465  	0.06013064  	0.04928035  	0.09246892  	0.10320002  
2023-06-01 19:35:34.941: [iter 112 : loss : 3.8471 = 0.0198 + 3.8198 + 0.0076, time: 89.637023]
2023-06-01 19:35:39.004: epoch 112:	0.02695833  	0.05998133  	0.04922227  	0.09259885  	0.10325780  
2023-06-01 19:37:10.305: [iter 113 : loss : 3.8470 = 0.0196 + 3.8198 + 0.0076, time: 88.448524]
2023-06-01 19:37:14.497: epoch 113:	0.02699623  	0.06008038  	0.04924016  	0.09229623  	0.10311608  
2023-06-01 19:38:46.903: [iter 114 : loss : 3.8468 = 0.0194 + 3.8198 + 0.0077, time: 89.606196]
2023-06-01 19:38:51.092: epoch 114:	0.02688258  	0.05982031  	0.04916551  	0.09223684  	0.10310272  
2023-06-01 19:40:22.743: [iter 115 : loss : 3.8464 = 0.0190 + 3.8197 + 0.0077, time: 88.870469]
2023-06-01 19:40:26.758: epoch 115:	0.02688733  	0.05986327  	0.04919178  	0.09228045  	0.10324136  
2023-06-01 19:41:59.276: [iter 116 : loss : 3.8467 = 0.0193 + 3.8197 + 0.0077, time: 89.718850]
2023-06-01 19:42:03.548: epoch 116:	0.02687152  	0.05978360  	0.04916182  	0.09246921  	0.10322227  
2023-06-01 19:43:35.990: [iter 117 : loss : 3.8467 = 0.0193 + 3.8196 + 0.0078, time: 89.624227]
2023-06-01 19:43:39.966: epoch 117:	0.02689679  	0.05996783  	0.04921033  	0.09245381  	0.10329421  
2023-06-01 19:45:13.219: [iter 118 : loss : 3.8463 = 0.0190 + 3.8196 + 0.0078, time: 90.467029]
2023-06-01 19:45:16.735: epoch 118:	0.02684471  	0.05969625  	0.04911805  	0.09235358  	0.10334800  
2023-06-01 19:46:48.471: [iter 119 : loss : 3.8461 = 0.0187 + 3.8196 + 0.0078, time: 88.934377]
2023-06-01 19:46:52.639: epoch 119:	0.02683523  	0.05977290  	0.04915332  	0.09256466  	0.10342028  
2023-06-01 19:48:25.928: [iter 120 : loss : 3.8460 = 0.0186 + 3.8195 + 0.0079, time: 90.480769]
2023-06-01 19:48:28.922: epoch 120:	0.02687784  	0.05986491  	0.04920267  	0.09247234  	0.10348022  
2023-06-01 19:50:00.685: [iter 121 : loss : 3.8460 = 0.0186 + 3.8195 + 0.0079, time: 89.284661]
2023-06-01 19:50:04.887: epoch 121:	0.02689994  	0.05995930  	0.04917289  	0.09219519  	0.10308620  
2023-06-01 19:51:37.326: [iter 122 : loss : 3.8459 = 0.0186 + 3.8194 + 0.0079, time: 89.607993]
2023-06-01 19:51:41.143: epoch 122:	0.02689204  	0.05984523  	0.04920633  	0.09240514  	0.10348462  
2023-06-01 19:53:13.605: [iter 123 : loss : 3.8461 = 0.0187 + 3.8194 + 0.0079, time: 89.591259]
2023-06-01 19:53:17.537: epoch 123:	0.02683050  	0.05971806  	0.04916499  	0.09262587  	0.10361986  
2023-06-01 19:54:50.583: [iter 124 : loss : 3.8458 = 0.0184 + 3.8194 + 0.0080, time: 90.254670]
2023-06-01 19:54:54.398: epoch 124:	0.02688420  	0.05982834  	0.04918177  	0.09246720  	0.10345577  
2023-06-01 19:56:26.927: [iter 125 : loss : 3.8455 = 0.0181 + 3.8193 + 0.0080, time: 89.709918]
2023-06-01 19:56:30.952: epoch 125:	0.02696629  	0.05992139  	0.04927018  	0.09247930  	0.10358150  
2023-06-01 19:58:04.079: [iter 126 : loss : 3.8453 = 0.0180 + 3.8193 + 0.0080, time: 90.317222]
2023-06-01 19:58:08.311: epoch 126:	0.02698526  	0.05997040  	0.04935111  	0.09284944  	0.10395049  
2023-06-01 19:59:39.620: [iter 127 : loss : 3.8455 = 0.0181 + 3.8193 + 0.0081, time: 88.503989]
2023-06-01 19:59:43.756: epoch 127:	0.02703259  	0.06017886  	0.04943491  	0.09284835  	0.10395011  
2023-06-01 20:01:16.864: [iter 128 : loss : 3.8453 = 0.0180 + 3.8192 + 0.0081, time: 90.274319]
2023-06-01 20:01:21.034: epoch 128:	0.02699945  	0.06011056  	0.04946144  	0.09326397  	0.10432141  
2023-06-01 20:02:52.496: [iter 129 : loss : 3.8451 = 0.0178 + 3.8192 + 0.0081, time: 88.635727]
2023-06-01 20:02:56.729: epoch 129:	0.02701838  	0.06008041  	0.04951587  	0.09341397  	0.10460391  
2023-06-01 20:04:28.503: [iter 130 : loss : 3.8451 = 0.0178 + 3.8192 + 0.0082, time: 88.942929]
2023-06-01 20:04:32.661: epoch 130:	0.02701679  	0.06014276  	0.04948892  	0.09338918  	0.10440286  
2023-06-01 20:06:03.958: [iter 131 : loss : 3.8447 = 0.0174 + 3.8192 + 0.0082, time: 88.458117]
2023-06-01 20:06:08.141: epoch 131:	0.02694101  	0.05996527  	0.04940071  	0.09320033  	0.10436919  
2023-06-01 20:07:38.869: [iter 132 : loss : 3.8447 = 0.0174 + 3.8191 + 0.0082, time: 87.918033]
2023-06-01 20:07:43.179: epoch 132:	0.02698048  	0.06008491  	0.04947739  	0.09338184  	0.10450280  
2023-06-01 20:09:14.786: [iter 133 : loss : 3.8447 = 0.0174 + 3.8191 + 0.0083, time: 88.771397]
2023-06-01 20:09:18.918: epoch 133:	0.02704047  	0.06015429  	0.04948324  	0.09314219  	0.10424975  
2023-06-01 20:10:51.788: [iter 134 : loss : 3.8445 = 0.0171 + 3.8191 + 0.0083, time: 89.990613]
2023-06-01 20:10:55.611: epoch 134:	0.02698523  	0.06007746  	0.04941132  	0.09273307  	0.10404929  
2023-06-01 20:12:26.677: [iter 135 : loss : 3.8445 = 0.0172 + 3.8190 + 0.0083, time: 88.255353]
2023-06-01 20:12:30.169: epoch 135:	0.02704835  	0.06017902  	0.04946551  	0.09272844  	0.10405257  
2023-06-01 20:14:02.088: [iter 136 : loss : 3.8445 = 0.0171 + 3.8190 + 0.0083, time: 89.092901]
2023-06-01 20:14:06.375: epoch 136:	0.02706099  	0.06017476  	0.04948415  	0.09285017  	0.10405673  
2023-06-01 20:15:37.665: [iter 137 : loss : 3.8444 = 0.0171 + 3.8190 + 0.0084, time: 88.470774]
2023-06-01 20:15:41.381: epoch 137:	0.02714940  	0.06037657  	0.04961482  	0.09301939  	0.10424575  
2023-06-01 20:15:41.381: Found a better model.
2023-06-01 20:15:41.381: Save model to file as pretrain.
2023-06-01 20:17:15.144: [iter 138 : loss : 3.8442 = 0.0169 + 3.8189 + 0.0084, time: 89.769782]
2023-06-01 20:17:19.607: epoch 138:	0.02712256  	0.06037832  	0.04953087  	0.09284515  	0.10393277  
2023-06-01 20:17:19.608: Found a better model.
2023-06-01 20:17:19.608: Save model to file as pretrain.
