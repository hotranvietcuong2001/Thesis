2023-05-22 20:40:22.755: Dataset name: yelp2018
The number of users: 31668
The number of items: 38048
The number of ratings: 1561406
Average actions of users: 49.31
Average actions of items: 41.04
The sparsity of the dataset: 99.870412%
2023-05-22 20:40:22.755: 

NeuRec hyperparameters:
recommender=SGL
config_dir=./conf
gpu_id=1
gpu_mem=0.5
data.input.path=dataset
data.input.dataset=yelp2018
data.column.format=UI
data.convert.separator=','
user_min=0
item_min=0
splitter=given
ratio=0.8
by_time=False
metric=["Precision", "Recall", "NDCG", "MAP", "MRR"]
topk=[20]
group_view=None
rec.evaluate.neg=0
test_batch_size=128
num_thread=8
start_testing_epoch=0
proj_path=./

SGL's hyperparameters:
seed=2021
aug_type=1
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.1
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
init_method=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=50
pretrain=1
save_flag=1

2023-05-22 20:40:26.452: metrics:	Precision@20	Recall@20   	NDCG@20     	MAP@20      	MRR@20      
2023-05-22 20:40:33.489: 		0.02221291  	0.04850223  	0.03919857  	0.07377946  	0.08156340  
2023-05-22 20:41:35.573: [iter 1 : loss : 0.0681 = 0.0660 + 0.0000 + 0.0021, time: 59.237137]
2023-05-22 20:41:41.475: epoch 1:	0.02247181  	0.04933302  	0.03978591  	0.07479808  	0.08269763  
2023-05-22 20:41:41.476: Found a better model.
2023-05-22 20:41:41.476: Save model to file as pretrain.
2023-05-22 20:42:46.115: [iter 2 : loss : 0.0643 = 0.0621 + 0.0000 + 0.0022, time: 60.420147]
2023-05-22 20:42:52.682: epoch 2:	0.02266598  	0.04980717  	0.04029205  	0.07600380  	0.08411473  
2023-05-22 20:42:52.682: Found a better model.
2023-05-22 20:42:52.682: Save model to file as pretrain.
2023-05-22 20:43:55.078: [iter 3 : loss : 0.0618 = 0.0595 + 0.0000 + 0.0023, time: 58.284006]
2023-05-22 20:44:02.421: epoch 3:	0.02284595  	0.05028557  	0.04067074  	0.07660685  	0.08489554  
2023-05-22 20:44:02.422: Found a better model.
2023-05-22 20:44:02.422: Save model to file as pretrain.
2023-05-22 20:45:05.372: [iter 4 : loss : 0.0597 = 0.0573 + 0.0000 + 0.0024, time: 58.595100]
2023-05-22 20:45:11.188: epoch 4:	0.02299118  	0.05061644  	0.04091437  	0.07714238  	0.08529946  
2023-05-22 20:45:11.188: Found a better model.
2023-05-22 20:45:11.188: Save model to file as pretrain.
2023-05-22 20:46:14.163: [iter 5 : loss : 0.0571 = 0.0547 + 0.0000 + 0.0025, time: 58.768452]
2023-05-22 20:46:20.582: epoch 5:	0.02314588  	0.05108327  	0.04125249  	0.07748263  	0.08582763  
2023-05-22 20:46:20.582: Found a better model.
2023-05-22 20:46:20.583: Save model to file as pretrain.
2023-05-22 20:47:21.853: [iter 6 : loss : 0.0644 = 0.0618 + 0.0000 + 0.0025, time: 56.983235]
2023-05-22 20:47:29.235: epoch 6:	0.02344897  	0.05189711  	0.04183360  	0.07839774  	0.08693056  
2023-05-22 20:47:29.235: Found a better model.
2023-05-22 20:47:29.235: Save model to file as pretrain.
2023-05-22 20:48:31.645: [iter 7 : loss : 0.0624 = 0.0598 + 0.0000 + 0.0026, time: 58.368358]
2023-05-22 20:48:38.180: epoch 7:	0.02368262  	0.05248115  	0.04232038  	0.07926366  	0.08782743  
2023-05-22 20:48:38.180: Found a better model.
2023-05-22 20:48:38.180: Save model to file as pretrain.
2023-05-22 20:49:39.212: [iter 8 : loss : 0.0607 = 0.0580 + 0.0000 + 0.0027, time: 56.869021]
2023-05-22 20:49:45.970: epoch 8:	0.02390839  	0.05295541  	0.04270707  	0.07990840  	0.08851967  
2023-05-22 20:49:45.970: Found a better model.
2023-05-22 20:49:45.970: Save model to file as pretrain.
2023-05-22 20:50:48.670: [iter 9 : loss : 0.0590 = 0.0563 + 0.0000 + 0.0027, time: 58.535913]
2023-05-22 20:50:55.794: epoch 9:	0.02413886  	0.05344411  	0.04305273  	0.08051145  	0.08898384  
2023-05-22 20:50:55.794: Found a better model.
2023-05-22 20:50:55.794: Save model to file as pretrain.
2023-05-22 20:51:58.205: [iter 10 : loss : 0.0580 = 0.0552 + 0.0000 + 0.0028, time: 58.285610]
2023-05-22 20:52:05.173: epoch 10:	0.02421149  	0.05372514  	0.04328123  	0.08089580  	0.08954129  
2023-05-22 20:52:05.173: Found a better model.
2023-05-22 20:52:05.173: Save model to file as pretrain.
2023-05-22 20:53:07.064: [iter 11 : loss : 0.0562 = 0.0534 + 0.0000 + 0.0028, time: 57.621634]
2023-05-22 20:53:12.353: epoch 11:	0.02439302  	0.05413289  	0.04356499  	0.08116341  	0.09004236  
2023-05-22 20:53:12.353: Found a better model.
2023-05-22 20:53:12.353: Save model to file as pretrain.
2023-05-22 20:54:14.423: [iter 12 : loss : 0.0550 = 0.0521 + 0.0000 + 0.0029, time: 57.942132]
2023-05-22 20:54:21.490: epoch 12:	0.02449089  	0.05431098  	0.04383679  	0.08183142  	0.09068916  
2023-05-22 20:54:21.490: Found a better model.
2023-05-22 20:54:21.490: Save model to file as pretrain.
2023-05-22 20:55:23.848: [iter 13 : loss : 0.0543 = 0.0513 + 0.0000 + 0.0030, time: 58.270604]
2023-05-22 20:55:31.451: epoch 13:	0.02468667  	0.05478289  	0.04425365  	0.08271308  	0.09167301  
2023-05-22 20:55:31.451: Found a better model.
2023-05-22 20:55:31.451: Save model to file as pretrain.
2023-05-22 20:56:46.339: [iter 14 : loss : 0.0533 = 0.0502 + 0.0000 + 0.0030, time: 70.569739]
2023-05-22 20:56:54.370: epoch 14:	0.02470720  	0.05491028  	0.04439772  	0.08300292  	0.09191710  
2023-05-22 20:56:54.370: Found a better model.
2023-05-22 20:56:54.370: Save model to file as pretrain.
2023-05-22 20:57:56.980: [iter 15 : loss : 0.0521 = 0.0490 + 0.0000 + 0.0031, time: 58.174116]
2023-05-22 20:58:04.307: epoch 15:	0.02489663  	0.05536430  	0.04479215  	0.08364560  	0.09281311  
2023-05-22 20:58:04.307: Found a better model.
2023-05-22 20:58:04.307: Save model to file as pretrain.
2023-05-22 20:59:06.619: [iter 16 : loss : 0.0506 = 0.0474 + 0.0000 + 0.0032, time: 58.160228]
2023-05-22 20:59:13.544: epoch 16:	0.02501186  	0.05559323  	0.04499909  	0.08404595  	0.09309272  
2023-05-22 20:59:13.544: Found a better model.
2023-05-22 20:59:13.544: Save model to file as pretrain.
2023-05-22 21:00:14.965: [iter 17 : loss : 0.0503 = 0.0471 + 0.0000 + 0.0032, time: 57.157637]
2023-05-22 21:00:21.870: epoch 17:	0.02507658  	0.05566977  	0.04513986  	0.08439277  	0.09340601  
2023-05-22 21:00:21.871: Found a better model.
2023-05-22 21:00:21.871: Save model to file as pretrain.
2023-05-22 21:01:23.006: [iter 18 : loss : 0.0491 = 0.0458 + 0.0000 + 0.0033, time: 56.906564]
2023-05-22 21:01:30.061: epoch 18:	0.02522500  	0.05600297  	0.04544117  	0.08480131  	0.09410352  
2023-05-22 21:01:30.061: Found a better model.
2023-05-22 21:01:30.061: Save model to file as pretrain.
2023-05-22 21:02:33.033: [iter 19 : loss : 0.0489 = 0.0455 + 0.0000 + 0.0033, time: 58.887858]
2023-05-22 21:02:39.861: epoch 19:	0.02532288  	0.05628921  	0.04562252  	0.08512525  	0.09431362  
2023-05-22 21:02:39.861: Found a better model.
2023-05-22 21:02:39.861: Save model to file as pretrain.
2023-05-22 21:03:41.816: [iter 20 : loss : 0.0479 = 0.0445 + 0.0000 + 0.0034, time: 57.726883]
2023-05-22 21:03:48.789: epoch 20:	0.02552181  	0.05679680  	0.04593111  	0.08535072  	0.09461708  
2023-05-22 21:03:48.789: Found a better model.
2023-05-22 21:03:48.789: Save model to file as pretrain.
2023-05-22 21:04:51.804: [iter 21 : loss : 0.0470 = 0.0436 + 0.0000 + 0.0035, time: 58.844534]
2023-05-22 21:04:59.048: epoch 21:	0.02568126  	0.05720164  	0.04619934  	0.08559950  	0.09503436  
2023-05-22 21:04:59.048: Found a better model.
2023-05-22 21:04:59.048: Save model to file as pretrain.
2023-05-22 21:06:00.642: [iter 22 : loss : 0.0459 = 0.0424 + 0.0000 + 0.0035, time: 57.504467]
2023-05-22 21:06:07.904: epoch 22:	0.02567494  	0.05721440  	0.04620014  	0.08566490  	0.09491301  
2023-05-22 21:06:07.904: Found a better model.
2023-05-22 21:06:07.904: Save model to file as pretrain.
2023-05-22 21:07:10.581: [iter 23 : loss : 0.0455 = 0.0419 + 0.0000 + 0.0036, time: 58.495157]
2023-05-22 21:07:17.186: epoch 23:	0.02567177  	0.05728472  	0.04633848  	0.08614946  	0.09540693  
2023-05-22 21:07:17.186: Found a better model.
2023-05-22 21:07:17.186: Save model to file as pretrain.
2023-05-22 21:08:19.751: [iter 24 : loss : 0.0451 = 0.0415 + 0.0000 + 0.0036, time: 58.340679]
2023-05-22 21:08:25.829: epoch 24:	0.02576647  	0.05753189  	0.04647096  	0.08634482  	0.09551849  
2023-05-22 21:08:25.830: Found a better model.
2023-05-22 21:08:25.830: Save model to file as pretrain.
2023-05-22 21:09:29.091: [iter 25 : loss : 0.0444 = 0.0407 + 0.0000 + 0.0037, time: 58.880321]
2023-05-22 21:09:36.022: epoch 25:	0.02590382  	0.05784943  	0.04677093  	0.08676694  	0.09615187  
2023-05-22 21:09:36.023: Found a better model.
2023-05-22 21:09:36.023: Save model to file as pretrain.
2023-05-22 21:10:38.054: [iter 26 : loss : 0.0434 = 0.0397 + 0.0000 + 0.0038, time: 57.774218]
2023-05-22 21:10:45.011: epoch 26:	0.02596065  	0.05800769  	0.04688811  	0.08690859  	0.09636642  
2023-05-22 21:10:45.011: Found a better model.
2023-05-22 21:10:45.012: Save model to file as pretrain.
2023-05-22 21:11:48.061: [iter 27 : loss : 0.0427 = 0.0389 + 0.0000 + 0.0038, time: 58.962231]
2023-05-22 21:11:53.880: epoch 27:	0.02611218  	0.05841855  	0.04703418  	0.08675484  	0.09617085  
2023-05-22 21:11:53.880: Found a better model.
2023-05-22 21:11:53.880: Save model to file as pretrain.
2023-05-22 21:12:55.722: [iter 28 : loss : 0.0425 = 0.0387 + 0.0000 + 0.0039, time: 57.579747]
2023-05-22 21:13:02.406: epoch 28:	0.02614219  	0.05845693  	0.04722929  	0.08724247  	0.09694534  
2023-05-22 21:13:02.406: Found a better model.
2023-05-22 21:13:02.406: Save model to file as pretrain.
2023-05-22 21:14:05.165: [iter 29 : loss : 0.0421 = 0.0382 + 0.0000 + 0.0039, time: 58.354606]
2023-05-22 21:14:12.452: epoch 29:	0.02622113  	0.05876152  	0.04743361  	0.08762142  	0.09734067  
2023-05-22 21:14:12.453: Found a better model.
2023-05-22 21:14:12.453: Save model to file as pretrain.
2023-05-22 21:15:14.260: [iter 30 : loss : 0.0415 = 0.0375 + 0.0000 + 0.0040, time: 57.693148]
2023-05-22 21:15:21.384: epoch 30:	0.02628269  	0.05889092  	0.04760803  	0.08814354  	0.09783405  
2023-05-22 21:15:21.384: Found a better model.
2023-05-22 21:15:21.384: Save model to file as pretrain.
2023-05-22 21:16:23.698: [iter 31 : loss : 0.0410 = 0.0370 + 0.0000 + 0.0040, time: 58.174444]
2023-05-22 21:16:30.382: epoch 31:	0.02632060  	0.05888949  	0.04770617  	0.08840428  	0.09808248  
2023-05-22 21:17:30.241: [iter 32 : loss : 0.0406 = 0.0365 + 0.0000 + 0.0041, time: 57.094211]
2023-05-22 21:17:37.307: epoch 32:	0.02636480  	0.05892471  	0.04783691  	0.08890751  	0.09859794  
2023-05-22 21:17:37.307: Found a better model.
2023-05-22 21:17:37.307: Save model to file as pretrain.
2023-05-22 21:18:40.500: [iter 33 : loss : 0.0402 = 0.0361 + 0.0000 + 0.0041, time: 59.027132]
2023-05-22 21:18:47.547: epoch 33:	0.02652426  	0.05933452  	0.04804698  	0.08904538  	0.09873186  
2023-05-22 21:18:47.548: Found a better model.
2023-05-22 21:18:47.548: Save model to file as pretrain.
2023-05-22 21:19:49.486: [iter 34 : loss : 0.0399 = 0.0357 + 0.0000 + 0.0042, time: 57.671590]
2023-05-22 21:19:56.271: epoch 34:	0.02650689  	0.05930952  	0.04808392  	0.08925728  	0.09893380  
2023-05-22 21:20:57.239: [iter 35 : loss : 0.0391 = 0.0349 + 0.0000 + 0.0042, time: 58.247401]
2023-05-22 21:21:04.102: epoch 35:	0.02659844  	0.05957615  	0.04830061  	0.08960836  	0.09933717  
2023-05-22 21:21:04.103: Found a better model.
2023-05-22 21:21:04.103: Save model to file as pretrain.
2023-05-22 21:22:05.826: [iter 36 : loss : 0.0383 = 0.0340 + 0.0000 + 0.0043, time: 57.653526]
2023-05-22 21:22:13.084: epoch 36:	0.02661898  	0.05962841  	0.04830419  	0.08939241  	0.09931905  
2023-05-22 21:22:13.084: Found a better model.
2023-05-22 21:22:13.084: Save model to file as pretrain.
2023-05-22 21:23:14.848: [iter 37 : loss : 0.0384 = 0.0340 + 0.0000 + 0.0043, time: 57.637906]
2023-05-22 21:23:21.941: epoch 37:	0.02672948  	0.05993493  	0.04858043  	0.08990124  	0.09995867  
2023-05-22 21:23:21.941: Found a better model.
2023-05-22 21:23:21.941: Save model to file as pretrain.
2023-05-22 21:24:24.221: [iter 38 : loss : 0.0380 = 0.0336 + 0.0000 + 0.0044, time: 58.120103]
2023-05-22 21:24:30.847: epoch 38:	0.02675316  	0.06000698  	0.04867974  	0.09028635  	0.10039081  
2023-05-22 21:24:30.848: Found a better model.
2023-05-22 21:24:30.848: Save model to file as pretrain.
2023-05-22 21:25:34.049: [iter 39 : loss : 0.0374 = 0.0330 + 0.0000 + 0.0044, time: 58.966562]
2023-05-22 21:25:40.916: epoch 39:	0.02683841  	0.06007649  	0.04878199  	0.09049042  	0.10056224  
2023-05-22 21:25:40.916: Found a better model.
2023-05-22 21:25:40.916: Save model to file as pretrain.
2023-05-22 21:26:43.197: [iter 40 : loss : 0.0370 = 0.0325 + 0.0000 + 0.0045, time: 58.325682]
2023-05-22 21:26:49.845: epoch 40:	0.02691101  	0.06033028  	0.04892933  	0.09081107  	0.10092201  
2023-05-22 21:26:49.845: Found a better model.
2023-05-22 21:26:49.845: Save model to file as pretrain.
2023-05-22 21:27:52.776: [iter 41 : loss : 0.0370 = 0.0325 + 0.0000 + 0.0045, time: 58.843713]
2023-05-22 21:27:59.585: epoch 41:	0.02695680  	0.06041448  	0.04902106  	0.09086529  	0.10116952  
2023-05-22 21:27:59.585: Found a better model.
2023-05-22 21:27:59.585: Save model to file as pretrain.
2023-05-22 21:29:01.504: [iter 42 : loss : 0.0363 = 0.0317 + 0.0000 + 0.0046, time: 57.710990]
2023-05-22 21:29:08.668: epoch 42:	0.02699151  	0.06055262  	0.04908964  	0.09090651  	0.10110958  
2023-05-22 21:29:08.668: Found a better model.
2023-05-22 21:29:08.668: Save model to file as pretrain.
2023-05-22 21:30:11.195: [iter 43 : loss : 0.0360 = 0.0314 + 0.0000 + 0.0046, time: 58.332922]
2023-05-22 21:30:18.368: epoch 43:	0.02709885  	0.06082707  	0.04931583  	0.09133715  	0.10179868  
2023-05-22 21:30:18.368: Found a better model.
2023-05-22 21:30:18.368: Save model to file as pretrain.
2023-05-22 21:31:19.293: [iter 44 : loss : 0.0361 = 0.0314 + 0.0000 + 0.0047, time: 56.818976]
2023-05-22 21:31:26.755: epoch 44:	0.02714622  	0.06098608  	0.04950738  	0.09180512  	0.10216922  
2023-05-22 21:31:26.755: Found a better model.
2023-05-22 21:31:26.755: Save model to file as pretrain.
2023-05-22 21:32:30.096: [iter 45 : loss : 0.0351 = 0.0303 + 0.0000 + 0.0047, time: 58.976823]
2023-05-22 21:32:37.153: epoch 45:	0.02721884  	0.06107707  	0.04961682  	0.09182858  	0.10237002  
2023-05-22 21:32:37.153: Found a better model.
2023-05-22 21:32:37.153: Save model to file as pretrain.
2023-05-22 21:33:39.687: [iter 46 : loss : 0.0350 = 0.0302 + 0.0000 + 0.0048, time: 58.268104]
2023-05-22 21:33:45.564: epoch 46:	0.02734514  	0.06131849  	0.04974607  	0.09177402  	0.10229599  
2023-05-22 21:33:45.565: Found a better model.
2023-05-22 21:33:45.565: Save model to file as pretrain.
2023-05-22 21:34:47.318: [iter 47 : loss : 0.0347 = 0.0299 + 0.0000 + 0.0048, time: 57.569001]
2023-05-22 21:34:54.385: epoch 47:	0.02728674  	0.06124583  	0.04970811  	0.09198821  	0.10229033  
2023-05-22 21:35:55.448: [iter 48 : loss : 0.0343 = 0.0294 + 0.0000 + 0.0049, time: 58.297450]
2023-05-22 21:36:02.537: epoch 48:	0.02740514  	0.06155809  	0.04986075  	0.09205072  	0.10240904  
2023-05-22 21:36:02.537: Found a better model.
2023-05-22 21:36:02.537: Save model to file as pretrain.
2023-05-22 21:37:04.965: [iter 49 : loss : 0.0341 = 0.0291 + 0.0000 + 0.0049, time: 58.362113]
2023-05-22 21:37:10.850: epoch 49:	0.02740829  	0.06170451  	0.04990319  	0.09210596  	0.10227443  
2023-05-22 21:37:10.851: Found a better model.
2023-05-22 21:37:10.851: Save model to file as pretrain.
2023-05-22 21:38:13.176: [iter 50 : loss : 0.0338 = 0.0289 + 0.0000 + 0.0050, time: 58.088036]
2023-05-22 21:38:20.173: epoch 50:	0.02747616  	0.06188785  	0.05003241  	0.09208298  	0.10249991  
2023-05-22 21:38:20.173: Found a better model.
2023-05-22 21:38:20.173: Save model to file as pretrain.
2023-05-22 21:39:22.627: [iter 51 : loss : 0.0332 = 0.0282 + 0.0000 + 0.0050, time: 58.291236]
2023-05-22 21:39:29.563: epoch 51:	0.02747776  	0.06178657  	0.04998889  	0.09217754  	0.10237259  
2023-05-22 21:40:30.102: [iter 52 : loss : 0.0332 = 0.0281 + 0.0000 + 0.0051, time: 57.754814]
2023-05-22 21:40:37.190: epoch 52:	0.02749196  	0.06179356  	0.05002553  	0.09227435  	0.10265478  
2023-05-22 21:41:38.864: [iter 53 : loss : 0.0330 = 0.0279 + 0.0000 + 0.0051, time: 58.986781]
2023-05-22 21:41:45.850: epoch 53:	0.02756615  	0.06200773  	0.05014069  	0.09229763  	0.10267592  
2023-05-22 21:41:45.850: Found a better model.
2023-05-22 21:41:45.850: Save model to file as pretrain.
2023-05-22 21:42:47.550: [iter 54 : loss : 0.0328 = 0.0277 + 0.0000 + 0.0051, time: 57.570914]
2023-05-22 21:42:54.888: epoch 54:	0.02751248  	0.06182586  	0.05019971  	0.09265248  	0.10331894  
2023-05-22 21:43:56.561: [iter 55 : loss : 0.0323 = 0.0272 + 0.0000 + 0.0052, time: 58.942479]
2023-05-22 21:44:03.323: epoch 55:	0.02751719  	0.06185247  	0.05018755  	0.09260124  	0.10313904  
2023-05-22 21:45:03.673: [iter 56 : loss : 0.0321 = 0.0269 + 0.0000 + 0.0052, time: 57.568607]
2023-05-22 21:45:10.690: epoch 56:	0.02750775  	0.06187866  	0.05026240  	0.09287086  	0.10353897  
2023-05-22 21:46:11.587: [iter 57 : loss : 0.0319 = 0.0266 + 0.0000 + 0.0053, time: 58.156765]
2023-05-22 21:46:18.564: epoch 57:	0.02761508  	0.06209364  	0.05030798  	0.09261914  	0.10323437  
2023-05-22 21:46:18.564: Found a better model.
2023-05-22 21:46:18.564: Save model to file as pretrain.
2023-05-22 21:47:20.295: [iter 58 : loss : 0.0314 = 0.0261 + 0.0000 + 0.0053, time: 57.699201]
2023-05-22 21:47:27.361: epoch 58:	0.02763245  	0.06206195  	0.05038847  	0.09297676  	0.10368376  
2023-05-22 21:48:28.037: [iter 59 : loss : 0.0314 = 0.0260 + 0.0000 + 0.0054, time: 57.955673]
2023-05-22 21:48:33.400: epoch 59:	0.02765139  	0.06207713  	0.05037153  	0.09276265  	0.10343641  
2023-05-22 21:49:32.635: [iter 60 : loss : 0.0310 = 0.0256 + 0.0000 + 0.0054, time: 56.650469]
2023-05-22 21:49:39.391: epoch 60:	0.02768139  	0.06221141  	0.05056351  	0.09339518  	0.10429753  
2023-05-22 21:49:39.391: Found a better model.
2023-05-22 21:49:39.391: Save model to file as pretrain.
2023-05-22 21:50:41.983: [iter 61 : loss : 0.0309 = 0.0254 + 0.0000 + 0.0054, time: 58.942837]
2023-05-22 21:50:48.918: epoch 61:	0.02765770  	0.06207542  	0.05054684  	0.09358785  	0.10445771  
2023-05-22 21:51:48.701: [iter 62 : loss : 0.0308 = 0.0253 + 0.0000 + 0.0055, time: 57.070189]
2023-05-22 21:51:55.666: epoch 62:	0.02770030  	0.06224519  	0.05062524  	0.09351975  	0.10441227  
2023-05-22 21:51:55.666: Found a better model.
2023-05-22 21:51:55.666: Save model to file as pretrain.
2023-05-22 21:52:56.580: [iter 63 : loss : 0.0307 = 0.0252 + 0.0000 + 0.0055, time: 57.750010]
2023-05-22 21:53:03.869: epoch 63:	0.02784873  	0.06252247  	0.05081458  	0.09375672  	0.10471186  
2023-05-22 21:53:03.870: Found a better model.
2023-05-22 21:53:03.870: Save model to file as pretrain.
2023-05-22 21:54:05.985: [iter 64 : loss : 0.0302 = 0.0247 + 0.0000 + 0.0056, time: 58.924952]
2023-05-22 21:54:13.227: epoch 64:	0.02790871  	0.06273932  	0.05095239  	0.09382767  	0.10506391  
2023-05-22 21:54:13.227: Found a better model.
2023-05-22 21:54:13.227: Save model to file as pretrain.
2023-05-22 21:55:14.156: [iter 65 : loss : 0.0304 = 0.0248 + 0.0000 + 0.0056, time: 57.686359]
2023-05-22 21:55:21.206: epoch 65:	0.02805079  	0.06298100  	0.05110353  	0.09395747  	0.10517495  
2023-05-22 21:55:21.206: Found a better model.
2023-05-22 21:55:21.206: Save model to file as pretrain.
2023-05-22 21:56:21.123: [iter 66 : loss : 0.0299 = 0.0243 + 0.0000 + 0.0056, time: 56.711850]
2023-05-22 21:56:26.560: epoch 66:	0.02806501  	0.06300398  	0.05111814  	0.09374250  	0.10514236  
2023-05-22 21:56:26.560: Found a better model.
2023-05-22 21:56:26.560: Save model to file as pretrain.
2023-05-22 21:57:26.644: [iter 67 : loss : 0.0295 = 0.0238 + 0.0000 + 0.0057, time: 56.996144]
2023-05-22 21:57:33.527: epoch 67:	0.02801607  	0.06285535  	0.05104094  	0.09386872  	0.10500304  
2023-05-22 21:58:33.222: [iter 68 : loss : 0.0296 = 0.0239 + 0.0000 + 0.0057, time: 56.990560]
2023-05-22 21:58:40.329: epoch 68:	0.02802399  	0.06276128  	0.05107144  	0.09397937  	0.10521421  
2023-05-22 21:59:41.911: [iter 69 : loss : 0.0293 = 0.0235 + 0.0000 + 0.0058, time: 58.769097]
2023-05-22 21:59:48.658: epoch 69:	0.02798925  	0.06283227  	0.05113360  	0.09420545  	0.10553230  
2023-05-22 22:00:48.992: [iter 70 : loss : 0.0288 = 0.0230 + 0.0000 + 0.0058, time: 57.570859]
2023-05-22 22:00:56.020: epoch 70:	0.02802237  	0.06291647  	0.05104821  	0.09383961  	0.10500157  
2023-05-22 22:01:57.238: [iter 71 : loss : 0.0288 = 0.0230 + 0.0000 + 0.0058, time: 58.415334]
2023-05-22 22:02:03.867: epoch 71:	0.02813920  	0.06309652  	0.05124167  	0.09427706  	0.10539161  
2023-05-22 22:02:03.867: Found a better model.
2023-05-22 22:02:03.867: Save model to file as pretrain.
2023-05-22 22:03:04.746: [iter 72 : loss : 0.0289 = 0.0230 + 0.0000 + 0.0059, time: 57.677367]
2023-05-22 22:03:11.774: epoch 72:	0.02820235  	0.06322530  	0.05127909  	0.09405053  	0.10522052  
2023-05-22 22:03:11.774: Found a better model.
2023-05-22 22:03:11.774: Save model to file as pretrain.
2023-05-22 22:04:12.990: [iter 73 : loss : 0.0284 = 0.0225 + 0.0000 + 0.0059, time: 58.042283]
2023-05-22 22:04:20.125: epoch 73:	0.02825132  	0.06333739  	0.05140629  	0.09431552  	0.10540610  
2023-05-22 22:04:20.125: Found a better model.
2023-05-22 22:04:20.125: Save model to file as pretrain.
2023-05-22 22:05:21.568: [iter 74 : loss : 0.0285 = 0.0226 + 0.0000 + 0.0059, time: 58.298880]
2023-05-22 22:05:28.760: epoch 74:	0.02827340  	0.06348371  	0.05149832  	0.09452524  	0.10581893  
2023-05-22 22:05:28.761: Found a better model.
2023-05-22 22:05:28.761: Save model to file as pretrain.
2023-05-22 22:06:30.349: [iter 75 : loss : 0.0284 = 0.0225 + 0.0000 + 0.0060, time: 58.394187]
2023-05-22 22:06:37.326: epoch 75:	0.02826552  	0.06347442  	0.05152507  	0.09455256  	0.10592718  
2023-05-22 22:07:38.839: [iter 76 : loss : 0.0283 = 0.0223 + 0.0000 + 0.0060, time: 58.742609]
2023-05-22 22:07:44.088: epoch 76:	0.02823554  	0.06342977  	0.05151592  	0.09462931  	0.10594703  
2023-05-22 22:08:44.639: [iter 77 : loss : 0.0279 = 0.0219 + 0.0000 + 0.0060, time: 57.728340]
2023-05-22 22:08:51.558: epoch 77:	0.02816291  	0.06324355  	0.05143316  	0.09477920  	0.10594351  
2023-05-22 22:09:51.372: [iter 78 : loss : 0.0275 = 0.0214 + 0.0000 + 0.0061, time: 57.066936]
2023-05-22 22:09:58.321: epoch 78:	0.02813291  	0.06318519  	0.05141009  	0.09480299  	0.10598037  
2023-05-22 22:10:59.266: [iter 79 : loss : 0.0277 = 0.0216 + 0.0000 + 0.0061, time: 58.164105]
2023-05-22 22:11:06.500: epoch 79:	0.02828759  	0.06351985  	0.05162809  	0.09501795  	0.10611509  
2023-05-22 22:11:06.500: Found a better model.
2023-05-22 22:11:06.500: Save model to file as pretrain.
2023-05-22 22:12:08.516: [iter 80 : loss : 0.0274 = 0.0213 + 0.0000 + 0.0061, time: 58.886489]
2023-05-22 22:12:15.482: epoch 80:	0.02819918  	0.06343757  	0.05163302  	0.09531119  	0.10652165  
2023-05-22 22:13:16.043: [iter 81 : loss : 0.0273 = 0.0211 + 0.0000 + 0.0062, time: 57.808752]
2023-05-22 22:13:23.355: epoch 81:	0.02834915  	0.06366026  	0.05180464  	0.09543395  	0.10666401  
2023-05-22 22:13:23.356: Found a better model.
2023-05-22 22:13:23.356: Save model to file as pretrain.
2023-05-22 22:14:25.292: [iter 82 : loss : 0.0272 = 0.0210 + 0.0000 + 0.0062, time: 58.727097]
2023-05-22 22:14:32.012: epoch 82:	0.02830180  	0.06359994  	0.05168007  	0.09515232  	0.10627619  
2023-05-22 22:15:32.416: [iter 83 : loss : 0.0269 = 0.0207 + 0.0000 + 0.0063, time: 57.639353]
2023-05-22 22:15:39.365: epoch 83:	0.02830182  	0.06357110  	0.05165749  	0.09510469  	0.10604752  
2023-05-22 22:16:41.044: [iter 84 : loss : 0.0271 = 0.0208 + 0.0000 + 0.0063, time: 58.933703]
2023-05-22 22:16:48.204: epoch 84:	0.02838389  	0.06371295  	0.05176057  	0.09516078  	0.10613889  
2023-05-22 22:16:48.204: Found a better model.
2023-05-22 22:16:48.204: Save model to file as pretrain.
2023-05-22 22:17:49.563: [iter 85 : loss : 0.0269 = 0.0206 + 0.0000 + 0.0063, time: 58.196505]
2023-05-22 22:17:56.530: epoch 85:	0.02854809  	0.06404655  	0.05205145  	0.09575900  	0.10685524  
2023-05-22 22:17:56.530: Found a better model.
2023-05-22 22:17:56.530: Save model to file as pretrain.
2023-05-22 22:18:58.491: [iter 86 : loss : 0.0265 = 0.0202 + 0.0000 + 0.0063, time: 58.791926]
2023-05-22 22:19:05.498: epoch 86:	0.02858598  	0.06410018  	0.05206534  	0.09541375  	0.10665281  
2023-05-22 22:19:05.499: Found a better model.
2023-05-22 22:19:05.499: Save model to file as pretrain.
2023-05-22 22:20:05.704: [iter 87 : loss : 0.0271 = 0.0207 + 0.0000 + 0.0064, time: 57.077626]
2023-05-22 22:20:12.707: epoch 87:	0.02856861  	0.06410193  	0.05203562  	0.09545487  	0.10664419  
2023-05-22 22:20:12.708: Found a better model.
2023-05-22 22:20:12.708: Save model to file as pretrain.
2023-05-22 22:21:13.520: [iter 88 : loss : 0.0265 = 0.0201 + 0.0000 + 0.0064, time: 57.612495]
2023-05-22 22:21:20.346: epoch 88:	0.02856862  	0.06404017  	0.05200484  	0.09532007  	0.10660401  
2023-05-22 22:22:22.124: [iter 89 : loss : 0.0264 = 0.0200 + 0.0000 + 0.0064, time: 58.961748]
2023-05-22 22:22:27.948: epoch 89:	0.02853545  	0.06394868  	0.05204741  	0.09577969  	0.10699987  
2023-05-22 22:23:28.380: [iter 90 : loss : 0.0263 = 0.0198 + 0.0000 + 0.0065, time: 57.684204]
2023-05-22 22:23:35.360: epoch 90:	0.02852126  	0.06389656  	0.05200105  	0.09550094  	0.10689934  
2023-05-22 22:24:35.911: [iter 91 : loss : 0.0262 = 0.0197 + 0.0000 + 0.0065, time: 57.793156]
2023-05-22 22:24:43.197: epoch 91:	0.02842495  	0.06370898  	0.05188012  	0.09545350  	0.10681784  
2023-05-22 22:25:43.484: [iter 92 : loss : 0.0260 = 0.0194 + 0.0000 + 0.0065, time: 57.526284]
2023-05-22 22:25:49.968: epoch 92:	0.02838075  	0.06359481  	0.05186712  	0.09557585  	0.10675676  
2023-05-22 22:26:49.559: [iter 93 : loss : 0.0260 = 0.0194 + 0.0000 + 0.0066, time: 56.819139]
2023-05-22 22:26:56.622: epoch 93:	0.02840127  	0.06369153  	0.05189425  	0.09548076  	0.10659518  
2023-05-22 22:27:56.412: [iter 94 : loss : 0.0258 = 0.0192 + 0.0000 + 0.0066, time: 57.027863]
2023-05-22 22:28:03.053: epoch 94:	0.02836813  	0.06359217  	0.05187830  	0.09564728  	0.10680690  
2023-05-22 22:29:04.601: [iter 95 : loss : 0.0256 = 0.0190 + 0.0000 + 0.0066, time: 58.814915]
2023-05-22 22:29:11.562: epoch 95:	0.02831922  	0.06348392  	0.05181694  	0.09551508  	0.10672372  
2023-05-22 22:30:11.960: [iter 96 : loss : 0.0256 = 0.0189 + 0.0000 + 0.0066, time: 57.655225]
2023-05-22 22:30:19.157: epoch 96:	0.02846758  	0.06378298  	0.05202009  	0.09574783  	0.10704125  
2023-05-22 22:31:20.276: [iter 97 : loss : 0.0258 = 0.0191 + 0.0000 + 0.0067, time: 58.353641]
2023-05-22 22:31:26.934: epoch 97:	0.02839498  	0.06362133  	0.05201336  	0.09610681  	0.10750809  
2023-05-22 22:32:28.573: [iter 98 : loss : 0.0254 = 0.0187 + 0.0000 + 0.0067, time: 58.859160]
2023-05-22 22:32:35.868: epoch 98:	0.02846285  	0.06377637  	0.05204467  	0.09578530  	0.10741206  
2023-05-22 22:33:36.901: [iter 99 : loss : 0.0253 = 0.0186 + 0.0000 + 0.0067, time: 58.297047]
2023-05-22 22:33:42.756: epoch 99:	0.02845812  	0.06389476  	0.05214695  	0.09625550  	0.10772160  
2023-05-22 22:34:43.164: [iter 100 : loss : 0.0252 = 0.0184 + 0.0000 + 0.0068, time: 57.668888]
2023-05-22 22:34:49.894: epoch 100:	0.02849918  	0.06397145  	0.05217249  	0.09613095  	0.10767408  
2023-05-22 22:35:50.833: [iter 101 : loss : 0.0251 = 0.0183 + 0.0000 + 0.0068, time: 58.203002]
2023-05-22 22:35:58.051: epoch 101:	0.02863493  	0.06423740  	0.05233046  	0.09635445  	0.10779469  
2023-05-22 22:35:58.051: Found a better model.
2023-05-22 22:35:58.051: Save model to file as pretrain.
2023-05-22 22:36:58.122: [iter 102 : loss : 0.0251 = 0.0182 + 0.0000 + 0.0068, time: 56.924337]
2023-05-22 22:37:04.687: epoch 102:	0.02859074  	0.06426498  	0.05225704  	0.09620851  	0.10769865  
2023-05-22 22:37:04.687: Found a better model.
2023-05-22 22:37:04.688: Save model to file as pretrain.
2023-05-22 22:38:06.083: [iter 103 : loss : 0.0251 = 0.0182 + 0.0000 + 0.0068, time: 58.232111]
2023-05-22 22:38:13.594: epoch 103:	0.02853390  	0.06397478  	0.05206439  	0.09575552  	0.10730737  
2023-05-22 22:39:12.517: [iter 104 : loss : 0.0246 = 0.0178 + 0.0000 + 0.0069, time: 56.202907]
2023-05-22 22:39:19.264: epoch 104:	0.02847235  	0.06400309  	0.05208209  	0.09583565  	0.10734605  
2023-05-22 22:40:21.029: [iter 105 : loss : 0.0249 = 0.0180 + 0.0000 + 0.0069, time: 59.017802]
2023-05-22 22:40:27.885: epoch 105:	0.02842497  	0.06396636  	0.05207989  	0.09620544  	0.10752796  
2023-05-22 22:41:27.622: [iter 106 : loss : 0.0245 = 0.0175 + 0.0000 + 0.0069, time: 57.009429]
2023-05-22 22:41:34.424: epoch 106:	0.02848179  	0.06399424  	0.05216752  	0.09626311  	0.10766110  
2023-05-22 22:42:35.907: [iter 107 : loss : 0.0247 = 0.0177 + 0.0000 + 0.0069, time: 58.779195]
2023-05-22 22:42:42.891: epoch 107:	0.02841864  	0.06375229  	0.05202797  	0.09616946  	0.10730828  
2023-05-22 22:43:43.898: [iter 108 : loss : 0.0243 = 0.0174 + 0.0000 + 0.0070, time: 58.311549]
2023-05-22 22:43:50.644: epoch 108:	0.02851337  	0.06393361  	0.05218081  	0.09635582  	0.10771054  
2023-05-22 22:44:51.227: [iter 109 : loss : 0.0246 = 0.0176 + 0.0000 + 0.0070, time: 57.861844]
2023-05-22 22:44:56.551: epoch 109:	0.02855444  	0.06395523  	0.05224141  	0.09644836  	0.10786682  
2023-05-22 22:45:57.153: [iter 110 : loss : 0.0243 = 0.0173 + 0.0000 + 0.0070, time: 57.957820]
2023-05-22 22:46:04.606: epoch 110:	0.02846759  	0.06376840  	0.05220970  	0.09670654  	0.10805588  
2023-05-22 22:47:04.980: [iter 111 : loss : 0.0240 = 0.0170 + 0.0000 + 0.0070, time: 57.574631]
2023-05-22 22:47:11.949: epoch 111:	0.02855127  	0.06402669  	0.05227992  	0.09648399  	0.10784194  
2023-05-22 22:48:13.550: [iter 112 : loss : 0.0243 = 0.0172 + 0.0000 + 0.0071, time: 58.894036]
2023-05-22 22:48:20.590: epoch 112:	0.02857811  	0.06401334  	0.05223453  	0.09633478  	0.10757469  
2023-05-22 22:49:20.970: [iter 113 : loss : 0.0241 = 0.0170 + 0.0000 + 0.0071, time: 57.697410]
2023-05-22 22:49:27.904: epoch 113:	0.02857969  	0.06401237  	0.05223887  	0.09627156  	0.10756369  
2023-05-22 22:50:28.867: [iter 114 : loss : 0.0239 = 0.0168 + 0.0000 + 0.0071, time: 58.257032]
2023-05-22 22:50:36.338: epoch 114:	0.02857813  	0.06404350  	0.05233804  	0.09663942  	0.10805114  
2023-05-22 22:51:36.766: [iter 115 : loss : 0.0238 = 0.0166 + 0.0000 + 0.0071, time: 57.752580]
2023-05-22 22:51:43.965: epoch 115:	0.02853708  	0.06400835  	0.05231638  	0.09654109  	0.10807199  
2023-05-22 22:52:44.991: [iter 116 : loss : 0.0238 = 0.0166 + 0.0000 + 0.0072, time: 58.261412]
2023-05-22 22:52:52.053: epoch 116:	0.02860496  	0.06408169  	0.05238868  	0.09655750  	0.10814912  
2023-05-22 22:53:52.847: [iter 117 : loss : 0.0241 = 0.0169 + 0.0000 + 0.0072, time: 58.045985]
2023-05-22 22:53:59.740: epoch 117:	0.02863179  	0.06421135  	0.05249171  	0.09680541  	0.10857079  
2023-05-22 22:55:00.867: [iter 118 : loss : 0.0237 = 0.0165 + 0.0000 + 0.0072, time: 58.324129]
2023-05-22 22:55:07.922: epoch 118:	0.02857181  	0.06391396  	0.05236133  	0.09674387  	0.10845186  
2023-05-22 22:56:09.568: [iter 119 : loss : 0.0236 = 0.0163 + 0.0000 + 0.0072, time: 58.849531]
2023-05-22 22:56:16.357: epoch 119:	0.02849921  	0.06360874  	0.05218799  	0.09638602  	0.10810467  
2023-05-22 22:57:16.567: [iter 120 : loss : 0.0235 = 0.0163 + 0.0000 + 0.0073, time: 57.435341]
2023-05-22 22:57:23.865: epoch 120:	0.02845654  	0.06355177  	0.05213472  	0.09646808  	0.10794748  
2023-05-22 22:58:25.036: [iter 121 : loss : 0.0236 = 0.0163 + 0.0000 + 0.0073, time: 58.394650]
2023-05-22 22:58:32.062: epoch 121:	0.02860810  	0.06390796  	0.05227099  	0.09636056  	0.10782683  
2023-05-22 22:59:33.053: [iter 122 : loss : 0.0235 = 0.0162 + 0.0000 + 0.0073, time: 58.207612]
2023-05-22 22:59:38.081: epoch 122:	0.02852601  	0.06376487  	0.05228782  	0.09686253  	0.10825238  
2023-05-22 23:00:36.771: [iter 123 : loss : 0.0237 = 0.0164 + 0.0000 + 0.0073, time: 56.219642]
2023-05-22 23:00:43.821: epoch 123:	0.02852286  	0.06381217  	0.05234111  	0.09702104  	0.10843640  
2023-05-22 23:01:44.283: [iter 124 : loss : 0.0235 = 0.0161 + 0.0000 + 0.0073, time: 57.670019]
2023-05-22 23:01:51.366: epoch 124:	0.02853702  	0.06380745  	0.05232587  	0.09693874  	0.10835441  
2023-05-22 23:02:51.997: [iter 125 : loss : 0.0232 = 0.0159 + 0.0000 + 0.0074, time: 57.851304]
2023-05-22 23:02:58.753: epoch 125:	0.02862384  	0.06401673  	0.05243326  	0.09692331  	0.10842637  
2023-05-22 23:04:00.265: [iter 126 : loss : 0.0232 = 0.0158 + 0.0000 + 0.0074, time: 58.741385]
2023-05-22 23:04:07.146: epoch 126:	0.02868071  	0.06416968  	0.05253227  	0.09725193  	0.10865765  
2023-05-22 23:05:08.365: [iter 127 : loss : 0.0233 = 0.0159 + 0.0000 + 0.0074, time: 58.415144]
2023-05-22 23:05:15.341: epoch 127:	0.02858756  	0.06403351  	0.05248224  	0.09721429  	0.10876469  
2023-05-22 23:06:15.880: [iter 128 : loss : 0.0231 = 0.0157 + 0.0000 + 0.0074, time: 57.755918]
2023-05-22 23:06:23.070: epoch 128:	0.02866178  	0.06414764  	0.05255007  	0.09715229  	0.10883892  
2023-05-22 23:07:24.190: [iter 129 : loss : 0.0231 = 0.0157 + 0.0000 + 0.0074, time: 58.366447]
2023-05-22 23:07:29.958: epoch 129:	0.02860653  	0.06401611  	0.05247457  	0.09706779  	0.10876524  
2023-05-22 23:08:30.931: [iter 130 : loss : 0.0230 = 0.0156 + 0.0000 + 0.0075, time: 58.205313]
2023-05-22 23:08:37.954: epoch 130:	0.02869493  	0.06430159  	0.05262430  	0.09721234  	0.10896397  
2023-05-22 23:08:37.954: Found a better model.
2023-05-22 23:08:37.954: Save model to file as pretrain.
2023-05-22 23:09:39.541: [iter 131 : loss : 0.0227 = 0.0152 + 0.0000 + 0.0075, time: 58.363079]
2023-05-22 23:09:46.845: epoch 131:	0.02870123  	0.06435145  	0.05268822  	0.09753069  	0.10926400  
2023-05-22 23:09:46.845: Found a better model.
2023-05-22 23:09:46.845: Save model to file as pretrain.
2023-05-22 23:10:47.835: [iter 132 : loss : 0.0228 = 0.0153 + 0.0000 + 0.0075, time: 57.758664]
2023-05-22 23:10:53.803: epoch 132:	0.02857968  	0.06396797  	0.05245892  	0.09732320  	0.10892057  
2023-05-22 23:11:55.481: [iter 133 : loss : 0.0229 = 0.0154 + 0.0000 + 0.0075, time: 58.884229]
2023-05-22 23:12:01.763: epoch 133:	0.02864916  	0.06406590  	0.05249074  	0.09710646  	0.10883515  
2023-05-22 23:13:02.345: [iter 134 : loss : 0.0227 = 0.0151 + 0.0000 + 0.0075, time: 57.759684]
2023-05-22 23:13:09.114: epoch 134:	0.02860336  	0.06404835  	0.05245319  	0.09702498  	0.10873818  
2023-05-22 23:14:10.887: [iter 135 : loss : 0.0227 = 0.0151 + 0.0000 + 0.0076, time: 59.023550]
2023-05-22 23:14:17.543: epoch 135:	0.02861442  	0.06406672  	0.05235494  	0.09674001  	0.10820298  
2023-05-22 23:15:17.839: [iter 136 : loss : 0.0226 = 0.0150 + 0.0000 + 0.0076, time: 57.515885]
2023-05-22 23:15:25.001: epoch 136:	0.02851809  	0.06391232  	0.05229712  	0.09690550  	0.10827363  
2023-05-22 23:16:26.220: [iter 137 : loss : 0.0227 = 0.0151 + 0.0000 + 0.0076, time: 58.452508]
2023-05-22 23:16:33.286: epoch 137:	0.02852604  	0.06394500  	0.05236402  	0.09686882  	0.10838717  
2023-05-22 23:17:33.079: [iter 138 : loss : 0.0225 = 0.0149 + 0.0000 + 0.0076, time: 57.032036]
2023-05-22 23:17:40.167: epoch 138:	0.02866653  	0.06413261  	0.05242672  	0.09684916  	0.10837521  
2023-05-22 23:18:41.156: [iter 139 : loss : 0.0225 = 0.0149 + 0.0000 + 0.0076, time: 58.183717]
2023-05-22 23:18:46.457: epoch 139:	0.02867284  	0.06420979  	0.05250100  	0.09697503  	0.10859306  
2023-05-22 23:19:46.314: [iter 140 : loss : 0.0224 = 0.0148 + 0.0000 + 0.0077, time: 57.131100]
2023-05-22 23:19:53.401: epoch 140:	0.02873441  	0.06437450  	0.05254706  	0.09691446  	0.10844462  
2023-05-22 23:19:53.401: Found a better model.
2023-05-22 23:19:53.401: Save model to file as pretrain.
2023-05-22 23:20:54.295: [iter 141 : loss : 0.0223 = 0.0146 + 0.0000 + 0.0077, time: 57.608773]
2023-05-22 23:21:00.954: epoch 141:	0.02861599  	0.06413223  	0.05243052  	0.09700239  	0.10850590  
2023-05-22 23:22:01.865: [iter 142 : loss : 0.0225 = 0.0148 + 0.0000 + 0.0077, time: 58.118575]
2023-05-22 23:22:08.201: epoch 142:	0.02859863  	0.06409228  	0.05235424  	0.09662846  	0.10825796  
2023-05-22 23:23:08.641: [iter 143 : loss : 0.0221 = 0.0144 + 0.0000 + 0.0077, time: 57.669450]
2023-05-22 23:23:15.667: epoch 143:	0.02870598  	0.06423495  	0.05240134  	0.09646538  	0.10810368  
2023-05-22 23:24:16.821: [iter 144 : loss : 0.0224 = 0.0146 + 0.0000 + 0.0077, time: 58.402587]
2023-05-22 23:24:24.063: epoch 144:	0.02860338  	0.06401502  	0.05237226  	0.09687331  	0.10835084  
2023-05-22 23:25:25.688: [iter 145 : loss : 0.0224 = 0.0146 + 0.0000 + 0.0077, time: 58.795063]
2023-05-22 23:25:32.870: epoch 145:	0.02857812  	0.06393112  	0.05238687  	0.09687986  	0.10851498  
2023-05-22 23:26:34.500: [iter 146 : loss : 0.0222 = 0.0145 + 0.0000 + 0.0078, time: 58.897891]
2023-05-22 23:26:41.354: epoch 146:	0.02864601  	0.06407364  	0.05247423  	0.09702953  	0.10868764  
2023-05-22 23:27:42.461: [iter 147 : loss : 0.0219 = 0.0142 + 0.0000 + 0.0078, time: 58.358804]
2023-05-22 23:27:49.585: epoch 147:	0.02866809  	0.06427261  	0.05254736  	0.09713081  	0.10881211  
2023-05-22 23:28:50.841: [iter 148 : loss : 0.0221 = 0.0143 + 0.0000 + 0.0078, time: 58.401648]
2023-05-22 23:28:58.013: epoch 148:	0.02868390  	0.06424864  	0.05242610  	0.09685100  	0.10828341  
2023-05-22 23:29:58.895: [iter 149 : loss : 0.0218 = 0.0140 + 0.0000 + 0.0078, time: 58.108754]
2023-05-22 23:30:04.393: epoch 149:	0.02863812  	0.06408462  	0.05233123  	0.09680936  	0.10811155  
2023-05-22 23:31:04.648: [iter 150 : loss : 0.0220 = 0.0142 + 0.0000 + 0.0078, time: 57.645486]
2023-05-22 23:31:11.596: epoch 150:	0.02865547  	0.06415514  	0.05234464  	0.09652387  	0.10794178  
2023-05-22 23:32:13.319: [iter 151 : loss : 0.0219 = 0.0141 + 0.0000 + 0.0078, time: 58.980196]
2023-05-22 23:32:20.694: epoch 151:	0.02862394  	0.06403752  	0.05226474  	0.09660710  	0.10789736  
2023-05-22 23:33:21.664: [iter 152 : loss : 0.0219 = 0.0140 + 0.0000 + 0.0079, time: 58.213208]
2023-05-22 23:33:27.722: epoch 152:	0.02855919  	0.06395763  	0.05222202  	0.09671047  	0.10794292  
2023-05-22 23:34:28.508: [iter 153 : loss : 0.0219 = 0.0141 + 0.0000 + 0.0079, time: 58.042174]
2023-05-22 23:34:35.427: epoch 153:	0.02857658  	0.06398413  	0.05225699  	0.09679268  	0.10803872  
2023-05-22 23:35:36.719: [iter 154 : loss : 0.0219 = 0.0140 + 0.0000 + 0.0079, time: 58.465887]
2023-05-22 23:35:43.919: epoch 154:	0.02863813  	0.06411071  	0.05235640  	0.09686799  	0.10811893  
2023-05-22 23:36:44.370: [iter 155 : loss : 0.0219 = 0.0140 + 0.0000 + 0.0079, time: 57.658935]
2023-05-22 23:36:51.364: epoch 155:	0.02862236  	0.06391774  	0.05229054  	0.09679280  	0.10805394  
2023-05-22 23:37:51.807: [iter 156 : loss : 0.0219 = 0.0140 + 0.0000 + 0.0079, time: 57.691403]
2023-05-22 23:37:58.915: epoch 156:	0.02871231  	0.06415248  	0.05244542  	0.09715393  	0.10840197  
2023-05-22 23:39:00.665: [iter 157 : loss : 0.0217 = 0.0138 + 0.0000 + 0.0079, time: 58.948676]
2023-05-22 23:39:07.894: epoch 157:	0.02864601  	0.06404148  	0.05232452  	0.09709658  	0.10801648  
2023-05-22 23:40:07.577: [iter 158 : loss : 0.0217 = 0.0137 + 0.0000 + 0.0079, time: 56.863363]
2023-05-22 23:40:14.450: epoch 158:	0.02863495  	0.06384682  	0.05223903  	0.09659042  	0.10781171  
2023-05-22 23:41:16.236: [iter 159 : loss : 0.0216 = 0.0136 + 0.0000 + 0.0080, time: 59.096735]
2023-05-22 23:41:23.445: epoch 159:	0.02864600  	0.06397121  	0.05234656  	0.09686887  	0.10806268  
2023-05-22 23:42:22.547: [iter 160 : loss : 0.0215 = 0.0135 + 0.0000 + 0.0080, time: 56.314439]
2023-05-22 23:42:29.812: epoch 160:	0.02866810  	0.06414607  	0.05239248  	0.09686564  	0.10797922  
2023-05-22 23:43:29.948: [iter 161 : loss : 0.0216 = 0.0136 + 0.0000 + 0.0080, time: 57.354777]
2023-05-22 23:43:37.211: epoch 161:	0.02866336  	0.06411996  	0.05235860  	0.09682564  	0.10805647  
2023-05-22 23:44:37.362: [iter 162 : loss : 0.0215 = 0.0135 + 0.0000 + 0.0080, time: 57.342649]
2023-05-22 23:44:44.856: epoch 162:	0.02862233  	0.06395055  	0.05233518  	0.09702170  	0.10818070  
2023-05-22 23:45:43.757: [iter 163 : loss : 0.0216 = 0.0135 + 0.0000 + 0.0080, time: 56.102143]
2023-05-22 23:45:51.014: epoch 163:	0.02854184  	0.06377606  	0.05230623  	0.09725894  	0.10844628  
2023-05-22 23:46:51.115: [iter 164 : loss : 0.0213 = 0.0133 + 0.0000 + 0.0080, time: 57.334439]
2023-05-22 23:46:58.901: epoch 164:	0.02863024  	0.06409958  	0.05237791  	0.09691615  	0.10807675  
2023-05-22 23:47:57.220: [iter 165 : loss : 0.0217 = 0.0136 + 0.0000 + 0.0080, time: 55.527668]
2023-05-22 23:48:02.930: epoch 165:	0.02870759  	0.06413265  	0.05249520  	0.09735799  	0.10849781  
2023-05-22 23:49:02.557: [iter 166 : loss : 0.0214 = 0.0133 + 0.0000 + 0.0081, time: 56.886327]
2023-05-22 23:49:09.216: epoch 166:	0.02876599  	0.06419193  	0.05252856  	0.09709312  	0.10848711  
2023-05-22 23:50:09.367: [iter 167 : loss : 0.0214 = 0.0134 + 0.0000 + 0.0081, time: 57.371509]
2023-05-22 23:50:16.286: epoch 167:	0.02878178  	0.06420236  	0.05262467  	0.09747873  	0.10897062  
2023-05-22 23:51:14.758: [iter 168 : loss : 0.0213 = 0.0132 + 0.0000 + 0.0081, time: 55.680247]
2023-05-22 23:51:21.830: epoch 168:	0.02876754  	0.06422254  	0.05255983  	0.09755966  	0.10887277  
2023-05-22 23:52:19.718: [iter 169 : loss : 0.0212 = 0.0131 + 0.0000 + 0.0081, time: 55.147641]
2023-05-22 23:52:26.796: epoch 169:	0.02878964  	0.06432848  	0.05263445  	0.09753985  	0.10900673  
2023-05-22 23:53:24.903: [iter 170 : loss : 0.0212 = 0.0131 + 0.0000 + 0.0081, time: 55.345470]
2023-05-22 23:53:31.863: epoch 170:	0.02873282  	0.06404938  	0.05249919  	0.09746069  	0.10881525  
2023-05-22 23:54:32.120: [iter 171 : loss : 0.0210 = 0.0129 + 0.0000 + 0.0081, time: 57.485088]
2023-05-22 23:54:39.467: epoch 171:	0.02863653  	0.06374913  	0.05237175  	0.09742206  	0.10880541  
2023-05-22 23:55:48.417: [iter 172 : loss : 0.0213 = 0.0132 + 0.0000 + 0.0081, time: 66.197939]
2023-05-22 23:55:55.134: epoch 172:	0.02856547  	0.06358950  	0.05229930  	0.09738487  	0.10880284  
2023-05-22 23:56:58.118: [iter 173 : loss : 0.0212 = 0.0131 + 0.0000 + 0.0081, time: 60.271791]
2023-05-22 23:57:04.918: epoch 173:	0.02867127  	0.06387641  	0.05236059  	0.09720933  	0.10847531  
2023-05-22 23:58:03.766: [iter 174 : loss : 0.0211 = 0.0130 + 0.0000 + 0.0082, time: 56.072614]
2023-05-22 23:58:10.490: epoch 174:	0.02864127  	0.06375802  	0.05233941  	0.09717280  	0.10860164  
2023-05-22 23:59:09.367: [iter 175 : loss : 0.0212 = 0.0131 + 0.0000 + 0.0082, time: 56.096699]
2023-05-22 23:59:15.197: epoch 175:	0.02862867  	0.06375176  	0.05240402  	0.09728753  	0.10894816  
2023-05-23 00:00:13.535: [iter 176 : loss : 0.0211 = 0.0129 + 0.0000 + 0.0082, time: 55.585092]
2023-05-23 00:00:20.614: epoch 176:	0.02866023  	0.06378259  	0.05246942  	0.09756189  	0.10918736  
2023-05-23 00:01:24.110: [iter 177 : loss : 0.0210 = 0.0129 + 0.0000 + 0.0082, time: 60.719692]
2023-05-23 00:01:30.971: epoch 177:	0.02865391  	0.06384993  	0.05246545  	0.09760361  	0.10928570  
2023-05-23 00:02:31.475: [iter 178 : loss : 0.0210 = 0.0128 + 0.0000 + 0.0082, time: 57.720609]
2023-05-23 00:02:37.873: epoch 178:	0.02864443  	0.06380317  	0.05251882  	0.09785729  	0.10961853  
2023-05-23 00:03:38.235: [iter 179 : loss : 0.0210 = 0.0128 + 0.0000 + 0.0082, time: 57.603177]
2023-05-23 00:03:45.616: epoch 179:	0.02869179  	0.06403469  	0.05255213  	0.09787849  	0.10933334  
2023-05-23 00:04:47.312: [iter 180 : loss : 0.0208 = 0.0126 + 0.0000 + 0.0082, time: 58.896995]
2023-05-23 00:04:54.168: epoch 180:	0.02864918  	0.06385128  	0.05250595  	0.09784179  	0.10934509  
2023-05-23 00:05:54.079: [iter 181 : loss : 0.0209 = 0.0127 + 0.0000 + 0.0082, time: 57.140388]
2023-05-23 00:06:00.674: epoch 181:	0.02872496  	0.06406614  	0.05261162  	0.09799591  	0.10951470  
2023-05-23 00:07:02.064: [iter 182 : loss : 0.0208 = 0.0126 + 0.0000 + 0.0082, time: 58.585940]
2023-05-23 00:07:09.424: epoch 182:	0.02865547  	0.06385162  	0.05253129  	0.09797300  	0.10940330  
2023-05-23 00:08:09.785: [iter 183 : loss : 0.0209 = 0.0127 + 0.0000 + 0.0083, time: 57.592029]
2023-05-23 00:08:16.973: epoch 183:	0.02865233  	0.06388018  	0.05253536  	0.09805175  	0.10956549  
2023-05-23 00:09:17.545: [iter 184 : loss : 0.0208 = 0.0125 + 0.0000 + 0.0083, time: 57.724784]
2023-05-23 00:09:24.633: epoch 184:	0.02865391  	0.06383818  	0.05257341  	0.09831607  	0.10959157  
2023-05-23 00:10:25.134: [iter 185 : loss : 0.0211 = 0.0128 + 0.0000 + 0.0083, time: 57.707394]
2023-05-23 00:10:31.853: epoch 185:	0.02862706  	0.06386503  	0.05260348  	0.09846670  	0.10985194  
2023-05-23 00:11:33.063: [iter 186 : loss : 0.0205 = 0.0122 + 0.0000 + 0.0083, time: 58.458999]
2023-05-23 00:11:40.446: epoch 186:	0.02864126  	0.06387874  	0.05255564  	0.09811243  	0.10950929  
2023-05-23 00:12:40.174: [iter 187 : loss : 0.0209 = 0.0126 + 0.0000 + 0.0083, time: 56.960388]
2023-05-23 00:12:47.235: epoch 187:	0.02865704  	0.06380431  	0.05254796  	0.09797053  	0.10944562  
2023-05-23 00:13:47.333: [iter 188 : loss : 0.0207 = 0.0124 + 0.0000 + 0.0083, time: 57.277841]
2023-05-23 00:13:54.070: epoch 188:	0.02874072  	0.06407417  	0.05261695  	0.09786136  	0.10946974  
2023-05-23 00:14:55.909: [iter 189 : loss : 0.0210 = 0.0127 + 0.0000 + 0.0083, time: 59.037822]
2023-05-23 00:15:02.799: epoch 189:	0.02870442  	0.06394373  	0.05254208  	0.09786112  	0.10938572  
2023-05-23 00:16:02.591: [iter 190 : loss : 0.0206 = 0.0123 + 0.0000 + 0.0083, time: 57.040567]
2023-05-23 00:16:09.535: epoch 190:	0.02883230  	0.06430399  	0.05265868  	0.09771185  	0.10927533  
2023-05-23 00:16:09.535: Early stopping is trigger at epoch: 190
2023-05-23 00:16:09.535: best_result@epoch 140:

2023-05-23 00:16:09.535: Loading from the saved model.
2023-05-23 00:16:16.292: 		0.02873441  	0.06437450  	0.05254706  	0.09691446  	0.10844462  
