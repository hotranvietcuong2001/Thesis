2023-05-23 22:02:09.368: Dataset name: ifashion
The number of users: 300000
The number of items: 81614
The number of ratings: 1607813
Average actions of users: 5.36
Average actions of items: 19.70
The sparsity of the dataset: 99.993433%
2023-05-23 22:02:09.368: 

NeuRec hyperparameters:
recommender=SGL
config_dir=./conf
gpu_id=1
gpu_mem=0.5
data.input.path=dataset
data.input.dataset=ifashion
data.column.format=UI
data.convert.separator=','
user_min=0
item_min=0
splitter=given
ratio=0.8
by_time=False
metric=["Precision", "Recall", "NDCG", "MAP", "MRR"]
topk=[20]
group_view=None
rec.evaluate.neg=0
test_batch_size=128
num_thread=8
start_testing_epoch=0
proj_path=./

SGL's hyperparameters:
seed=2021
aug_type=1
reg=1e-3
embed_size=64
n_layers=3
ssl_reg=0.02
ssl_ratio=0.4
ssl_temp=0.5
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=512
num_negatives=1
init_method=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=50
pretrain=0
save_flag=1

2023-05-23 22:02:30.048: metrics:	Precision@20	Recall@20   	NDCG@20     	MAP@20      	MRR@20      
2023-05-23 22:03:33.267: 		0.00000558  	0.00009621  	0.00003600  	0.00002021  	0.00002021  
2023-05-23 22:09:09.325: [iter 1 : loss : 0.9906 = 0.5853 + 0.4042 + 0.0010, time: 334.469872]
2023-05-23 22:09:58.776: epoch 1:	0.00306596  	0.04922947  	0.02134424  	0.01521117  	0.01531035  
2023-05-23 22:09:58.777: Found a better model.
2023-05-23 22:09:58.777: Save model to file as pretrain.
2023-05-23 22:15:33.955: [iter 2 : loss : 0.6140 = 0.1890 + 0.4182 + 0.0068, time: 333.254467]
2023-05-23 22:16:22.597: epoch 2:	0.00368159  	0.05903217  	0.02583770  	0.01852515  	0.01866051  
2023-05-23 22:16:22.597: Found a better model.
2023-05-23 22:16:22.597: Save model to file as pretrain.
2023-05-23 22:22:38.769: [iter 3 : loss : 0.5311 = 0.1083 + 0.4135 + 0.0093, time: 373.594651]
2023-05-23 22:23:26.838: epoch 3:	0.00419132  	0.06723015  	0.02961624  	0.02128372  	0.02145282  
2023-05-23 22:23:26.838: Found a better model.
2023-05-23 22:23:26.838: Save model to file as pretrain.
2023-05-23 22:28:57.815: [iter 4 : loss : 0.4961 = 0.0752 + 0.4101 + 0.0108, time: 328.463614]
2023-05-23 22:29:45.452: epoch 4:	0.00456213  	0.07337248  	0.03262351  	0.02361571  	0.02379090  
2023-05-23 22:29:45.452: Found a better model.
2023-05-23 22:29:45.452: Save model to file as pretrain.
2023-05-23 22:35:18.257: [iter 5 : loss : 0.4760 = 0.0561 + 0.4079 + 0.0120, time: 330.309616]
2023-05-23 22:36:05.363: epoch 5:	0.00484359  	0.07793215  	0.03485287  	0.02530572  	0.02549322  
2023-05-23 22:36:05.363: Found a better model.
2023-05-23 22:36:05.364: Save model to file as pretrain.
2023-05-23 22:41:42.778: [iter 6 : loss : 0.4629 = 0.0436 + 0.4064 + 0.0129, time: 334.925453]
2023-05-23 22:42:31.460: epoch 6:	0.00504910  	0.08128975  	0.03659125  	0.02670608  	0.02691355  
2023-05-23 22:42:31.460: Found a better model.
2023-05-23 22:42:31.460: Save model to file as pretrain.
2023-05-23 22:48:46.001: [iter 7 : loss : 0.4542 = 0.0352 + 0.4053 + 0.0137, time: 372.077954]
2023-05-23 22:49:33.527: epoch 7:	0.00519578  	0.08358303  	0.03810050  	0.02807845  	0.02831868  
2023-05-23 22:49:33.527: Found a better model.
2023-05-23 22:49:33.527: Save model to file as pretrain.
2023-05-23 22:55:10.704: [iter 8 : loss : 0.4475 = 0.0289 + 0.4044 + 0.0142, time: 334.679190]
2023-05-23 22:55:58.900: epoch 8:	0.00534582  	0.08602900  	0.03940739  	0.02910880  	0.02935949  
2023-05-23 22:55:58.900: Found a better model.
2023-05-23 22:55:58.900: Save model to file as pretrain.
2023-05-23 23:01:36.070: [iter 9 : loss : 0.4427 = 0.0242 + 0.4038 + 0.0147, time: 334.652819]
2023-05-23 23:02:23.940: epoch 9:	0.00548132  	0.08802086  	0.04044463  	0.02995760  	0.03023787  
2023-05-23 23:02:23.940: Found a better model.
2023-05-23 23:02:23.940: Save model to file as pretrain.
2023-05-23 23:08:39.596: [iter 10 : loss : 0.4390 = 0.0209 + 0.4032 + 0.0150, time: 373.152341]
2023-05-23 23:09:24.394: epoch 10:	0.00558389  	0.08960319  	0.04123364  	0.03057943  	0.03087481  
2023-05-23 23:09:24.395: Found a better model.
2023-05-23 23:09:24.395: Save model to file as pretrain.
2023-05-23 23:14:57.278: [iter 11 : loss : 0.4358 = 0.0178 + 0.4028 + 0.0152, time: 330.362549]
2023-05-23 23:15:45.425: epoch 11:	0.00566858  	0.09091835  	0.04205013  	0.03128866  	0.03159650  
2023-05-23 23:15:45.425: Found a better model.
2023-05-23 23:15:45.425: Save model to file as pretrain.
2023-05-23 23:22:02.816: [iter 12 : loss : 0.4334 = 0.0157 + 0.4024 + 0.0153, time: 374.903145]
2023-05-23 23:22:50.071: epoch 12:	0.00574044  	0.09197772  	0.04261598  	0.03174210  	0.03204877  
2023-05-23 23:22:50.071: Found a better model.
2023-05-23 23:22:50.071: Save model to file as pretrain.
2023-05-23 23:29:08.027: [iter 13 : loss : 0.4315 = 0.0140 + 0.4021 + 0.0153, time: 375.475281]
2023-05-23 23:29:56.706: epoch 13:	0.00579349  	0.09274513  	0.04315625  	0.03228260  	0.03258828  
2023-05-23 23:29:56.706: Found a better model.
2023-05-23 23:29:56.706: Save model to file as pretrain.
2023-05-23 23:35:32.308: [iter 14 : loss : 0.4301 = 0.0129 + 0.4019 + 0.0153, time: 333.092681]
2023-05-23 23:36:20.440: epoch 14:	0.00585658  	0.09369866  	0.04370961  	0.03275535  	0.03308340  
2023-05-23 23:36:20.440: Found a better model.
2023-05-23 23:36:20.440: Save model to file as pretrain.
2023-05-23 23:41:51.414: [iter 15 : loss : 0.4290 = 0.0120 + 0.4017 + 0.0153, time: 328.475516]
2023-05-23 23:42:37.564: epoch 15:	0.00590517  	0.09462754  	0.04419941  	0.03314215  	0.03346732  
2023-05-23 23:42:37.564: Found a better model.
2023-05-23 23:42:37.564: Save model to file as pretrain.
2023-05-23 23:48:08.532: [iter 16 : loss : 0.4278 = 0.0110 + 0.4015 + 0.0153, time: 328.422511]
2023-05-23 23:48:56.123: epoch 16:	0.00594202  	0.09514557  	0.04448203  	0.03339324  	0.03371405  
2023-05-23 23:48:56.123: Found a better model.
2023-05-23 23:48:56.123: Save model to file as pretrain.
2023-05-23 23:54:33.199: [iter 17 : loss : 0.4268 = 0.0102 + 0.4014 + 0.0152, time: 334.513218]
2023-05-23 23:55:20.834: epoch 17:	0.00596249  	0.09539564  	0.04476045  	0.03368337  	0.03403578  
2023-05-23 23:55:20.834: Found a better model.
2023-05-23 23:55:20.834: Save model to file as pretrain.
2023-05-24 00:00:51.852: [iter 18 : loss : 0.4261 = 0.0097 + 0.4013 + 0.0152, time: 328.523865]
2023-05-24 00:01:36.544: epoch 18:	0.00598912  	0.09578422  	0.04502108  	0.03390146  	0.03425539  
2023-05-24 00:01:36.544: Found a better model.
2023-05-24 00:01:36.544: Save model to file as pretrain.
2023-05-24 00:07:52.979: [iter 19 : loss : 0.4254 = 0.0091 + 0.4011 + 0.0151, time: 373.902350]
2023-05-24 00:08:39.514: epoch 19:	0.00600234  	0.09604853  	0.04522160  	0.03411660  	0.03447595  
2023-05-24 00:08:39.515: Found a better model.
2023-05-24 00:08:39.515: Save model to file as pretrain.
2023-05-24 00:14:18.466: [iter 20 : loss : 0.4249 = 0.0088 + 0.4011 + 0.0151, time: 336.418644]
2023-05-24 00:15:05.562: epoch 20:	0.00601332  	0.09624583  	0.04528098  	0.03412958  	0.03449842  
2023-05-24 00:15:05.562: Found a better model.
2023-05-24 00:15:05.562: Save model to file as pretrain.
2023-05-24 00:20:36.573: [iter 21 : loss : 0.4244 = 0.0085 + 0.4010 + 0.0150, time: 328.397962]
2023-05-24 00:21:24.857: epoch 21:	0.00605558  	0.09691357  	0.04557756  	0.03435071  	0.03471566  
2023-05-24 00:21:24.857: Found a better model.
2023-05-24 00:21:24.857: Save model to file as pretrain.
2023-05-24 00:27:39.395: [iter 22 : loss : 0.4241 = 0.0082 + 0.4009 + 0.0150, time: 372.047662]
2023-05-24 00:28:28.989: epoch 22:	0.00606190  	0.09696598  	0.04567831  	0.03443191  	0.03479777  
2023-05-24 00:28:28.989: Found a better model.
2023-05-24 00:28:28.989: Save model to file as pretrain.
2023-05-24 00:34:43.768: [iter 23 : loss : 0.4237 = 0.0079 + 0.4008 + 0.0149, time: 372.146191]
2023-05-24 00:35:30.471: epoch 23:	0.00607884  	0.09723575  	0.04586096  	0.03463876  	0.03501130  
2023-05-24 00:35:30.471: Found a better model.
2023-05-24 00:35:30.471: Save model to file as pretrain.
2023-05-24 00:41:46.935: [iter 24 : loss : 0.4235 = 0.0078 + 0.4008 + 0.0149, time: 373.945088]
2023-05-24 00:42:32.074: epoch 24:	0.00609913  	0.09752761  	0.04592155  	0.03461419  	0.03498035  
2023-05-24 00:42:32.074: Found a better model.
2023-05-24 00:42:32.074: Save model to file as pretrain.
2023-05-24 00:48:32.988: [iter 25 : loss : 0.4231 = 0.0074 + 0.4007 + 0.0149, time: 358.375374]
2023-05-24 00:49:20.252: epoch 25:	0.00611589  	0.09781947  	0.04608142  	0.03477517  	0.03514579  
2023-05-24 00:49:20.252: Found a better model.
2023-05-24 00:49:20.252: Save model to file as pretrain.
2023-05-24 00:54:57.704: [iter 26 : loss : 0.4229 = 0.0073 + 0.4007 + 0.0149, time: 334.981909]
2023-05-24 00:55:46.170: epoch 26:	0.00611458  	0.09784333  	0.04616199  	0.03487563  	0.03524610  
2023-05-24 00:55:46.170: Found a better model.
2023-05-24 00:55:46.170: Save model to file as pretrain.
2023-05-24 01:01:25.372: [iter 27 : loss : 0.4226 = 0.0071 + 0.4007 + 0.0149, time: 336.679500]
2023-05-24 01:02:14.675: epoch 27:	0.00613878  	0.09825817  	0.04634559  	0.03498886  	0.03537451  
2023-05-24 01:02:14.675: Found a better model.
2023-05-24 01:02:14.675: Save model to file as pretrain.
2023-05-24 01:08:27.637: [iter 28 : loss : 0.4225 = 0.0070 + 0.4006 + 0.0149, time: 370.446547]
2023-05-24 01:09:00.258: epoch 28:	0.00615143  	0.09845302  	0.04652137  	0.03517487  	0.03557092  
2023-05-24 01:09:00.258: Found a better model.
2023-05-24 01:09:00.258: Save model to file as pretrain.
2023-05-24 01:15:16.225: [iter 29 : loss : 0.4224 = 0.0069 + 0.4006 + 0.0149, time: 373.542882]
2023-05-24 01:16:03.661: epoch 29:	0.00616595  	0.09862413  	0.04663831  	0.03527807  	0.03567801  
2023-05-24 01:16:03.661: Found a better model.
2023-05-24 01:16:03.661: Save model to file as pretrain.
2023-05-24 01:22:17.459: [iter 30 : loss : 0.4223 = 0.0068 + 0.4006 + 0.0149, time: 371.306173]
2023-05-24 01:23:05.750: epoch 30:	0.00615274  	0.09848333  	0.04665945  	0.03534781  	0.03575470  
2023-05-24 01:29:21.279: [iter 31 : loss : 0.4221 = 0.0067 + 0.4006 + 0.0149, time: 374.011060]
2023-05-24 01:30:09.137: epoch 31:	0.00618476  	0.09889451  	0.04681199  	0.03543131  	0.03584190  
2023-05-24 01:30:09.137: Found a better model.
2023-05-24 01:30:09.137: Save model to file as pretrain.
2023-05-24 01:36:26.405: [iter 32 : loss : 0.4220 = 0.0066 + 0.4005 + 0.0149, time: 374.757845]
2023-05-24 01:37:14.423: epoch 32:	0.00619853  	0.09910679  	0.04693718  	0.03552722  	0.03593792  
2023-05-24 01:37:14.423: Found a better model.
2023-05-24 01:37:14.423: Save model to file as pretrain.
2023-05-24 01:43:31.941: [iter 33 : loss : 0.4220 = 0.0066 + 0.4005 + 0.0149, time: 374.996089]
2023-05-24 01:44:19.344: epoch 33:	0.00619499  	0.09908096  	0.04689521  	0.03550080  	0.03590517  
2023-05-24 01:49:49.107: [iter 34 : loss : 0.4218 = 0.0064 + 0.4005 + 0.0149, time: 328.232958]
2023-05-24 01:50:35.053: epoch 34:	0.00621714  	0.09946506  	0.04708487  	0.03567722  	0.03607782  
2023-05-24 01:50:35.053: Found a better model.
2023-05-24 01:50:35.053: Save model to file as pretrain.
2023-05-24 01:56:51.500: [iter 35 : loss : 0.4216 = 0.0063 + 0.4005 + 0.0149, time: 373.943799]
2023-05-24 01:57:38.230: epoch 35:	0.00622459  	0.09963431  	0.04709674  	0.03560704  	0.03600627  
2023-05-24 01:57:38.230: Found a better model.
2023-05-24 01:57:38.231: Save model to file as pretrain.
2023-05-24 02:03:15.406: [iter 36 : loss : 0.4217 = 0.0063 + 0.4005 + 0.0149, time: 334.684484]
2023-05-24 02:04:03.760: epoch 36:	0.00625642  	0.10000201  	0.04728543  	0.03573151  	0.03614029  
2023-05-24 02:04:03.761: Found a better model.
2023-05-24 02:04:03.761: Save model to file as pretrain.
2023-05-24 02:09:34.757: [iter 37 : loss : 0.4215 = 0.0061 + 0.4005 + 0.0149, time: 328.528820]
2023-05-24 02:10:16.503: epoch 37:	0.00624767  	0.09992422  	0.04730007  	0.03582929  	0.03623677  
2023-05-24 02:15:49.608: [iter 38 : loss : 0.4215 = 0.0061 + 0.4004 + 0.0149, time: 331.801538]
2023-05-24 02:16:38.166: epoch 38:	0.00626181  	0.10018363  	0.04738075  	0.03580989  	0.03621792  
2023-05-24 02:16:38.166: Found a better model.
2023-05-24 02:16:38.166: Save model to file as pretrain.
2023-05-24 02:22:54.153: [iter 39 : loss : 0.4214 = 0.0060 + 0.4004 + 0.0149, time: 373.462962]
2023-05-24 02:23:42.488: epoch 39:	0.00627577  	0.10041272  	0.04749520  	0.03587414  	0.03627373  
2023-05-24 02:23:42.488: Found a better model.
2023-05-24 02:23:42.488: Save model to file as pretrain.
2023-05-24 02:30:01.323: [iter 40 : loss : 0.4214 = 0.0061 + 0.4004 + 0.0149, time: 376.317222]
2023-05-24 02:30:48.545: epoch 40:	0.00628248  	0.10057151  	0.04758854  	0.03599718  	0.03640655  
2023-05-24 02:30:48.547: Found a better model.
2023-05-24 02:30:48.547: Save model to file as pretrain.
2023-05-24 02:36:24.214: [iter 41 : loss : 0.4213 = 0.0060 + 0.4004 + 0.0149, time: 333.212911]
2023-05-24 02:37:10.090: epoch 41:	0.00628564  	0.10059461  	0.04759564  	0.03598614  	0.03639255  
2023-05-24 02:37:10.090: Found a better model.
2023-05-24 02:37:10.090: Save model to file as pretrain.
2023-05-24 02:42:41.685: [iter 42 : loss : 0.4213 = 0.0059 + 0.4004 + 0.0149, time: 329.100233]
2023-05-24 02:43:30.544: epoch 42:	0.00628080  	0.10041122  	0.04754128  	0.03594200  	0.03634911  
2023-05-24 02:49:05.683: [iter 43 : loss : 0.4211 = 0.0058 + 0.4004 + 0.0149, time: 333.618210]
2023-05-24 02:49:52.910: epoch 43:	0.00630779  	0.10083865  	0.04778153  	0.03613092  	0.03655604  
2023-05-24 02:49:52.910: Found a better model.
2023-05-24 02:49:52.910: Save model to file as pretrain.
2023-05-24 02:56:07.378: [iter 44 : loss : 0.4211 = 0.0058 + 0.4004 + 0.0149, time: 371.974758]
2023-05-24 02:56:54.810: epoch 44:	0.00629941  	0.10072089  	0.04779374  	0.03619676  	0.03661145  
2023-05-24 03:02:34.566: [iter 45 : loss : 0.4211 = 0.0057 + 0.4004 + 0.0149, time: 338.247295]
2023-05-24 03:03:20.349: epoch 45:	0.00630258  	0.10081632  	0.04780200  	0.03618411  	0.03659584  
2023-05-24 03:09:35.511: [iter 46 : loss : 0.4210 = 0.0057 + 0.4004 + 0.0150, time: 373.658825]
2023-05-24 03:10:23.386: epoch 46:	0.00631766  	0.10109982  	0.04787956  	0.03619372  	0.03661416  
2023-05-24 03:10:23.386: Found a better model.
2023-05-24 03:10:23.386: Save model to file as pretrain.
2023-05-24 03:16:04.086: [iter 47 : loss : 0.4211 = 0.0057 + 0.4004 + 0.0150, time: 338.163279]
2023-05-24 03:16:51.808: epoch 47:	0.00631580  	0.10095360  	0.04784373  	0.03616161  	0.03658191  
2023-05-24 03:22:28.014: [iter 48 : loss : 0.4210 = 0.0057 + 0.4004 + 0.0150, time: 334.685340]
2023-05-24 03:23:15.918: epoch 48:	0.00632064  	0.10122526  	0.04784277  	0.03608696  	0.03650292  
2023-05-24 03:23:15.918: Found a better model.
2023-05-24 03:23:15.919: Save model to file as pretrain.
2023-05-24 03:28:51.568: [iter 49 : loss : 0.4210 = 0.0057 + 0.4003 + 0.0150, time: 333.144953]
2023-05-24 03:29:37.581: epoch 49:	0.00632548  	0.10126701  	0.04795879  	0.03623691  	0.03666222  
2023-05-24 03:29:37.581: Found a better model.
2023-05-24 03:29:37.581: Save model to file as pretrain.
2023-05-24 03:35:54.077: [iter 50 : loss : 0.4210 = 0.0057 + 0.4003 + 0.0150, time: 373.969321]
2023-05-24 03:36:41.059: epoch 50:	0.00634261  	0.10157626  	0.04800856  	0.03625184  	0.03665329  
2023-05-24 03:36:41.068: Found a better model.
2023-05-24 03:36:41.068: Save model to file as pretrain.
2023-05-24 03:42:16.560: [iter 51 : loss : 0.4209 = 0.0056 + 0.4003 + 0.0150, time: 332.997565]
2023-05-24 03:43:03.437: epoch 51:	0.00634354  	0.10161142  	0.04801967  	0.03622825  	0.03664288  
2023-05-24 03:43:03.437: Found a better model.
2023-05-24 03:43:03.437: Save model to file as pretrain.
2023-05-24 03:48:34.071: [iter 52 : loss : 0.4208 = 0.0055 + 0.4003 + 0.0150, time: 328.125739]
2023-05-24 03:49:21.220: epoch 52:	0.00635061  	0.10166150  	0.04809766  	0.03630507  	0.03672767  
2023-05-24 03:49:21.220: Found a better model.
2023-05-24 03:49:21.220: Save model to file as pretrain.
2023-05-24 03:54:57.543: [iter 53 : loss : 0.4207 = 0.0054 + 0.4003 + 0.0150, time: 333.861118]
2023-05-24 03:55:42.371: epoch 53:	0.00635527  	0.10185275  	0.04823556  	0.03646825  	0.03689067  
2023-05-24 03:55:42.371: Found a better model.
2023-05-24 03:55:42.371: Save model to file as pretrain.
2023-05-24 04:01:19.545: [iter 54 : loss : 0.4209 = 0.0056 + 0.4003 + 0.0150, time: 334.666141]
2023-05-24 04:02:08.357: epoch 54:	0.00634894  	0.10169695  	0.04816349  	0.03643179  	0.03685459  
2023-05-24 04:08:21.812: [iter 55 : loss : 0.4208 = 0.0055 + 0.4003 + 0.0150, time: 371.937904]
2023-05-24 04:09:10.377: epoch 55:	0.00636011  	0.10196799  	0.04823454  	0.03642061  	0.03685947  
2023-05-24 04:09:10.377: Found a better model.
2023-05-24 04:09:10.377: Save model to file as pretrain.
2023-05-24 04:14:45.813: [iter 56 : loss : 0.4208 = 0.0055 + 0.4003 + 0.0150, time: 332.939412]
2023-05-24 04:15:34.263: epoch 56:	0.00637481  	0.10202651  	0.04836009  	0.03656711  	0.03701531  
2023-05-24 04:15:34.263: Found a better model.
2023-05-24 04:15:34.263: Save model to file as pretrain.
2023-05-24 04:21:22.266: [iter 57 : loss : 0.4207 = 0.0054 + 0.4003 + 0.0150, time: 345.493725]
2023-05-24 04:22:10.326: epoch 57:	0.00638431  	0.10226609  	0.04848360  	0.03669000  	0.03712375  
2023-05-24 04:22:10.326: Found a better model.
2023-05-24 04:22:10.326: Save model to file as pretrain.
2023-05-24 04:27:41.176: [iter 58 : loss : 0.4208 = 0.0055 + 0.4003 + 0.0150, time: 328.326377]
2023-05-24 04:28:29.994: epoch 58:	0.00638784  	0.10231420  	0.04850565  	0.03670502  	0.03712500  
2023-05-24 04:28:29.994: Found a better model.
2023-05-24 04:28:29.994: Save model to file as pretrain.
2023-05-24 04:34:42.769: [iter 59 : loss : 0.4207 = 0.0054 + 0.4003 + 0.0150, time: 370.256571]
2023-05-24 04:35:30.637: epoch 59:	0.00638002  	0.10224885  	0.04842238  	0.03662155  	0.03702713  
2023-05-24 04:41:00.825: [iter 60 : loss : 0.4206 = 0.0054 + 0.4003 + 0.0150, time: 328.701022]
2023-05-24 04:41:49.101: epoch 60:	0.00638859  	0.10238388  	0.04845202  	0.03659137  	0.03702977  
2023-05-24 04:41:49.101: Found a better model.
2023-05-24 04:41:49.101: Save model to file as pretrain.
2023-05-24 04:48:01.861: [iter 61 : loss : 0.4206 = 0.0053 + 0.4003 + 0.0150, time: 370.265589]
2023-05-24 04:48:49.686: epoch 61:	0.00640050  	0.10258506  	0.04853727  	0.03664236  	0.03706574  
2023-05-24 04:48:49.686: Found a better model.
2023-05-24 04:48:49.686: Save model to file as pretrain.
2023-05-24 04:55:04.291: [iter 62 : loss : 0.4207 = 0.0055 + 0.4003 + 0.0150, time: 372.079525]
2023-05-24 04:55:52.003: epoch 62:	0.00641651  	0.10272565  	0.04861474  	0.03671486  	0.03714539  
2023-05-24 04:55:52.003: Found a better model.
2023-05-24 04:55:52.003: Save model to file as pretrain.
2023-05-24 05:01:29.911: [iter 63 : loss : 0.4205 = 0.0052 + 0.4003 + 0.0150, time: 335.421032]
2023-05-24 05:02:18.223: epoch 63:	0.00642488  	0.10294292  	0.04868023  	0.03676607  	0.03719201  
2023-05-24 05:02:18.226: Found a better model.
2023-05-24 05:02:18.226: Save model to file as pretrain.
2023-05-24 05:08:33.205: [iter 64 : loss : 0.4205 = 0.0052 + 0.4003 + 0.0150, time: 372.464916]
2023-05-24 05:09:21.411: epoch 64:	0.00642432  	0.10288006  	0.04876446  	0.03687917  	0.03732442  
2023-05-24 05:14:54.502: [iter 65 : loss : 0.4206 = 0.0053 + 0.4003 + 0.0150, time: 331.590017]
2023-05-24 05:15:42.320: epoch 65:	0.00642898  	0.10302775  	0.04878368  	0.03688372  	0.03732567  
2023-05-24 05:15:42.320: Found a better model.
2023-05-24 05:15:42.320: Save model to file as pretrain.
2023-05-24 05:21:56.848: [iter 66 : loss : 0.4205 = 0.0053 + 0.4003 + 0.0150, time: 372.020133]
2023-05-24 05:22:45.225: epoch 66:	0.00643140  	0.10304401  	0.04878123  	0.03687850  	0.03730775  
2023-05-24 05:22:45.225: Found a better model.
2023-05-24 05:22:45.225: Save model to file as pretrain.
2023-05-24 05:28:17.933: [iter 67 : loss : 0.4205 = 0.0053 + 0.4003 + 0.0150, time: 330.246439]
2023-05-24 05:29:03.537: epoch 67:	0.00643382  	0.10306744  	0.04884330  	0.03692487  	0.03737033  
2023-05-24 05:29:03.537: Found a better model.
2023-05-24 05:29:03.537: Save model to file as pretrain.
2023-05-24 05:34:36.097: [iter 68 : loss : 0.4205 = 0.0053 + 0.4003 + 0.0150, time: 330.008881]
2023-05-24 05:35:24.464: epoch 68:	0.00643624  	0.10314857  	0.04889160  	0.03700381  	0.03742288  
2023-05-24 05:35:24.464: Found a better model.
2023-05-24 05:35:24.465: Save model to file as pretrain.
2023-05-24 05:41:00.886: [iter 69 : loss : 0.4205 = 0.0053 + 0.4003 + 0.0150, time: 333.898803]
2023-05-24 05:41:49.640: epoch 69:	0.00643308  	0.10308633  	0.04888796  	0.03697814  	0.03740782  
2023-05-24 05:47:27.277: [iter 70 : loss : 0.4205 = 0.0052 + 0.4003 + 0.0150, time: 336.121334]
2023-05-24 05:48:15.412: epoch 70:	0.00644945  	0.10337018  	0.04904536  	0.03711571  	0.03753157  
2023-05-24 05:48:15.412: Found a better model.
2023-05-24 05:48:15.412: Save model to file as pretrain.
2023-05-24 05:53:52.558: [iter 71 : loss : 0.4204 = 0.0052 + 0.4003 + 0.0150, time: 334.644398]
2023-05-24 05:54:37.155: epoch 71:	0.00645113  	0.10340853  	0.04907103  	0.03712312  	0.03756822  
2023-05-24 05:54:37.155: Found a better model.
2023-05-24 05:54:37.155: Save model to file as pretrain.
2023-05-24 06:00:14.214: [iter 72 : loss : 0.4205 = 0.0053 + 0.4003 + 0.0150, time: 334.582457]
2023-05-24 06:01:02.668: epoch 72:	0.00644313  	0.10319109  	0.04904266  	0.03714966  	0.03757335  
2023-05-24 06:06:40.585: [iter 73 : loss : 0.4204 = 0.0052 + 0.4003 + 0.0150, time: 336.390758]
2023-05-24 06:07:27.468: epoch 73:	0.00645857  	0.10351588  	0.04912901  	0.03716445  	0.03759682  
2023-05-24 06:07:27.468: Found a better model.
2023-05-24 06:07:27.468: Save model to file as pretrain.
2023-05-24 06:13:06.198: [iter 74 : loss : 0.4205 = 0.0053 + 0.4003 + 0.0150, time: 336.235043]
2023-05-24 06:13:44.769: epoch 74:	0.00647533  	0.10376596  	0.04920063  	0.03721595  	0.03765931  
2023-05-24 06:13:44.771: Found a better model.
2023-05-24 06:13:44.771: Save model to file as pretrain.
2023-05-24 06:19:58.720: [iter 75 : loss : 0.4204 = 0.0052 + 0.4003 + 0.0150, time: 371.534078]
2023-05-24 06:20:46.991: epoch 75:	0.00646603  	0.10362620  	0.04918618  	0.03722207  	0.03767079  
2023-05-24 06:26:24.168: [iter 76 : loss : 0.4204 = 0.0052 + 0.4003 + 0.0149, time: 335.610403]
2023-05-24 06:27:11.430: epoch 76:	0.00646323  	0.10354336  	0.04917932  	0.03723579  	0.03769019  
2023-05-24 06:32:47.404: [iter 77 : loss : 0.4204 = 0.0052 + 0.4003 + 0.0150, time: 334.422145]
2023-05-24 06:33:34.544: epoch 77:	0.00645113  	0.10333482  	0.04907696  	0.03714563  	0.03759161  
2023-05-24 06:39:09.029: [iter 78 : loss : 0.4204 = 0.0052 + 0.4003 + 0.0149, time: 332.943549]
2023-05-24 06:39:55.762: epoch 78:	0.00647533  	0.10374670  	0.04916893  	0.03717925  	0.03761295  
2023-05-24 06:45:29.522: [iter 79 : loss : 0.4204 = 0.0052 + 0.4003 + 0.0149, time: 332.194375]
2023-05-24 06:46:17.815: epoch 79:	0.00647216  	0.10361888  	0.04918643  	0.03721771  	0.03766932  
2023-05-24 06:51:55.698: [iter 80 : loss : 0.4204 = 0.0052 + 0.4003 + 0.0150, time: 336.345619]
2023-05-24 06:52:43.018: epoch 80:	0.00648258  	0.10390357  	0.04924475  	0.03722790  	0.03766710  
2023-05-24 06:52:43.019: Found a better model.
2023-05-24 06:52:43.019: Save model to file as pretrain.
2023-05-24 06:58:16.170: [iter 81 : loss : 0.4203 = 0.0051 + 0.4003 + 0.0150, time: 330.677629]
2023-05-24 06:58:54.334: epoch 81:	0.00648557  	0.10395875  	0.04927946  	0.03727047  	0.03772352  
2023-05-24 06:58:54.334: Found a better model.
2023-05-24 06:58:54.335: Save model to file as pretrain.
2023-05-24 07:05:08.212: [iter 82 : loss : 0.4203 = 0.0051 + 0.4003 + 0.0149, time: 371.481005]
2023-05-24 07:05:55.710: epoch 82:	0.00647682  	0.10380074  	0.04918659  	0.03718124  	0.03762173  
2023-05-24 07:11:28.834: [iter 83 : loss : 0.4204 = 0.0052 + 0.4003 + 0.0149, time: 331.618502]
2023-05-24 07:12:17.740: epoch 83:	0.00648855  	0.10390891  	0.04923880  	0.03720013  	0.03765361  
2023-05-24 07:17:50.845: [iter 84 : loss : 0.4203 = 0.0051 + 0.4003 + 0.0150, time: 331.577123]
2023-05-24 07:18:27.245: epoch 84:	0.00650362  	0.10419393  	0.04943690  	0.03739810  	0.03785676  
2023-05-24 07:18:27.245: Found a better model.
2023-05-24 07:18:27.245: Save model to file as pretrain.
2023-05-24 07:24:41.677: [iter 85 : loss : 0.4203 = 0.0051 + 0.4003 + 0.0149, time: 372.036251]
2023-05-24 07:25:29.778: epoch 85:	0.00649320  	0.10405239  	0.04931558  	0.03727298  	0.03772467  
2023-05-24 07:31:43.895: [iter 86 : loss : 0.4204 = 0.0052 + 0.4003 + 0.0149, time: 372.621053]
2023-05-24 07:32:32.346: epoch 86:	0.00649785  	0.10412543  	0.04940331  	0.03738312  	0.03781375  
2023-05-24 07:38:48.320: [iter 87 : loss : 0.4203 = 0.0051 + 0.4003 + 0.0149, time: 374.442925]
2023-05-24 07:39:36.407: epoch 87:	0.00651013  	0.10418983  	0.04946961  	0.03743200  	0.03787445  
2023-05-24 07:45:15.972: [iter 88 : loss : 0.4203 = 0.0051 + 0.4003 + 0.0149, time: 338.115679]
2023-05-24 07:46:04.351: epoch 88:	0.00652670  	0.10454481  	0.04953284  	0.03741091  	0.03787419  
2023-05-24 07:46:04.360: Found a better model.
2023-05-24 07:46:04.360: Save model to file as pretrain.
2023-05-24 07:51:53.918: [iter 89 : loss : 0.4203 = 0.0051 + 0.4003 + 0.0149, time: 347.030076]
2023-05-24 07:52:37.086: epoch 89:	0.00652037  	0.10439203  	0.04957923  	0.03755032  	0.03800234  
2023-05-24 07:58:15.054: [iter 90 : loss : 0.4202 = 0.0050 + 0.4003 + 0.0149, time: 336.458059]
2023-05-24 07:59:02.968: epoch 90:	0.00652521  	0.10461224  	0.04951634  	0.03743017  	0.03788685  
2023-05-24 07:59:02.968: Found a better model.
2023-05-24 07:59:02.968: Save model to file as pretrain.
2023-05-24 08:04:55.510: [iter 91 : loss : 0.4203 = 0.0051 + 0.4003 + 0.0149, time: 350.084098]
2023-05-24 08:05:42.303: epoch 91:	0.00653638  	0.10469590  	0.04963025  	0.03754511  	0.03799737  
2023-05-24 08:05:42.303: Found a better model.
2023-05-24 08:05:42.303: Save model to file as pretrain.
2023-05-24 08:11:19.331: [iter 92 : loss : 0.4203 = 0.0051 + 0.4003 + 0.0149, time: 334.573925]
2023-05-24 08:12:07.501: epoch 92:	0.00654364  	0.10487836  	0.04958718  	0.03741117  	0.03787383  
2023-05-24 08:12:07.501: Found a better model.
2023-05-24 08:12:07.501: Save model to file as pretrain.
2023-05-24 08:18:23.602: [iter 93 : loss : 0.4203 = 0.0051 + 0.4003 + 0.0149, time: 373.657341]
2023-05-24 08:19:00.468: epoch 93:	0.00653433  	0.10481829  	0.04951486  	0.03733784  	0.03779697  
2023-05-24 08:24:45.757: [iter 94 : loss : 0.4203 = 0.0051 + 0.4002 + 0.0149, time: 343.968200]
2023-05-24 08:25:32.765: epoch 94:	0.00654513  	0.10491131  	0.04965702  	0.03749223  	0.03793817  
2023-05-24 08:25:32.766: Found a better model.
2023-05-24 08:25:32.766: Save model to file as pretrain.
2023-05-24 08:31:05.644: [iter 95 : loss : 0.4203 = 0.0051 + 0.4003 + 0.0149, time: 330.384037]
2023-05-24 08:31:54.347: epoch 95:	0.00656374  	0.10517748  	0.04982273  	0.03765401  	0.03808349  
2023-05-24 08:31:54.347: Found a better model.
2023-05-24 08:31:54.347: Save model to file as pretrain.
2023-05-24 08:37:25.365: [iter 96 : loss : 0.4202 = 0.0051 + 0.4002 + 0.0149, time: 328.551224]
2023-05-24 08:38:12.219: epoch 96:	0.00657268  	0.10538269  	0.04992957  	0.03776932  	0.03821837  
2023-05-24 08:38:12.219: Found a better model.
2023-05-24 08:38:12.219: Save model to file as pretrain.
2023-05-24 08:43:45.116: [iter 97 : loss : 0.4202 = 0.0050 + 0.4003 + 0.0149, time: 330.378620]
2023-05-24 08:44:32.994: epoch 97:	0.00655407  	0.10511528  	0.04983222  	0.03769317  	0.03814000  
2023-05-24 08:50:25.082: [iter 98 : loss : 0.4202 = 0.0050 + 0.4003 + 0.0149, time: 350.587525]
2023-05-24 08:51:13.321: epoch 98:	0.00654829  	0.10494882  	0.04982975  	0.03771280  	0.03816134  
2023-05-24 08:57:29.092: [iter 99 : loss : 0.4202 = 0.0050 + 0.4003 + 0.0149, time: 374.250566]
2023-05-24 08:58:01.199: epoch 99:	0.00654755  	0.10487870  	0.04977361  	0.03765987  	0.03811493  
2023-05-24 09:04:14.541: [iter 100 : loss : 0.4202 = 0.0050 + 0.4003 + 0.0149, time: 372.029011]
2023-05-24 09:05:02.883: epoch 100:	0.00656691  	0.10523406  	0.04993231  	0.03778892  	0.03822688  
2023-05-24 09:10:41.070: [iter 101 : loss : 0.4202 = 0.0051 + 0.4002 + 0.0149, time: 336.654786]
2023-05-24 09:11:29.428: epoch 101:	0.00656988  	0.10528602  	0.04988428  	0.03771976  	0.03816826  
2023-05-24 09:17:03.301: [iter 102 : loss : 0.4202 = 0.0051 + 0.4002 + 0.0149, time: 332.366267]
2023-05-24 09:17:37.587: epoch 102:	0.00657249  	0.10535577  	0.04992324  	0.03776482  	0.03822796  
2023-05-24 09:23:13.557: [iter 103 : loss : 0.4202 = 0.0050 + 0.4003 + 0.0149, time: 334.633285]
2023-05-24 09:24:01.295: epoch 103:	0.00657695  	0.10540551  	0.04998114  	0.03778891  	0.03825509  
2023-05-24 09:24:01.296: Found a better model.
2023-05-24 09:24:01.296: Save model to file as pretrain.
2023-05-24 09:29:40.079: [iter 104 : loss : 0.4202 = 0.0050 + 0.4002 + 0.0149, time: 336.326334]
2023-05-24 09:30:28.154: epoch 104:	0.00656821  	0.10529374  	0.04993489  	0.03778816  	0.03823422  
2023-05-24 09:36:19.028: [iter 105 : loss : 0.4202 = 0.0050 + 0.4002 + 0.0149, time: 349.354064]
2023-05-24 09:37:01.429: epoch 105:	0.00657268  	0.10533290  	0.04994170  	0.03778888  	0.03823985  
2023-05-24 09:42:37.324: [iter 106 : loss : 0.4202 = 0.0050 + 0.4002 + 0.0149, time: 334.563248]
2023-05-24 09:43:24.947: epoch 106:	0.00656914  	0.10527360  	0.04993628  	0.03781190  	0.03827269  
2023-05-24 09:48:56.919: [iter 107 : loss : 0.4202 = 0.0050 + 0.4002 + 0.0149, time: 330.425721]
2023-05-24 09:49:45.344: epoch 107:	0.00658663  	0.10555387  	0.05000331  	0.03777507  	0.03823875  
2023-05-24 09:49:45.344: Found a better model.
2023-05-24 09:49:45.344: Save model to file as pretrain.
2023-05-24 09:56:01.704: [iter 108 : loss : 0.4202 = 0.0051 + 0.4002 + 0.0149, time: 373.917047]
2023-05-24 09:56:39.888: epoch 108:	0.00659408  	0.10555290  	0.04997223  	0.03774633  	0.03820271  
2023-05-24 10:02:39.017: [iter 109 : loss : 0.4202 = 0.0050 + 0.4002 + 0.0149, time: 357.790488]
2023-05-24 10:03:27.255: epoch 109:	0.00658142  	0.10544790  	0.04992019  	0.03766798  	0.03815165  
2023-05-24 10:09:41.159: [iter 110 : loss : 0.4202 = 0.0050 + 0.4002 + 0.0149, time: 372.366989]
2023-05-24 10:10:29.824: epoch 110:	0.00658776  	0.10548569  	0.04996125  	0.03771521  	0.03817366  
2023-05-24 10:16:28.631: [iter 111 : loss : 0.4202 = 0.0051 + 0.4002 + 0.0149, time: 357.293545]
2023-05-24 10:17:16.948: epoch 111:	0.00661102  	0.10598034  	0.05016492  	0.03787114  	0.03835144  
2023-05-24 10:17:16.948: Found a better model.
2023-05-24 10:17:16.948: Save model to file as pretrain.
2023-05-24 10:22:48.185: [iter 112 : loss : 0.4201 = 0.0050 + 0.4002 + 0.0149, time: 328.781594]
2023-05-24 10:23:35.363: epoch 112:	0.00660581  	0.10594413  	0.05011993  	0.03779312  	0.03827025  
2023-05-24 10:29:31.283: [iter 113 : loss : 0.4202 = 0.0050 + 0.4002 + 0.0149, time: 354.411998]
2023-05-24 10:30:18.216: epoch 113:	0.00660358  	0.10587537  	0.05019980  	0.03794122  	0.03842570  
2023-05-24 10:35:52.071: [iter 114 : loss : 0.4201 = 0.0050 + 0.4002 + 0.0149, time: 332.331711]
2023-05-24 10:36:39.759: epoch 114:	0.00661846  	0.10606863  	0.05016407  	0.03783753  	0.03830182  
2023-05-24 10:36:39.759: Found a better model.
2023-05-24 10:36:39.759: Save model to file as pretrain.
2023-05-24 10:42:28.619: [iter 115 : loss : 0.4201 = 0.0050 + 0.4002 + 0.0149, time: 346.364354]
2023-05-24 10:43:13.668: epoch 115:	0.00662145  	0.10617277  	0.05022299  	0.03791168  	0.03835250  
2023-05-24 10:43:13.668: Found a better model.
2023-05-24 10:43:13.668: Save model to file as pretrain.
2023-05-24 10:48:44.813: [iter 116 : loss : 0.4202 = 0.0050 + 0.4002 + 0.0149, time: 328.643274]
2023-05-24 10:49:34.021: epoch 116:	0.00661772  	0.10602943  	0.05014710  	0.03783605  	0.03829350  
2023-05-24 10:55:08.068: [iter 117 : loss : 0.4202 = 0.0051 + 0.4002 + 0.0149, time: 332.531300]
2023-05-24 10:55:57.013: epoch 117:	0.00663485  	0.10628028  	0.05024507  	0.03789485  	0.03834581  
2023-05-24 10:55:57.013: Found a better model.
2023-05-24 10:55:57.013: Save model to file as pretrain.
2023-05-24 11:02:12.541: [iter 118 : loss : 0.4202 = 0.0051 + 0.4002 + 0.0149, time: 373.109182]
2023-05-24 11:02:59.238: epoch 118:	0.00662294  	0.10607512  	0.05024869  	0.03797968  	0.03842761  
2023-05-24 11:09:12.423: [iter 119 : loss : 0.4201 = 0.0050 + 0.4002 + 0.0149, time: 371.715351]
2023-05-24 11:09:59.949: epoch 119:	0.00662629  	0.10615144  	0.05018390  	0.03787572  	0.03833225  
2023-05-24 11:15:36.640: [iter 120 : loss : 0.4202 = 0.0051 + 0.4002 + 0.0149, time: 335.274327]
2023-05-24 11:16:24.047: epoch 120:	0.00662462  	0.10616741  	0.05022104  	0.03790942  	0.03837381  
2023-05-24 11:21:58.618: [iter 121 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0149, time: 333.045783]
2023-05-24 11:22:47.746: epoch 121:	0.00662498  	0.10609176  	0.05018571  	0.03788382  	0.03833020  
2023-05-24 11:28:25.932: [iter 122 : loss : 0.4201 = 0.0050 + 0.4002 + 0.0149, time: 336.675458]
2023-05-24 11:29:14.857: epoch 122:	0.00662722  	0.10610711  	0.05022517  	0.03793826  	0.03839363  
2023-05-24 11:34:51.330: [iter 123 : loss : 0.4201 = 0.0050 + 0.4002 + 0.0149, time: 334.980268]
2023-05-24 11:35:40.362: epoch 123:	0.00662219  	0.10601903  	0.05021724  	0.03795906  	0.03841501  
2023-05-24 11:41:18.997: [iter 124 : loss : 0.4201 = 0.0050 + 0.4002 + 0.0149, time: 337.129319]
2023-05-24 11:41:52.370: epoch 124:	0.00663355  	0.10625760  	0.05035846  	0.03809153  	0.03854004  
2023-05-24 11:47:28.840: [iter 125 : loss : 0.4201 = 0.0049 + 0.4002 + 0.0149, time: 334.968571]
2023-05-24 11:48:17.462: epoch 125:	0.00663653  	0.10627295  	0.05031728  	0.03800648  	0.03846904  
2023-05-24 11:53:55.669: [iter 126 : loss : 0.4201 = 0.0050 + 0.4002 + 0.0149, time: 336.671530]
2023-05-24 11:54:43.317: epoch 126:	0.00663504  	0.10618781  	0.05034311  	0.03809547  	0.03855843  
2023-05-24 12:00:15.341: [iter 127 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0149, time: 330.512789]
2023-05-24 12:01:02.753: epoch 127:	0.00664676  	0.10644407  	0.05042185  	0.03812055  	0.03857998  
2023-05-24 12:01:02.753: Found a better model.
2023-05-24 12:01:02.753: Save model to file as pretrain.
2023-05-24 12:06:36.124: [iter 128 : loss : 0.4201 = 0.0050 + 0.4002 + 0.0149, time: 330.840938]
2023-05-24 12:07:25.240: epoch 128:	0.00664155  	0.10630694  	0.05042156  	0.03816498  	0.03862625  
2023-05-24 12:13:16.671: [iter 129 : loss : 0.4201 = 0.0049 + 0.4002 + 0.0149, time: 349.908905]
2023-05-24 12:14:04.568: epoch 129:	0.00665793  	0.10672975  	0.05050737  	0.03814489  	0.03861558  
2023-05-24 12:14:04.568: Found a better model.
2023-05-24 12:14:04.568: Save model to file as pretrain.
2023-05-24 12:19:39.413: [iter 130 : loss : 0.4201 = 0.0050 + 0.4002 + 0.0149, time: 332.320702]
2023-05-24 12:20:28.065: epoch 130:	0.00665346  	0.10655538  	0.05042968  	0.03808056  	0.03854526  
2023-05-24 12:26:04.135: [iter 131 : loss : 0.4201 = 0.0050 + 0.4002 + 0.0149, time: 334.526966]
2023-05-24 12:26:52.425: epoch 131:	0.00665960  	0.10665414  	0.05050989  	0.03816059  	0.03862917  
2023-05-24 12:32:26.934: [iter 132 : loss : 0.4201 = 0.0049 + 0.4002 + 0.0149, time: 332.917012]
2023-05-24 12:33:13.024: epoch 132:	0.00666463  	0.10678883  	0.05053171  	0.03816365  	0.03863785  
2023-05-24 12:33:13.024: Found a better model.
2023-05-24 12:33:13.024: Save model to file as pretrain.
2023-05-24 12:39:29.874: [iter 133 : loss : 0.4201 = 0.0050 + 0.4002 + 0.0149, time: 374.300887]
2023-05-24 12:40:18.426: epoch 133:	0.00665402  	0.10651203  	0.05046668  	0.03813162  	0.03858659  
2023-05-24 12:46:33.032: [iter 134 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0149, time: 373.038395]
2023-05-24 12:47:21.418: epoch 134:	0.00667059  	0.10682234  	0.05050548  	0.03809286  	0.03855992  
2023-05-24 12:47:21.418: Found a better model.
2023-05-24 12:47:21.418: Save model to file as pretrain.
2023-05-24 12:52:57.976: [iter 135 : loss : 0.4201 = 0.0050 + 0.4002 + 0.0149, time: 334.010738]
2023-05-24 12:53:46.475: epoch 135:	0.00666519  	0.10675592  	0.05049706  	0.03808102  	0.03854116  
2023-05-24 12:59:19.429: [iter 136 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0149, time: 331.388321]
2023-05-24 13:00:07.617: epoch 136:	0.00667841  	0.10698554  	0.05055139  	0.03813543  	0.03857864  
2023-05-24 13:00:07.618: Found a better model.
2023-05-24 13:00:07.618: Save model to file as pretrain.
2023-05-24 13:05:43.203: [iter 137 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0149, time: 333.061359]
2023-05-24 13:06:32.468: epoch 137:	0.00667878  	0.10688610  	0.05059059  	0.03820598  	0.03867188  
2023-05-24 13:12:04.686: [iter 138 : loss : 0.4201 = 0.0050 + 0.4002 + 0.0149, time: 330.668539]
2023-05-24 13:12:37.896: epoch 138:	0.00668511  	0.10701717  	0.05070527  	0.03835837  	0.03882684  
2023-05-24 13:12:37.897: Found a better model.
2023-05-24 13:12:37.897: Save model to file as pretrain.
2023-05-24 13:18:12.145: [iter 139 : loss : 0.4200 = 0.0050 + 0.4002 + 0.0149, time: 331.726753]
2023-05-24 13:19:00.738: epoch 139:	0.00667413  	0.10680944  	0.05069302  	0.03841127  	0.03887259  
2023-05-24 13:24:37.172: [iter 140 : loss : 0.4200 = 0.0050 + 0.4002 + 0.0149, time: 334.859553]
2023-05-24 13:25:24.275: epoch 140:	0.00666352  	0.10666418  	0.05054497  	0.03821125  	0.03867750  
2023-05-24 13:31:02.027: [iter 141 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0149, time: 336.070175]
2023-05-24 13:31:51.409: epoch 141:	0.00667004  	0.10683011  	0.05057330  	0.03821411  	0.03867387  
2023-05-24 13:38:10.228: [iter 142 : loss : 0.4201 = 0.0050 + 0.4002 + 0.0149, time: 377.316558]
2023-05-24 13:39:05.726: epoch 142:	0.00665365  	0.10647053  	0.05047728  	0.03818506  	0.03864799  
2023-05-24 13:45:20.942: [iter 143 : loss : 0.4201 = 0.0050 + 0.4002 + 0.0149, time: 373.700608]
2023-05-24 13:46:08.846: epoch 143:	0.00666036  	0.10661016  	0.05059425  	0.03828498  	0.03875640  
2023-05-24 13:51:45.525: [iter 144 : loss : 0.4201 = 0.0050 + 0.4002 + 0.0149, time: 335.156982]
2023-05-24 13:52:30.676: epoch 144:	0.00666333  	0.10674129  	0.05062598  	0.03832581  	0.03879319  
2023-05-24 13:58:49.878: [iter 145 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0149, time: 377.700968]
2023-05-24 13:59:38.452: epoch 145:	0.00666818  	0.10679185  	0.05063467  	0.03834330  	0.03881269  
2023-05-24 14:05:54.206: [iter 146 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0149, time: 374.317138]
2023-05-24 14:06:41.620: epoch 146:	0.00668809  	0.10714649  	0.05073511  	0.03838110  	0.03885898  
2023-05-24 14:06:41.620: Found a better model.
2023-05-24 14:06:41.620: Save model to file as pretrain.
2023-05-24 14:12:14.867: [iter 147 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0149, time: 330.753660]
2023-05-24 14:12:53.851: epoch 147:	0.00667878  	0.10692388  	0.05064366  	0.03828949  	0.03876387  
2023-05-24 14:18:27.946: [iter 148 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0149, time: 332.774692]
2023-05-24 14:19:16.798: epoch 148:	0.00666631  	0.10682936  	0.05056857  	0.03823085  	0.03869409  
2023-05-24 14:24:52.081: [iter 149 : loss : 0.4200 = 0.0050 + 0.4002 + 0.0149, time: 333.747396]
2023-05-24 14:25:28.179: epoch 149:	0.00667785  	0.10698903  	0.05066594  	0.03827620  	0.03875371  
2023-05-24 14:31:00.868: [iter 150 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0149, time: 331.179720]
2023-05-24 14:31:48.975: epoch 150:	0.00666650  	0.10674423  	0.05062132  	0.03829490  	0.03876682  
2023-05-24 14:38:06.104: [iter 151 : loss : 0.4201 = 0.0050 + 0.4002 + 0.0149, time: 375.608405]
2023-05-24 14:38:53.575: epoch 151:	0.00666724  	0.10672596  	0.05061165  	0.03828603  	0.03874251  
2023-05-24 14:45:11.023: [iter 152 : loss : 0.4201 = 0.0050 + 0.4002 + 0.0149, time: 375.966619]
2023-05-24 14:45:48.751: epoch 152:	0.00666482  	0.10671342  	0.05060149  	0.03826198  	0.03872713  
2023-05-24 14:51:25.350: [iter 153 : loss : 0.4201 = 0.0050 + 0.4002 + 0.0149, time: 335.088202]
2023-05-24 14:52:14.441: epoch 153:	0.00666072  	0.10668396  	0.05060121  	0.03830144  	0.03875606  
2023-05-24 14:57:51.156: [iter 154 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0148, time: 335.178127]
2023-05-24 14:58:39.134: epoch 154:	0.00666985  	0.10672012  	0.05067215  	0.03837233  	0.03881701  
2023-05-24 15:04:55.207: [iter 155 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0148, time: 374.565341]
2023-05-24 15:05:41.012: epoch 155:	0.00668827  	0.10698920  	0.05073941  	0.03840642  	0.03887123  
2023-05-24 15:11:20.200: [iter 156 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0148, time: 337.704256]
2023-05-24 15:12:08.728: epoch 156:	0.00668380  	0.10701621  	0.05074793  	0.03841158  	0.03887878  
2023-05-24 15:17:45.532: [iter 157 : loss : 0.4200 = 0.0050 + 0.4002 + 0.0148, time: 335.293108]
2023-05-24 15:18:34.453: epoch 157:	0.00669051  	0.10718910  	0.05076177  	0.03839890  	0.03885881  
2023-05-24 15:18:34.455: Found a better model.
2023-05-24 15:18:34.455: Save model to file as pretrain.
2023-05-24 15:24:10.732: [iter 158 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0149, time: 333.777769]
2023-05-24 15:24:58.999: epoch 158:	0.00669349  	0.10721017  	0.05075833  	0.03836771  	0.03883633  
2023-05-24 15:24:58.999: Found a better model.
2023-05-24 15:24:59.000: Save model to file as pretrain.
2023-05-24 15:31:19.402: [iter 159 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0149, time: 377.941368]
2023-05-24 15:32:06.901: epoch 159:	0.00669553  	0.10724083  	0.05084702  	0.03848791  	0.03894624  
2023-05-24 15:32:06.901: Found a better model.
2023-05-24 15:32:06.901: Save model to file as pretrain.
2023-05-24 15:38:25.578: [iter 160 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0149, time: 376.147580]
2023-05-24 15:39:13.816: epoch 160:	0.00669666  	0.10736097  	0.05091229  	0.03854315  	0.03900127  
2023-05-24 15:39:13.816: Found a better model.
2023-05-24 15:39:13.816: Save model to file as pretrain.
2023-05-24 15:45:31.982: [iter 161 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0149, time: 375.622637]
2023-05-24 15:46:18.636: epoch 161:	0.00669739  	0.10721221  	0.05086908  	0.03850959  	0.03897242  
2023-05-24 15:52:34.439: [iter 162 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0149, time: 374.294213]
2023-05-24 15:53:22.478: epoch 162:	0.00669665  	0.10716645  	0.05090309  	0.03854557  	0.03902644  
2023-05-24 15:59:40.995: [iter 163 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0149, time: 376.990301]
2023-05-24 16:00:29.518: epoch 163:	0.00668809  	0.10710533  	0.05087181  	0.03851123  	0.03899261  
2023-05-24 16:06:03.670: [iter 164 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0148, time: 332.680188]
2023-05-24 16:06:47.541: epoch 164:	0.00669200  	0.10723194  	0.05087828  	0.03848028  	0.03895443  
2023-05-24 16:12:23.460: [iter 165 : loss : 0.4200 = 0.0050 + 0.4002 + 0.0149, time: 334.584383]
2023-05-24 16:13:11.059: epoch 165:	0.00670876  	0.10749154  	0.05099820  	0.03857374  	0.03904499  
2023-05-24 16:13:11.070: Found a better model.
2023-05-24 16:13:11.070: Save model to file as pretrain.
2023-05-24 16:18:44.200: [iter 166 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0149, time: 330.609029]
2023-05-24 16:19:32.448: epoch 166:	0.00671062  	0.10738318  	0.05100523  	0.03865868  	0.03912441  
2023-05-24 16:25:07.339: [iter 167 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0148, time: 333.409380]
2023-05-24 16:25:56.187: epoch 167:	0.00670782  	0.10747082  	0.05103270  	0.03867003  	0.03912519  
2023-05-24 16:32:13.712: [iter 168 : loss : 0.4201 = 0.0050 + 0.4002 + 0.0148, time: 376.017551]
2023-05-24 16:33:03.317: epoch 168:	0.00671322  	0.10766176  	0.05106286  	0.03870243  	0.03914112  
2023-05-24 16:33:03.317: Found a better model.
2023-05-24 16:33:03.317: Save model to file as pretrain.
2023-05-24 16:38:37.754: [iter 169 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 331.875018]
2023-05-24 16:39:25.234: epoch 169:	0.00670392  	0.10747589  	0.05103089  	0.03868125  	0.03912245  
2023-05-24 16:45:00.151: [iter 170 : loss : 0.4200 = 0.0050 + 0.4002 + 0.0148, time: 333.386423]
2023-05-24 16:45:48.915: epoch 170:	0.00670206  	0.10733300  	0.05098352  	0.03861838  	0.03909605  
2023-05-24 16:51:25.335: [iter 171 : loss : 0.4199 = 0.0048 + 0.4002 + 0.0149, time: 334.947329]
2023-05-24 16:52:14.172: epoch 171:	0.00670559  	0.10745975  	0.05101050  	0.03862638  	0.03909582  
2023-05-24 16:57:40.417: [iter 172 : loss : 0.4200 = 0.0050 + 0.4002 + 0.0148, time: 324.723490]
2023-05-24 16:58:27.611: epoch 172:	0.00670522  	0.10737419  	0.05095112  	0.03857492  	0.03903251  
2023-05-24 17:04:01.176: [iter 173 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 332.057061]
2023-05-24 17:04:48.764: epoch 173:	0.00671006  	0.10744397  	0.05100924  	0.03863103  	0.03909541  
2023-05-24 17:10:20.793: [iter 174 : loss : 0.4200 = 0.0050 + 0.4002 + 0.0148, time: 330.532559]
2023-05-24 17:11:13.169: epoch 174:	0.00670932  	0.10754376  	0.05102061  	0.03861271  	0.03906146  
2023-05-24 17:17:01.151: [iter 175 : loss : 0.4199 = 0.0048 + 0.4002 + 0.0148, time: 346.493047]
2023-05-24 17:17:49.884: epoch 175:	0.00671825  	0.10766267  	0.05112577  	0.03875386  	0.03921440  
2023-05-24 17:17:49.884: Found a better model.
2023-05-24 17:17:49.884: Save model to file as pretrain.
2023-05-24 17:23:27.661: [iter 176 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0148, time: 335.260928]
2023-05-24 17:24:16.483: epoch 176:	0.00672011  	0.10781894  	0.05117052  	0.03878714  	0.03922210  
2023-05-24 17:24:16.492: Found a better model.
2023-05-24 17:24:16.492: Save model to file as pretrain.
2023-05-24 17:30:34.885: [iter 177 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 375.840671]
2023-05-24 17:31:21.157: epoch 177:	0.00672701  	0.10782809  	0.05118001  	0.03877200  	0.03922322  
2023-05-24 17:31:21.158: Found a better model.
2023-05-24 17:31:21.158: Save model to file as pretrain.
2023-05-24 17:37:07.188: [iter 178 : loss : 0.4200 = 0.0050 + 0.4002 + 0.0148, time: 343.470813]
2023-05-24 17:37:55.774: epoch 178:	0.00669945  	0.10740620  	0.05109308  	0.03873581  	0.03920636  
2023-05-24 17:43:32.653: [iter 179 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0148, time: 335.362921]
2023-05-24 17:44:21.295: epoch 179:	0.00671286  	0.10762987  	0.05110130  	0.03870884  	0.03917464  
2023-05-24 17:49:53.829: [iter 180 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0148, time: 331.077690]
2023-05-24 17:50:39.194: epoch 180:	0.00671695  	0.10767820  	0.05107877  	0.03864846  	0.03910195  
2023-05-24 17:56:11.606: [iter 181 : loss : 0.4200 = 0.0050 + 0.4002 + 0.0148, time: 330.907388]
2023-05-24 17:56:59.548: epoch 181:	0.00672755  	0.10767576  	0.05111641  	0.03866013  	0.03913865  
2023-05-24 18:02:32.136: [iter 182 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0148, time: 331.046096]
2023-05-24 18:03:20.801: epoch 182:	0.00672904  	0.10762500  	0.05107905  	0.03861601  	0.03910271  
2023-05-24 18:09:38.160: [iter 183 : loss : 0.4199 = 0.0048 + 0.4002 + 0.0148, time: 375.819853]
2023-05-24 18:10:15.462: epoch 183:	0.00670502  	0.10738944  	0.05101031  	0.03860317  	0.03907293  
2023-05-24 18:15:51.585: [iter 184 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 334.757942]
2023-05-24 18:16:39.455: epoch 184:	0.00672327  	0.10780440  	0.05108827  	0.03862089  	0.03908609  
2023-05-24 18:22:21.064: [iter 185 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 340.101875]
2023-05-24 18:23:10.023: epoch 185:	0.00672401  	0.10778213  	0.05110171  	0.03865156  	0.03911807  
2023-05-24 18:28:46.605: [iter 186 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0148, time: 335.017664]
2023-05-24 18:29:33.854: epoch 186:	0.00673388  	0.10778890  	0.05113867  	0.03872411  	0.03918869  
2023-05-24 18:35:08.488: [iter 187 : loss : 0.4199 = 0.0048 + 0.4002 + 0.0148, time: 333.098695]
2023-05-24 18:35:57.334: epoch 187:	0.00671545  	0.10751113  	0.05104924  	0.03867049  	0.03914111  
2023-05-24 18:41:29.558: [iter 188 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 330.685168]
2023-05-24 18:42:17.406: epoch 188:	0.00675250  	0.10813823  	0.05115048  	0.03865304  	0.03910550  
2023-05-24 18:42:17.406: Found a better model.
2023-05-24 18:42:17.406: Save model to file as pretrain.
2023-05-24 18:47:53.734: [iter 189 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0148, time: 333.757438]
2023-05-24 18:48:42.084: epoch 189:	0.00672495  	0.10776844  	0.05103916  	0.03861430  	0.03907866  
2023-05-24 18:54:20.694: [iter 190 : loss : 0.4199 = 0.0048 + 0.4002 + 0.0148, time: 337.046386]
2023-05-24 18:55:09.496: epoch 190:	0.00672811  	0.10775178  	0.05100518  	0.03854553  	0.03900985  
2023-05-24 19:00:41.648: [iter 191 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 330.575758]
2023-05-24 19:01:15.162: epoch 191:	0.00675454  	0.10819688  	0.05117491  	0.03865642  	0.03910661  
2023-05-24 19:01:15.162: Found a better model.
2023-05-24 19:01:15.163: Save model to file as pretrain.
2023-05-24 19:07:30.417: [iter 192 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 372.795479]
2023-05-24 19:08:19.528: epoch 192:	0.00674654  	0.10812300  	0.05124654  	0.03878771  	0.03923173  
2023-05-24 19:14:34.408: [iter 193 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 373.291296]
2023-05-24 19:15:22.466: epoch 193:	0.00677204  	0.10848164  	0.05134935  	0.03880972  	0.03924951  
2023-05-24 19:15:22.466: Found a better model.
2023-05-24 19:15:22.466: Save model to file as pretrain.
2023-05-24 19:21:40.697: [iter 194 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0148, time: 375.694637]
2023-05-24 19:22:29.463: epoch 194:	0.00674561  	0.10811620  	0.05123850  	0.03876376  	0.03921084  
2023-05-24 19:28:05.818: [iter 195 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 334.864619]
2023-05-24 19:28:40.894: epoch 195:	0.00673518  	0.10789214  	0.05112935  	0.03867142  	0.03913567  
2023-05-24 19:34:14.322: [iter 196 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0148, time: 332.073489]
2023-05-24 19:35:02.301: epoch 196:	0.00673239  	0.10781687  	0.05107115  	0.03861874  	0.03906334  
2023-05-24 19:40:39.166: [iter 197 : loss : 0.4200 = 0.0050 + 0.4002 + 0.0148, time: 335.304694]
2023-05-24 19:41:28.021: epoch 197:	0.00672271  	0.10766501  	0.05102400  	0.03860055  	0.03903742  
2023-05-24 19:47:01.615: [iter 198 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 332.040100]
2023-05-24 19:47:50.012: epoch 198:	0.00672979  	0.10780203  	0.05108079  	0.03860667  	0.03905600  
2023-05-24 19:54:08.694: [iter 199 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 377.125162]
2023-05-24 19:54:57.101: epoch 199:	0.00672402  	0.10775755  	0.05108369  	0.03865055  	0.03909678  
2023-05-24 20:01:12.551: [iter 200 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0148, time: 373.916731]
2023-05-24 20:02:00.798: epoch 200:	0.00673277  	0.10781589  	0.05106577  	0.03863167  	0.03908230  
2023-05-24 20:07:34.396: [iter 201 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0148, time: 332.108013]
2023-05-24 20:08:22.266: epoch 201:	0.00672830  	0.10785050  	0.05113640  	0.03871016  	0.03916442  
2023-05-24 20:14:39.611: [iter 202 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 375.867855]
2023-05-24 20:15:20.079: epoch 202:	0.00673704  	0.10798139  	0.05123752  	0.03880363  	0.03926564  
2023-05-24 20:21:38.228: [iter 203 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0148, time: 376.796646]
2023-05-24 20:22:28.191: epoch 203:	0.00674505  	0.10810054  	0.05125279  	0.03877481  	0.03925200  
2023-05-24 20:28:17.528: [iter 204 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 347.804907]
2023-05-24 20:29:04.311: epoch 204:	0.00673575  	0.10790146  	0.05119983  	0.03876648  	0.03923135  
2023-05-24 20:34:42.482: [iter 205 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 336.633832]
2023-05-24 20:35:29.454: epoch 205:	0.00672923  	0.10786504  	0.05117514  	0.03872908  	0.03918932  
2023-05-24 20:41:07.902: [iter 206 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 336.892460]
2023-05-24 20:42:03.723: epoch 206:	0.00675231  	0.10823806  	0.05130537  	0.03878567  	0.03924926  
2023-05-24 20:47:38.295: [iter 207 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 333.004917]
2023-05-24 20:48:26.845: epoch 207:	0.00674989  	0.10807851  	0.05131109  	0.03880873  	0.03927787  
2023-05-24 20:54:43.496: [iter 208 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 375.156666]
2023-05-24 20:55:31.522: epoch 208:	0.00673667  	0.10785375  	0.05118852  	0.03874565  	0.03923663  
2023-05-24 21:01:07.081: [iter 209 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 334.029877]
2023-05-24 21:01:52.674: epoch 209:	0.00672737  	0.10774137  	0.05110100  	0.03863775  	0.03911003  
2023-05-24 21:08:11.043: [iter 210 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 376.876784]
2023-05-24 21:09:00.106: epoch 210:	0.00675194  	0.10804966  	0.05122273  	0.03871609  	0.03920450  
2023-05-24 21:15:17.201: [iter 211 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0148, time: 375.568899]
2023-05-24 21:16:06.205: epoch 211:	0.00674151  	0.10804674  	0.05126240  	0.03879406  	0.03927221  
2023-05-24 21:22:21.165: [iter 212 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 373.490575]
2023-05-24 21:23:09.000: epoch 212:	0.00675436  	0.10816716  	0.05126835  	0.03880606  	0.03927863  
2023-05-24 21:28:47.725: [iter 213 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 337.238774]
2023-05-24 21:29:33.650: epoch 213:	0.00674951  	0.10801498  	0.05119468  	0.03870840  	0.03918980  
2023-05-24 21:35:01.005: [iter 214 : loss : 0.4200 = 0.0050 + 0.4002 + 0.0148, time: 325.845280]
2023-05-24 21:35:50.454: epoch 214:	0.00674244  	0.10795072  	0.05123274  	0.03880006  	0.03927081  
2023-05-24 21:41:27.568: [iter 215 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 335.581795]
2023-05-24 21:42:15.585: epoch 215:	0.00675641  	0.10820681  	0.05124164  	0.03875223  	0.03921514  
2023-05-24 21:47:51.898: [iter 216 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 334.837100]
2023-05-24 21:48:36.947: epoch 216:	0.00675194  	0.10808208  	0.05122156  	0.03872990  	0.03919432  
2023-05-24 21:54:11.576: [iter 217 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 333.101511]
2023-05-24 21:54:58.901: epoch 217:	0.00676181  	0.10831582  	0.05125619  	0.03870726  	0.03915959  
2023-05-24 22:00:31.740: [iter 218 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 331.357711]
2023-05-24 22:01:20.305: epoch 218:	0.00675827  	0.10832267  	0.05130420  	0.03877407  	0.03922632  
2023-05-24 22:06:56.639: [iter 219 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 334.839669]
2023-05-24 22:07:42.822: epoch 219:	0.00675845  	0.10840927  	0.05131658  	0.03877614  	0.03922819  
2023-05-24 22:13:19.292: [iter 220 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 334.945219]
2023-05-24 22:14:07.943: epoch 220:	0.00675733  	0.10820312  	0.05120052  	0.03870533  	0.03916916  
2023-05-24 22:19:44.915: [iter 221 : loss : 0.4199 = 0.0048 + 0.4002 + 0.0148, time: 335.457173]
2023-05-24 22:20:32.620: epoch 221:	0.00675659  	0.10831680  	0.05126924  	0.03873603  	0.03921882  
2023-05-24 22:26:25.269: [iter 222 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 351.131282]
2023-05-24 22:27:10.671: epoch 222:	0.00675883  	0.10828027  	0.05124924  	0.03873296  	0.03920847  
2023-05-24 22:32:47.169: [iter 223 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 335.007242]
2023-05-24 22:33:35.568: epoch 223:	0.00675789  	0.10819229  	0.05126631  	0.03876343  	0.03924585  
2023-05-24 22:39:10.253: [iter 224 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 333.202799]
2023-05-24 22:39:58.302: epoch 224:	0.00675566  	0.10827015  	0.05131191  	0.03882512  	0.03930246  
2023-05-24 22:45:34.772: [iter 225 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 334.924214]
2023-05-24 22:46:15.875: epoch 225:	0.00674933  	0.10820216  	0.05130199  	0.03883179  	0.03929386  
2023-05-24 22:51:49.824: [iter 226 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0148, time: 332.619418]
2023-05-24 22:52:37.702: epoch 226:	0.00675733  	0.10840137  	0.05136481  	0.03881361  	0.03928067  
2023-05-24 22:58:12.775: [iter 227 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 333.574254]
2023-05-24 22:59:01.183: epoch 227:	0.00676757  	0.10839144  	0.05142840  	0.03894203  	0.03941571  
2023-05-24 23:04:37.465: [iter 228 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 334.777053]
2023-05-24 23:05:25.647: epoch 228:	0.00676366  	0.10834531  	0.05141476  	0.03894005  	0.03941494  
2023-05-24 23:11:03.651: [iter 229 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 336.498284]
2023-05-24 23:11:51.730: epoch 229:	0.00674765  	0.10803090  	0.05126236  	0.03878922  	0.03925609  
2023-05-24 23:17:26.393: [iter 230 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 333.172263]
2023-05-24 23:18:15.336: epoch 230:	0.00674524  	0.10806751  	0.05130617  	0.03885297  	0.03930077  
2023-05-24 23:23:47.283: [iter 231 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 330.477705]
2023-05-24 23:24:35.578: epoch 231:	0.00673891  	0.10795598  	0.05120984  	0.03875065  	0.03918760  
2023-05-24 23:30:10.441: [iter 232 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 333.342385]
2023-05-24 23:30:59.129: epoch 232:	0.00673295  	0.10777323  	0.05123161  	0.03882964  	0.03926833  
2023-05-24 23:36:32.658: [iter 233 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 332.012685]
2023-05-24 23:37:19.899: epoch 233:	0.00675622  	0.10813896  	0.05138533  	0.03894597  	0.03940305  
2023-05-24 23:43:14.438: [iter 234 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 353.038965]
2023-05-24 23:44:02.162: epoch 234:	0.00675455  	0.10809548  	0.05132176  	0.03888774  	0.03935185  
2023-05-24 23:49:38.735: [iter 235 : loss : 0.4199 = 0.0048 + 0.4002 + 0.0148, time: 335.066308]
2023-05-24 23:50:26.579: epoch 235:	0.00676441  	0.10830599  	0.05143673  	0.03897134  	0.03943758  
2023-05-24 23:56:01.848: [iter 236 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 333.723645]
2023-05-24 23:56:51.470: epoch 236:	0.00677669  	0.10853209  	0.05157826  	0.03912408  	0.03958279  
2023-05-24 23:56:51.470: Found a better model.
2023-05-24 23:56:51.470: Save model to file as pretrain.
2023-05-25 00:02:25.871: [iter 237 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0148, time: 331.908301]
2023-05-25 00:03:11.801: epoch 237:	0.00677092  	0.10846309  	0.05153950  	0.03905882  	0.03950919  
2023-05-25 00:08:56.846: [iter 238 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 343.523998]
2023-05-25 00:09:44.126: epoch 238:	0.00676627  	0.10839897  	0.05145618  	0.03897085  	0.03942612  
2023-05-25 00:15:20.677: [iter 239 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 335.022359]
2023-05-25 00:16:07.983: epoch 239:	0.00674672  	0.10809612  	0.05131914  	0.03888596  	0.03933764  
2023-05-25 00:21:45.094: [iter 240 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 335.599069]
2023-05-25 00:22:30.604: epoch 240:	0.00676459  	0.10830431  	0.05149790  	0.03905920  	0.03951441  
2023-05-25 00:28:37.813: [iter 241 : loss : 0.4199 = 0.0048 + 0.4002 + 0.0148, time: 365.650712]
2023-05-25 00:29:25.891: epoch 241:	0.00677129  	0.10843425  	0.05155173  	0.03908243  	0.03954932  
2023-05-25 00:35:00.539: [iter 242 : loss : 0.4199 = 0.0048 + 0.4002 + 0.0148, time: 333.126321]
2023-05-25 00:35:48.460: epoch 242:	0.00677930  	0.10854328  	0.05155099  	0.03904019  	0.03949964  
2023-05-25 00:35:48.460: Found a better model.
2023-05-25 00:35:48.460: Save model to file as pretrain.
2023-05-25 00:42:06.632: [iter 243 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 375.621469]
2023-05-25 00:42:55.394: epoch 243:	0.00676013  	0.10833903  	0.05145297  	0.03896874  	0.03943322  
2023-05-25 00:48:32.283: [iter 244 : loss : 0.4197 = 0.0047 + 0.4002 + 0.0148, time: 335.368119]
2023-05-25 00:49:18.504: epoch 244:	0.00677036  	0.10844973  	0.05141464  	0.03887393  	0.03933709  
2023-05-25 00:54:53.667: [iter 245 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 333.627317]
2023-05-25 00:55:41.449: epoch 245:	0.00676980  	0.10841364  	0.05135907  	0.03884173  	0.03929322  
2023-05-25 01:01:19.432: [iter 246 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 336.457298]
2023-05-25 01:02:06.163: epoch 246:	0.00677074  	0.10847343  	0.05138807  	0.03887914  	0.03934487  
2023-05-25 01:07:41.092: [iter 247 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 333.391519]
2023-05-25 01:08:29.520: epoch 247:	0.00675994  	0.10820742  	0.05136354  	0.03889645  	0.03936231  
2023-05-25 01:14:03.399: [iter 248 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 332.340832]
2023-05-25 01:14:52.154: epoch 248:	0.00677055  	0.10835988  	0.05146489  	0.03898386  	0.03946292  
2023-05-25 01:20:26.772: [iter 249 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 333.074183]
2023-05-25 01:21:14.581: epoch 249:	0.00678581  	0.10862180  	0.05150187  	0.03896666  	0.03943045  
2023-05-25 01:21:14.581: Found a better model.
2023-05-25 01:21:14.581: Save model to file as pretrain.
2023-05-25 01:26:47.359: [iter 250 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 330.227811]
2023-05-25 01:27:35.906: epoch 250:	0.00676626  	0.10837156  	0.05145106  	0.03894004  	0.03940519  
2023-05-25 01:33:52.936: [iter 251 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 375.457858]
2023-05-25 01:34:41.467: epoch 251:	0.00677874  	0.10851562  	0.05149855  	0.03897740  	0.03945134  
2023-05-25 01:40:17.157: [iter 252 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 334.126493]
2023-05-25 01:41:05.300: epoch 252:	0.00677148  	0.10834122  	0.05145257  	0.03896836  	0.03943567  
2023-05-25 01:46:37.627: [iter 253 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 330.780125]
2023-05-25 01:47:24.641: epoch 253:	0.00678246  	0.10856862  	0.05147230  	0.03893068  	0.03937454  
2023-05-25 01:52:55.671: [iter 254 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 329.491893]
2023-05-25 01:53:43.918: epoch 254:	0.00677799  	0.10842373  	0.05143561  	0.03890708  	0.03934592  
2023-05-25 01:59:14.111: [iter 255 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 328.692494]
2023-05-25 02:00:02.673: epoch 255:	0.00676831  	0.10836472  	0.05144745  	0.03895460  	0.03941299  
2023-05-25 02:05:38.901: [iter 256 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 334.722458]
2023-05-25 02:06:26.911: epoch 256:	0.00676831  	0.10830507  	0.05141868  	0.03892741  	0.03938661  
2023-05-25 02:12:43.698: [iter 257 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 375.247523]
2023-05-25 02:13:31.844: epoch 257:	0.00675026  	0.10814270  	0.05134184  	0.03888978  	0.03933931  
2023-05-25 02:19:15.534: [iter 258 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 342.145495]
2023-05-25 02:20:04.087: epoch 258:	0.00676645  	0.10829245  	0.05140821  	0.03889441  	0.03936193  
2023-05-25 02:25:40.673: [iter 259 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 335.027204]
2023-05-25 02:26:27.155: epoch 259:	0.00676068  	0.10818323  	0.05133722  	0.03882480  	0.03926622  
2023-05-25 02:32:05.443: [iter 260 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 336.747277]
2023-05-25 02:32:53.273: epoch 260:	0.00677390  	0.10850412  	0.05135756  	0.03876731  	0.03923079  
2023-05-25 02:38:25.305: [iter 261 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 330.496581]
2023-05-25 02:39:13.628: epoch 261:	0.00675454  	0.10820588  	0.05131951  	0.03882784  	0.03927923  
2023-05-25 02:44:45.740: [iter 262 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 330.574862]
2023-05-25 02:45:31.477: epoch 262:	0.00675678  	0.10832120  	0.05132323  	0.03883743  	0.03927871  
2023-05-25 02:51:03.700: [iter 263 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 330.694432]
2023-05-25 02:51:52.468: epoch 263:	0.00677297  	0.10850304  	0.05136833  	0.03883374  	0.03929033  
2023-05-25 02:57:29.350: [iter 264 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 335.367068]
2023-05-25 02:58:17.351: epoch 264:	0.00678320  	0.10865699  	0.05141074  	0.03884256  	0.03929690  
2023-05-25 02:58:17.351: Found a better model.
2023-05-25 02:58:17.351: Save model to file as pretrain.
2023-05-25 03:03:52.716: [iter 265 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 332.852969]
2023-05-25 03:04:30.528: epoch 265:	0.00676757  	0.10842851  	0.05128385  	0.03869076  	0.03914814  
2023-05-25 03:10:06.509: [iter 266 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 334.657819]
2023-05-25 03:10:54.875: epoch 266:	0.00676888  	0.10844707  	0.05137167  	0.03883553  	0.03929232  
2023-05-25 03:16:25.363: [iter 267 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 328.977556]
2023-05-25 03:17:14.144: epoch 267:	0.00677986  	0.10863471  	0.05134911  	0.03877247  	0.03921907  
2023-05-25 03:22:50.829: [iter 268 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 335.189739]
2023-05-25 03:23:37.478: epoch 268:	0.00678376  	0.10870206  	0.05143013  	0.03881424  	0.03927434  
2023-05-25 03:23:37.478: Found a better model.
2023-05-25 03:23:37.478: Save model to file as pretrain.
2023-05-25 03:29:25.654: [iter 269 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 345.603326]
2023-05-25 03:30:14.058: epoch 269:	0.00677948  	0.10857116  	0.05140468  	0.03882273  	0.03928130  
2023-05-25 03:36:31.897: [iter 270 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 376.296486]
2023-05-25 03:37:20.363: epoch 270:	0.00678600  	0.10868870  	0.05142349  	0.03880745  	0.03927039  
2023-05-25 03:43:35.472: [iter 271 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0148, time: 373.609912]
2023-05-25 03:44:24.074: epoch 271:	0.00677949  	0.10863765  	0.05149588  	0.03892801  	0.03937071  
2023-05-25 03:49:56.068: [iter 272 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 330.480630]
2023-05-25 03:50:43.412: epoch 272:	0.00677428  	0.10850641  	0.05142645  	0.03889747  	0.03935462  
2023-05-25 03:57:00.314: [iter 273 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 375.384391]
2023-05-25 03:57:48.417: epoch 273:	0.00677576  	0.10852804  	0.05143395  	0.03889960  	0.03936306  
2023-05-25 04:03:23.542: [iter 274 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 333.584831]
2023-05-25 04:04:12.345: epoch 274:	0.00677316  	0.10855211  	0.05150061  	0.03897946  	0.03942648  
2023-05-25 04:09:44.143: [iter 275 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 330.273309]
2023-05-25 04:10:24.452: epoch 275:	0.00678172  	0.10860676  	0.05150351  	0.03897223  	0.03945997  
2023-05-25 04:16:01.578: [iter 276 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 335.791972]
2023-05-25 04:16:49.699: epoch 276:	0.00678712  	0.10879910  	0.05155098  	0.03896471  	0.03942625  
2023-05-25 04:16:49.699: Found a better model.
2023-05-25 04:16:49.699: Save model to file as pretrain.
2023-05-25 04:22:20.962: [iter 277 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 328.749190]
2023-05-25 04:23:09.262: epoch 277:	0.00677297  	0.10847601  	0.05143429  	0.03888689  	0.03936945  
2023-05-25 04:29:25.903: [iter 278 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 375.103373]
2023-05-25 04:30:12.756: epoch 278:	0.00678861  	0.10876707  	0.05156795  	0.03895478  	0.03942458  
2023-05-25 04:36:28.054: [iter 279 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 373.764734]
2023-05-25 04:37:14.586: epoch 279:	0.00678340  	0.10866933  	0.05149331  	0.03891509  	0.03936341  
2023-05-25 04:42:49.365: [iter 280 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0148, time: 333.258360]
2023-05-25 04:43:37.453: epoch 280:	0.00677446  	0.10846358  	0.05142079  	0.03885876  	0.03933252  
2023-05-25 04:49:14.438: [iter 281 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 335.437015]
2023-05-25 04:50:03.903: epoch 281:	0.00676795  	0.10838243  	0.05145822  	0.03897872  	0.03942832  
2023-05-25 04:55:36.053: [iter 282 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0148, time: 330.596680]
2023-05-25 04:56:22.896: epoch 282:	0.00677037  	0.10848271  	0.05148667  	0.03895724  	0.03940890  
2023-05-25 05:01:59.326: [iter 283 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 334.907672]
2023-05-25 05:02:47.545: epoch 283:	0.00677279  	0.10847348  	0.05147047  	0.03897339  	0.03943901  
2023-05-25 05:08:17.648: [iter 284 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 328.565146]
2023-05-25 05:09:05.105: epoch 284:	0.00677335  	0.10852978  	0.05147262  	0.03893043  	0.03939234  
2023-05-25 05:14:41.142: [iter 285 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 334.583894]
2023-05-25 05:15:28.043: epoch 285:	0.00678656  	0.10872034  	0.05158898  	0.03904014  	0.03949909  
2023-05-25 05:21:04.089: [iter 286 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 334.530427]
2023-05-25 05:21:52.742: epoch 286:	0.00679606  	0.10887293  	0.05162018  	0.03901546  	0.03946808  
2023-05-25 05:21:52.743: Found a better model.
2023-05-25 05:21:52.743: Save model to file as pretrain.
2023-05-25 05:27:29.864: [iter 287 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 334.611441]
2023-05-25 05:28:18.785: epoch 287:	0.00679494  	0.10887026  	0.05163662  	0.03905912  	0.03949992  
2023-05-25 05:33:53.364: [iter 288 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 333.089878]
2023-05-25 05:34:38.188: epoch 288:	0.00680480  	0.10902178  	0.05170289  	0.03910710  	0.03955917  
2023-05-25 05:34:38.188: Found a better model.
2023-05-25 05:34:38.188: Save model to file as pretrain.
2023-05-25 05:40:57.673: [iter 289 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 376.953327]
2023-05-25 05:41:46.680: epoch 289:	0.00680312  	0.10898404  	0.05170034  	0.03910410  	0.03957263  
2023-05-25 05:47:21.692: [iter 290 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 333.449107]
2023-05-25 05:48:10.762: epoch 290:	0.00680238  	0.10893687  	0.05170398  	0.03912652  	0.03959100  
2023-05-25 05:53:46.957: [iter 291 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 334.652628]
2023-05-25 05:54:34.403: epoch 291:	0.00680294  	0.10891009  	0.05164086  	0.03905590  	0.03951707  
2023-05-25 06:00:10.831: [iter 292 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 334.937797]
2023-05-25 06:00:58.832: epoch 292:	0.00679494  	0.10887389  	0.05168219  	0.03911017  	0.03958124  
2023-05-25 06:06:30.699: [iter 293 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 330.336860]
2023-05-25 06:07:19.763: epoch 293:	0.00678991  	0.10878693  	0.05164110  	0.03911192  	0.03956015  
2023-05-25 06:12:53.511: [iter 294 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 332.194151]
2023-05-25 06:13:39.815: epoch 294:	0.00678320  	0.10869691  	0.05165683  	0.03917512  	0.03963250  
2023-05-25 06:19:16.549: [iter 295 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 335.168736]
2023-05-25 06:20:04.932: epoch 295:	0.00679791  	0.10894886  	0.05169129  	0.03914492  	0.03960136  
2023-05-25 06:25:37.864: [iter 296 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 331.390196]
2023-05-25 06:26:27.182: epoch 296:	0.00678600  	0.10875519  	0.05162758  	0.03911905  	0.03955728  
2023-05-25 06:32:03.451: [iter 297 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 334.728996]
2023-05-25 06:32:51.128: epoch 297:	0.00680071  	0.10895249  	0.05172615  	0.03921171  	0.03965980  
2023-05-25 06:38:25.868: [iter 298 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0148, time: 333.207338]
2023-05-25 06:39:14.168: epoch 298:	0.00680592  	0.10897369  	0.05171781  	0.03920132  	0.03965708  
2023-05-25 06:44:46.147: [iter 299 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 330.495462]
2023-05-25 06:45:33.497: epoch 299:	0.00680685  	0.10901558  	0.05174383  	0.03920584  	0.03966369  
2023-05-25 06:51:09.603: [iter 300 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 334.594840]
2023-05-25 06:51:56.286: epoch 300:	0.00680089  	0.10898282  	0.05162904  	0.03905060  	0.03948453  
2023-05-25 06:57:32.461: [iter 301 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 334.632057]
2023-05-25 06:58:20.661: epoch 301:	0.00680481  	0.10922591  	0.05173073  	0.03913865  	0.03958935  
2023-05-25 06:58:20.661: Found a better model.
2023-05-25 06:58:20.661: Save model to file as pretrain.
2023-05-25 07:03:53.650: [iter 302 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0148, time: 330.447184]
2023-05-25 07:04:42.414: epoch 302:	0.00679959  	0.10905011  	0.05175233  	0.03919351  	0.03963792  
2023-05-25 07:10:25.908: [iter 303 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 341.990728]
2023-05-25 07:11:13.811: epoch 303:	0.00679196  	0.10888311  	0.05173002  	0.03923186  	0.03967818  
2023-05-25 07:16:43.954: [iter 304 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 328.610116]
2023-05-25 07:17:31.977: epoch 304:	0.00680983  	0.10926043  	0.05179723  	0.03922397  	0.03967364  
2023-05-25 07:17:31.977: Found a better model.
2023-05-25 07:17:31.977: Save model to file as pretrain.
2023-05-25 07:23:09.238: [iter 305 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 334.732563]
2023-05-25 07:23:57.677: epoch 305:	0.00680666  	0.10913470  	0.05185335  	0.03934231  	0.03979987  
2023-05-25 07:29:27.837: [iter 306 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 328.688007]
2023-05-25 07:30:14.766: epoch 306:	0.00680890  	0.10927003  	0.05177376  	0.03917413  	0.03961847  
2023-05-25 07:30:14.766: Found a better model.
2023-05-25 07:30:14.766: Save model to file as pretrain.
2023-05-25 07:35:47.599: [iter 307 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0148, time: 330.337576]
2023-05-25 07:36:35.935: epoch 307:	0.00680889  	0.10915156  	0.05169303  	0.03909129  	0.03955033  
2023-05-25 07:42:52.260: [iter 308 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 374.827047]
2023-05-25 07:43:40.416: epoch 308:	0.00679866  	0.10898173  	0.05170920  	0.03915735  	0.03961272  
2023-05-25 07:49:16.949: [iter 309 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0148, time: 334.990407]
2023-05-25 07:50:05.338: epoch 309:	0.00679084  	0.10883734  	0.05164987  	0.03910516  	0.03957989  
2023-05-25 07:55:37.194: [iter 310 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 330.303429]
2023-05-25 07:56:17.252: epoch 310:	0.00680015  	0.10897542  	0.05169329  	0.03913428  	0.03958286  
2023-05-25 08:01:48.656: [iter 311 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 330.051939]
2023-05-25 08:02:37.627: epoch 311:	0.00680704  	0.10905463  	0.05171181  	0.03915194  	0.03959057  
2023-05-25 08:08:13.693: [iter 312 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 334.529034]
2023-05-25 08:09:01.030: epoch 312:	0.00680015  	0.10888927  	0.05173273  	0.03920533  	0.03966601  
2023-05-25 08:14:37.141: [iter 313 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 334.583026]
2023-05-25 08:15:23.235: epoch 313:	0.00681317  	0.10920253  	0.05173787  	0.03913535  	0.03959780  
2023-05-25 08:20:57.729: [iter 314 : loss : 0.4197 = 0.0047 + 0.4002 + 0.0148, time: 332.949150]
2023-05-25 08:21:45.666: epoch 314:	0.00680127  	0.10895992  	0.05166628  	0.03909712  	0.03954597  
2023-05-25 08:27:21.043: [iter 315 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 333.845368]
2023-05-25 08:28:08.962: epoch 315:	0.00680536  	0.10890955  	0.05174268  	0.03918748  	0.03962955  
2023-05-25 08:33:44.974: [iter 316 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0148, time: 334.506880]
2023-05-25 08:34:24.975: epoch 316:	0.00679661  	0.10888205  	0.05163192  	0.03906445  	0.03952348  
2023-05-25 08:40:02.078: [iter 317 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0148, time: 335.761654]
2023-05-25 08:40:50.829: epoch 317:	0.00680908  	0.10899895  	0.05169505  	0.03912384  	0.03958009  
2023-05-25 08:46:26.815: [iter 318 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 334.444069]
2023-05-25 08:47:14.310: epoch 318:	0.00680480  	0.10896953  	0.05165882  	0.03908294  	0.03950031  
2023-05-25 08:53:30.455: [iter 319 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 374.610449]
2023-05-25 08:54:13.936: epoch 319:	0.00681523  	0.10910515  	0.05178212  	0.03918368  	0.03963692  
2023-05-25 08:59:47.620: [iter 320 : loss : 0.4197 = 0.0047 + 0.4002 + 0.0148, time: 332.212109]
2023-05-25 09:00:42.769: epoch 320:	0.00681485  	0.10906821  	0.05172291  	0.03912462  	0.03957736  
2023-05-25 09:06:19.277: [iter 321 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 334.975516]
2023-05-25 09:07:08.374: epoch 321:	0.00681895  	0.10919825  	0.05179201  	0.03917180  	0.03964500  
2023-05-25 09:12:40.255: [iter 322 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 330.342459]
2023-05-25 09:13:22.478: epoch 322:	0.00681094  	0.10912229  	0.05166151  	0.03906709  	0.03949615  
2023-05-25 09:18:55.470: [iter 323 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0148, time: 331.635302]
2023-05-25 09:19:42.486: epoch 323:	0.00681039  	0.10916433  	0.05170995  	0.03912470  	0.03957335  
2023-05-25 09:26:00.329: [iter 324 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 376.272113]
2023-05-25 09:26:48.405: epoch 324:	0.00681858  	0.10923190  	0.05171917  	0.03911269  	0.03955897  
2023-05-25 09:32:18.704: [iter 325 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 328.766073]
2023-05-25 09:33:05.560: epoch 325:	0.00681969  	0.10923730  	0.05172947  	0.03913206  	0.03959773  
2023-05-25 09:38:41.306: [iter 326 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 334.249281]
2023-05-25 09:39:29.498: epoch 326:	0.00681672  	0.10917355  	0.05179077  	0.03921475  	0.03965567  
2023-05-25 09:45:05.958: [iter 327 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0148, time: 334.928094]
2023-05-25 09:45:54.807: epoch 327:	0.00680201  	0.10889489  	0.05164100  	0.03905880  	0.03951931  
2023-05-25 09:51:27.163: [iter 328 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 330.826827]
2023-05-25 09:52:16.550: epoch 328:	0.00681076  	0.10905574  	0.05177721  	0.03918962  	0.03963951  
2023-05-25 09:58:32.083: [iter 329 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 373.924209]
2023-05-25 09:59:20.025: epoch 329:	0.00681281  	0.10903236  	0.05164922  	0.03901727  	0.03947059  
2023-05-25 10:04:52.372: [iter 330 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0148, time: 330.810341]
2023-05-25 10:05:41.232: epoch 330:	0.00679327  	0.10880022  	0.05165673  	0.03912781  	0.03959349  
2023-05-25 10:11:18.004: [iter 331 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 335.220019]
2023-05-25 10:12:04.825: epoch 331:	0.00681746  	0.10918579  	0.05172906  	0.03906993  	0.03951321  
2023-05-25 10:17:37.284: [iter 332 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0148, time: 330.931700]
2023-05-25 10:18:27.647: epoch 332:	0.00681448  	0.10916280  	0.05169405  	0.03903938  	0.03948893  
2023-05-25 10:24:04.474: [iter 333 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0148, time: 335.286102]
2023-05-25 10:24:52.312: epoch 333:	0.00681653  	0.10908114  	0.05177006  	0.03918089  	0.03962358  
2023-05-25 10:31:04.089: [iter 334 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 370.232500]
2023-05-25 10:31:51.719: epoch 334:	0.00682174  	0.10918120  	0.05177608  	0.03911518  	0.03959272  
2023-05-25 10:37:28.377: [iter 335 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 335.118934]
2023-05-25 10:38:16.346: epoch 335:	0.00682342  	0.10931607  	0.05188840  	0.03927683  	0.03972374  
2023-05-25 10:38:16.346: Found a better model.
2023-05-25 10:38:16.346: Save model to file as pretrain.
2023-05-25 10:44:36.250: [iter 336 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0148, time: 377.378527]
2023-05-25 10:45:24.216: epoch 336:	0.00683272  	0.10938899  	0.05192810  	0.03931782  	0.03978413  
2023-05-25 10:45:24.216: Found a better model.
2023-05-25 10:45:24.216: Save model to file as pretrain.
2023-05-25 10:50:59.262: [iter 337 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 332.487714]
2023-05-25 10:51:46.358: epoch 337:	0.00680350  	0.10901070  	0.05180890  	0.03928463  	0.03974221  
2023-05-25 10:57:40.847: [iter 338 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 352.992844]
2023-05-25 10:58:28.649: epoch 338:	0.00682639  	0.10940234  	0.05185455  	0.03923480  	0.03970882  
2023-05-25 10:58:28.649: Found a better model.
2023-05-25 10:58:28.649: Save model to file as pretrain.
2023-05-25 11:04:46.554: [iter 339 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 375.418729]
2023-05-25 11:05:34.772: epoch 339:	0.00682379  	0.10936414  	0.05183328  	0.03921428  	0.03968308  
2023-05-25 11:11:51.738: [iter 340 : loss : 0.4197 = 0.0047 + 0.4002 + 0.0148, time: 375.428488]
2023-05-25 11:12:40.816: epoch 340:	0.00681113  	0.10904791  	0.05175024  	0.03916824  	0.03964439  
2023-05-25 11:18:57.812: [iter 341 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 375.512666]
2023-05-25 11:19:45.454: epoch 341:	0.00683291  	0.10949065  	0.05194801  	0.03935068  	0.03982404  
2023-05-25 11:19:45.455: Found a better model.
2023-05-25 11:19:45.455: Save model to file as pretrain.
2023-05-25 11:25:23.093: [iter 342 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 335.098735]
2023-05-25 11:26:12.389: epoch 342:	0.00682807  	0.10934883  	0.05188694  	0.03930442  	0.03977699  
2023-05-25 11:31:48.830: [iter 343 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 334.938155]
2023-05-25 11:32:36.270: epoch 343:	0.00682062  	0.10921577  	0.05189034  	0.03930212  	0.03976011  
2023-05-25 11:38:08.341: [iter 344 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 330.538665]
2023-05-25 11:38:54.498: epoch 344:	0.00681206  	0.10911664  	0.05188346  	0.03934446  	0.03980372  
2023-05-25 11:44:28.734: [iter 345 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 332.676901]
2023-05-25 11:45:16.280: epoch 345:	0.00682193  	0.10921781  	0.05182942  	0.03923273  	0.03968633  
2023-05-25 11:50:52.906: [iter 346 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 335.110670]
2023-05-25 11:51:41.559: epoch 346:	0.00682118  	0.10921242  	0.05181387  	0.03917060  	0.03964294  
2023-05-25 11:57:18.027: [iter 347 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 334.969638]
2023-05-25 11:58:05.449: epoch 347:	0.00680871  	0.10906532  	0.05175843  	0.03915980  	0.03960226  
2023-05-25 12:03:37.720: [iter 348 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0148, time: 330.748816]
2023-05-25 12:04:25.937: epoch 348:	0.00681764  	0.10912268  	0.05183617  	0.03926625  	0.03972574  
2023-05-25 12:09:57.052: [iter 349 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 329.592876]
2023-05-25 12:10:43.602: epoch 349:	0.00680833  	0.10912351  	0.05183162  	0.03924146  	0.03970660  
2023-05-25 12:16:15.741: [iter 350 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 330.646350]
2023-05-25 12:17:04.705: epoch 350:	0.00680498  	0.10896551  	0.05176074  	0.03920617  	0.03966672  
2023-05-25 12:22:43.103: [iter 351 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 336.854962]
2023-05-25 12:23:32.252: epoch 351:	0.00679903  	0.10889374  	0.05174104  	0.03920835  	0.03968383  
2023-05-25 12:29:07.471: [iter 352 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 333.667701]
2023-05-25 12:29:53.407: epoch 352:	0.00679940  	0.10885978  	0.05173651  	0.03920672  	0.03965944  
2023-05-25 12:35:29.739: [iter 353 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 334.808531]
2023-05-25 12:36:19.930: epoch 353:	0.00682043  	0.10922992  	0.05187956  	0.03931373  	0.03977979  
2023-05-25 12:41:56.637: [iter 354 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 335.158676]
2023-05-25 12:42:51.710: epoch 354:	0.00680443  	0.10897866  	0.05182539  	0.03929551  	0.03977416  
2023-05-25 12:48:31.631: [iter 355 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 338.446385]
2023-05-25 12:49:20.236: epoch 355:	0.00681615  	0.10914958  	0.05183797  	0.03927261  	0.03973803  
2023-05-25 12:55:37.690: [iter 356 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0148, time: 375.867272]
2023-05-25 12:56:25.816: epoch 356:	0.00680908  	0.10897842  	0.05186090  	0.03935206  	0.03981170  
2023-05-25 13:01:59.319: [iter 357 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0148, time: 331.976380]
2023-05-25 13:02:48.741: epoch 357:	0.00681224  	0.10913824  	0.05181454  	0.03923569  	0.03969926  
2023-05-25 13:08:27.187: [iter 358 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 336.894118]
2023-05-25 13:09:13.469: epoch 358:	0.00681113  	0.10909179  	0.05174274  	0.03914561  	0.03960768  
2023-05-25 13:14:48.487: [iter 359 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 333.450763]
2023-05-25 13:15:36.777: epoch 359:	0.00680964  	0.10905378  	0.05178280  	0.03920247  	0.03967916  
2023-05-25 13:21:10.383: [iter 360 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 332.042767]
2023-05-25 13:21:58.916: epoch 360:	0.00681913  	0.10926530  	0.05190566  	0.03931257  	0.03977958  
2023-05-25 13:27:54.708: [iter 361 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 354.261180]
2023-05-25 13:28:41.308: epoch 361:	0.00681486  	0.10919461  	0.05181535  	0.03921069  	0.03965367  
2023-05-25 13:34:13.592: [iter 362 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 330.720907]
2023-05-25 13:35:01.811: epoch 362:	0.00682006  	0.10917528  	0.05185325  	0.03925802  	0.03972911  
2023-05-25 13:40:31.250: [iter 363 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 327.893110]
2023-05-25 13:41:18.270: epoch 363:	0.00680908  	0.10901489  	0.05177999  	0.03920320  	0.03967068  
2023-05-25 13:46:51.594: [iter 364 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0148, time: 331.754950]
2023-05-25 13:47:39.239: epoch 364:	0.00681373  	0.10905576  	0.05179836  	0.03921142  	0.03965914  
2023-05-25 13:53:15.725: [iter 365 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 334.962277]
2023-05-25 13:54:03.526: epoch 365:	0.00682396  	0.10920420  	0.05182013  	0.03919284  	0.03965615  
2023-05-25 13:59:40.083: [iter 366 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 334.999401]
2023-05-25 14:00:28.255: epoch 366:	0.00682360  	0.10931525  	0.05179192  	0.03913869  	0.03958658  
2023-05-25 14:06:05.516: [iter 367 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 335.734487]
2023-05-25 14:06:54.119: epoch 367:	0.00684873  	0.10965178  	0.05189464  	0.03918198  	0.03966060  
2023-05-25 14:06:54.119: Found a better model.
2023-05-25 14:06:54.119: Save model to file as pretrain.
2023-05-25 14:13:08.300: [iter 368 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 371.612070]
2023-05-25 14:13:57.389: epoch 368:	0.00682844  	0.10935707  	0.05170685  	0.03903535  	0.03947446  
2023-05-25 14:20:14.196: [iter 369 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 375.234585]
2023-05-25 14:21:00.069: epoch 369:	0.00682565  	0.10927706  	0.05167845  	0.03901997  	0.03946174  
2023-05-25 14:27:13.509: [iter 370 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 371.912744]
2023-05-25 14:28:01.540: epoch 370:	0.00682732  	0.10933551  	0.05171943  	0.03903898  	0.03948409  
2023-05-25 14:33:43.850: [iter 371 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 340.760092]
2023-05-25 14:34:32.491: epoch 371:	0.00682844  	0.10934136  	0.05169670  	0.03900790  	0.03945549  
2023-05-25 14:40:46.931: [iter 372 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 372.884646]
2023-05-25 14:41:34.489: epoch 372:	0.00681337  	0.10917056  	0.05168680  	0.03905828  	0.03948339  
2023-05-25 14:47:08.500: [iter 373 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0148, time: 332.494995]
2023-05-25 14:47:55.986: epoch 373:	0.00683160  	0.10939189  	0.05175282  	0.03909155  	0.03952182  
2023-05-25 14:53:32.948: [iter 374 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 335.432184]
2023-05-25 14:54:20.273: epoch 374:	0.00682713  	0.10942763  	0.05180789  	0.03915404  	0.03959294  
2023-05-25 14:59:55.298: [iter 375 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 333.522172]
2023-05-25 15:00:43.541: epoch 375:	0.00682044  	0.10923613  	0.05177191  	0.03916917  	0.03959932  
2023-05-25 15:06:18.432: [iter 376 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 333.340839]
2023-05-25 15:07:05.890: epoch 376:	0.00683159  	0.10940809  	0.05185767  	0.03924141  	0.03968809  
2023-05-25 15:12:39.631: [iter 377 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 332.230501]
2023-05-25 15:13:28.646: epoch 377:	0.00681727  	0.10928110  	0.05182002  	0.03922240  	0.03967598  
2023-05-25 15:19:02.460: [iter 378 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 332.296453]
2023-05-25 15:19:47.990: epoch 378:	0.00682006  	0.10933497  	0.05187078  	0.03929529  	0.03973955  
2023-05-25 15:25:20.288: [iter 379 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 330.760081]
2023-05-25 15:26:08.787: epoch 379:	0.00683979  	0.10962178  	0.05189731  	0.03925973  	0.03971342  
2023-05-25 15:31:39.735: [iter 380 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 329.433844]
2023-05-25 15:32:28.499: epoch 380:	0.00683924  	0.10964996  	0.05190320  	0.03924040  	0.03969719  
2023-05-25 15:38:07.483: [iter 381 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 337.420227]
2023-05-25 15:38:55.584: epoch 381:	0.00684352  	0.10971037  	0.05197745  	0.03932734  	0.03977030  
2023-05-25 15:38:55.584: Found a better model.
2023-05-25 15:38:55.584: Save model to file as pretrain.
2023-05-25 15:45:12.098: [iter 382 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0148, time: 373.989190]
2023-05-25 15:46:00.566: epoch 382:	0.00683886  	0.10957163  	0.05197219  	0.03937096  	0.03982366  
2023-05-25 15:52:16.241: [iter 383 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 374.185580]
2023-05-25 15:53:03.768: epoch 383:	0.00682751  	0.10937168  	0.05180369  	0.03920109  	0.03964444  
2023-05-25 15:58:35.935: [iter 384 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 330.630999]
2023-05-25 15:59:23.986: epoch 384:	0.00683626  	0.10945899  	0.05187962  	0.03929969  	0.03972722  
2023-05-25 16:04:59.195: [iter 385 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 333.669663]
2023-05-25 16:05:47.467: epoch 385:	0.00683942  	0.10953385  	0.05194828  	0.03936287  	0.03980756  
2023-05-25 16:11:20.560: [iter 386 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 331.590790]
2023-05-25 16:12:10.050: epoch 386:	0.00683384  	0.10942820  	0.05194318  	0.03937063  	0.03981293  
2023-05-25 16:17:46.848: [iter 387 : loss : 0.4197 = 0.0047 + 0.4002 + 0.0148, time: 335.236510]
2023-05-25 16:18:33.650: epoch 387:	0.00684761  	0.10970623  	0.05194736  	0.03928337  	0.03973814  
2023-05-25 16:24:10.053: [iter 388 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 334.881402]
2023-05-25 16:24:57.339: epoch 388:	0.00683719  	0.10952435  	0.05186005  	0.03920014  	0.03964956  
2023-05-25 16:30:32.186: [iter 389 : loss : 0.4197 = 0.0047 + 0.4002 + 0.0148, time: 333.308020]
2023-05-25 16:31:21.114: epoch 389:	0.00683049  	0.10945632  	0.05187366  	0.03924004  	0.03968767  
2023-05-25 16:36:57.643: [iter 390 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0148, time: 335.041529]
2023-05-25 16:37:48.655: epoch 390:	0.00684444  	0.10981140  	0.05196561  	0.03926757  	0.03972742  
2023-05-25 16:37:48.656: Found a better model.
2023-05-25 16:37:48.656: Save model to file as pretrain.
2023-05-25 16:44:04.246: [iter 391 : loss : 0.4197 = 0.0047 + 0.4002 + 0.0148, time: 373.120318]
2023-05-25 16:44:51.960: epoch 391:	0.00683718  	0.10961904  	0.05186173  	0.03917434  	0.03963022  
2023-05-25 16:50:25.584: [iter 392 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 332.099113]
2023-05-25 16:51:13.307: epoch 392:	0.00683513  	0.10950659  	0.05183344  	0.03916296  	0.03961661  
2023-05-25 16:56:58.910: [iter 393 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 344.057559]
2023-05-25 16:57:35.524: epoch 393:	0.00682508  	0.10947699  	0.05182531  	0.03917736  	0.03963337  
2023-05-25 17:03:51.761: [iter 394 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 374.894406]
2023-05-25 17:04:40.436: epoch 394:	0.00684184  	0.10966411  	0.05196439  	0.03931852  	0.03975664  
2023-05-25 17:10:16.702: [iter 395 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 334.750618]
2023-05-25 17:11:04.728: epoch 395:	0.00682732  	0.10936664  	0.05186239  	0.03924217  	0.03969117  
2023-05-25 17:16:41.168: [iter 396 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 334.907052]
2023-05-25 17:17:26.725: epoch 396:	0.00682211  	0.10926121  	0.05184165  	0.03925174  	0.03971756  
2023-05-25 17:23:03.060: [iter 397 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0148, time: 334.801920]
2023-05-25 17:23:51.677: epoch 397:	0.00684389  	0.10961840  	0.05199426  	0.03935228  	0.03980950  
2023-05-25 17:29:26.594: [iter 398 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 333.391828]
2023-05-25 17:30:15.862: epoch 398:	0.00683979  	0.10944855  	0.05192728  	0.03927115  	0.03974098  
2023-05-25 17:35:48.650: [iter 399 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 331.252135]
2023-05-25 17:36:31.450: epoch 399:	0.00682938  	0.10929927  	0.05177818  	0.03913352  	0.03958436  
2023-05-25 17:42:00.913: [iter 400 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0148, time: 328.107497]
2023-05-25 17:42:50.188: epoch 400:	0.00681895  	0.10907167  	0.05181209  	0.03921628  	0.03967689  
2023-05-25 17:49:08.951: [iter 401 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 377.230040]
2023-05-25 17:49:56.720: epoch 401:	0.00681708  	0.10907372  	0.05184912  	0.03932481  	0.03978915  
2023-05-25 17:55:28.773: [iter 402 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 330.485750]
2023-05-25 17:56:13.812: epoch 402:	0.00683700  	0.10941805  	0.05189278  	0.03928056  	0.03974178  
2023-05-25 18:01:50.617: [iter 403 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 335.289062]
2023-05-25 18:02:38.082: epoch 403:	0.00682491  	0.10928861  	0.05174650  	0.03910119  	0.03955658  
2023-05-25 18:08:55.138: [iter 404 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 375.586951]
2023-05-25 18:09:42.659: epoch 404:	0.00683812  	0.10945984  	0.05182044  	0.03913774  	0.03962246  
2023-05-25 18:15:14.799: [iter 405 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0148, time: 330.608331]
2023-05-25 18:16:03.867: epoch 405:	0.00683551  	0.10944421  	0.05193222  	0.03930479  	0.03977434  
2023-05-25 18:21:48.533: [iter 406 : loss : 0.4197 = 0.0047 + 0.4002 + 0.0148, time: 343.145401]
2023-05-25 18:22:37.283: epoch 406:	0.00683960  	0.10942670  	0.05191135  	0.03929565  	0.03977266  
2023-05-25 18:28:12.172: [iter 407 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 333.361968]
2023-05-25 18:29:00.220: epoch 407:	0.00682043  	0.10910930  	0.05173893  	0.03913793  	0.03961390  
2023-05-25 18:34:33.551: [iter 408 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 331.812335]
2023-05-25 18:35:22.028: epoch 408:	0.00681615  	0.10913172  	0.05176960  	0.03917366  	0.03964402  
2023-05-25 18:40:58.186: [iter 409 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 334.627726]
2023-05-25 18:41:45.084: epoch 409:	0.00681056  	0.10905678  	0.05180270  	0.03922532  	0.03970598  
2023-05-25 18:47:28.537: [iter 410 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0148, time: 341.875316]
2023-05-25 18:48:17.063: epoch 410:	0.00681988  	0.10929347  	0.05184694  	0.03923245  	0.03971354  
2023-05-25 18:53:51.770: [iter 411 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 333.142069]
2023-05-25 18:54:40.227: epoch 411:	0.00683180  	0.10948216  	0.05185404  	0.03919285  	0.03965973  
2023-05-25 19:00:12.050: [iter 412 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 330.250053]
2023-05-25 19:00:57.765: epoch 412:	0.00682863  	0.10935926  	0.05185139  	0.03921296  	0.03967284  
2023-05-25 19:06:35.473: [iter 413 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 336.180166]
2023-05-25 19:07:23.986: epoch 413:	0.00682546  	0.10930472  	0.05188552  	0.03927280  	0.03973690  
2023-05-25 19:12:59.067: [iter 414 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 333.530763]
2023-05-25 19:13:46.731: epoch 414:	0.00682621  	0.10932928  	0.05183770  	0.03920376  	0.03967423  
2023-05-25 19:19:23.282: [iter 415 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0147, time: 334.997752]
2023-05-25 19:20:10.109: epoch 415:	0.00683495  	0.10951996  	0.05190127  	0.03928359  	0.03973292  
2023-05-25 19:25:43.263: [iter 416 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 331.636091]
2023-05-25 19:26:31.262: epoch 416:	0.00683849  	0.10965961  	0.05196509  	0.03929135  	0.03977417  
2023-05-25 19:32:03.260: [iter 417 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0148, time: 330.438666]
2023-05-25 19:32:51.222: epoch 417:	0.00683105  	0.10948791  	0.05195088  	0.03931827  	0.03979211  
2023-05-25 19:39:06.662: [iter 418 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0147, time: 373.869877]
2023-05-25 19:39:41.404: epoch 418:	0.00683124  	0.10953885  	0.05191015  	0.03927335  	0.03974754  
2023-05-25 19:45:59.792: [iter 419 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 377.029927]
2023-05-25 19:46:47.847: epoch 419:	0.00684576  	0.10976233  	0.05199423  	0.03934268  	0.03981972  
2023-05-25 19:52:24.509: [iter 420 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 335.112143]
2023-05-25 19:53:13.325: epoch 420:	0.00684873  	0.10970369  	0.05206896  	0.03944927  	0.03994026  
2023-05-25 19:58:49.738: [iter 421 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 334.847924]
2023-05-25 19:59:37.416: epoch 421:	0.00683348  	0.10945489  	0.05195690  	0.03936389  	0.03983141  
2023-05-25 20:05:09.475: [iter 422 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0148, time: 330.519290]
2023-05-25 20:05:57.800: epoch 422:	0.00683403  	0.10946836  	0.05191057  	0.03932298  	0.03977794  
2023-05-25 20:11:44.401: [iter 423 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0148, time: 345.103596]
2023-05-25 20:12:33.176: epoch 423:	0.00684780  	0.10978073  	0.05198263  	0.03932715  	0.03978721  
2023-05-25 20:17:59.040: [iter 424 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 324.340486]
2023-05-25 20:18:47.675: epoch 424:	0.00682677  	0.10932684  	0.05193033  	0.03936882  	0.03985360  
2023-05-25 20:24:22.496: [iter 425 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 333.258067]
2023-05-25 20:25:07.990: epoch 425:	0.00684315  	0.10957140  	0.05198092  	0.03936399  	0.03983191  
2023-05-25 20:30:38.204: [iter 426 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0148, time: 328.654944]
2023-05-25 20:31:25.825: epoch 426:	0.00682733  	0.10932492  	0.05190577  	0.03933625  	0.03981798  
2023-05-25 20:37:02.400: [iter 427 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 335.080452]
2023-05-25 20:37:49.966: epoch 427:	0.00682044  	0.10926581  	0.05184506  	0.03926870  	0.03974218  
2023-05-25 20:43:26.090: [iter 428 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0148, time: 334.614990]
2023-05-25 20:44:11.605: epoch 428:	0.00683477  	0.10942459  	0.05190025  	0.03931892  	0.03979285  
2023-05-25 20:50:27.108: [iter 429 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 373.957334]
2023-05-25 20:51:15.210: epoch 429:	0.00683552  	0.10945923  	0.05196881  	0.03940901  	0.03987540  
2023-05-25 20:56:45.448: [iter 430 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 328.713691]
2023-05-25 20:57:33.022: epoch 430:	0.00681541  	0.10915992  	0.05182371  	0.03926312  	0.03973201  
2023-05-25 21:03:03.093: [iter 431 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 328.539123]
2023-05-25 21:03:49.243: epoch 431:	0.00682844  	0.10929911  	0.05185329  	0.03929994  	0.03975529  
2023-05-25 21:09:19.401: [iter 432 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0148, time: 328.611783]
2023-05-25 21:10:06.845: epoch 432:	0.00683942  	0.10936781  	0.05195427  	0.03943098  	0.03989327  
2023-05-25 21:15:36.874: [iter 433 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0148, time: 328.507509]
2023-05-25 21:16:26.129: epoch 433:	0.00685543  	0.10970959  	0.05204649  	0.03946680  	0.03994539  
2023-05-25 21:22:02.632: [iter 434 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 334.922780]
2023-05-25 21:22:38.751: epoch 434:	0.00684966  	0.10971515  	0.05209839  	0.03955034  	0.04001676  
2023-05-25 21:28:12.572: [iter 435 : loss : 0.4196 = 0.0047 + 0.4002 + 0.0148, time: 332.482857]
2023-05-25 21:29:00.668: epoch 435:	0.00684184  	0.10963246  	0.05201661  	0.03942932  	0.03988668  
2023-05-25 21:34:37.042: [iter 436 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 334.813002]
2023-05-25 21:35:25.667: epoch 436:	0.00684668  	0.10968008  	0.05200091  	0.03937098  	0.03983130  
2023-05-25 21:41:00.188: [iter 437 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 333.000992]
2023-05-25 21:41:46.371: epoch 437:	0.00684166  	0.10956833  	0.05191065  	0.03926325  	0.03972891  
2023-05-25 21:47:16.569: [iter 438 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 328.670959]
2023-05-25 21:48:04.510: epoch 438:	0.00684315  	0.10966588  	0.05197908  	0.03934378  	0.03981525  
2023-05-25 21:54:21.489: [iter 439 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 375.427918]
2023-05-25 21:55:09.820: epoch 439:	0.00685543  	0.10976120  	0.05186017  	0.03916908  	0.03962154  
2023-05-25 22:01:26.940: [iter 440 : loss : 0.4197 = 0.0047 + 0.4002 + 0.0148, time: 375.622186]
2023-05-25 22:02:15.474: epoch 440:	0.00685655  	0.10985752  	0.05191144  	0.03922661  	0.03966710  
2023-05-25 22:02:15.482: Found a better model.
2023-05-25 22:02:15.482: Save model to file as pretrain.
2023-05-25 22:07:51.483: [iter 441 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 333.509515]
2023-05-25 22:08:36.297: epoch 441:	0.00683124  	0.10949556  	0.05181638  	0.03917862  	0.03963546  
2023-05-25 22:14:09.519: [iter 442 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 331.675958]
2023-05-25 22:14:57.487: epoch 442:	0.00682732  	0.10937206  	0.05186884  	0.03927707  	0.03973905  
2023-05-25 22:20:33.981: [iter 443 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 334.980668]
2023-05-25 22:21:22.541: epoch 443:	0.00682695  	0.10937178  	0.05188593  	0.03932088  	0.03978166  
2023-05-25 22:26:58.931: [iter 444 : loss : 0.4197 = 0.0047 + 0.4002 + 0.0148, time: 334.848249]
2023-05-25 22:27:41.009: epoch 444:	0.00682212  	0.10922273  	0.05177584  	0.03920653  	0.03966131  
2023-05-25 22:33:12.426: [iter 445 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 330.054620]
2023-05-25 22:34:00.085: epoch 445:	0.00683011  	0.10944127  	0.05193149  	0.03936095  	0.03981871  
2023-05-25 22:39:36.571: [iter 446 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0148, time: 334.934110]
2023-05-25 22:40:25.089: epoch 446:	0.00683329  	0.10938615  	0.05188302  	0.03929192  	0.03975791  
2023-05-25 22:45:55.274: [iter 447 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 328.666307]
2023-05-25 22:46:44.066: epoch 447:	0.00683123  	0.10933142  	0.05184939  	0.03924302  	0.03971250  
2023-05-25 22:52:58.602: [iter 448 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 372.991077]
2023-05-25 22:53:46.661: epoch 448:	0.00680778  	0.10897042  	0.05174873  	0.03920323  	0.03966680  
2023-05-25 22:59:19.655: [iter 449 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 331.449156]
2023-05-25 23:00:07.904: epoch 449:	0.00682807  	0.10933026  	0.05184476  	0.03924150  	0.03971412  
2023-05-25 23:05:43.160: [iter 450 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 333.759451]
2023-05-25 23:06:28.441: epoch 450:	0.00681169  	0.10912739  	0.05184047  	0.03931629  	0.03977744  
2023-05-25 23:12:00.850: [iter 451 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0147, time: 330.888988]
2023-05-25 23:12:49.396: epoch 451:	0.00683551  	0.10944118  	0.05190170  	0.03930216  	0.03978919  
2023-05-25 23:18:26.048: [iter 452 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0148, time: 335.126170]
2023-05-25 23:19:14.339: epoch 452:	0.00682992  	0.10937343  	0.05185593  	0.03923973  	0.03972872  
2023-05-25 23:24:49.154: [iter 453 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 333.284907]
2023-05-25 23:25:34.607: epoch 453:	0.00683346  	0.10949872  	0.05191179  	0.03929821  	0.03978022  
2023-05-25 23:31:04.922: [iter 454 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 328.815865]
2023-05-25 23:31:55.139: epoch 454:	0.00684351  	0.10965806  	0.05197136  	0.03931620  	0.03979064  
2023-05-25 23:38:12.216: [iter 455 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 375.549065]
2023-05-25 23:39:00.523: epoch 455:	0.00683421  	0.10953166  	0.05186361  	0.03919845  	0.03966707  
2023-05-25 23:45:11.593: [iter 456 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 369.521874]
2023-05-25 23:46:03.191: epoch 456:	0.00681876  	0.10924885  	0.05184035  	0.03923627  	0.03970516  
2023-05-25 23:51:55.560: [iter 457 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 350.843725]
2023-05-25 23:52:44.461: epoch 457:	0.00682044  	0.10926692  	0.05181793  	0.03921542  	0.03969111  
2023-05-25 23:58:21.090: [iter 458 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 335.062918]
2023-05-25 23:59:06.909: epoch 458:	0.00684129  	0.10948764  	0.05196976  	0.03935772  	0.03982333  
2023-05-26 00:04:40.163: [iter 459 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0147, time: 331.727035]
2023-05-26 00:05:31.466: epoch 459:	0.00684110  	0.10949425  	0.05199990  	0.03940211  	0.03987932  
2023-05-26 00:11:06.885: [iter 460 : loss : 0.4196 = 0.0047 + 0.4002 + 0.0148, time: 333.864991]
2023-05-26 00:11:58.581: epoch 460:	0.00683738  	0.10951294  	0.05197423  	0.03936045  	0.03983773  
2023-05-26 00:17:35.180: [iter 461 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0147, time: 334.939615]
2023-05-26 00:18:19.617: epoch 461:	0.00684650  	0.10972161  	0.05206399  	0.03939128  	0.03988439  
2023-05-26 00:23:55.965: [iter 462 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 334.841511]
2023-05-26 00:24:46.466: epoch 462:	0.00686455  	0.10984262  	0.05208523  	0.03940854  	0.03988024  
2023-05-26 00:30:18.514: [iter 463 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 330.501798]
2023-05-26 00:31:07.299: epoch 463:	0.00685189  	0.10964841  	0.05211975  	0.03952345  	0.04000046  
2023-05-26 00:36:44.269: [iter 464 : loss : 0.4196 = 0.0047 + 0.4002 + 0.0148, time: 335.424522]
2023-05-26 00:37:26.074: epoch 464:	0.00685152  	0.10967316  	0.05203638  	0.03940329  	0.03985672  
2023-05-26 00:43:03.739: [iter 465 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 336.307805]
2023-05-26 00:43:51.572: epoch 465:	0.00684277  	0.10948491  	0.05191214  	0.03929096  	0.03975513  
2023-05-26 00:49:25.932: [iter 466 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 332.780618]
2023-05-26 00:50:15.382: epoch 466:	0.00682434  	0.10939018  	0.05193301  	0.03934709  	0.03981237  
2023-05-26 00:55:51.890: [iter 467 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 334.922006]
2023-05-26 00:56:38.470: epoch 467:	0.00682807  	0.10939541  	0.05190575  	0.03933445  	0.03978437  
2023-05-26 01:02:15.345: [iter 468 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 335.345144]
2023-05-26 01:03:03.797: epoch 468:	0.00685505  	0.10986777  	0.05205213  	0.03937246  	0.03982929  
2023-05-26 01:03:03.797: Found a better model.
2023-05-26 01:03:03.797: Save model to file as pretrain.
2023-05-26 01:08:40.322: [iter 469 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0147, time: 333.974362]
2023-05-26 01:09:28.152: epoch 469:	0.00684836  	0.10971223  	0.05199634  	0.03933757  	0.03980447  
2023-05-26 01:15:04.449: [iter 470 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 334.785893]
2023-05-26 01:15:50.725: epoch 470:	0.00684575  	0.10968876  	0.05197530  	0.03931738  	0.03977824  
2023-05-26 01:21:25.816: [iter 471 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0147, time: 333.523537]
2023-05-26 01:22:13.891: epoch 471:	0.00683942  	0.10964391  	0.05203262  	0.03942388  	0.03987401  
2023-05-26 01:27:48.173: [iter 472 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 332.745462]
2023-05-26 01:28:36.526: epoch 472:	0.00684501  	0.10963760  	0.05205568  	0.03941714  	0.03989166  
2023-05-26 01:34:14.556: [iter 473 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 336.473335]
2023-05-26 01:34:51.296: epoch 473:	0.00683868  	0.10959046  	0.05197125  	0.03931670  	0.03977772  
2023-05-26 01:40:25.339: [iter 474 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 332.667968]
2023-05-26 01:41:12.781: epoch 474:	0.00682863  	0.10940609  	0.05197581  	0.03936849  	0.03985529  
2023-05-26 01:46:49.065: [iter 475 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 334.765473]
2023-05-26 01:47:38.084: epoch 475:	0.00682509  	0.10932337  	0.05189177  	0.03928603  	0.03975417  
2023-05-26 01:53:10.448: [iter 476 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 330.829522]
2023-05-26 01:53:56.202: epoch 476:	0.00683440  	0.10953417  	0.05196660  	0.03932544  	0.03977963  
2023-05-26 02:00:10.122: [iter 477 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 372.379210]
2023-05-26 02:00:58.644: epoch 477:	0.00681858  	0.10924184  	0.05187267  	0.03928078  	0.03972685  
2023-05-26 02:06:29.968: [iter 478 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 329.806036]
2023-05-26 02:07:19.790: epoch 478:	0.00682286  	0.10928784  	0.05191068  	0.03930185  	0.03976190  
2023-05-26 02:12:56.398: [iter 479 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 335.105007]
2023-05-26 02:13:29.630: epoch 479:	0.00684873  	0.10979671  	0.05202160  	0.03931624  	0.03978917  
2023-05-26 02:19:05.590: [iter 480 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 334.606592]
2023-05-26 02:19:53.415: epoch 480:	0.00684445  	0.10974130  	0.05198333  	0.03929685  	0.03975344  
2023-05-26 02:25:27.812: [iter 481 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 332.865454]
2023-05-26 02:26:16.621: epoch 481:	0.00683050  	0.10943839  	0.05186981  	0.03922983  	0.03968304  
2023-05-26 02:31:53.284: [iter 482 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 335.125216]
2023-05-26 02:32:36.706: epoch 482:	0.00683812  	0.10949444  	0.05192522  	0.03925719  	0.03972616  
2023-05-26 02:38:13.568: [iter 483 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0148, time: 335.492377]
2023-05-26 02:39:01.501: epoch 483:	0.00684184  	0.10960522  	0.05197332  	0.03931459  	0.03977809  
2023-05-26 02:45:18.987: [iter 484 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0147, time: 375.945642]
2023-05-26 02:46:09.869: epoch 484:	0.00685432  	0.10978466  	0.05210711  	0.03942639  	0.03990429  
2023-05-26 02:52:25.148: [iter 485 : loss : 0.4197 = 0.0047 + 0.4002 + 0.0148, time: 373.716663]
2023-05-26 02:53:13.272: epoch 485:	0.00684799  	0.10966610  	0.05196018  	0.03926438  	0.03974895  
2023-05-26 02:58:45.645: [iter 486 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 330.842774]
2023-05-26 02:59:31.285: epoch 486:	0.00685990  	0.10987844  	0.05197222  	0.03925392  	0.03974646  
2023-05-26 02:59:31.285: Found a better model.
2023-05-26 02:59:31.285: Save model to file as pretrain.
2023-05-26 03:05:04.727: [iter 487 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0147, time: 330.871580]
2023-05-26 03:05:53.136: epoch 487:	0.00684259  	0.10973171  	0.05201543  	0.03933512  	0.03980587  
2023-05-26 03:11:26.354: [iter 488 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 331.654606]
2023-05-26 03:12:13.949: epoch 488:	0.00684259  	0.10969291  	0.05203721  	0.03938627  	0.03985724  
2023-05-26 03:17:48.866: [iter 489 : loss : 0.4197 = 0.0047 + 0.4002 + 0.0148, time: 333.386252]
2023-05-26 03:18:30.735: epoch 489:	0.00685487  	0.10986935  	0.05200379  	0.03928655  	0.03975431  
2023-05-26 03:24:08.251: [iter 490 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 336.159755]
2023-05-26 03:24:56.098: epoch 490:	0.00683682  	0.10963494  	0.05198044  	0.03932310  	0.03977377  
2023-05-26 03:30:32.564: [iter 491 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 334.901747]
2023-05-26 03:31:20.539: epoch 491:	0.00684631  	0.10970164  	0.05205245  	0.03943232  	0.03986992  
2023-05-26 03:37:35.705: [iter 492 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 373.641024]
2023-05-26 03:38:23.658: epoch 492:	0.00683551  	0.10952535  	0.05199704  	0.03940080  	0.03984851  
2023-05-26 03:44:42.685: [iter 493 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 377.515510]
2023-05-26 03:45:28.324: epoch 493:	0.00683700  	0.10951715  	0.05192157  	0.03931313  	0.03975734  
2023-05-26 03:51:45.356: [iter 494 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 375.491580]
2023-05-26 03:52:33.109: epoch 494:	0.00683496  	0.10954299  	0.05196316  	0.03933926  	0.03978381  
2023-05-26 03:58:03.455: [iter 495 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 328.815386]
2023-05-26 03:58:51.958: epoch 495:	0.00684110  	0.10957880  	0.05196103  	0.03932497  	0.03978827  
2023-05-26 04:04:27.842: [iter 496 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0147, time: 334.344159]
2023-05-26 04:05:16.077: epoch 496:	0.00683085  	0.10930768  	0.05197200  	0.03943842  	0.03991523  
2023-05-26 04:10:48.765: [iter 497 : loss : 0.4197 = 0.0047 + 0.4002 + 0.0148, time: 331.134471]
2023-05-26 04:11:36.458: epoch 497:	0.00684798  	0.10962555  	0.05205666  	0.03947245  	0.03993024  
2023-05-26 04:17:13.030: [iter 498 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 335.043759]
2023-05-26 04:18:00.386: epoch 498:	0.00686027  	0.10986347  	0.05200928  	0.03934004  	0.03979399  
2023-05-26 04:23:31.198: [iter 499 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 329.261596]
2023-05-26 04:24:20.651: epoch 499:	0.00684836  	0.10979314  	0.05195761  	0.03928434  	0.03974695  
2023-05-26 04:29:56.826: [iter 500 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 334.664760]
2023-05-26 04:30:44.181: epoch 500:	0.00685748  	0.10987040  	0.05202579  	0.03939915  	0.03987541  
2023-05-26 04:36:19.077: [iter 501 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 333.357931]
2023-05-26 04:37:07.717: epoch 501:	0.00685915  	0.10987113  	0.05204729  	0.03940877  	0.03987262  
2023-05-26 04:42:44.006: [iter 502 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0147, time: 334.738695]
2023-05-26 04:43:32.040: epoch 502:	0.00686102  	0.10988923  	0.05207079  	0.03940000  	0.03987018  
2023-05-26 04:43:32.041: Found a better model.
2023-05-26 04:43:32.041: Save model to file as pretrain.
2023-05-26 04:49:07.897: [iter 503 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 333.292148]
2023-05-26 04:49:53.250: epoch 503:	0.00686976  	0.11000418  	0.05204678  	0.03931957  	0.03978505  
2023-05-26 04:49:53.250: Found a better model.
2023-05-26 04:49:53.250: Save model to file as pretrain.
2023-05-26 04:56:11.353: [iter 504 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 375.545302]
2023-05-26 04:56:59.011: epoch 504:	0.00686734  	0.11002508  	0.05203876  	0.03932229  	0.03978456  
2023-05-26 04:56:59.011: Found a better model.
2023-05-26 04:56:59.011: Save model to file as pretrain.
2023-05-26 05:02:34.065: [iter 505 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 332.472784]
2023-05-26 05:03:21.691: epoch 505:	0.00685469  	0.10984922  	0.05202526  	0.03935807  	0.03983071  
2023-05-26 05:08:50.207: [iter 506 : loss : 0.4197 = 0.0047 + 0.4002 + 0.0148, time: 326.977873]
2023-05-26 05:09:38.537: epoch 506:	0.00685692  	0.10983320  	0.05196163  	0.03930482  	0.03977318  
2023-05-26 05:15:13.279: [iter 507 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 333.235085]
2023-05-26 05:16:00.500: epoch 507:	0.00686511  	0.10998108  	0.05202601  	0.03934577  	0.03980754  
2023-05-26 05:21:35.211: [iter 508 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 333.162973]
2023-05-26 05:22:23.796: epoch 508:	0.00684855  	0.10978667  	0.05195358  	0.03932383  	0.03979200  
2023-05-26 05:27:59.984: [iter 509 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 334.673759]
2023-05-26 05:28:47.994: epoch 509:	0.00686213  	0.11003319  	0.05209308  	0.03941768  	0.03989407  
2023-05-26 05:28:47.994: Found a better model.
2023-05-26 05:28:47.994: Save model to file as pretrain.
2023-05-26 05:34:25.778: [iter 510 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0147, time: 335.232974]
2023-05-26 05:35:12.405: epoch 510:	0.00687424  	0.11027760  	0.05211873  	0.03940849  	0.03987164  
2023-05-26 05:35:12.405: Found a better model.
2023-05-26 05:35:12.405: Save model to file as pretrain.
2023-05-26 05:40:53.024: [iter 511 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0147, time: 338.081326]
2023-05-26 05:41:41.299: epoch 511:	0.00685730  	0.10992407  	0.05204615  	0.03937408  	0.03985668  
2023-05-26 05:47:16.922: [iter 512 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 334.100098]
2023-05-26 05:48:05.030: epoch 512:	0.00686921  	0.11012835  	0.05197871  	0.03924715  	0.03971124  
2023-05-26 05:53:43.143: [iter 513 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0148, time: 336.577652]
2023-05-26 05:54:26.088: epoch 513:	0.00683794  	0.10951114  	0.05181073  	0.03918333  	0.03963774  
2023-05-26 06:00:41.926: [iter 514 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 374.484407]
2023-05-26 06:01:29.371: epoch 514:	0.00683682  	0.10965293  	0.05192029  	0.03927734  	0.03974459  
2023-05-26 06:07:11.782: [iter 515 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 340.847350]
2023-05-26 06:07:59.427: epoch 515:	0.00683626  	0.10962024  	0.05187009  	0.03920723  	0.03967445  
2023-05-26 06:13:34.712: [iter 516 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 333.738971]
2023-05-26 06:14:10.506: epoch 516:	0.00685078  	0.10984124  	0.05190786  	0.03919620  	0.03966168  
2023-05-26 06:19:48.563: [iter 517 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0147, time: 336.712959]
2023-05-26 06:20:36.141: epoch 517:	0.00685711  	0.10996455  	0.05200299  	0.03928851  	0.03974514  
2023-05-26 06:26:12.631: [iter 518 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0147, time: 334.960611]
2023-05-26 06:27:00.052: epoch 518:	0.00687720  	0.11010616  	0.05204951  	0.03929069  	0.03976044  
2023-05-26 06:32:35.767: [iter 519 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 334.169556]
2023-05-26 06:33:20.492: epoch 519:	0.00686586  	0.11008724  	0.05206465  	0.03932573  	0.03979327  
2023-05-26 06:38:58.715: [iter 520 : loss : 0.4197 = 0.0047 + 0.4002 + 0.0147, time: 336.681636]
2023-05-26 06:39:47.543: epoch 520:	0.00687628  	0.11030173  	0.05217013  	0.03944352  	0.03993242  
2023-05-26 06:39:47.543: Found a better model.
2023-05-26 06:39:47.543: Save model to file as pretrain.
2023-05-26 06:45:26.727: [iter 521 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0148, time: 336.626170]
2023-05-26 06:46:15.908: epoch 521:	0.00688726  	0.11037771  	0.05217091  	0.03939379  	0.03988450  
2023-05-26 06:46:15.909: Found a better model.
2023-05-26 06:46:15.909: Save model to file as pretrain.
2023-05-26 06:51:49.710: [iter 522 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 331.270063]
2023-05-26 06:52:35.211: epoch 522:	0.00686474  	0.11002906  	0.05208577  	0.03940591  	0.03987323  
2023-05-26 06:58:19.882: [iter 523 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 343.121156]
2023-05-26 06:59:07.629: epoch 523:	0.00687591  	0.11017295  	0.05201511  	0.03926284  	0.03974047  
2023-05-26 07:05:22.807: [iter 524 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0147, time: 373.642103]
2023-05-26 07:06:10.851: epoch 524:	0.00686474  	0.10992245  	0.05197829  	0.03926133  	0.03973322  
2023-05-26 07:12:29.601: [iter 525 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 377.196463]
2023-05-26 07:13:18.405: epoch 525:	0.00686661  	0.11016868  	0.05206792  	0.03930828  	0.03977414  
2023-05-26 07:19:35.470: [iter 526 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 375.583869]
2023-05-26 07:20:23.947: epoch 526:	0.00686828  	0.11011472  	0.05198259  	0.03919349  	0.03967628  
2023-05-26 07:25:57.554: [iter 527 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 332.063077]
2023-05-26 07:26:43.838: epoch 527:	0.00686717  	0.11015029  	0.05205670  	0.03930860  	0.03978147  
2023-05-26 07:32:15.940: [iter 528 : loss : 0.4197 = 0.0047 + 0.4002 + 0.0147, time: 330.534910]
2023-05-26 07:33:05.360: epoch 528:	0.00687163  	0.11009804  	0.05207824  	0.03932486  	0.03980894  
2023-05-26 07:38:42.474: [iter 529 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0147, time: 335.554734]
2023-05-26 07:39:30.509: epoch 529:	0.00686102  	0.10991737  	0.05203491  	0.03932059  	0.03981149  
2023-05-26 07:45:04.152: [iter 530 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 332.094764]
2023-05-26 07:45:49.164: epoch 530:	0.00685581  	0.10984584  	0.05204523  	0.03935469  	0.03983038  
2023-05-26 07:51:25.366: [iter 531 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 334.687583]
2023-05-26 07:52:12.619: epoch 531:	0.00686177  	0.10998172  	0.05217804  	0.03952031  	0.03999831  
2023-05-26 07:57:48.075: [iter 532 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 333.912545]
2023-05-26 07:58:35.647: epoch 532:	0.00685636  	0.10991982  	0.05207562  	0.03940574  	0.03987456  
2023-05-26 08:04:08.726: [iter 533 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 331.547857]
2023-05-26 08:04:44.183: epoch 533:	0.00685376  	0.10992184  	0.05206510  	0.03937205  	0.03982883  
2023-05-26 08:10:14.023: [iter 534 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0147, time: 328.483462]
2023-05-26 08:11:02.301: epoch 534:	0.00687070  	0.11015578  	0.05212316  	0.03938280  	0.03984308  
2023-05-26 08:17:20.840: [iter 535 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0147, time: 376.969449]
2023-05-26 08:18:07.827: epoch 535:	0.00685618  	0.10983006  	0.05206901  	0.03936529  	0.03984154  
2023-05-26 08:23:37.970: [iter 536 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 328.604203]
2023-05-26 08:24:24.535: epoch 536:	0.00686772  	0.11005077  	0.05203486  	0.03927845  	0.03973003  
2023-05-26 08:30:42.764: [iter 537 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0147, time: 376.696203]
2023-05-26 08:31:26.854: epoch 537:	0.00687070  	0.11020235  	0.05207344  	0.03930078  	0.03975711  
2023-05-26 08:37:08.090: [iter 538 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 339.716482]
2023-05-26 08:37:56.717: epoch 538:	0.00689229  	0.11038740  	0.05216616  	0.03935571  	0.03981021  
2023-05-26 08:37:56.719: Found a better model.
2023-05-26 08:37:56.719: Save model to file as pretrain.
2023-05-26 08:44:14.552: [iter 539 : loss : 0.4197 = 0.0047 + 0.4002 + 0.0148, time: 375.301364]
2023-05-26 08:45:02.210: epoch 539:	0.00687666  	0.11019552  	0.05212448  	0.03940428  	0.03984390  
2023-05-26 08:51:17.547: [iter 540 : loss : 0.4196 = 0.0047 + 0.4002 + 0.0147, time: 373.828664]
2023-05-26 08:52:05.356: epoch 540:	0.00687554  	0.11019414  	0.05209606  	0.03931279  	0.03977996  
2023-05-26 08:57:37.169: [iter 541 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 330.259757]
2023-05-26 08:58:22.184: epoch 541:	0.00687498  	0.11008511  	0.05207548  	0.03934112  	0.03980766  
2023-05-26 09:03:54.073: [iter 542 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 330.323805]
2023-05-26 09:04:42.950: epoch 542:	0.00687535  	0.11013925  	0.05204868  	0.03929135  	0.03976504  
2023-05-26 09:10:13.137: [iter 543 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 328.634843]
2023-05-26 09:11:01.514: epoch 543:	0.00686437  	0.10997802  	0.05193656  	0.03917062  	0.03964275  
2023-05-26 09:16:31.843: [iter 544 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0147, time: 328.792933]
2023-05-26 09:17:17.396: epoch 544:	0.00685301  	0.10978032  	0.05196745  	0.03928562  	0.03975289  
2023-05-26 09:22:51.196: [iter 545 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 332.341390]
2023-05-26 09:23:38.946: epoch 545:	0.00685208  	0.10974745  	0.05197313  	0.03929595  	0.03977001  
2023-05-26 09:29:17.032: [iter 546 : loss : 0.4197 = 0.0047 + 0.4002 + 0.0147, time: 336.556573]
2023-05-26 09:30:04.957: epoch 546:	0.00685394  	0.10980006  	0.05196797  	0.03927179  	0.03973985  
2023-05-26 09:35:43.078: [iter 547 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 336.575874]
2023-05-26 09:36:24.113: epoch 547:	0.00685989  	0.10982097  	0.05200025  	0.03934152  	0.03980324  
2023-05-26 09:41:58.405: [iter 548 : loss : 0.4197 = 0.0047 + 0.4002 + 0.0147, time: 332.943995]
2023-05-26 09:42:46.751: epoch 548:	0.00686846  	0.10997801  	0.05203190  	0.03937283  	0.03983506  
2023-05-26 09:48:22.879: [iter 549 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 334.584076]
2023-05-26 09:49:10.738: epoch 549:	0.00685375  	0.10981701  	0.05207057  	0.03946701  	0.03991837  
2023-05-26 09:54:46.937: [iter 550 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 334.695108]
2023-05-26 09:55:34.304: epoch 550:	0.00685171  	0.10972948  	0.05204112  	0.03945722  	0.03988792  
2023-05-26 10:01:08.775: [iter 551 : loss : 0.4197 = 0.0047 + 0.4002 + 0.0147, time: 332.928408]
2023-05-26 10:01:57.500: epoch 551:	0.00686269  	0.11003339  	0.05217199  	0.03954198  	0.03999240  
2023-05-26 10:07:29.578: [iter 552 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0147, time: 330.545081]
2023-05-26 10:08:17.277: epoch 552:	0.00685301  	0.10981106  	0.05199273  	0.03928933  	0.03975837  
2023-05-26 10:13:47.538: [iter 553 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 328.752777]
2023-05-26 10:14:33.224: epoch 553:	0.00685041  	0.10980424  	0.05200573  	0.03934421  	0.03979103  
2023-05-26 10:20:06.727: [iter 554 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 331.971141]
2023-05-26 10:20:56.202: epoch 554:	0.00685972  	0.10995190  	0.05197168  	0.03922880  	0.03968889  
2023-05-26 10:27:11.017: [iter 555 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0148, time: 373.296860]
2023-05-26 10:27:59.758: epoch 555:	0.00685562  	0.10986688  	0.05211461  	0.03949228  	0.03995433  
2023-05-26 10:33:35.723: [iter 556 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 334.447399]
2023-05-26 10:34:22.680: epoch 556:	0.00685265  	0.10976012  	0.05203930  	0.03938735  	0.03984932  
2023-05-26 10:39:57.144: [iter 557 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0147, time: 332.925061]
2023-05-26 10:40:45.217: epoch 557:	0.00687238  	0.11010943  	0.05210342  	0.03936905  	0.03981823  
2023-05-26 10:46:18.057: [iter 558 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 331.283765]
2023-05-26 10:47:06.446: epoch 558:	0.00687386  	0.11011381  	0.05214981  	0.03940729  	0.03988166  
2023-05-26 10:52:38.444: [iter 559 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 330.468965]
2023-05-26 10:53:27.116: epoch 559:	0.00685488  	0.10982224  	0.05205215  	0.03939210  	0.03987086  
2023-05-26 10:59:43.789: [iter 560 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 375.136048]
2023-05-26 11:00:29.806: epoch 560:	0.00685525  	0.10981966  	0.05206597  	0.03940916  	0.03988626  
2023-05-26 11:06:48.127: [iter 561 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 376.837778]
2023-05-26 11:07:34.730: epoch 561:	0.00684203  	0.10962310  	0.05200353  	0.03940127  	0.03985159  
2023-05-26 11:13:18.569: [iter 562 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 342.288635]
2023-05-26 11:14:07.426: epoch 562:	0.00685450  	0.10971899  	0.05202248  	0.03936995  	0.03984614  
2023-05-26 11:20:25.793: [iter 563 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 376.843684]
2023-05-26 11:21:13.962: epoch 563:	0.00685432  	0.10986093  	0.05208126  	0.03939562  	0.03987223  
2023-05-26 11:26:45.731: [iter 564 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 330.235030]
2023-05-26 11:27:33.318: epoch 564:	0.00685432  	0.10977846  	0.05203650  	0.03938153  	0.03985388  
2023-05-26 11:33:09.864: [iter 565 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 335.015888]
2023-05-26 11:33:58.406: epoch 565:	0.00685338  	0.10978068  	0.05197057  	0.03929312  	0.03975741  
2023-05-26 11:39:34.202: [iter 566 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0147, time: 334.267309]
2023-05-26 11:40:21.291: epoch 566:	0.00685543  	0.10978327  	0.05207488  	0.03942754  	0.03988849  
2023-05-26 11:45:57.478: [iter 567 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 334.626080]
2023-05-26 11:46:44.586: epoch 567:	0.00685878  	0.10985038  	0.05205963  	0.03939491  	0.03986089  
2023-05-26 11:52:16.472: [iter 568 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 330.371768]
2023-05-26 11:53:03.505: epoch 568:	0.00686530  	0.10999263  	0.05207867  	0.03934826  	0.03981513  
2023-05-26 11:58:39.626: [iter 569 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 334.602568]
2023-05-26 11:59:28.309: epoch 569:	0.00685264  	0.10983694  	0.05208103  	0.03941804  	0.03988785  
2023-05-26 12:05:04.261: [iter 570 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0147, time: 334.486724]
2023-05-26 12:05:52.675: epoch 570:	0.00685767  	0.10990202  	0.05210784  	0.03942428  	0.03990027  
2023-05-26 12:11:27.845: [iter 571 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 333.628418]
2023-05-26 12:12:05.067: epoch 571:	0.00684873  	0.10963796  	0.05201269  	0.03936072  	0.03981594  
2023-05-26 12:18:22.818: [iter 572 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 376.398134]
2023-05-26 12:19:11.304: epoch 572:	0.00686455  	0.10992746  	0.05207317  	0.03936382  	0.03982762  
2023-05-26 12:24:52.341: [iter 573 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 339.505805]
2023-05-26 12:25:41.255: epoch 573:	0.00687013  	0.10996829  	0.05205339  	0.03930972  	0.03979459  
2023-05-26 12:31:19.535: [iter 574 : loss : 0.4197 = 0.0047 + 0.4002 + 0.0147, time: 336.742478]
2023-05-26 12:32:07.835: epoch 574:	0.00685878  	0.10982231  	0.05201809  	0.03932633  	0.03979709  
2023-05-26 12:37:39.558: [iter 575 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0148, time: 330.227436]
2023-05-26 12:38:27.245: epoch 575:	0.00684686  	0.10957496  	0.05199499  	0.03932500  	0.03980208  
2023-05-26 12:44:02.269: [iter 576 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0147, time: 333.496581]
2023-05-26 12:44:49.998: epoch 576:	0.00685283  	0.10974690  	0.05208087  	0.03941477  	0.03990918  
2023-05-26 12:50:27.027: [iter 577 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 335.482460]
2023-05-26 12:51:15.865: epoch 577:	0.00686642  	0.10992838  	0.05209930  	0.03939825  	0.03987937  
2023-05-26 12:56:50.674: [iter 578 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 333.262286]
2023-05-26 12:57:37.508: epoch 578:	0.00685059  	0.10968101  	0.05208632  	0.03944789  	0.03995023  
2023-05-26 13:03:11.686: [iter 579 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 332.649228]
2023-05-26 13:03:59.656: epoch 579:	0.00686846  	0.11003157  	0.05214674  	0.03943057  	0.03992260  
2023-05-26 13:10:16.781: [iter 580 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 375.539017]
2023-05-26 13:11:06.027: epoch 580:	0.00686455  	0.10989583  	0.05209437  	0.03942396  	0.03991740  
2023-05-26 13:17:22.864: [iter 581 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 375.281202]
2023-05-26 13:18:11.898: epoch 581:	0.00685394  	0.10970192  	0.05201912  	0.03933620  	0.03982668  
2023-05-26 13:23:55.831: [iter 582 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 342.389209]
2023-05-26 13:24:43.110: epoch 582:	0.00684817  	0.10974492  	0.05200951  	0.03932456  	0.03980676  
2023-05-26 13:30:25.642: [iter 583 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 340.990605]
2023-05-26 13:31:13.678: epoch 583:	0.00683681  	0.10952397  	0.05196950  	0.03933912  	0.03981556  
2023-05-26 13:36:50.043: [iter 584 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 334.821473]
2023-05-26 13:37:38.814: epoch 584:	0.00683030  	0.10946132  	0.05190264  	0.03924754  	0.03974448  
2023-05-26 13:43:17.326: [iter 585 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 336.928932]
2023-05-26 13:44:05.650: epoch 585:	0.00683980  	0.10964819  	0.05195231  	0.03927577  	0.03975993  
2023-05-26 13:49:39.915: [iter 586 : loss : 0.4197 = 0.0048 + 0.4002 + 0.0147, time: 332.672507]
2023-05-26 13:50:26.831: epoch 586:	0.00683868  	0.10952645  	0.05193564  	0.03929244  	0.03976413  
2023-05-26 13:56:01.589: [iter 587 : loss : 0.4198 = 0.0049 + 0.4002 + 0.0147, time: 333.196161]
2023-05-26 13:56:50.367: epoch 587:	0.00683924  	0.10962185  	0.05188639  	0.03917956  	0.03965699  
2023-05-26 14:02:26.501: [iter 588 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0147, time: 334.599418]
2023-05-26 14:03:15.704: epoch 588:	0.00684911  	0.10983432  	0.05192656  	0.03919899  	0.03967613  
2023-05-26 14:03:15.704: Early stopping is trigger at epoch: 588
2023-05-26 14:03:15.704: best_result@epoch 538:

2023-05-26 14:03:15.704: Loading from the saved model.
2023-05-26 14:04:04.278: 		0.00689229  	0.11038740  	0.05216616  	0.03935571  	0.03981021  
