seed= 2021
load saved data...
Item degree grouping...
User degree grouping...
Data loading finished
Evaluate model with cpp
2023-06-09 10:21:19.312: Dataset name: ifashion
The number of users: 300000
The number of items: 81614
The number of ratings: 1607813
Average actions of users: 5.36
Average actions of items: 19.70
The sparsity of the dataset: 99.993433%
2023-06-09 10:21:19.312: 

NeuRec hyperparameters:
recommender=SGL
config_dir=./conf
gpu_id=0
gpu_mem=1.0
data.input.path=dataset
data.input.dataset=ifashion
data.column.format=UI
data.convert.separator=','
user_min=0
item_min=0
splitter=given
ratio=0.8
by_time=False
metric=["Precision", "Recall", "NDCG", "MAP", "MRR"]
topk=[20]
group_view=None
rec.evaluate.neg=0
test_batch_size=128
num_thread=8
start_testing_epoch=0
proj_path=./

SGL's hyperparameters:
seed=2021
aug_type=0
reg=1e-3
embed_size=64
n_layers=3
ssl_reg=0.02
ssl_ratio=0.4
ssl_temp=0.5
ssl_mode=both_side
ssl_loss_type=1
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=1024
num_negatives=1
init_method=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=20
pretrain=0
save_flag=1

Using decoupled loss
2023-06-09 10:21:41.566: metrics:	Precision@20	Recall@20   	NDCG@20     	MAP@20      	MRR@20      
2023-06-09 10:23:05.313: 		0.00000502  	0.00007604  	0.00002224  	0.00000956  	0.00000956  
2023-06-09 10:26:20.792: [iter 1 : loss : 1.0054 = 0.6012 + 0.4037 + 0.0006, time: 194.526640]
2023-06-09 10:27:44.758: epoch 1:	0.00241426  	0.03888346  	0.01663901  	0.01172958  	0.01178569  
2023-06-09 10:27:44.758: Found a better model.
2023-06-09 10:27:44.758: Save model to file as pretrain.
2023-06-09 10:31:00.428: [iter 2 : loss : 0.6926 = 0.2650 + 0.4236 + 0.0040, time: 193.568051]
2023-06-09 10:32:16.757: epoch 2:	0.00282685  	0.04533562  	0.01987344  	0.01434710  	0.01442412  
2023-06-09 10:32:16.758: Found a better model.
2023-06-09 10:32:16.758: Save model to file as pretrain.
2023-06-09 10:35:34.288: [iter 3 : loss : 0.5952 = 0.1690 + 0.4200 + 0.0062, time: 195.627012]
2023-06-09 10:36:52.622: epoch 3:	0.00330805  	0.05307128  	0.02326510  	0.01675783  	0.01686489  
2023-06-09 10:36:52.622: Found a better model.
2023-06-09 10:36:52.623: Save model to file as pretrain.
2023-06-09 10:40:12.738: [iter 4 : loss : 0.5481 = 0.1250 + 0.4155 + 0.0076, time: 198.167332]
2023-06-09 10:41:28.797: epoch 4:	0.00370372  	0.05946786  	0.02633157  	0.01908598  	0.01921331  
2023-06-09 10:41:28.797: Found a better model.
2023-06-09 10:41:28.797: Save model to file as pretrain.
2023-06-09 10:44:50.714: [iter 5 : loss : 0.5186 = 0.0976 + 0.4124 + 0.0087, time: 199.921148]
2023-06-09 10:46:05.820: epoch 5:	0.00401782  	0.06461108  	0.02866056  	0.02075585  	0.02089807  
2023-06-09 10:46:05.820: Found a better model.
2023-06-09 10:46:05.820: Save model to file as pretrain.
2023-06-09 10:49:23.070: [iter 6 : loss : 0.4986 = 0.0789 + 0.4101 + 0.0097, time: 195.176412]
2023-06-09 10:50:40.710: epoch 6:	0.00428142  	0.06882562  	0.03068109  	0.02225465  	0.02240874  
2023-06-09 10:50:40.711: Found a better model.
2023-06-09 10:50:40.711: Save model to file as pretrain.
2023-06-09 10:53:58.911: [iter 7 : loss : 0.4840 = 0.0650 + 0.4085 + 0.0106, time: 196.097397]
2023-06-09 10:55:17.610: epoch 7:	0.00448190  	0.07212029  	0.03232357  	0.02351790  	0.02369797  
2023-06-09 10:55:17.611: Found a better model.
2023-06-09 10:55:17.611: Save model to file as pretrain.
2023-06-09 10:58:51.898: [iter 8 : loss : 0.4730 = 0.0545 + 0.4071 + 0.0113, time: 212.376291]
2023-06-09 11:00:10.812: epoch 8:	0.00464106  	0.07469868  	0.03358690  	0.02449176  	0.02468592  
2023-06-09 11:00:10.812: Found a better model.
2023-06-09 11:00:10.812: Save model to file as pretrain.
2023-06-09 11:03:28.998: [iter 9 : loss : 0.4648 = 0.0466 + 0.4061 + 0.0121, time: 196.190080]
2023-06-09 11:04:40.525: epoch 9:	0.00480915  	0.07744613  	0.03492649  	0.02552642  	0.02572138  
2023-06-09 11:04:40.525: Found a better model.
2023-06-09 11:04:40.525: Save model to file as pretrain.
2023-06-09 11:08:14.924: [iter 10 : loss : 0.4580 = 0.0401 + 0.4052 + 0.0127, time: 212.401695]
2023-06-09 11:09:31.831: epoch 10:	0.00495323  	0.07973938  	0.03607581  	0.02640337  	0.02660502  
2023-06-09 11:09:31.831: Found a better model.
2023-06-09 11:09:31.831: Save model to file as pretrain.
2023-06-09 11:12:52.036: [iter 11 : loss : 0.4525 = 0.0347 + 0.4046 + 0.0132, time: 194.837015]
2023-06-09 11:14:15.989: epoch 11:	0.00508670  	0.08190581  	0.03707047  	0.02713936  	0.02734258  
2023-06-09 11:14:15.989: Found a better model.
2023-06-09 11:14:15.989: Save model to file as pretrain.
2023-06-09 11:17:37.612: [iter 12 : loss : 0.4482 = 0.0305 + 0.4040 + 0.0137, time: 196.152787]
2023-06-09 11:18:55.129: epoch 12:	0.00521551  	0.08399154  	0.03804523  	0.02787786  	0.02809840  
2023-06-09 11:18:55.129: Found a better model.
2023-06-09 11:18:55.129: Save model to file as pretrain.
2023-06-09 11:22:14.956: [iter 13 : loss : 0.4446 = 0.0270 + 0.4034 + 0.0141, time: 193.826562]
2023-06-09 11:23:31.681: epoch 13:	0.00532887  	0.08572166  	0.03894855  	0.02854756  	0.02879031  
2023-06-09 11:23:31.682: Found a better model.
2023-06-09 11:23:31.682: Save model to file as pretrain.
2023-06-09 11:26:51.392: [iter 14 : loss : 0.4416 = 0.0242 + 0.4030 + 0.0145, time: 193.734672]
2023-06-09 11:28:09.618: epoch 14:	0.00542548  	0.08737299  	0.03982244  	0.02926849  	0.02952091  
2023-06-09 11:28:09.618: Found a better model.
2023-06-09 11:28:09.618: Save model to file as pretrain.
2023-06-09 11:31:28.661: [iter 15 : loss : 0.4394 = 0.0220 + 0.4026 + 0.0148, time: 193.342714]
2023-06-09 11:32:40.776: epoch 15:	0.00550162  	0.08856758  	0.04045068  	0.02979210  	0.03004459  
2023-06-09 11:32:40.777: Found a better model.
2023-06-09 11:32:40.777: Save model to file as pretrain.
2023-06-09 11:36:19.002: [iter 16 : loss : 0.4368 = 0.0195 + 0.4023 + 0.0151, time: 212.532367]
2023-06-09 11:37:36.813: epoch 16:	0.00557813  	0.08979931  	0.04105229  	0.03025783  	0.03052890  
2023-06-09 11:37:36.813: Found a better model.
2023-06-09 11:37:36.813: Save model to file as pretrain.
2023-06-09 11:40:58.100: [iter 17 : loss : 0.4350 = 0.0179 + 0.4019 + 0.0152, time: 195.425265]
2023-06-09 11:42:14.378: epoch 17:	0.00563285  	0.09062833  	0.04160788  	0.03075713  	0.03104836  
2023-06-09 11:42:14.378: Found a better model.
2023-06-09 11:42:14.378: Save model to file as pretrain.
2023-06-09 11:45:51.179: [iter 18 : loss : 0.4333 = 0.0162 + 0.4017 + 0.0154, time: 211.021411]
2023-06-09 11:47:09.860: epoch 18:	0.00566654  	0.09113232  	0.04203262  	0.03118541  	0.03146914  
2023-06-09 11:47:09.861: Found a better model.
2023-06-09 11:47:09.861: Save model to file as pretrain.
2023-06-09 11:50:27.341: [iter 19 : loss : 0.4318 = 0.0149 + 0.4015 + 0.0155, time: 191.573153]
2023-06-09 11:51:49.450: epoch 19:	0.00571160  	0.09189525  	0.04245650  	0.03152569  	0.03180856  
2023-06-09 11:51:49.457: Found a better model.
2023-06-09 11:51:49.457: Save model to file as pretrain.
2023-06-09 11:55:09.116: [iter 20 : loss : 0.4311 = 0.0143 + 0.4013 + 0.0156, time: 193.960344]
2023-06-09 11:56:30.954: epoch 20:	0.00575422  	0.09242161  	0.04282930  	0.03189292  	0.03218161  
2023-06-09 11:56:30.954: Found a better model.
2023-06-09 11:56:30.954: Save model to file as pretrain.
2023-06-09 11:59:59.931: [iter 21 : loss : 0.4296 = 0.0130 + 0.4011 + 0.0156, time: 203.331329]
2023-06-09 12:01:15.915: epoch 21:	0.00580373  	0.09308391  	0.04326715  	0.03225444  	0.03256913  
2023-06-09 12:01:15.915: Found a better model.
2023-06-09 12:01:15.919: Save model to file as pretrain.
2023-06-09 12:04:38.019: [iter 22 : loss : 0.4288 = 0.0123 + 0.4009 + 0.0156, time: 196.229039]
2023-06-09 12:05:55.204: epoch 22:	0.00584971  	0.09376040  	0.04362810  	0.03254668  	0.03287236  
2023-06-09 12:05:55.204: Found a better model.
2023-06-09 12:05:55.205: Save model to file as pretrain.
2023-06-09 12:09:16.631: [iter 23 : loss : 0.4280 = 0.0117 + 0.4008 + 0.0156, time: 196.061886]
2023-06-09 12:10:28.921: epoch 23:	0.00587614  	0.09423821  	0.04392924  	0.03283103  	0.03315374  
2023-06-09 12:10:28.922: Found a better model.
2023-06-09 12:10:28.922: Save model to file as pretrain.
2023-06-09 12:13:51.436: [iter 24 : loss : 0.4272 = 0.0110 + 0.4006 + 0.0156, time: 196.791382]
2023-06-09 12:15:01.964: epoch 24:	0.00590723  	0.09463641  	0.04417302  	0.03304231  	0.03337985  
2023-06-09 12:15:01.964: Found a better model.
2023-06-09 12:15:01.964: Save model to file as pretrain.
2023-06-09 12:18:39.797: [iter 25 : loss : 0.4266 = 0.0105 + 0.4005 + 0.0155, time: 212.118152]
2023-06-09 12:19:59.501: epoch 25:	0.00592603  	0.09492642  	0.04445322  	0.03333826  	0.03367968  
2023-06-09 12:19:59.502: Found a better model.
2023-06-09 12:19:59.502: Save model to file as pretrain.
2023-06-09 12:23:39.124: [iter 26 : loss : 0.4260 = 0.0101 + 0.4004 + 0.0155, time: 213.748458]
2023-06-09 12:24:56.740: epoch 26:	0.00595116  	0.09529319  	0.04477817  	0.03367463  	0.03401646  
2023-06-09 12:24:56.741: Found a better model.
2023-06-09 12:24:56.741: Save model to file as pretrain.
2023-06-09 12:28:17.097: [iter 27 : loss : 0.4253 = 0.0096 + 0.4003 + 0.0155, time: 194.794673]
2023-06-09 12:29:28.353: epoch 27:	0.00595916  	0.09536874  	0.04486512  	0.03379811  	0.03412344  
2023-06-09 12:29:28.353: Found a better model.
2023-06-09 12:29:28.353: Save model to file as pretrain.
2023-06-09 12:32:48.519: [iter 28 : loss : 0.4249 = 0.0092 + 0.4002 + 0.0154, time: 194.503938]
2023-06-09 12:34:04.694: epoch 28:	0.00597480  	0.09561869  	0.04498414  	0.03389952  	0.03422997  
2023-06-09 12:34:04.695: Found a better model.
2023-06-09 12:34:04.695: Save model to file as pretrain.
2023-06-09 12:37:24.833: [iter 29 : loss : 0.4244 = 0.0089 + 0.4001 + 0.0154, time: 195.121267]
2023-06-09 12:38:35.762: epoch 29:	0.00600459  	0.09607346  	0.04516778  	0.03400796  	0.03435852  
2023-06-09 12:38:35.762: Found a better model.
2023-06-09 12:38:35.762: Save model to file as pretrain.
2023-06-09 12:41:56.130: [iter 30 : loss : 0.4242 = 0.0088 + 0.4001 + 0.0153, time: 194.680351]
2023-06-09 12:43:07.619: epoch 30:	0.00601221  	0.09624080  	0.04529165  	0.03412151  	0.03446772  
2023-06-09 12:43:07.620: Found a better model.
2023-06-09 12:43:07.620: Save model to file as pretrain.
2023-06-09 12:46:28.229: [iter 31 : loss : 0.4238 = 0.0086 + 0.4000 + 0.0153, time: 196.002824]
2023-06-09 12:47:41.330: epoch 31:	0.00602915  	0.09649406  	0.04542140  	0.03422350  	0.03457439  
2023-06-09 12:47:41.331: Found a better model.
2023-06-09 12:47:41.331: Save model to file as pretrain.
2023-06-09 12:50:58.165: [iter 32 : loss : 0.4234 = 0.0082 + 0.3999 + 0.0153, time: 194.814959]
2023-06-09 12:52:16.798: epoch 32:	0.00603753  	0.09667070  	0.04553305  	0.03432632  	0.03468768  
2023-06-09 12:52:16.798: Found a better model.
2023-06-09 12:52:16.798: Save model to file as pretrain.
2023-06-09 12:55:34.163: [iter 33 : loss : 0.4230 = 0.0080 + 0.3998 + 0.0152, time: 195.405571]
2023-06-09 12:56:46.925: epoch 33:	0.00606825  	0.09706599  	0.04574533  	0.03452107  	0.03488221  
2023-06-09 12:56:46.925: Found a better model.
2023-06-09 12:56:46.925: Save model to file as pretrain.
2023-06-09 13:00:06.398: [iter 34 : loss : 0.4229 = 0.0079 + 0.3998 + 0.0152, time: 197.452446]
2023-06-09 13:01:23.644: epoch 34:	0.00608351  	0.09730184  	0.04587961  	0.03462742  	0.03498713  
2023-06-09 13:01:23.644: Found a better model.
2023-06-09 13:01:23.644: Save model to file as pretrain.
2023-06-09 13:04:42.303: [iter 35 : loss : 0.4226 = 0.0077 + 0.3997 + 0.0152, time: 195.844964]
2023-06-09 13:05:53.460: epoch 35:	0.00609691  	0.09744660  	0.04601417  	0.03477594  	0.03514547  
2023-06-09 13:05:53.461: Found a better model.
2023-06-09 13:05:53.461: Save model to file as pretrain.
2023-06-09 13:09:16.374: [iter 36 : loss : 0.4223 = 0.0075 + 0.3997 + 0.0151, time: 197.607446]
2023-06-09 13:10:34.764: epoch 36:	0.00610342  	0.09743117  	0.04608814  	0.03488956  	0.03526064  
2023-06-09 13:13:48.548: [iter 37 : loss : 0.4220 = 0.0073 + 0.3996 + 0.0151, time: 192.999697]
2023-06-09 13:15:07.924: epoch 37:	0.00610771  	0.09765529  	0.04620330  	0.03498745  	0.03535476  
2023-06-09 13:15:07.925: Found a better model.
2023-06-09 13:15:07.925: Save model to file as pretrain.
2023-06-09 13:18:25.642: [iter 38 : loss : 0.4218 = 0.0071 + 0.3996 + 0.0151, time: 192.553372]
2023-06-09 13:19:44.191: epoch 38:	0.00612018  	0.09789347  	0.04624219  	0.03499946  	0.03535150  
2023-06-09 13:19:44.191: Found a better model.
2023-06-09 13:19:44.192: Save model to file as pretrain.
2023-06-09 13:23:05.381: [iter 39 : loss : 0.4217 = 0.0070 + 0.3996 + 0.0151, time: 195.713576]
2023-06-09 13:24:23.588: epoch 39:	0.00611478  	0.09772359  	0.04626792  	0.03504001  	0.03540891  
2023-06-09 13:27:40.915: [iter 40 : loss : 0.4217 = 0.0071 + 0.3996 + 0.0150, time: 196.323425]
2023-06-09 13:28:51.726: epoch 40:	0.00613116  	0.09791405  	0.04645467  	0.03522769  	0.03561165  
2023-06-09 13:28:51.726: Found a better model.
2023-06-09 13:28:51.726: Save model to file as pretrain.
2023-06-09 13:32:28.964: [iter 41 : loss : 0.4215 = 0.0070 + 0.3995 + 0.0150, time: 212.093589]
2023-06-09 13:33:45.853: epoch 41:	0.00612260  	0.09778221  	0.04644169  	0.03524701  	0.03563040  
2023-06-09 13:37:09.734: [iter 42 : loss : 0.4213 = 0.0068 + 0.3995 + 0.0150, time: 202.873145]
2023-06-09 13:38:27.608: epoch 42:	0.00614660  	0.09811731  	0.04655694  	0.03528238  	0.03566681  
2023-06-09 13:38:27.608: Found a better model.
2023-06-09 13:38:27.608: Save model to file as pretrain.
2023-06-09 13:41:49.575: [iter 43 : loss : 0.4211 = 0.0067 + 0.3994 + 0.0150, time: 196.740172]
2023-06-09 13:43:01.495: epoch 43:	0.00614735  	0.09820313  	0.04655199  	0.03527003  	0.03565494  
2023-06-09 13:43:01.495: Found a better model.
2023-06-09 13:43:01.495: Save model to file as pretrain.
2023-06-09 13:46:28.933: [iter 44 : loss : 0.4211 = 0.0067 + 0.3994 + 0.0150, time: 201.986894]
2023-06-09 13:47:32.307: epoch 44:	0.00614884  	0.09820805  	0.04662165  	0.03538324  	0.03574912  
2023-06-09 13:47:32.307: Found a better model.
2023-06-09 13:47:32.307: Save model to file as pretrain.
2023-06-09 13:50:45.994: [iter 45 : loss : 0.4209 = 0.0065 + 0.3994 + 0.0150, time: 188.685263]
2023-06-09 13:51:50.302: epoch 45:	0.00616615  	0.09844992  	0.04668954  	0.03539548  	0.03577496  
2023-06-09 13:51:50.302: Found a better model.
2023-06-09 13:51:50.302: Save model to file as pretrain.
2023-06-09 13:55:02.576: [iter 46 : loss : 0.4208 = 0.0064 + 0.3994 + 0.0150, time: 187.340157]
2023-06-09 13:56:12.911: epoch 46:	0.00617900  	0.09867205  	0.04678778  	0.03546945  	0.03585843  
2023-06-09 13:56:12.911: Found a better model.
2023-06-09 13:56:12.911: Save model to file as pretrain.
2023-06-09 13:59:24.710: [iter 47 : loss : 0.4208 = 0.0065 + 0.3993 + 0.0150, time: 186.696897]
2023-06-09 14:00:15.065: epoch 47:	0.00617285  	0.09853878  	0.04674269  	0.03543165  	0.03580730  
2023-06-09 14:03:23.433: [iter 48 : loss : 0.4205 = 0.0062 + 0.3993 + 0.0150, time: 187.735708]
2023-06-09 14:04:13.010: epoch 48:	0.00617714  	0.09863645  	0.04674055  	0.03539998  	0.03578047  
2023-06-09 14:07:22.811: [iter 49 : loss : 0.4206 = 0.0063 + 0.3993 + 0.0150, time: 189.135999]
2023-06-09 14:08:11.825: epoch 49:	0.00618366  	0.09886713  	0.04686096  	0.03551160  	0.03589881  
2023-06-09 14:08:11.825: Found a better model.
2023-06-09 14:08:11.825: Save model to file as pretrain.
2023-06-09 14:11:23.379: [iter 50 : loss : 0.4204 = 0.0062 + 0.3993 + 0.0150, time: 186.760505]
2023-06-09 14:12:12.742: epoch 50:	0.00620339  	0.09909748  	0.04692001  	0.03552112  	0.03590290  
2023-06-09 14:12:12.742: Found a better model.
2023-06-09 14:12:12.742: Save model to file as pretrain.
2023-06-09 14:15:24.853: [iter 51 : loss : 0.4203 = 0.0061 + 0.3993 + 0.0149, time: 186.827028]
2023-06-09 14:16:13.810: epoch 51:	0.00619129  	0.09889887  	0.04694977  	0.03561711  	0.03599550  
2023-06-09 14:19:21.544: [iter 52 : loss : 0.4204 = 0.0062 + 0.3993 + 0.0149, time: 187.083613]
2023-06-09 14:20:11.686: epoch 52:	0.00620804  	0.09927914  	0.04703728  	0.03563650  	0.03601564  
2023-06-09 14:20:11.686: Found a better model.
2023-06-09 14:20:11.686: Save model to file as pretrain.
2023-06-09 14:23:36.038: [iter 53 : loss : 0.4202 = 0.0060 + 0.3992 + 0.0149, time: 199.631395]
2023-06-09 14:24:46.293: epoch 53:	0.00620599  	0.09924652  	0.04712080  	0.03575796  	0.03614114  
2023-06-09 14:27:53.865: [iter 54 : loss : 0.4202 = 0.0060 + 0.3992 + 0.0150, time: 186.930815]
2023-06-09 14:28:57.413: epoch 54:	0.00620915  	0.09929586  	0.04713028  	0.03576172  	0.03615065  
2023-06-09 14:28:57.414: Found a better model.
2023-06-09 14:28:57.414: Save model to file as pretrain.
2023-06-09 14:32:09.915: [iter 55 : loss : 0.4201 = 0.0060 + 0.3992 + 0.0149, time: 187.206847]
2023-06-09 14:33:12.957: epoch 55:	0.00621697  	0.09930047  	0.04715280  	0.03577259  	0.03615053  
2023-06-09 14:33:12.957: Found a better model.
2023-06-09 14:33:12.957: Save model to file as pretrain.
2023-06-09 14:36:25.663: [iter 56 : loss : 0.4202 = 0.0060 + 0.3992 + 0.0149, time: 187.281954]
2023-06-09 14:37:15.398: epoch 56:	0.00622386  	0.09937321  	0.04721701  	0.03584009  	0.03624025  
2023-06-09 14:37:15.398: Found a better model.
2023-06-09 14:37:15.398: Save model to file as pretrain.
2023-06-09 14:40:27.800: [iter 57 : loss : 0.4200 = 0.0058 + 0.3992 + 0.0149, time: 187.030216]
2023-06-09 14:41:19.527: epoch 57:	0.00622627  	0.09941924  	0.04721934  	0.03580169  	0.03621133  
2023-06-09 14:41:19.527: Found a better model.
2023-06-09 14:41:19.527: Save model to file as pretrain.
2023-06-09 14:44:34.862: [iter 58 : loss : 0.4200 = 0.0059 + 0.3992 + 0.0149, time: 189.826851]
2023-06-09 14:45:37.695: epoch 58:	0.00623391  	0.09963696  	0.04726282  	0.03583384  	0.03622427  
2023-06-09 14:45:37.695: Found a better model.
2023-06-09 14:45:37.696: Save model to file as pretrain.
2023-06-09 14:49:03.254: [iter 59 : loss : 0.4199 = 0.0058 + 0.3992 + 0.0149, time: 199.953460]
2023-06-09 14:50:06.456: epoch 59:	0.00623931  	0.09971862  	0.04732656  	0.03585204  	0.03626531  
2023-06-09 14:50:06.456: Found a better model.
2023-06-09 14:50:06.456: Save model to file as pretrain.
2023-06-09 14:53:18.905: [iter 60 : loss : 0.4198 = 0.0057 + 0.3992 + 0.0149, time: 186.882226]
2023-06-09 14:54:21.880: epoch 60:	0.00624601  	0.09974596  	0.04732042  	0.03584316  	0.03626128  
2023-06-09 14:54:21.883: Found a better model.
2023-06-09 14:54:21.883: Save model to file as pretrain.
2023-06-09 14:57:34.939: [iter 61 : loss : 0.4198 = 0.0057 + 0.3991 + 0.0149, time: 187.517416]
2023-06-09 14:58:25.426: epoch 61:	0.00624136  	0.09978265  	0.04736123  	0.03591147  	0.03632636  
2023-06-09 14:58:25.426: Found a better model.
2023-06-09 14:58:25.426: Save model to file as pretrain.
2023-06-09 15:01:36.820: [iter 62 : loss : 0.4198 = 0.0057 + 0.3991 + 0.0149, time: 186.056499]
2023-06-09 15:02:39.685: epoch 62:	0.00623782  	0.09962585  	0.04735665  	0.03594910  	0.03636564  
2023-06-09 15:05:47.711: [iter 63 : loss : 0.4198 = 0.0057 + 0.3991 + 0.0149, time: 187.397798]
2023-06-09 15:06:50.628: epoch 63:	0.00625773  	0.10001822  	0.04747562  	0.03598711  	0.03640753  
2023-06-09 15:06:50.628: Found a better model.
2023-06-09 15:06:50.628: Save model to file as pretrain.
2023-06-09 15:10:01.747: [iter 64 : loss : 0.4197 = 0.0057 + 0.3991 + 0.0149, time: 187.012996]
2023-06-09 15:11:04.906: epoch 64:	0.00625364  	0.09998420  	0.04742819  	0.03592246  	0.03634946  
2023-06-09 15:14:24.728: [iter 65 : loss : 0.4196 = 0.0055 + 0.3991 + 0.0149, time: 199.183880]
2023-06-09 15:15:28.024: epoch 65:	0.00625625  	0.09999814  	0.04746033  	0.03596476  	0.03637294  
2023-06-09 15:18:49.179: [iter 66 : loss : 0.4197 = 0.0056 + 0.3991 + 0.0149, time: 200.521074]
2023-06-09 15:19:49.079: epoch 66:	0.00625606  	0.10000592  	0.04745235  	0.03597755  	0.03638737  
2023-06-09 15:23:10.170: [iter 67 : loss : 0.4196 = 0.0056 + 0.3991 + 0.0149, time: 200.448866]
2023-06-09 15:24:13.106: epoch 67:	0.00626834  	0.10016685  	0.04758883  	0.03612459  	0.03653342  
2023-06-09 15:24:13.106: Found a better model.
2023-06-09 15:24:13.107: Save model to file as pretrain.
2023-06-09 15:27:21.600: [iter 68 : loss : 0.4196 = 0.0056 + 0.3991 + 0.0149, time: 186.822875]
2023-06-09 15:28:25.126: epoch 68:	0.00628361  	0.10039372  	0.04769982  	0.03618905  	0.03659739  
2023-06-09 15:28:25.126: Found a better model.
2023-06-09 15:28:25.126: Save model to file as pretrain.
2023-06-09 15:31:33.861: [iter 69 : loss : 0.4196 = 0.0055 + 0.3991 + 0.0149, time: 187.080342]
2023-06-09 15:32:36.454: epoch 69:	0.00626871  	0.10013942  	0.04764574  	0.03616110  	0.03659431  
2023-06-09 15:35:57.136: [iter 70 : loss : 0.4195 = 0.0055 + 0.3991 + 0.0149, time: 200.034398]
2023-06-09 15:37:00.459: epoch 70:	0.00628659  	0.10050494  	0.04773030  	0.03621645  	0.03661840  
2023-06-09 15:37:00.459: Found a better model.
2023-06-09 15:37:00.459: Save model to file as pretrain.
2023-06-09 15:40:11.432: [iter 71 : loss : 0.4195 = 0.0055 + 0.3991 + 0.0149, time: 189.325551]
2023-06-09 15:41:14.706: epoch 71:	0.00629403  	0.10056031  	0.04774559  	0.03622482  	0.03663469  
2023-06-09 15:41:14.706: Found a better model.
2023-06-09 15:41:14.706: Save model to file as pretrain.
2023-06-09 15:44:37.476: [iter 72 : loss : 0.4195 = 0.0055 + 0.3991 + 0.0149, time: 201.103952]
2023-06-09 15:45:41.055: epoch 72:	0.00629496  	0.10054194  	0.04769159  	0.03612687  	0.03652141  
2023-06-09 15:49:03.406: [iter 73 : loss : 0.4194 = 0.0054 + 0.3991 + 0.0149, time: 201.695571]
2023-06-09 15:50:06.306: epoch 73:	0.00630054  	0.10066015  	0.04777044  	0.03618342  	0.03658169  
2023-06-09 15:50:06.307: Found a better model.
2023-06-09 15:50:06.307: Save model to file as pretrain.
2023-06-09 15:53:27.795: [iter 74 : loss : 0.4194 = 0.0054 + 0.3991 + 0.0149, time: 199.847394]
2023-06-09 15:54:29.912: epoch 74:	0.00630873  	0.10081559  	0.04782313  	0.03621887  	0.03662306  
2023-06-09 15:54:29.912: Found a better model.
2023-06-09 15:54:29.912: Save model to file as pretrain.
2023-06-09 15:57:37.148: [iter 75 : loss : 0.4194 = 0.0054 + 0.3991 + 0.0149, time: 185.584914]
2023-06-09 15:58:40.130: epoch 75:	0.00629831  	0.10062972  	0.04782362  	0.03629454  	0.03669647  
2023-06-09 16:01:54.953: [iter 76 : loss : 0.4193 = 0.0053 + 0.3991 + 0.0149, time: 194.176124]
2023-06-09 16:02:57.862: epoch 76:	0.00630929  	0.10079471  	0.04789437  	0.03634379  	0.03674965  
2023-06-09 16:06:05.067: [iter 77 : loss : 0.4193 = 0.0053 + 0.3991 + 0.0149, time: 186.536969]
2023-06-09 16:07:06.272: epoch 77:	0.00632753  	0.10119427  	0.04801814  	0.03640742  	0.03681151  
2023-06-09 16:07:06.272: Found a better model.
2023-06-09 16:07:06.272: Save model to file as pretrain.
2023-06-09 16:10:14.721: [iter 78 : loss : 0.4193 = 0.0054 + 0.3990 + 0.0149, time: 186.776516]
2023-06-09 16:11:06.578: epoch 78:	0.00632530  	0.10109401  	0.04801699  	0.03642465  	0.03683938  
2023-06-09 16:14:14.106: [iter 79 : loss : 0.4194 = 0.0054 + 0.3991 + 0.0149, time: 186.882269]
2023-06-09 16:15:05.042: epoch 79:	0.00632940  	0.10117552  	0.04803002  	0.03641428  	0.03682076  
2023-06-09 16:18:18.047: [iter 80 : loss : 0.4193 = 0.0053 + 0.3990 + 0.0149, time: 192.372548]
2023-06-09 16:19:08.369: epoch 80:	0.00633852  	0.10121990  	0.04812258  	0.03652268  	0.03693848  
2023-06-09 16:19:08.369: Found a better model.
2023-06-09 16:19:08.369: Save model to file as pretrain.
2023-06-09 16:22:17.890: [iter 81 : loss : 0.4193 = 0.0053 + 0.3990 + 0.0149, time: 187.866779]
2023-06-09 16:23:10.558: epoch 81:	0.00634206  	0.10136276  	0.04815357  	0.03654142  	0.03695568  
2023-06-09 16:23:10.561: Found a better model.
2023-06-09 16:23:10.561: Save model to file as pretrain.
2023-06-09 16:26:18.896: [iter 82 : loss : 0.4192 = 0.0052 + 0.3990 + 0.0149, time: 186.694362]
2023-06-09 16:27:09.761: epoch 82:	0.00632978  	0.10119734  	0.04810096  	0.03652304  	0.03693583  
2023-06-09 16:30:16.800: [iter 83 : loss : 0.4192 = 0.0052 + 0.3990 + 0.0149, time: 186.409085]
2023-06-09 16:31:08.166: epoch 83:	0.00635006  	0.10150927  	0.04820936  	0.03654889  	0.03696331  
2023-06-09 16:31:08.167: Found a better model.
2023-06-09 16:31:08.167: Save model to file as pretrain.
2023-06-09 16:34:17.689: [iter 84 : loss : 0.4193 = 0.0053 + 0.3990 + 0.0149, time: 187.891994]
2023-06-09 16:35:08.461: epoch 84:	0.00637388  	0.10179694  	0.04833315  	0.03662635  	0.03706425  
2023-06-09 16:35:08.461: Found a better model.
2023-06-09 16:35:08.461: Save model to file as pretrain.
2023-06-09 16:38:17.514: [iter 85 : loss : 0.4192 = 0.0052 + 0.3991 + 0.0149, time: 187.439069]
2023-06-09 16:39:11.073: epoch 85:	0.00635527  	0.10156769  	0.04826130  	0.03661692  	0.03704509  
2023-06-09 16:42:20.949: [iter 86 : loss : 0.4191 = 0.0052 + 0.3990 + 0.0149, time: 189.225224]
2023-06-09 16:43:23.739: epoch 86:	0.00637686  	0.10186793  	0.04836709  	0.03663446  	0.03707214  
2023-06-09 16:43:23.739: Found a better model.
2023-06-09 16:43:23.739: Save model to file as pretrain.
2023-06-09 16:46:35.331: [iter 87 : loss : 0.4191 = 0.0052 + 0.3990 + 0.0149, time: 189.887966]
2023-06-09 16:47:38.241: epoch 87:	0.00636886  	0.10178755  	0.04830921  	0.03660858  	0.03701983  
2023-06-09 16:50:45.950: [iter 88 : loss : 0.4192 = 0.0053 + 0.3990 + 0.0149, time: 187.077069]
2023-06-09 16:51:36.196: epoch 88:	0.00638636  	0.10212825  	0.04847183  	0.03675324  	0.03714335  
2023-06-09 16:51:36.196: Found a better model.
2023-06-09 16:51:36.196: Save model to file as pretrain.
2023-06-09 16:54:44.972: [iter 89 : loss : 0.4191 = 0.0052 + 0.3990 + 0.0149, time: 187.141104]
2023-06-09 16:55:47.222: epoch 89:	0.00638375  	0.10203891  	0.04848645  	0.03681152  	0.03722288  
2023-06-09 16:58:54.157: [iter 90 : loss : 0.4191 = 0.0052 + 0.3990 + 0.0149, time: 186.290590]
2023-06-09 16:59:45.113: epoch 90:	0.00639194  	0.10215588  	0.04847848  	0.03675352  	0.03717797  
2023-06-09 16:59:45.114: Found a better model.
2023-06-09 16:59:45.114: Save model to file as pretrain.
2023-06-09 17:02:55.477: [iter 91 : loss : 0.4190 = 0.0051 + 0.3990 + 0.0149, time: 188.729830]
2023-06-09 17:03:58.758: epoch 91:	0.00639938  	0.10226718  	0.04858475  	0.03687847  	0.03728817  
2023-06-09 17:03:58.759: Found a better model.
2023-06-09 17:03:58.759: Save model to file as pretrain.
2023-06-09 17:07:07.937: [iter 92 : loss : 0.4191 = 0.0052 + 0.3990 + 0.0149, time: 187.529342]
2023-06-09 17:07:59.957: epoch 92:	0.00639920  	0.10219748  	0.04855656  	0.03683132  	0.03724997  
2023-06-09 17:11:07.552: [iter 93 : loss : 0.4191 = 0.0052 + 0.3990 + 0.0149, time: 186.960732]
2023-06-09 17:11:58.952: epoch 93:	0.00640050  	0.10226554  	0.04862471  	0.03690583  	0.03731887  
2023-06-09 17:15:06.397: [iter 94 : loss : 0.4191 = 0.0052 + 0.3990 + 0.0149, time: 186.815099]
2023-06-09 17:16:09.438: epoch 94:	0.00641856  	0.10252648  	0.04870769  	0.03693746  	0.03735547  
2023-06-09 17:16:09.438: Found a better model.
2023-06-09 17:16:09.438: Save model to file as pretrain.
2023-06-09 17:19:16.723: [iter 95 : loss : 0.4191 = 0.0051 + 0.3990 + 0.0149, time: 185.601889]
2023-06-09 17:20:19.500: epoch 95:	0.00641056  	0.10254037  	0.04867534  	0.03686347  	0.03728010  
2023-06-09 17:20:19.501: Found a better model.
2023-06-09 17:20:19.501: Save model to file as pretrain.
2023-06-09 17:23:28.017: [iter 96 : loss : 0.4190 = 0.0051 + 0.3990 + 0.0149, time: 186.860025]
2023-06-09 17:24:30.332: epoch 96:	0.00642563  	0.10269868  	0.04874121  	0.03686939  	0.03728411  
2023-06-09 17:24:30.332: Found a better model.
2023-06-09 17:24:30.332: Save model to file as pretrain.
2023-06-09 17:27:39.031: [iter 97 : loss : 0.4190 = 0.0051 + 0.3990 + 0.0149, time: 186.437982]
2023-06-09 17:28:39.558: epoch 97:	0.00642433  	0.10263203  	0.04877054  	0.03693724  	0.03735331  
2023-06-09 17:31:46.005: [iter 98 : loss : 0.4190 = 0.0051 + 0.3990 + 0.0149, time: 185.810987]
2023-06-09 17:32:35.005: epoch 98:	0.00643662  	0.10284644  	0.04879514  	0.03693622  	0.03734922  
2023-06-09 17:32:35.005: Found a better model.
2023-06-09 17:32:35.005: Save model to file as pretrain.
2023-06-09 17:35:43.436: [iter 99 : loss : 0.4190 = 0.0050 + 0.3990 + 0.0149, time: 186.807096]
2023-06-09 17:36:34.623: epoch 99:	0.00643774  	0.10293557  	0.04889812  	0.03708683  	0.03749201  
2023-06-09 17:36:34.623: Found a better model.
2023-06-09 17:36:34.623: Save model to file as pretrain.
2023-06-09 17:39:42.706: [iter 100 : loss : 0.4190 = 0.0051 + 0.3990 + 0.0149, time: 186.451640]
2023-06-09 17:40:45.682: epoch 100:	0.00644536  	0.10303102  	0.04895280  	0.03714611  	0.03756713  
2023-06-09 17:40:45.683: Found a better model.
2023-06-09 17:40:45.683: Save model to file as pretrain.
2023-06-09 17:43:53.648: [iter 101 : loss : 0.4190 = 0.0051 + 0.3990 + 0.0149, time: 186.313324]
2023-06-09 17:44:56.325: epoch 101:	0.00645263  	0.10318165  	0.04897903  	0.03710143  	0.03752745  
2023-06-09 17:44:56.325: Found a better model.
2023-06-09 17:44:56.325: Save model to file as pretrain.
2023-06-09 17:48:02.074: [iter 102 : loss : 0.4191 = 0.0051 + 0.3990 + 0.0149, time: 184.095942]
2023-06-09 17:49:04.351: epoch 102:	0.00644555  	0.10304953  	0.04897815  	0.03716794  	0.03757648  
2023-06-09 17:52:10.290: [iter 103 : loss : 0.4190 = 0.0050 + 0.3990 + 0.0149, time: 185.301816]
2023-06-09 17:53:13.982: epoch 103:	0.00644649  	0.10300610  	0.04893249  	0.03710345  	0.03751005  
2023-06-09 17:56:20.788: [iter 104 : loss : 0.4190 = 0.0051 + 0.3990 + 0.0149, time: 186.171535]
2023-06-09 17:57:07.923: epoch 104:	0.00645393  	0.10309225  	0.04894520  	0.03707479  	0.03750522  
2023-06-09 18:00:13.258: [iter 105 : loss : 0.4188 = 0.0049 + 0.3990 + 0.0149, time: 184.700083]
2023-06-09 18:01:03.184: epoch 105:	0.00646342  	0.10343540  	0.04897380  	0.03702758  	0.03745094  
2023-06-09 18:01:03.184: Found a better model.
2023-06-09 18:01:03.184: Save model to file as pretrain.
2023-06-09 18:04:13.885: [iter 106 : loss : 0.4189 = 0.0050 + 0.3990 + 0.0149, time: 189.047945]
2023-06-09 18:05:03.407: epoch 106:	0.00646044  	0.10327391  	0.04900063  	0.03711815  	0.03754968  
2023-06-09 18:08:07.904: [iter 107 : loss : 0.4189 = 0.0051 + 0.3989 + 0.0149, time: 183.866125]
2023-06-09 18:08:57.762: epoch 107:	0.00646453  	0.10343523  	0.04906078  	0.03714781  	0.03758066  
2023-06-09 18:12:03.692: [iter 108 : loss : 0.4189 = 0.0050 + 0.3990 + 0.0149, time: 185.297759]
2023-06-09 18:12:52.124: epoch 108:	0.00646621  	0.10349167  	0.04904337  	0.03711735  	0.03755648  
2023-06-09 18:12:52.125: Found a better model.
2023-06-09 18:12:52.125: Save model to file as pretrain.
2023-06-09 18:15:58.222: [iter 109 : loss : 0.4189 = 0.0050 + 0.3990 + 0.0149, time: 184.480591]
2023-06-09 18:16:59.770: epoch 109:	0.00647440  	0.10361570  	0.04907377  	0.03713992  	0.03756355  
2023-06-09 18:16:59.770: Found a better model.
2023-06-09 18:16:59.770: Save model to file as pretrain.
2023-06-09 18:20:05.321: [iter 110 : loss : 0.4189 = 0.0050 + 0.3990 + 0.0149, time: 183.893960]
2023-06-09 18:20:53.088: epoch 110:	0.00646454  	0.10346341  	0.04906049  	0.03714632  	0.03756236  
2023-06-09 18:23:57.633: [iter 111 : loss : 0.4189 = 0.0051 + 0.3990 + 0.0149, time: 183.901014]
2023-06-09 18:24:45.831: epoch 111:	0.00647645  	0.10361519  	0.04913982  	0.03718859  	0.03761071  
2023-06-09 18:27:52.998: [iter 112 : loss : 0.4189 = 0.0051 + 0.3990 + 0.0149, time: 186.521384]
2023-06-09 18:28:42.283: epoch 112:	0.00647254  	0.10360347  	0.04909347  	0.03714000  	0.03755486  
2023-06-09 18:31:48.901: [iter 113 : loss : 0.4189 = 0.0050 + 0.3989 + 0.0149, time: 185.965387]
2023-06-09 18:32:48.717: epoch 113:	0.00647738  	0.10359976  	0.04916904  	0.03723025  	0.03766243  
2023-06-09 18:35:52.892: [iter 114 : loss : 0.4188 = 0.0049 + 0.3990 + 0.0149, time: 183.546179]
2023-06-09 18:37:02.860: epoch 114:	0.00646528  	0.10336326  	0.04902393  	0.03710128  	0.03754417  
2023-06-09 18:40:21.742: [iter 115 : loss : 0.4188 = 0.0049 + 0.3990 + 0.0149, time: 198.250629]
2023-06-09 18:41:24.400: epoch 115:	0.00646714  	0.10339012  	0.04901757  	0.03710982  	0.03753446  
2023-06-09 18:44:32.563: [iter 116 : loss : 0.4189 = 0.0050 + 0.3990 + 0.0149, time: 187.529580]
2023-06-09 18:45:42.660: epoch 116:	0.00647049  	0.10349611  	0.04908279  	0.03713630  	0.03756107  
2023-06-09 18:48:47.698: [iter 117 : loss : 0.4189 = 0.0051 + 0.3989 + 0.0149, time: 184.408130]
2023-06-09 18:49:57.186: epoch 117:	0.00648278  	0.10364553  	0.04907694  	0.03705263  	0.03749143  
2023-06-09 18:49:57.186: Found a better model.
2023-06-09 18:49:57.186: Save model to file as pretrain.
2023-06-09 18:53:02.450: [iter 118 : loss : 0.4188 = 0.0050 + 0.3990 + 0.0149, time: 183.572807]
2023-06-09 18:54:02.446: epoch 118:	0.00647794  	0.10350210  	0.04905752  	0.03708850  	0.03751369  
2023-06-09 18:57:05.578: [iter 119 : loss : 0.4188 = 0.0050 + 0.3990 + 0.0149, time: 182.477344]
2023-06-09 18:58:05.335: epoch 119:	0.00649711  	0.10381662  	0.04924551  	0.03726503  	0.03770286  
2023-06-09 18:58:05.335: Found a better model.
2023-06-09 18:58:05.335: Save model to file as pretrain.
2023-06-09 19:01:24.302: [iter 120 : loss : 0.4188 = 0.0049 + 0.3989 + 0.0149, time: 197.311949]
2023-06-09 19:02:26.715: epoch 120:	0.00649674  	0.10385033  	0.04934301  	0.03742483  	0.03784027  
2023-06-09 19:02:26.715: Found a better model.
2023-06-09 19:02:26.715: Save model to file as pretrain.
2023-06-09 19:05:33.808: [iter 121 : loss : 0.4188 = 0.0050 + 0.3990 + 0.0149, time: 185.421435]
2023-06-09 19:06:37.552: epoch 121:	0.00650251  	0.10400726  	0.04935909  	0.03740562  	0.03784030  
2023-06-09 19:06:37.552: Found a better model.
2023-06-09 19:06:37.552: Save model to file as pretrain.
2023-06-09 19:09:41.911: [iter 122 : loss : 0.4188 = 0.0049 + 0.3990 + 0.0149, time: 182.694372]
2023-06-09 19:10:45.163: epoch 122:	0.00650102  	0.10387631  	0.04929907  	0.03738490  	0.03782494  
2023-06-09 19:13:49.199: [iter 123 : loss : 0.4187 = 0.0049 + 0.3989 + 0.0149, time: 183.381775]
2023-06-09 19:14:51.473: epoch 123:	0.00648836  	0.10368194  	0.04923221  	0.03735210  	0.03777703  
2023-06-09 19:17:56.461: [iter 124 : loss : 0.4189 = 0.0050 + 0.3990 + 0.0149, time: 184.351080]
2023-06-09 19:18:59.606: epoch 124:	0.00652075  	0.10417186  	0.04946415  	0.03749968  	0.03795103  
2023-06-09 19:18:59.606: Found a better model.
2023-06-09 19:18:59.606: Save model to file as pretrain.
2023-06-09 19:22:04.995: [iter 125 : loss : 0.4188 = 0.0050 + 0.3989 + 0.0149, time: 183.732045]
2023-06-09 19:23:07.411: epoch 125:	0.00652522  	0.10425805  	0.04947769  	0.03750720  	0.03796151  
2023-06-09 19:23:07.412: Found a better model.
2023-06-09 19:23:07.412: Save model to file as pretrain.
2023-06-09 19:26:12.029: [iter 126 : loss : 0.4189 = 0.0050 + 0.3990 + 0.0149, time: 182.965082]
2023-06-09 19:27:21.672: epoch 126:	0.00652968  	0.10436397  	0.04947317  	0.03748151  	0.03793794  
2023-06-09 19:27:21.672: Found a better model.
2023-06-09 19:27:21.674: Save model to file as pretrain.
2023-06-09 19:30:28.611: [iter 127 : loss : 0.4187 = 0.0049 + 0.3989 + 0.0149, time: 185.266011]
2023-06-09 19:31:31.609: epoch 127:	0.00652558  	0.10432133  	0.04948568  	0.03750477  	0.03795435  
2023-06-09 19:34:38.835: [iter 128 : loss : 0.4187 = 0.0049 + 0.3989 + 0.0149, time: 186.538311]
2023-06-09 19:35:41.223: epoch 128:	0.00651795  	0.10418774  	0.04944320  	0.03748560  	0.03794015  
2023-06-09 19:38:47.747: [iter 129 : loss : 0.4189 = 0.0050 + 0.3990 + 0.0149, time: 185.884281]
2023-06-09 19:39:38.980: epoch 129:	0.00652763  	0.10442161  	0.04956142  	0.03756759  	0.03801585  
2023-06-09 19:39:38.980: Found a better model.
2023-06-09 19:39:38.980: Save model to file as pretrain.
2023-06-09 19:42:44.550: [iter 130 : loss : 0.4188 = 0.0049 + 0.3990 + 0.0149, time: 183.349571]
2023-06-09 19:43:35.292: epoch 130:	0.00653099  	0.10444596  	0.04953979  	0.03755214  	0.03799684  
2023-06-09 19:43:35.292: Found a better model.
2023-06-09 19:43:35.292: Save model to file as pretrain.
2023-06-09 19:46:41.614: [iter 131 : loss : 0.4188 = 0.0050 + 0.3990 + 0.0149, time: 184.687140]
2023-06-09 19:47:44.342: epoch 131:	0.00652560  	0.10438703  	0.04951343  	0.03751292  	0.03796160  
2023-06-09 19:50:48.498: [iter 132 : loss : 0.4187 = 0.0048 + 0.3989 + 0.0149, time: 183.503503]
2023-06-09 19:51:38.985: epoch 132:	0.00654011  	0.10460544  	0.04961432  	0.03761248  	0.03804799  
2023-06-09 19:51:38.985: Found a better model.
2023-06-09 19:51:38.985: Save model to file as pretrain.
2023-06-09 19:54:44.145: [iter 133 : loss : 0.4187 = 0.0049 + 0.3990 + 0.0149, time: 183.515371]
2023-06-09 19:55:44.601: epoch 133:	0.00651963  	0.10420379  	0.04948662  	0.03753663  	0.03798439  
2023-06-09 19:58:48.935: [iter 134 : loss : 0.4188 = 0.0050 + 0.3989 + 0.0149, time: 183.677178]
2023-06-09 19:59:48.873: epoch 134:	0.00652019  	0.10422456  	0.04952508  	0.03758430  	0.03803281  
2023-06-09 20:02:53.587: [iter 135 : loss : 0.4187 = 0.0049 + 0.3989 + 0.0149, time: 184.070486]
2023-06-09 20:03:42.914: epoch 135:	0.00652968  	0.10436515  	0.04951559  	0.03750061  	0.03795586  
2023-06-09 20:06:46.847: [iter 136 : loss : 0.4187 = 0.0049 + 0.3989 + 0.0149, time: 183.295460]
2023-06-09 20:07:35.625: epoch 136:	0.00654476  	0.10459992  	0.04958288  	0.03755946  	0.03802098  
2023-06-09 20:10:41.334: [iter 137 : loss : 0.4187 = 0.0049 + 0.3989 + 0.0149, time: 185.060240]
2023-06-09 20:11:42.865: epoch 137:	0.00654346  	0.10460213  	0.04959252  	0.03757204  	0.03802669  
2023-06-09 20:14:59.982: [iter 138 : loss : 0.4186 = 0.0049 + 0.3989 + 0.0149, time: 196.486802]
2023-06-09 20:16:02.857: epoch 138:	0.00654644  	0.10468355  	0.04957360  	0.03753739  	0.03798199  
2023-06-09 20:16:02.857: Found a better model.
2023-06-09 20:16:02.857: Save model to file as pretrain.
2023-06-09 20:19:08.666: [iter 139 : loss : 0.4186 = 0.0048 + 0.3989 + 0.0149, time: 184.144924]
2023-06-09 20:20:11.135: epoch 139:	0.00654625  	0.10461573  	0.04958933  	0.03755267  	0.03799216  
2023-06-09 20:23:29.195: [iter 140 : loss : 0.4187 = 0.0049 + 0.3989 + 0.0149, time: 197.432359]
2023-06-09 20:24:32.053: epoch 140:	0.00656487  	0.10492626  	0.04970807  	0.03763003  	0.03807471  
2023-06-09 20:24:32.053: Found a better model.
2023-06-09 20:24:32.053: Save model to file as pretrain.
2023-06-09 20:27:43.570: [iter 141 : loss : 0.4188 = 0.0050 + 0.3990 + 0.0148, time: 189.854804]
2023-06-09 20:28:45.780: epoch 141:	0.00654812  	0.10467062  	0.04969461  	0.03770450  	0.03815109  
2023-06-09 20:31:48.478: [iter 142 : loss : 0.4187 = 0.0049 + 0.3990 + 0.0149, time: 182.070083]
2023-06-09 20:32:51.640: epoch 142:	0.00654774  	0.10466315  	0.04963818  	0.03759717  	0.03803615  
2023-06-09 20:35:56.697: [iter 143 : loss : 0.4187 = 0.0049 + 0.3989 + 0.0148, time: 184.425235]
2023-06-09 20:36:48.248: epoch 143:	0.00653862  	0.10451272  	0.04952185  	0.03747239  	0.03793534  
2023-06-09 20:39:52.415: [iter 144 : loss : 0.4186 = 0.0049 + 0.3989 + 0.0148, time: 183.535853]
2023-06-09 20:40:42.509: epoch 144:	0.00653955  	0.10453029  	0.04955482  	0.03751644  	0.03797561  
2023-06-09 20:43:48.471: [iter 145 : loss : 0.4187 = 0.0049 + 0.3990 + 0.0149, time: 185.323940]
2023-06-09 20:44:38.433: epoch 145:	0.00655035  	0.10473935  	0.04964585  	0.03756931  	0.03802779  
2023-06-09 20:47:44.152: [iter 146 : loss : 0.4187 = 0.0049 + 0.3990 + 0.0148, time: 185.069097]
2023-06-09 20:48:35.148: epoch 146:	0.00654979  	0.10473417  	0.04958198  	0.03749276  	0.03792920  
2023-06-09 20:51:41.693: [iter 147 : loss : 0.4186 = 0.0048 + 0.3989 + 0.0148, time: 185.895123]
2023-06-09 20:52:44.292: epoch 147:	0.00655519  	0.10480785  	0.04963510  	0.03756469  	0.03800213  
2023-06-09 20:55:48.135: [iter 148 : loss : 0.4186 = 0.0048 + 0.3989 + 0.0148, time: 183.223903]
2023-06-09 20:56:36.127: epoch 148:	0.00656915  	0.10499503  	0.04968930  	0.03757463  	0.03801709  
2023-06-09 20:56:36.127: Found a better model.
2023-06-09 20:56:36.127: Save model to file as pretrain.
2023-06-09 20:59:42.715: [iter 149 : loss : 0.4187 = 0.0049 + 0.3989 + 0.0149, time: 184.941681]
2023-06-09 21:00:32.132: epoch 149:	0.00655891  	0.10485148  	0.04968133  	0.03760361  	0.03803387  
2023-06-09 21:03:36.010: [iter 150 : loss : 0.4186 = 0.0048 + 0.3990 + 0.0148, time: 183.249425]
2023-06-09 21:04:27.094: epoch 150:	0.00656989  	0.10513814  	0.04972832  	0.03758592  	0.03802274  
2023-06-09 21:04:27.094: Found a better model.
2023-06-09 21:04:27.094: Save model to file as pretrain.
2023-06-09 21:07:40.513: [iter 151 : loss : 0.4186 = 0.0048 + 0.3989 + 0.0148, time: 191.771001]
2023-06-09 21:08:42.798: epoch 151:	0.00657938  	0.10521673  	0.04983089  	0.03770684  	0.03815176  
2023-06-09 21:08:42.798: Found a better model.
2023-06-09 21:08:42.798: Save model to file as pretrain.
2023-06-09 21:11:46.999: [iter 152 : loss : 0.4186 = 0.0048 + 0.3989 + 0.0148, time: 182.522131]
2023-06-09 21:12:49.923: epoch 152:	0.00658571  	0.10529664  	0.04988677  	0.03775437  	0.03820043  
2023-06-09 21:12:49.924: Found a better model.
2023-06-09 21:12:49.926: Save model to file as pretrain.
2023-06-09 21:15:53.308: [iter 153 : loss : 0.4186 = 0.0048 + 0.3989 + 0.0148, time: 181.727571]
2023-06-09 21:16:43.625: epoch 153:	0.00658162  	0.10516207  	0.04988270  	0.03778839  	0.03822797  
2023-06-09 21:19:48.411: [iter 154 : loss : 0.4187 = 0.0049 + 0.3990 + 0.0148, time: 184.133237]
2023-06-09 21:20:38.142: epoch 154:	0.00659651  	0.10538236  	0.04985715  	0.03771244  	0.03816742  
2023-06-09 21:20:38.142: Found a better model.
2023-06-09 21:20:38.142: Save model to file as pretrain.
2023-06-09 21:23:45.315: [iter 155 : loss : 0.4186 = 0.0049 + 0.3989 + 0.0148, time: 185.535745]
2023-06-09 21:24:33.846: epoch 155:	0.00661363  	0.10570800  	0.04992197  	0.03773775  	0.03818083  
2023-06-09 21:24:33.846: Found a better model.
2023-06-09 21:24:33.846: Save model to file as pretrain.
2023-06-09 21:27:38.399: [iter 156 : loss : 0.4186 = 0.0048 + 0.3989 + 0.0148, time: 182.922038]
2023-06-09 21:28:26.361: epoch 156:	0.00660041  	0.10547523  	0.04994426  	0.03781962  	0.03825868  
2023-06-09 21:31:28.461: [iter 157 : loss : 0.4187 = 0.0049 + 0.3989 + 0.0148, time: 181.466245]
2023-06-09 21:32:28.294: epoch 157:	0.00660396  	0.10555693  	0.04996417  	0.03780460  	0.03825568  
2023-06-09 21:35:32.221: [iter 158 : loss : 0.4186 = 0.0048 + 0.3989 + 0.0148, time: 183.283764]
2023-06-09 21:36:32.458: epoch 158:	0.00660321  	0.10556723  	0.05000830  	0.03784135  	0.03829312  
2023-06-09 21:39:36.148: [iter 159 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 183.053699]
2023-06-09 21:40:25.040: epoch 159:	0.00661568  	0.10563299  	0.05002113  	0.03780852  	0.03827449  
2023-06-09 21:43:29.829: [iter 160 : loss : 0.4186 = 0.0048 + 0.3989 + 0.0148, time: 184.150102]
2023-06-09 21:44:19.094: epoch 160:	0.00661363  	0.10568970  	0.05008088  	0.03789735  	0.03833808  
2023-06-09 21:47:23.413: [iter 161 : loss : 0.4186 = 0.0049 + 0.3989 + 0.0148, time: 183.665715]
2023-06-09 21:48:33.153: epoch 161:	0.00660711  	0.10547290  	0.05002669  	0.03787749  	0.03833720  
2023-06-09 21:51:37.541: [iter 162 : loss : 0.4186 = 0.0049 + 0.3989 + 0.0148, time: 183.757317]
2023-06-09 21:52:26.305: epoch 162:	0.00660563  	0.10543471  	0.05002923  	0.03789323  	0.03836180  
2023-06-09 21:55:29.874: [iter 163 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 182.919257]
2023-06-09 21:56:18.774: epoch 163:	0.00660004  	0.10547018  	0.05002487  	0.03786643  	0.03832522  
2023-06-09 21:59:23.435: [iter 164 : loss : 0.4186 = 0.0048 + 0.3989 + 0.0148, time: 183.982841]
2023-06-09 22:00:14.273: epoch 164:	0.00660134  	0.10544053  	0.05008028  	0.03796451  	0.03840368  
2023-06-09 22:03:18.195: [iter 165 : loss : 0.4186 = 0.0049 + 0.3989 + 0.0148, time: 183.284731]
2023-06-09 22:04:06.872: epoch 165:	0.00661233  	0.10564695  	0.05009586  	0.03794068  	0.03838964  
2023-06-09 22:07:10.156: [iter 166 : loss : 0.4186 = 0.0049 + 0.3989 + 0.0148, time: 182.646991]
2023-06-09 22:07:59.819: epoch 166:	0.00661996  	0.10569627  	0.05016264  	0.03800929  	0.03847354  
2023-06-09 22:11:04.591: [iter 167 : loss : 0.4186 = 0.0048 + 0.3989 + 0.0148, time: 184.137633]
2023-06-09 22:12:06.578: epoch 167:	0.00662927  	0.10582978  	0.05018927  	0.03799949  	0.03846819  
2023-06-09 22:12:06.579: Found a better model.
2023-06-09 22:12:06.580: Save model to file as pretrain.
2023-06-09 22:15:11.578: [iter 168 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 183.362666]
2023-06-09 22:16:05.494: epoch 168:	0.00661847  	0.10577049  	0.05017133  	0.03800626  	0.03846243  
2023-06-09 22:19:11.557: [iter 169 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 185.398698]
2023-06-09 22:20:11.631: epoch 169:	0.00662536  	0.10593007  	0.05016323  	0.03794104  	0.03839135  
2023-06-09 22:20:11.631: Found a better model.
2023-06-09 22:20:11.631: Save model to file as pretrain.
2023-06-09 22:23:18.209: [iter 170 : loss : 0.4186 = 0.0048 + 0.3989 + 0.0148, time: 184.926189]
2023-06-09 22:24:20.411: epoch 170:	0.00662443  	0.10584355  	0.05017748  	0.03798128  	0.03843579  
2023-06-09 22:27:23.885: [iter 171 : loss : 0.4186 = 0.0048 + 0.3989 + 0.0148, time: 182.850126]
2023-06-09 22:28:26.296: epoch 171:	0.00662666  	0.10584974  	0.05020432  	0.03801808  	0.03846282  
2023-06-09 22:31:44.617: [iter 172 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 197.675343]
2023-06-09 22:32:46.320: epoch 172:	0.00660079  	0.10551294  	0.05015730  	0.03807890  	0.03853290  
2023-06-09 22:35:52.859: [iter 173 : loss : 0.4186 = 0.0049 + 0.3989 + 0.0148, time: 185.901181]
2023-06-09 22:36:42.634: epoch 173:	0.00661680  	0.10577720  	0.05019507  	0.03806277  	0.03849671  
2023-06-09 22:39:47.778: [iter 174 : loss : 0.4185 = 0.0047 + 0.3989 + 0.0148, time: 184.498045]
2023-06-09 22:40:50.754: epoch 174:	0.00662387  	0.10591063  	0.05022884  	0.03804050  	0.03849683  
2023-06-09 22:43:55.229: [iter 175 : loss : 0.4186 = 0.0048 + 0.3989 + 0.0148, time: 183.850272]
2023-06-09 22:44:55.727: epoch 175:	0.00662703  	0.10593417  	0.05028307  	0.03812523  	0.03857090  
2023-06-09 22:44:55.737: Found a better model.
2023-06-09 22:44:55.737: Save model to file as pretrain.
2023-06-09 22:48:04.633: [iter 176 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 187.233075]
2023-06-09 22:48:54.795: epoch 176:	0.00661047  	0.10575857  	0.05022523  	0.03810155  	0.03855360  
2023-06-09 22:51:59.559: [iter 177 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 184.130000]
2023-06-09 22:53:01.626: epoch 177:	0.00662256  	0.10594162  	0.05029137  	0.03813380  	0.03858090  
2023-06-09 22:53:01.626: Found a better model.
2023-06-09 22:53:01.626: Save model to file as pretrain.
2023-06-09 22:56:06.742: [iter 178 : loss : 0.4186 = 0.0049 + 0.3989 + 0.0148, time: 183.475265]
2023-06-09 22:57:15.839: epoch 178:	0.00662573  	0.10598605  	0.05028995  	0.03812637  	0.03857564  
2023-06-09 22:57:15.839: Found a better model.
2023-06-09 22:57:15.839: Save model to file as pretrain.
2023-06-09 23:00:22.783: [iter 179 : loss : 0.4186 = 0.0048 + 0.3989 + 0.0148, time: 185.241962]
2023-06-09 23:01:25.342: epoch 179:	0.00662424  	0.10598355  	0.05028338  	0.03813336  	0.03856855  
2023-06-09 23:04:29.722: [iter 180 : loss : 0.4185 = 0.0047 + 0.3990 + 0.0148, time: 183.740597]
2023-06-09 23:05:30.098: epoch 180:	0.00662238  	0.10586709  	0.05022943  	0.03807283  	0.03851211  
2023-06-09 23:08:35.100: [iter 181 : loss : 0.4186 = 0.0048 + 0.3989 + 0.0148, time: 184.335162]
2023-06-09 23:09:34.775: epoch 181:	0.00662927  	0.10602209  	0.05031168  	0.03816337  	0.03860722  
2023-06-09 23:09:34.775: Found a better model.
2023-06-09 23:09:34.776: Save model to file as pretrain.
2023-06-09 23:12:39.767: [iter 182 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 183.322819]
2023-06-09 23:13:42.551: epoch 182:	0.00662778  	0.10600739  	0.05037785  	0.03825720  	0.03870681  
2023-06-09 23:16:45.924: [iter 183 : loss : 0.4186 = 0.0049 + 0.3989 + 0.0148, time: 182.715932]
2023-06-09 23:17:48.588: epoch 183:	0.00661698  	0.10581538  	0.05029336  	0.03819027  	0.03864115  
2023-06-09 23:20:53.272: [iter 184 : loss : 0.4185 = 0.0047 + 0.3989 + 0.0148, time: 184.036853]
2023-06-09 23:21:43.519: epoch 184:	0.00662611  	0.10595971  	0.05031477  	0.03815120  	0.03860601  
2023-06-09 23:24:47.980: [iter 185 : loss : 0.4186 = 0.0048 + 0.3990 + 0.0148, time: 183.803810]
2023-06-09 23:25:38.813: epoch 185:	0.00663392  	0.10597958  	0.05023356  	0.03803143  	0.03849681  
2023-06-09 23:28:44.832: [iter 186 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 185.366565]
2023-06-09 23:29:35.215: epoch 186:	0.00661978  	0.10573725  	0.05025694  	0.03814166  	0.03859906  
2023-06-09 23:32:39.299: [iter 187 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 183.444659]
2023-06-09 23:33:38.896: epoch 187:	0.00663058  	0.10596815  	0.05029488  	0.03813393  	0.03858368  
2023-06-09 23:36:43.067: [iter 188 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 183.515146]
2023-06-09 23:37:31.763: epoch 188:	0.00661885  	0.10581357  	0.05028979  	0.03817487  	0.03863105  
2023-06-09 23:40:36.939: [iter 189 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 184.538753]
2023-06-09 23:41:26.050: epoch 189:	0.00663150  	0.10609805  	0.05037554  	0.03820845  	0.03865277  
2023-06-09 23:41:26.051: Found a better model.
2023-06-09 23:41:26.051: Save model to file as pretrain.
2023-06-09 23:44:30.972: [iter 190 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 183.273755]
2023-06-09 23:45:31.351: epoch 190:	0.00661941  	0.10590752  	0.05026723  	0.03811323  	0.03855226  
2023-06-09 23:48:39.932: [iter 191 : loss : 0.4185 = 0.0047 + 0.3989 + 0.0148, time: 187.934093]
2023-06-09 23:49:29.218: epoch 191:	0.00663448  	0.10607555  	0.05036585  	0.03817257  	0.03863009  
2023-06-09 23:52:35.994: [iter 192 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 186.104095]
2023-06-09 23:53:25.804: epoch 192:	0.00662908  	0.10595576  	0.05040486  	0.03826652  	0.03871248  
2023-06-09 23:56:31.001: [iter 193 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 184.553854]
2023-06-09 23:57:20.429: epoch 193:	0.00663095  	0.10604747  	0.05035207  	0.03815597  	0.03859550  
2023-06-10 00:00:25.427: [iter 194 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 184.355318]
2023-06-10 00:01:15.258: epoch 194:	0.00662052  	0.10589437  	0.05031680  	0.03816538  	0.03859900  
2023-06-10 00:04:20.901: [iter 195 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 185.014105]
2023-06-10 00:05:10.198: epoch 195:	0.00661512  	0.10577039  	0.05028473  	0.03815996  	0.03858639  
2023-06-10 00:08:24.070: [iter 196 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 193.210922]
2023-06-10 00:09:26.367: epoch 196:	0.00663448  	0.10612269  	0.05035606  	0.03813843  	0.03856721  
2023-06-10 00:09:26.367: Found a better model.
2023-06-10 00:09:26.367: Save model to file as pretrain.
2023-06-10 00:12:34.532: [iter 197 : loss : 0.4184 = 0.0048 + 0.3989 + 0.0148, time: 186.518243]
2023-06-10 00:13:25.370: epoch 197:	0.00664156  	0.10616267  	0.05039363  	0.03818426  	0.03862255  
2023-06-10 00:13:25.370: Found a better model.
2023-06-10 00:13:25.370: Save model to file as pretrain.
2023-06-10 00:16:46.239: [iter 198 : loss : 0.4185 = 0.0047 + 0.3990 + 0.0148, time: 199.247600]
2023-06-10 00:17:35.501: epoch 198:	0.00664230  	0.10613232  	0.05044885  	0.03825998  	0.03868483  
2023-06-10 00:20:38.398: [iter 199 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0148, time: 182.271339]
2023-06-10 00:21:29.212: epoch 199:	0.00665663  	0.10638007  	0.05052800  	0.03827971  	0.03872082  
2023-06-10 00:21:29.212: Found a better model.
2023-06-10 00:21:29.212: Save model to file as pretrain.
2023-06-10 00:24:34.538: [iter 200 : loss : 0.4184 = 0.0048 + 0.3989 + 0.0148, time: 183.672655]
2023-06-10 00:25:34.694: epoch 200:	0.00665496  	0.10639103  	0.05052001  	0.03829098  	0.03874081  
2023-06-10 00:25:34.694: Found a better model.
2023-06-10 00:25:34.694: Save model to file as pretrain.
2023-06-10 00:28:41.384: [iter 201 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 182.366066]
2023-06-10 00:29:44.134: epoch 201:	0.00665198  	0.10631387  	0.05042537  	0.03816850  	0.03861605  
2023-06-10 00:32:51.324: [iter 202 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 186.560628]
2023-06-10 00:33:53.404: epoch 202:	0.00664845  	0.10630918  	0.05038483  	0.03811439  	0.03855237  
2023-06-10 00:36:58.171: [iter 203 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0148, time: 184.122532]
2023-06-10 00:37:57.989: epoch 203:	0.00666948  	0.10669358  	0.05052087  	0.03818624  	0.03862901  
2023-06-10 00:37:57.989: Found a better model.
2023-06-10 00:37:57.989: Save model to file as pretrain.
2023-06-10 00:41:06.215: [iter 204 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0148, time: 183.241894]
2023-06-10 00:42:08.577: epoch 204:	0.00665310  	0.10640472  	0.05043808  	0.03814026  	0.03858141  
2023-06-10 00:45:13.741: [iter 205 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 184.522924]
2023-06-10 00:46:15.620: epoch 205:	0.00665049  	0.10640241  	0.05046540  	0.03817820  	0.03861742  
2023-06-10 00:49:19.655: [iter 206 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 183.397460]
2023-06-10 00:50:22.357: epoch 206:	0.00665086  	0.10641136  	0.05047579  	0.03822066  	0.03865610  
2023-06-10 00:53:29.422: [iter 207 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0148, time: 186.423339]
2023-06-10 00:54:17.802: epoch 207:	0.00665794  	0.10644712  	0.05043735  	0.03815231  	0.03857230  
2023-06-10 00:57:28.374: [iter 208 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0148, time: 189.917300]
2023-06-10 00:58:18.025: epoch 208:	0.00665142  	0.10639552  	0.05043898  	0.03816760  	0.03859875  
2023-06-10 01:01:22.951: [iter 209 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0148, time: 184.292442]
2023-06-10 01:02:12.320: epoch 209:	0.00665831  	0.10644578  	0.05042938  	0.03813426  	0.03856618  
2023-06-10 01:05:18.323: [iter 210 : loss : 0.4184 = 0.0048 + 0.3989 + 0.0148, time: 185.362777]
2023-06-10 01:06:10.337: epoch 210:	0.00664286  	0.10623343  	0.05041275  	0.03815293  	0.03858413  
2023-06-10 01:09:13.152: [iter 211 : loss : 0.4184 = 0.0048 + 0.3989 + 0.0148, time: 182.127835]
2023-06-10 01:10:15.765: epoch 211:	0.00665310  	0.10641001  	0.05042364  	0.03813984  	0.03857791  
2023-06-10 01:13:20.545: [iter 212 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 184.119362]
2023-06-10 01:14:23.601: epoch 212:	0.00666371  	0.10653482  	0.05050146  	0.03819400  	0.03864819  
2023-06-10 01:17:28.916: [iter 213 : loss : 0.4184 = 0.0048 + 0.3989 + 0.0148, time: 184.671170]
2023-06-10 01:18:31.203: epoch 213:	0.00664528  	0.10631115  	0.05039537  	0.03810776  	0.03856558  
2023-06-10 01:21:34.917: [iter 214 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0148, time: 183.072163]
2023-06-10 01:22:37.372: epoch 214:	0.00666650  	0.10656760  	0.05055888  	0.03826063  	0.03872614  
2023-06-10 01:25:41.285: [iter 215 : loss : 0.4184 = 0.0048 + 0.3989 + 0.0148, time: 183.279998]
2023-06-10 01:26:44.645: epoch 215:	0.00666315  	0.10655490  	0.05054810  	0.03826496  	0.03871724  
2023-06-10 01:30:02.483: [iter 216 : loss : 0.4184 = 0.0048 + 0.3989 + 0.0148, time: 197.180718]
2023-06-10 01:31:05.089: epoch 216:	0.00666036  	0.10655665  	0.05057973  	0.03831729  	0.03877171  
2023-06-10 01:34:11.562: [iter 217 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 185.807003]
2023-06-10 01:35:01.951: epoch 217:	0.00665775  	0.10645396  	0.05048930  	0.03823294  	0.03868933  
2023-06-10 01:38:05.716: [iter 218 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 183.120852]
2023-06-10 01:38:56.495: epoch 218:	0.00667618  	0.10670831  	0.05058219  	0.03829398  	0.03876042  
2023-06-10 01:38:56.495: Found a better model.
2023-06-10 01:38:56.495: Save model to file as pretrain.
2023-06-10 01:42:05.678: [iter 219 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0148, time: 184.237693]
2023-06-10 01:43:08.729: epoch 219:	0.00667265  	0.10674740  	0.05059944  	0.03831492  	0.03877802  
2023-06-10 01:43:08.729: Found a better model.
2023-06-10 01:43:08.729: Save model to file as pretrain.
2023-06-10 01:46:17.955: [iter 220 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0148, time: 184.113757]
2023-06-10 01:47:21.073: epoch 220:	0.00667953  	0.10680383  	0.05066944  	0.03838885  	0.03884345  
2023-06-10 01:47:21.073: Found a better model.
2023-06-10 01:47:21.073: Save model to file as pretrain.
2023-06-10 01:50:27.837: [iter 221 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0148, time: 181.692579]
2023-06-10 01:51:30.989: epoch 221:	0.00666985  	0.10658100  	0.05058661  	0.03831332  	0.03877458  
2023-06-10 01:54:35.171: [iter 222 : loss : 0.4184 = 0.0048 + 0.3989 + 0.0148, time: 183.544708]
2023-06-10 01:55:25.781: epoch 222:	0.00667841  	0.10674689  	0.05068181  	0.03839921  	0.03885505  
2023-06-10 01:58:32.460: [iter 223 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0148, time: 186.039425]
2023-06-10 01:59:22.473: epoch 223:	0.00666799  	0.10655461  	0.05059913  	0.03834862  	0.03879446  
2023-06-10 02:02:29.853: [iter 224 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 186.741441]
2023-06-10 02:03:39.501: epoch 224:	0.00668381  	0.10691810  	0.05058817  	0.03820461  	0.03865981  
2023-06-10 02:03:39.502: Found a better model.
2023-06-10 02:03:39.502: Save model to file as pretrain.
2023-06-10 02:07:02.733: [iter 225 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 198.235724]
2023-06-10 02:07:54.590: epoch 225:	0.00667730  	0.10675570  	0.05055490  	0.03822546  	0.03867632  
2023-06-10 02:10:58.853: [iter 226 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0148, time: 183.618164]
2023-06-10 02:11:59.537: epoch 226:	0.00668754  	0.10690113  	0.05062699  	0.03829494  	0.03873670  
2023-06-10 02:15:03.900: [iter 227 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0148, time: 183.725424]
2023-06-10 02:15:53.221: epoch 227:	0.00668437  	0.10680999  	0.05067098  	0.03837762  	0.03883304  
2023-06-10 02:18:58.168: [iter 228 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0148, time: 184.289786]
2023-06-10 02:19:46.277: epoch 228:	0.00668921  	0.10685425  	0.05073060  	0.03844061  	0.03889467  
2023-06-10 02:22:52.992: [iter 229 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0147, time: 186.079481]
2023-06-10 02:23:40.872: epoch 229:	0.00668921  	0.10686107  	0.05074849  	0.03844301  	0.03890125  
2023-06-10 02:26:45.728: [iter 230 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0148, time: 184.196398]
2023-06-10 02:27:54.482: epoch 230:	0.00669256  	0.10689132  	0.05072445  	0.03840905  	0.03887234  
2023-06-10 02:30:59.982: [iter 231 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0148, time: 184.849378]
2023-06-10 02:32:00.129: epoch 231:	0.00668343  	0.10678968  	0.05062361  	0.03828013  	0.03874917  
2023-06-10 02:35:05.509: [iter 232 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0148, time: 184.745082]
2023-06-10 02:36:06.035: epoch 232:	0.00669051  	0.10683278  	0.05067953  	0.03833564  	0.03880753  
2023-06-10 02:39:11.813: [iter 233 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0148, time: 185.093682]
2023-06-10 02:40:01.653: epoch 233:	0.00668921  	0.10690895  	0.05066929  	0.03827265  	0.03873953  
2023-06-10 02:43:06.450: [iter 234 : loss : 0.4184 = 0.0048 + 0.3989 + 0.0148, time: 184.167861]
2023-06-10 02:43:56.240: epoch 234:	0.00670019  	0.10709256  	0.05070797  	0.03831109  	0.03877971  
2023-06-10 02:43:56.240: Found a better model.
2023-06-10 02:43:56.240: Save model to file as pretrain.
2023-06-10 02:47:06.273: [iter 235 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0148, time: 184.984402]
2023-06-10 02:47:57.930: epoch 235:	0.00669907  	0.10704924  	0.05071132  	0.03829246  	0.03877344  
2023-06-10 02:51:03.805: [iter 236 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0148, time: 185.235156]
2023-06-10 02:51:54.672: epoch 236:	0.00669479  	0.10706120  	0.05073487  	0.03835755  	0.03882758  
2023-06-10 02:55:01.554: [iter 237 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0147, time: 186.219103]
2023-06-10 02:55:52.584: epoch 237:	0.00669423  	0.10707390  	0.05071692  	0.03834528  	0.03882562  
2023-06-10 02:58:56.272: [iter 238 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0148, time: 183.021698]
2023-06-10 02:59:45.750: epoch 238:	0.00669460  	0.10707083  	0.05073158  	0.03835328  	0.03880637  
2023-06-10 03:02:51.791: [iter 239 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 185.400686]
2023-06-10 03:03:42.775: epoch 239:	0.00670224  	0.10711057  	0.05072943  	0.03832241  	0.03878113  
2023-06-10 03:03:42.775: Found a better model.
2023-06-10 03:03:42.775: Save model to file as pretrain.
2023-06-10 03:06:54.162: [iter 240 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0147, time: 186.371135]
2023-06-10 03:07:57.046: epoch 240:	0.00669256  	0.10691473  	0.05073151  	0.03839861  	0.03885582  
2023-06-10 03:11:09.459: [iter 241 : loss : 0.4184 = 0.0048 + 0.3989 + 0.0147, time: 191.762706]
2023-06-10 03:12:00.385: epoch 241:	0.00668921  	0.10690265  	0.05075309  	0.03842666  	0.03887846  
2023-06-10 03:15:07.335: [iter 242 : loss : 0.4183 = 0.0047 + 0.3989 + 0.0147, time: 186.310650]
2023-06-10 03:16:08.361: epoch 242:	0.00668362  	0.10683619  	0.05072185  	0.03840251  	0.03885278  
2023-06-10 03:19:26.893: [iter 243 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0147, time: 197.883248]
2023-06-10 03:20:16.690: epoch 243:	0.00668958  	0.10692283  	0.05076907  	0.03844694  	0.03887831  
2023-06-10 03:23:21.401: [iter 244 : loss : 0.4183 = 0.0047 + 0.3989 + 0.0147, time: 184.080105]
2023-06-10 03:24:10.830: epoch 244:	0.00668289  	0.10685442  	0.05072020  	0.03838820  	0.03882159  
2023-06-10 03:27:15.221: [iter 245 : loss : 0.4183 = 0.0047 + 0.3989 + 0.0147, time: 183.720960]
2023-06-10 03:28:15.553: epoch 245:	0.00668177  	0.10686252  	0.05071653  	0.03838450  	0.03880696  
2023-06-10 03:31:20.651: [iter 246 : loss : 0.4184 = 0.0048 + 0.3989 + 0.0147, time: 184.460440]
2023-06-10 03:32:20.688: epoch 246:	0.00670634  	0.10718434  	0.05079815  	0.03841769  	0.03885659  
2023-06-10 03:32:20.688: Found a better model.
2023-06-10 03:32:20.689: Save model to file as pretrain.
2023-06-10 03:35:36.378: [iter 247 : loss : 0.4184 = 0.0048 + 0.3989 + 0.0147, time: 190.620367]
2023-06-10 03:36:38.770: epoch 247:	0.00669852  	0.10709224  	0.05078739  	0.03842005  	0.03887675  
2023-06-10 03:39:42.999: [iter 248 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0147, time: 183.599857]
2023-06-10 03:40:32.840: epoch 248:	0.00671881  	0.10742553  	0.05089084  	0.03849020  	0.03895260  
2023-06-10 03:40:32.841: Found a better model.
2023-06-10 03:40:32.851: Save model to file as pretrain.
2023-06-10 03:43:40.637: [iter 249 : loss : 0.4183 = 0.0046 + 0.3989 + 0.0147, time: 182.894234]
2023-06-10 03:44:30.629: epoch 249:	0.00670559  	0.10720627  	0.05084337  	0.03849027  	0.03894762  
2023-06-10 03:47:39.211: [iter 250 : loss : 0.4183 = 0.0046 + 0.3989 + 0.0147, time: 187.935435]
2023-06-10 03:48:27.593: epoch 250:	0.00670280  	0.10708234  	0.05082271  	0.03846604  	0.03891414  
2023-06-10 03:51:32.366: [iter 251 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0147, time: 184.123162]
2023-06-10 03:52:24.668: epoch 251:	0.00670057  	0.10710455  	0.05082076  	0.03847995  	0.03894322  
2023-06-10 03:55:31.627: [iter 252 : loss : 0.4183 = 0.0047 + 0.3989 + 0.0147, time: 186.271700]
2023-06-10 03:56:22.342: epoch 252:	0.00671285  	0.10739433  	0.05087667  	0.03849663  	0.03894923  
2023-06-10 03:59:26.017: [iter 253 : loss : 0.4184 = 0.0048 + 0.3989 + 0.0147, time: 183.036681]
2023-06-10 04:00:28.235: epoch 253:	0.00672700  	0.10747292  	0.05089344  	0.03846974  	0.03894535  
2023-06-10 04:00:28.244: Found a better model.
2023-06-10 04:00:28.244: Save model to file as pretrain.
2023-06-10 04:03:38.473: [iter 254 : loss : 0.4184 = 0.0048 + 0.3989 + 0.0147, time: 185.087192]
2023-06-10 04:04:27.309: epoch 254:	0.00672123  	0.10739976  	0.05090918  	0.03853478  	0.03901049  
2023-06-10 04:07:32.764: [iter 255 : loss : 0.4184 = 0.0048 + 0.3989 + 0.0147, time: 184.826306]
2023-06-10 04:08:21.922: epoch 255:	0.00672235  	0.10740852  	0.05091905  	0.03855619  	0.03902626  
2023-06-10 04:11:26.628: [iter 256 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0147, time: 184.063921]
2023-06-10 04:12:15.580: epoch 256:	0.00670894  	0.10710371  	0.05077112  	0.03842305  	0.03888875  
2023-06-10 04:15:19.427: [iter 257 : loss : 0.4184 = 0.0048 + 0.3989 + 0.0147, time: 183.218605]
2023-06-10 04:16:09.012: epoch 257:	0.00671639  	0.10726593  	0.05089439  	0.03856562  	0.03902440  
2023-06-10 04:19:14.145: [iter 258 : loss : 0.4183 = 0.0047 + 0.3989 + 0.0147, time: 184.486434]
2023-06-10 04:20:02.419: epoch 258:	0.00672644  	0.10743145  	0.05090509  	0.03851786  	0.03898107  
2023-06-10 04:23:07.472: [iter 259 : loss : 0.4183 = 0.0047 + 0.3989 + 0.0147, time: 184.418768]
2023-06-10 04:23:58.573: epoch 259:	0.00672513  	0.10741873  	0.05089387  	0.03850098  	0.03895199  
2023-06-10 04:27:03.465: [iter 260 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0147, time: 184.246151]
2023-06-10 04:27:51.225: epoch 260:	0.00673296  	0.10761357  	0.05089100  	0.03845071  	0.03890585  
2023-06-10 04:27:51.225: Found a better model.
2023-06-10 04:27:51.225: Save model to file as pretrain.
2023-06-10 04:30:59.911: [iter 261 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0147, time: 185.995605]
2023-06-10 04:32:02.851: epoch 261:	0.00672383  	0.10737441  	0.05081187  	0.03842897  	0.03886174  
2023-06-10 04:35:09.258: [iter 262 : loss : 0.4182 = 0.0046 + 0.3989 + 0.0147, time: 185.763515]
2023-06-10 04:36:11.661: epoch 262:	0.00672327  	0.10742799  	0.05080466  	0.03837793  	0.03882221  
2023-06-10 04:39:16.339: [iter 263 : loss : 0.4183 = 0.0047 + 0.3989 + 0.0147, time: 184.042093]
2023-06-10 04:40:18.832: epoch 263:	0.00671806  	0.10730191  	0.05084245  	0.03847309  	0.03890755  
2023-06-10 04:43:22.896: [iter 264 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0147, time: 183.413982]
2023-06-10 04:44:25.057: epoch 264:	0.00671620  	0.10735287  	0.05084703  	0.03844995  	0.03890421  
2023-06-10 04:47:31.041: [iter 265 : loss : 0.4183 = 0.0047 + 0.3989 + 0.0147, time: 185.348690]
2023-06-10 04:48:31.630: epoch 265:	0.00672626  	0.10748029  	0.05087317  	0.03843950  	0.03888696  
2023-06-10 04:51:37.911: [iter 266 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0147, time: 185.640559]
2023-06-10 04:52:26.577: epoch 266:	0.00673053  	0.10761359  	0.05090844  	0.03845541  	0.03890846  
2023-06-10 04:52:26.577: Found a better model.
2023-06-10 04:52:26.577: Save model to file as pretrain.
2023-06-10 04:55:32.287: [iter 267 : loss : 0.4184 = 0.0048 + 0.3989 + 0.0147, time: 184.032136]
2023-06-10 04:56:22.558: epoch 267:	0.00673928  	0.10765292  	0.05088626  	0.03841264  	0.03885081  
2023-06-10 04:56:22.558: Found a better model.
2023-06-10 04:56:22.558: Save model to file as pretrain.
2023-06-10 04:59:30.090: [iter 268 : loss : 0.4183 = 0.0046 + 0.3989 + 0.0147, time: 185.876892]
2023-06-10 05:00:20.256: epoch 268:	0.00672811  	0.10758893  	0.05090161  	0.03844776  	0.03888445  
2023-06-10 05:03:26.549: [iter 269 : loss : 0.4183 = 0.0047 + 0.3989 + 0.0147, time: 185.644098]
2023-06-10 05:04:16.564: epoch 269:	0.00672624  	0.10749448  	0.05092651  	0.03852123  	0.03895422  
2023-06-10 05:07:22.615: [iter 270 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0147, time: 185.416996]
2023-06-10 05:08:14.325: epoch 270:	0.00673146  	0.10765424  	0.05102609  	0.03859882  	0.03904500  
2023-06-10 05:08:14.325: Found a better model.
2023-06-10 05:08:14.325: Save model to file as pretrain.
2023-06-10 05:11:19.699: [iter 271 : loss : 0.4183 = 0.0047 + 0.3989 + 0.0147, time: 183.733105]
2023-06-10 05:12:29.833: epoch 271:	0.00672178  	0.10747156  	0.05098816  	0.03863025  	0.03906979  
2023-06-10 05:15:49.280: [iter 272 : loss : 0.4183 = 0.0047 + 0.3989 + 0.0147, time: 198.812038]
2023-06-10 05:16:58.889: epoch 272:	0.00673481  	0.10763950  	0.05105225  	0.03864796  	0.03909153  
2023-06-10 05:20:05.609: [iter 273 : loss : 0.4184 = 0.0048 + 0.3989 + 0.0147, time: 186.083503]
2023-06-10 05:21:08.387: epoch 273:	0.00670578  	0.10717313  	0.05093221  	0.03862740  	0.03907559  
2023-06-10 05:24:27.650: [iter 274 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0147, time: 198.606131]
2023-06-10 05:25:30.377: epoch 274:	0.00671508  	0.10728507  	0.05104254  	0.03873276  	0.03919205  
2023-06-10 05:28:36.014: [iter 275 : loss : 0.4184 = 0.0048 + 0.3989 + 0.0147, time: 184.998126]
2023-06-10 05:29:38.295: epoch 275:	0.00670708  	0.10714158  	0.05093197  	0.03862467  	0.03906549  
2023-06-10 05:32:44.837: [iter 276 : loss : 0.4183 = 0.0046 + 0.3989 + 0.0147, time: 185.901356]
2023-06-10 05:33:47.281: epoch 276:	0.00671099  	0.10724997  	0.05093991  	0.03862043  	0.03905531  
2023-06-10 05:36:54.386: [iter 277 : loss : 0.4182 = 0.0046 + 0.3989 + 0.0147, time: 186.465212]
2023-06-10 05:37:57.322: epoch 277:	0.00671731  	0.10737029  	0.05099976  	0.03864651  	0.03907802  
2023-06-10 05:41:05.232: [iter 278 : loss : 0.4184 = 0.0048 + 0.3989 + 0.0147, time: 187.262182]
2023-06-10 05:42:08.037: epoch 278:	0.00671471  	0.10730838  	0.05095463  	0.03861865  	0.03904880  
2023-06-10 05:45:14.586: [iter 279 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0147, time: 185.899028]
2023-06-10 05:46:17.531: epoch 279:	0.00672346  	0.10754387  	0.05097759  	0.03858239  	0.03902249  
2023-06-10 05:49:23.907: [iter 280 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0147, time: 185.743783]
2023-06-10 05:50:24.189: epoch 280:	0.00672680  	0.10756891  	0.05096241  	0.03855592  	0.03900341  
2023-06-10 05:53:31.101: [iter 281 : loss : 0.4183 = 0.0047 + 0.3989 + 0.0147, time: 186.276650]
2023-06-10 05:54:31.976: epoch 281:	0.00671993  	0.10754136  	0.05091595  	0.03851470  	0.03895143  
2023-06-10 05:57:39.092: [iter 282 : loss : 0.4182 = 0.0046 + 0.3989 + 0.0147, time: 186.462512]
2023-06-10 05:58:28.390: epoch 282:	0.00672364  	0.10748059  	0.05087556  	0.03846134  	0.03892082  
2023-06-10 06:01:34.187: [iter 283 : loss : 0.4183 = 0.0047 + 0.3989 + 0.0147, time: 185.155405]
2023-06-10 06:02:22.621: epoch 283:	0.00671732  	0.10735060  	0.05095812  	0.03860587  	0.03905964  
2023-06-10 06:05:28.696: [iter 284 : loss : 0.4183 = 0.0047 + 0.3989 + 0.0147, time: 185.446142]
2023-06-10 06:06:31.086: epoch 284:	0.00671751  	0.10747495  	0.05096160  	0.03858342  	0.03902460  
2023-06-10 06:09:38.313: [iter 285 : loss : 0.4183 = 0.0047 + 0.3989 + 0.0147, time: 186.568436]
2023-06-10 06:10:41.405: epoch 285:	0.00671919  	0.10749961  	0.05093748  	0.03852808  	0.03899331  
2023-06-10 06:13:50.159: [iter 286 : loss : 0.4183 = 0.0047 + 0.3989 + 0.0147, time: 188.106568]
2023-06-10 06:14:40.984: epoch 286:	0.00673240  	0.10767319  	0.05102575  	0.03859518  	0.03905310  
2023-06-10 06:14:40.984: Found a better model.
2023-06-10 06:14:40.984: Save model to file as pretrain.
2023-06-10 06:17:49.772: [iter 287 : loss : 0.4183 = 0.0047 + 0.3989 + 0.0147, time: 186.857768]
2023-06-10 06:18:53.168: epoch 287:	0.00673147  	0.10764264  	0.05102463  	0.03860885  	0.03906370  
2023-06-10 06:21:58.138: [iter 288 : loss : 0.4184 = 0.0048 + 0.3989 + 0.0147, time: 184.339784]
2023-06-10 06:23:01.122: epoch 288:	0.00672868  	0.10761625  	0.05109632  	0.03873081  	0.03918466  
2023-06-10 06:26:07.164: [iter 289 : loss : 0.4183 = 0.0047 + 0.3989 + 0.0147, time: 185.412324]
2023-06-10 06:27:10.399: epoch 289:	0.00672849  	0.10753465  	0.05101954  	0.03864267  	0.03910426  
2023-06-10 06:30:16.041: [iter 290 : loss : 0.4184 = 0.0048 + 0.3989 + 0.0147, time: 185.006000]
2023-06-10 06:31:18.696: epoch 290:	0.00674096  	0.10775353  	0.05099120  	0.03852454  	0.03899073  
2023-06-10 06:31:18.696: Found a better model.
2023-06-10 06:31:18.696: Save model to file as pretrain.
2023-06-10 06:34:25.342: [iter 291 : loss : 0.4183 = 0.0047 + 0.3989 + 0.0147, time: 185.008862]
2023-06-10 06:35:28.280: epoch 291:	0.00673611  	0.10765557  	0.05106752  	0.03865093  	0.03911975  
2023-06-10 06:38:48.197: [iter 292 : loss : 0.4183 = 0.0047 + 0.3989 + 0.0147, time: 199.256916]
2023-06-10 06:39:44.803: epoch 292:	0.00673947  	0.10768711  	0.05107721  	0.03868193  	0.03914633  
2023-06-10 06:43:05.276: [iter 293 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0147, time: 199.809129]
2023-06-10 06:43:57.528: epoch 293:	0.00674244  	0.10776141  	0.05106082  	0.03863527  	0.03909610  
2023-06-10 06:43:57.528: Found a better model.
2023-06-10 06:43:57.528: Save model to file as pretrain.
2023-06-10 06:47:08.242: [iter 294 : loss : 0.4183 = 0.0047 + 0.3989 + 0.0147, time: 189.038490]
2023-06-10 06:48:10.867: epoch 294:	0.00676143  	0.10807548  	0.05109292  	0.03858168  	0.03905466  
2023-06-10 06:48:10.867: Found a better model.
2023-06-10 06:48:10.867: Save model to file as pretrain.
2023-06-10 06:51:19.979: [iter 295 : loss : 0.4183 = 0.0047 + 0.3989 + 0.0147, time: 187.449455]
2023-06-10 06:52:19.982: epoch 295:	0.00675083  	0.10793694  	0.05110013  	0.03862188  	0.03909463  
2023-06-10 06:55:26.223: [iter 296 : loss : 0.4183 = 0.0047 + 0.3989 + 0.0147, time: 185.597919]
2023-06-10 06:56:27.129: epoch 296:	0.00676199  	0.10806800  	0.05110527  	0.03859618  	0.03906588  
2023-06-10 06:59:33.890: [iter 297 : loss : 0.4183 = 0.0047 + 0.3989 + 0.0147, time: 186.107518]
2023-06-10 07:00:34.885: epoch 297:	0.00674635  	0.10774642  	0.05101385  	0.03855269  	0.03902445  
2023-06-10 07:03:40.657: [iter 298 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0147, time: 185.123904]
2023-06-10 07:04:32.406: epoch 298:	0.00673761  	0.10766306  	0.05105938  	0.03865574  	0.03911651  
2023-06-10 07:07:39.355: [iter 299 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0147, time: 186.311312]
2023-06-10 07:08:29.667: epoch 299:	0.00674766  	0.10781171  	0.05119402  	0.03876915  	0.03924029  
2023-06-10 07:11:36.331: [iter 300 : loss : 0.4183 = 0.0047 + 0.3989 + 0.0147, time: 186.007469]
2023-06-10 07:12:37.569: epoch 300:	0.00674003  	0.10771247  	0.05114974  	0.03874642  	0.03921481  
2023-06-10 07:15:43.306: [iter 301 : loss : 0.4183 = 0.0047 + 0.3989 + 0.0147, time: 185.099634]
2023-06-10 07:16:44.391: epoch 301:	0.00673705  	0.10769428  	0.05120116  	0.03881960  	0.03930089  
2023-06-10 07:19:49.823: [iter 302 : loss : 0.4183 = 0.0047 + 0.3989 + 0.0147, time: 184.780501]
2023-06-10 07:20:50.617: epoch 302:	0.00674413  	0.10775355  	0.05119772  	0.03882035  	0.03928073  
2023-06-10 07:23:55.685: [iter 303 : loss : 0.4183 = 0.0047 + 0.3989 + 0.0147, time: 184.419220]
2023-06-10 07:24:55.022: epoch 303:	0.00674133  	0.10780326  	0.05114647  	0.03871792  	0.03917202  
2023-06-10 07:28:14.694: [iter 304 : loss : 0.4182 = 0.0046 + 0.3989 + 0.0147, time: 199.021334]
2023-06-10 07:29:16.300: epoch 304:	0.00674450  	0.10784652  	0.05115524  	0.03872194  	0.03917477  
2023-06-10 07:32:20.581: [iter 305 : loss : 0.4183 = 0.0047 + 0.3989 + 0.0147, time: 183.639089]
2023-06-10 07:33:10.157: epoch 305:	0.00673593  	0.10766799  	0.05116136  	0.03877209  	0.03923195  
2023-06-10 07:36:15.213: [iter 306 : loss : 0.4183 = 0.0047 + 0.3989 + 0.0147, time: 184.405884]
2023-06-10 07:37:03.963: epoch 306:	0.00674673  	0.10782908  	0.05112119  	0.03869630  	0.03913781  
2023-06-10 07:40:11.150: [iter 307 : loss : 0.4182 = 0.0046 + 0.3989 + 0.0147, time: 186.539325]
2023-06-10 07:41:12.801: epoch 307:	0.00675194  	0.10787309  	0.05116833  	0.03877016  	0.03920516  
2023-06-10 07:44:19.284: [iter 308 : loss : 0.4183 = 0.0047 + 0.3989 + 0.0147, time: 185.830684]
2023-06-10 07:45:09.488: epoch 308:	0.00675008  	0.10778993  	0.05118811  	0.03879197  	0.03925617  
2023-06-10 07:48:22.512: [iter 309 : loss : 0.4184 = 0.0048 + 0.3989 + 0.0147, time: 192.374873]
2023-06-10 07:49:23.904: epoch 309:	0.00674096  	0.10765988  	0.05120225  	0.03884267  	0.03931160  
2023-06-10 07:52:38.559: [iter 310 : loss : 0.4183 = 0.0047 + 0.3989 + 0.0147, time: 193.997805]
2023-06-10 07:53:41.280: epoch 310:	0.00673760  	0.10767505  	0.05118861  	0.03882292  	0.03928397  
2023-06-10 07:56:46.508: [iter 311 : loss : 0.4182 = 0.0047 + 0.3989 + 0.0147, time: 184.587163]
2023-06-10 07:57:36.586: epoch 311:	0.00673891  	0.10776792  	0.05114749  	0.03877952  	0.03924384  
2023-06-10 08:00:42.199: [iter 312 : loss : 0.4183 = 0.0047 + 0.3989 + 0.0147, time: 184.969878]
2023-06-10 08:01:44.992: epoch 312:	0.00674394  	0.10776845  	0.05112117  	0.03872734  	0.03919603  
2023-06-10 08:05:05.121: [iter 313 : loss : 0.4183 = 0.0047 + 0.3989 + 0.0147, time: 199.474090]
2023-06-10 08:06:08.105: epoch 313:	0.00673817  	0.10770954  	0.05112757  	0.03875369  	0.03921719  
2023-06-10 08:09:26.445: [iter 314 : loss : 0.4183 = 0.0047 + 0.3989 + 0.0147, time: 197.701354]
2023-06-10 08:10:29.349: epoch 314:	0.00673873  	0.10768126  	0.05120451  	0.03887341  	0.03933428  
2023-06-10 08:10:29.350: Early stopping is triggered at epoch: 314
2023-06-10 08:10:29.350: best_result@epoch 294:

2023-06-10 08:10:29.350: Loading from the saved model.
2023-06-10 08:11:32.848: 		0.00676143  	0.10807548  	0.05109295  	0.03858173  	0.03905471  
/home/Thesis/model/general_recommender/SGL.py:146: RuntimeWarning: divide by zero encountered in power
  d_inv = np.power(rowsum, -0.5).flatten()
