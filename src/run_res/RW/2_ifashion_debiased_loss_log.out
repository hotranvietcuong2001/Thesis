seed= 2021
load saved data...
Item degree grouping...
User degree grouping...
Data loading finished
Evaluate model with cpp
2023-06-11 07:18:51.850: Dataset name: ifashion
The number of users: 300000
The number of items: 81614
The number of ratings: 1607813
Average actions of users: 5.36
Average actions of items: 19.70
The sparsity of the dataset: 99.993433%
2023-06-11 07:18:51.850: 

NeuRec hyperparameters:
recommender=SGL
config_dir=./conf
gpu_id=0
gpu_mem=1.0
data.input.path=dataset
data.input.dataset=ifashion
data.column.format=UI
data.convert.separator=','
user_min=0
item_min=0
splitter=given
ratio=0.8
by_time=False
metric=["Precision", "Recall", "NDCG", "MAP", "MRR"]
topk=[20]
group_view=None
rec.evaluate.neg=0
test_batch_size=128
num_thread=8
start_testing_epoch=0
proj_path=./

SGL's hyperparameters:
seed=2021
aug_type=2
reg=1e-3
embed_size=64
n_layers=3
ssl_reg=0.02
ssl_ratio=0.4
ssl_temp=0.5
ssl_mode=both_side
ssl_loss_type=2
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=1024
num_negatives=1
init_method=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=20
pretrain=0
save_flag=1

Using debiased loss
2023-06-11 07:19:12.216: metrics:	Precision@20	Recall@20   	NDCG@20     	MAP@20      	MRR@20      
2023-06-11 07:20:20.310: 		0.00000651  	0.00011212  	0.00003431  	0.00001500  	0.00001500  
2023-06-11 07:25:52.572: [iter 1 : loss : 1.0709 = 0.6722 + 0.3985 + 0.0002, time: 327.578830]
2023-06-11 07:26:43.054: epoch 1:	0.00286069  	0.04597135  	0.02061653  	0.01512553  	0.01522159  
2023-06-11 07:26:43.054: Found a better model.
2023-06-11 07:26:43.054: Save model to file as pretrain.
2023-06-11 07:32:30.767: [iter 2 : loss : 0.7298 = 0.3077 + 0.4174 + 0.0048, time: 341.698349]
2023-06-11 07:33:19.655: epoch 2:	0.00343504  	0.05523304  	0.02456323  	0.01791527  	0.01803165  
2023-06-11 07:33:19.655: Found a better model.
2023-06-11 07:33:19.655: Save model to file as pretrain.
2023-06-11 07:39:06.267: [iter 3 : loss : 0.5800 = 0.1548 + 0.4169 + 0.0082, time: 341.072222]
2023-06-11 07:39:54.966: epoch 3:	0.00389478  	0.06253433  	0.02778064  	0.02016323  	0.02031118  
2023-06-11 07:39:54.966: Found a better model.
2023-06-11 07:39:54.966: Save model to file as pretrain.
2023-06-11 07:45:18.527: [iter 4 : loss : 0.5311 = 0.1080 + 0.4133 + 0.0098, time: 318.151877]
2023-06-11 07:46:06.327: epoch 4:	0.00426541  	0.06851253  	0.03047343  	0.02207745  	0.02224463  
2023-06-11 07:46:06.327: Found a better model.
2023-06-11 07:46:06.327: Save model to file as pretrain.
2023-06-11 07:51:47.681: [iter 5 : loss : 0.5037 = 0.0822 + 0.4107 + 0.0108, time: 335.814988]
2023-06-11 07:52:36.103: epoch 5:	0.00456809  	0.07339159  	0.03288487  	0.02394023  	0.02413539  
2023-06-11 07:52:36.104: Found a better model.
2023-06-11 07:52:36.104: Save model to file as pretrain.
2023-06-11 07:58:18.295: [iter 6 : loss : 0.4859 = 0.0654 + 0.4088 + 0.0117, time: 336.355524]
2023-06-11 07:59:07.425: epoch 6:	0.00480115  	0.07726736  	0.03471008  	0.02533966  	0.02554473  
2023-06-11 07:59:07.425: Found a better model.
2023-06-11 07:59:07.425: Save model to file as pretrain.
2023-06-11 08:04:45.176: [iter 7 : loss : 0.4731 = 0.0532 + 0.4074 + 0.0125, time: 332.292502]
2023-06-11 08:05:32.905: epoch 7:	0.00498804  	0.08031714  	0.03621622  	0.02647722  	0.02671016  
2023-06-11 08:05:32.905: Found a better model.
2023-06-11 08:05:32.905: Save model to file as pretrain.
2023-06-11 08:11:11.259: [iter 8 : loss : 0.4641 = 0.0447 + 0.4063 + 0.0131, time: 332.828868]
2023-06-11 08:11:59.847: epoch 8:	0.00514274  	0.08289832  	0.03747894  	0.02746240  	0.02769312  
2023-06-11 08:11:59.848: Found a better model.
2023-06-11 08:11:59.848: Save model to file as pretrain.
2023-06-11 08:17:31.777: [iter 9 : loss : 0.4573 = 0.0381 + 0.4055 + 0.0136, time: 326.450429]
2023-06-11 08:18:20.156: epoch 9:	0.00527342  	0.08491644  	0.03849262  	0.02825112  	0.02849769  
2023-06-11 08:18:20.157: Found a better model.
2023-06-11 08:18:20.157: Save model to file as pretrain.
2023-06-11 08:23:42.464: [iter 10 : loss : 0.4519 = 0.0330 + 0.4048 + 0.0141, time: 316.780877]
2023-06-11 08:24:32.017: epoch 10:	0.00535029  	0.08603796  	0.03928158  	0.02897640  	0.02924172  
2023-06-11 08:24:32.017: Found a better model.
2023-06-11 08:24:32.017: Save model to file as pretrain.
2023-06-11 08:29:59.509: [iter 11 : loss : 0.4474 = 0.0286 + 0.4043 + 0.0145, time: 321.972272]
2023-06-11 08:30:49.534: epoch 11:	0.00545435  	0.08762231  	0.04007582  	0.02960204  	0.02987846  
2023-06-11 08:30:49.534: Found a better model.
2023-06-11 08:30:49.534: Save model to file as pretrain.
2023-06-11 08:36:24.906: [iter 12 : loss : 0.4435 = 0.0249 + 0.4038 + 0.0149, time: 329.887796]
2023-06-11 08:37:12.958: epoch 12:	0.00554016  	0.08906569  	0.04081784  	0.03018812  	0.03046651  
2023-06-11 08:37:12.958: Found a better model.
2023-06-11 08:37:12.958: Save model to file as pretrain.
2023-06-11 08:42:48.376: [iter 13 : loss : 0.4406 = 0.0221 + 0.4034 + 0.0151, time: 329.899140]
2023-06-11 08:43:37.743: epoch 13:	0.00561666  	0.09031598  	0.04146878  	0.03070317  	0.03099188  
2023-06-11 08:43:37.743: Found a better model.
2023-06-11 08:43:37.743: Save model to file as pretrain.
2023-06-11 08:49:21.911: [iter 14 : loss : 0.4381 = 0.0197 + 0.4031 + 0.0153, time: 338.632279]
2023-06-11 08:50:10.721: epoch 14:	0.00570005  	0.09146715  	0.04209682  	0.03123236  	0.03152185  
2023-06-11 08:50:10.721: Found a better model.
2023-06-11 08:50:10.721: Save model to file as pretrain.
2023-06-11 08:55:47.721: [iter 15 : loss : 0.4363 = 0.0181 + 0.4028 + 0.0155, time: 331.415474]
2023-06-11 08:56:36.801: epoch 15:	0.00576018  	0.09246322  	0.04271242  	0.03181531  	0.03210637  
2023-06-11 08:56:36.802: Found a better model.
2023-06-11 08:56:36.802: Save model to file as pretrain.
2023-06-11 09:02:06.650: [iter 16 : loss : 0.4345 = 0.0164 + 0.4025 + 0.0156, time: 323.920186]
2023-06-11 09:02:55.518: epoch 16:	0.00579610  	0.09300267  	0.04308662  	0.03215280  	0.03247010  
2023-06-11 09:02:55.518: Found a better model.
2023-06-11 09:02:55.520: Save model to file as pretrain.
2023-06-11 09:08:27.935: [iter 17 : loss : 0.4331 = 0.0151 + 0.4023 + 0.0157, time: 326.836174]
2023-06-11 09:09:17.207: epoch 17:	0.00585064  	0.09384998  	0.04342717  	0.03237238  	0.03268482  
2023-06-11 09:09:17.207: Found a better model.
2023-06-11 09:09:17.207: Save model to file as pretrain.
2023-06-11 09:14:51.094: [iter 18 : loss : 0.4318 = 0.0140 + 0.4021 + 0.0158, time: 328.223318]
2023-06-11 09:15:39.218: epoch 18:	0.00588172  	0.09433007  	0.04372678  	0.03265058  	0.03297901  
2023-06-11 09:15:39.218: Found a better model.
2023-06-11 09:15:39.218: Save model to file as pretrain.
2023-06-11 09:21:22.535: [iter 19 : loss : 0.4306 = 0.0129 + 0.4019 + 0.0158, time: 337.735205]
2023-06-11 09:22:09.508: epoch 19:	0.00592230  	0.09502150  	0.04410117  	0.03296926  	0.03328060  
2023-06-11 09:22:09.508: Found a better model.
2023-06-11 09:22:09.508: Save model to file as pretrain.
2023-06-11 09:27:47.592: [iter 20 : loss : 0.4296 = 0.0121 + 0.4018 + 0.0158, time: 332.502822]
2023-06-11 09:28:37.365: epoch 20:	0.00596624  	0.09567730  	0.04437746  	0.03313715  	0.03346674  
2023-06-11 09:28:37.365: Found a better model.
2023-06-11 09:28:37.365: Save model to file as pretrain.
2023-06-11 09:34:17.529: [iter 21 : loss : 0.4288 = 0.0114 + 0.4017 + 0.0157, time: 334.629172]
2023-06-11 09:35:05.833: epoch 21:	0.00599248  	0.09599334  	0.04472236  	0.03349839  	0.03383924  
2023-06-11 09:35:05.833: Found a better model.
2023-06-11 09:35:05.833: Save model to file as pretrain.
2023-06-11 09:40:37.087: [iter 22 : loss : 0.4281 = 0.0109 + 0.4015 + 0.0157, time: 325.692115]
2023-06-11 09:41:25.141: epoch 22:	0.00602431  	0.09654994  	0.04497463  	0.03370319  	0.03404936  
2023-06-11 09:41:25.141: Found a better model.
2023-06-11 09:41:25.141: Save model to file as pretrain.
2023-06-11 09:47:06.180: [iter 23 : loss : 0.4275 = 0.0104 + 0.4014 + 0.0156, time: 335.437939]
2023-06-11 09:47:55.332: epoch 23:	0.00604460  	0.09685148  	0.04519355  	0.03388752  	0.03423989  
2023-06-11 09:47:55.333: Found a better model.
2023-06-11 09:47:55.340: Save model to file as pretrain.
2023-06-11 09:53:44.857: [iter 24 : loss : 0.4268 = 0.0099 + 0.4013 + 0.0156, time: 343.887070]
2023-06-11 09:54:33.759: epoch 24:	0.00605913  	0.09719764  	0.04537574  	0.03399731  	0.03435111  
2023-06-11 09:54:33.759: Found a better model.
2023-06-11 09:54:33.759: Save model to file as pretrain.
2023-06-11 10:00:04.447: [iter 25 : loss : 0.4262 = 0.0094 + 0.4013 + 0.0155, time: 325.170512]
2023-06-11 10:00:54.325: epoch 25:	0.00608332  	0.09752800  	0.04555687  	0.03415785  	0.03451864  
2023-06-11 10:00:54.326: Found a better model.
2023-06-11 10:00:54.326: Save model to file as pretrain.
2023-06-11 10:06:23.217: [iter 26 : loss : 0.4257 = 0.0091 + 0.4012 + 0.0155, time: 323.317218]
2023-06-11 10:07:12.310: epoch 26:	0.00609635  	0.09768822  	0.04566820  	0.03427007  	0.03463309  
2023-06-11 10:07:12.310: Found a better model.
2023-06-11 10:07:12.310: Save model to file as pretrain.
2023-06-11 10:12:53.922: [iter 27 : loss : 0.4254 = 0.0089 + 0.4011 + 0.0154, time: 336.057428]
2023-06-11 10:13:45.342: epoch 27:	0.00612092  	0.09788668  	0.04591450  	0.03454178  	0.03490913  
2023-06-11 10:13:45.345: Found a better model.
2023-06-11 10:13:45.345: Save model to file as pretrain.
2023-06-11 10:19:27.367: [iter 28 : loss : 0.4249 = 0.0085 + 0.4011 + 0.0154, time: 336.212001]
2023-06-11 10:20:17.715: epoch 28:	0.00613301  	0.09816311  	0.04606776  	0.03467641  	0.03505481  
2023-06-11 10:20:17.715: Found a better model.
2023-06-11 10:20:17.715: Save model to file as pretrain.
2023-06-11 10:25:51.541: [iter 29 : loss : 0.4247 = 0.0083 + 0.4010 + 0.0153, time: 328.300602]
2023-06-11 10:26:39.721: epoch 29:	0.00614419  	0.09830543  	0.04620238  	0.03479836  	0.03517599  
2023-06-11 10:26:39.721: Found a better model.
2023-06-11 10:26:39.721: Save model to file as pretrain.
2023-06-11 10:32:12.348: [iter 30 : loss : 0.4242 = 0.0080 + 0.4010 + 0.0153, time: 327.124161]
2023-06-11 10:33:00.970: epoch 30:	0.00616726  	0.09873330  	0.04640269  	0.03493697  	0.03532084  
2023-06-11 10:33:00.970: Found a better model.
2023-06-11 10:33:00.970: Save model to file as pretrain.
2023-06-11 10:38:19.932: [iter 31 : loss : 0.4240 = 0.0078 + 0.4009 + 0.0152, time: 313.461848]
2023-06-11 10:39:07.584: epoch 31:	0.00617360  	0.09887462  	0.04650972  	0.03505003  	0.03543947  
2023-06-11 10:39:07.584: Found a better model.
2023-06-11 10:39:07.584: Save model to file as pretrain.
2023-06-11 10:44:36.617: [iter 32 : loss : 0.4237 = 0.0076 + 0.4009 + 0.0152, time: 323.547008]
2023-06-11 10:45:25.352: epoch 32:	0.00617992  	0.09891580  	0.04657155  	0.03509931  	0.03549295  
2023-06-11 10:45:25.354: Found a better model.
2023-06-11 10:45:25.354: Save model to file as pretrain.
2023-06-11 10:50:51.421: [iter 33 : loss : 0.4234 = 0.0074 + 0.4008 + 0.0152, time: 320.574890]
2023-06-11 10:51:39.173: epoch 33:	0.00619575  	0.09907304  	0.04669650  	0.03525069  	0.03563526  
2023-06-11 10:51:39.173: Found a better model.
2023-06-11 10:51:39.173: Save model to file as pretrain.
2023-06-11 10:57:29.811: [iter 34 : loss : 0.4233 = 0.0073 + 0.4008 + 0.0151, time: 345.180727]
2023-06-11 10:58:18.315: epoch 34:	0.00620189  	0.09913243  	0.04671593  	0.03526172  	0.03565235  
2023-06-11 10:58:18.316: Found a better model.
2023-06-11 10:58:18.316: Save model to file as pretrain.
2023-06-11 11:03:43.620: [iter 35 : loss : 0.4231 = 0.0072 + 0.4008 + 0.0151, time: 319.291817]
2023-06-11 11:04:33.219: epoch 35:	0.00621566  	0.09926083  	0.04684671  	0.03541313  	0.03580676  
2023-06-11 11:04:33.219: Found a better model.
2023-06-11 11:04:33.219: Save model to file as pretrain.
2023-06-11 11:10:10.392: [iter 36 : loss : 0.4229 = 0.0070 + 0.4008 + 0.0151, time: 331.741537]
2023-06-11 11:10:58.592: epoch 36:	0.00623242  	0.09956826  	0.04694575  	0.03546140  	0.03585777  
2023-06-11 11:10:58.592: Found a better model.
2023-06-11 11:10:58.592: Save model to file as pretrain.
2023-06-11 11:16:29.233: [iter 37 : loss : 0.4228 = 0.0070 + 0.4007 + 0.0151, time: 325.170058]
2023-06-11 11:17:17.730: epoch 37:	0.00625233  	0.09990986  	0.04707699  	0.03553443  	0.03593117  
2023-06-11 11:17:17.731: Found a better model.
2023-06-11 11:17:17.731: Save model to file as pretrain.
2023-06-11 11:22:54.633: [iter 38 : loss : 0.4226 = 0.0069 + 0.4007 + 0.0150, time: 331.503567]
2023-06-11 11:23:42.313: epoch 38:	0.00625736  	0.09993970  	0.04713860  	0.03562110  	0.03600874  
2023-06-11 11:23:42.313: Found a better model.
2023-06-11 11:23:42.313: Save model to file as pretrain.
2023-06-11 11:29:01.996: [iter 39 : loss : 0.4224 = 0.0067 + 0.4007 + 0.0150, time: 314.153690]
2023-06-11 11:29:49.858: epoch 39:	0.00627318  	0.10019427  	0.04725764  	0.03569001  	0.03611565  
2023-06-11 11:29:49.858: Found a better model.
2023-06-11 11:29:49.858: Save model to file as pretrain.
2023-06-11 11:35:25.141: [iter 40 : loss : 0.4222 = 0.0065 + 0.4007 + 0.0150, time: 329.840141]
2023-06-11 11:36:14.440: epoch 40:	0.00628101  	0.10044086  	0.04729503  	0.03569612  	0.03610558  
2023-06-11 11:36:14.440: Found a better model.
2023-06-11 11:36:14.440: Save model to file as pretrain.
2023-06-11 11:41:59.570: [iter 41 : loss : 0.4221 = 0.0065 + 0.4006 + 0.0150, time: 339.697724]
2023-06-11 11:42:49.084: epoch 41:	0.00627952  	0.10039678  	0.04732567  	0.03573640  	0.03615934  
2023-06-11 11:48:26.973: [iter 42 : loss : 0.4220 = 0.0065 + 0.4006 + 0.0150, time: 333.379941]
2023-06-11 11:49:14.714: epoch 42:	0.00628547  	0.10046569  	0.04738507  	0.03578128  	0.03619863  
2023-06-11 11:49:14.714: Found a better model.
2023-06-11 11:49:14.714: Save model to file as pretrain.
2023-06-11 11:54:45.076: [iter 43 : loss : 0.4219 = 0.0064 + 0.4006 + 0.0150, time: 324.909217]
2023-06-11 11:55:33.924: epoch 43:	0.00629105  	0.10052555  	0.04745672  	0.03585460  	0.03628534  
2023-06-11 11:55:33.924: Found a better model.
2023-06-11 11:55:33.924: Save model to file as pretrain.
2023-06-11 12:01:13.659: [iter 44 : loss : 0.4219 = 0.0063 + 0.4006 + 0.0149, time: 334.227509]
2023-06-11 12:02:02.127: epoch 44:	0.00629905  	0.10063359  	0.04755880  	0.03596491  	0.03638480  
2023-06-11 12:02:02.127: Found a better model.
2023-06-11 12:02:02.127: Save model to file as pretrain.
2023-06-11 12:07:31.399: [iter 45 : loss : 0.4218 = 0.0062 + 0.4006 + 0.0150, time: 323.774832]
2023-06-11 12:08:19.852: epoch 45:	0.00630408  	0.10076322  	0.04756876  	0.03593690  	0.03637085  
2023-06-11 12:08:19.852: Found a better model.
2023-06-11 12:08:19.852: Save model to file as pretrain.
2023-06-11 12:13:54.297: [iter 46 : loss : 0.4216 = 0.0061 + 0.4006 + 0.0149, time: 328.885755]
2023-06-11 12:14:42.034: epoch 46:	0.00629682  	0.10066554  	0.04754416  	0.03594199  	0.03637155  
2023-06-11 12:20:15.906: [iter 47 : loss : 0.4215 = 0.0061 + 0.4006 + 0.0149, time: 329.304798]
2023-06-11 12:21:04.579: epoch 47:	0.00629235  	0.10061856  	0.04754373  	0.03595428  	0.03639738  
2023-06-11 12:26:33.593: [iter 48 : loss : 0.4215 = 0.0060 + 0.4005 + 0.0149, time: 324.514727]
2023-06-11 12:27:22.425: epoch 48:	0.00629719  	0.10070877  	0.04755452  	0.03595218  	0.03636828  
2023-06-11 12:32:55.282: [iter 49 : loss : 0.4215 = 0.0060 + 0.4005 + 0.0149, time: 328.312520]
2023-06-11 12:33:43.974: epoch 49:	0.00633182  	0.10120401  	0.04772457  	0.03605042  	0.03647428  
2023-06-11 12:33:43.975: Found a better model.
2023-06-11 12:33:43.975: Save model to file as pretrain.
2023-06-11 12:39:17.366: [iter 50 : loss : 0.4215 = 0.0060 + 0.4005 + 0.0149, time: 327.860059]
2023-06-11 12:40:05.663: epoch 50:	0.00634820  	0.10152541  	0.04785723  	0.03614082  	0.03658229  
2023-06-11 12:40:05.663: Found a better model.
2023-06-11 12:40:05.663: Save model to file as pretrain.
2023-06-11 12:45:44.037: [iter 51 : loss : 0.4214 = 0.0060 + 0.4005 + 0.0149, time: 332.897918]
2023-06-11 12:46:32.957: epoch 51:	0.00634522  	0.10152061  	0.04785441  	0.03616149  	0.03658809  
2023-06-11 12:52:09.031: [iter 52 : loss : 0.4213 = 0.0059 + 0.4005 + 0.0149, time: 331.526574]
2023-06-11 12:52:57.208: epoch 52:	0.00635695  	0.10159232  	0.04787708  	0.03616620  	0.03659826  
2023-06-11 12:52:57.208: Found a better model.
2023-06-11 12:52:57.208: Save model to file as pretrain.
2023-06-11 12:58:36.579: [iter 53 : loss : 0.4213 = 0.0058 + 0.4005 + 0.0149, time: 333.795960]
2023-06-11 12:59:28.437: epoch 53:	0.00636457  	0.10174114  	0.04789535  	0.03614212  	0.03656567  
2023-06-11 12:59:28.437: Found a better model.
2023-06-11 12:59:28.437: Save model to file as pretrain.
2023-06-11 13:05:09.998: [iter 54 : loss : 0.4211 = 0.0057 + 0.4005 + 0.0149, time: 335.772099]
2023-06-11 13:05:58.337: epoch 54:	0.00636402  	0.10179583  	0.04790514  	0.03613311  	0.03655700  
2023-06-11 13:05:58.337: Found a better model.
2023-06-11 13:05:58.337: Save model to file as pretrain.
2023-06-11 13:11:32.833: [iter 55 : loss : 0.4211 = 0.0057 + 0.4005 + 0.0149, time: 328.979452]
2023-06-11 13:12:21.557: epoch 55:	0.00637407  	0.10190795  	0.04795003  	0.03613565  	0.03656569  
2023-06-11 13:12:21.557: Found a better model.
2023-06-11 13:12:21.557: Save model to file as pretrain.
2023-06-11 13:18:05.215: [iter 56 : loss : 0.4211 = 0.0057 + 0.4005 + 0.0149, time: 338.150362]
2023-06-11 13:18:54.804: epoch 56:	0.00636104  	0.10172690  	0.04795565  	0.03620282  	0.03662710  
2023-06-11 13:24:40.947: [iter 57 : loss : 0.4210 = 0.0056 + 0.4005 + 0.0149, time: 341.660339]
2023-06-11 13:25:29.856: epoch 57:	0.00637110  	0.10194468  	0.04801850  	0.03623550  	0.03665647  
2023-06-11 13:25:29.856: Found a better model.
2023-06-11 13:25:29.856: Save model to file as pretrain.
2023-06-11 13:30:59.623: [iter 58 : loss : 0.4210 = 0.0056 + 0.4005 + 0.0149, time: 320.992543]
2023-06-11 13:31:48.018: epoch 58:	0.00637463  	0.10205314  	0.04804472  	0.03624548  	0.03667450  
2023-06-11 13:31:48.018: Found a better model.
2023-06-11 13:31:48.018: Save model to file as pretrain.
2023-06-11 13:37:26.240: [iter 59 : loss : 0.4210 = 0.0056 + 0.4004 + 0.0149, time: 329.715446]
2023-06-11 13:38:16.895: epoch 59:	0.00636849  	0.10197426  	0.04802717  	0.03624927  	0.03667051  
2023-06-11 13:43:43.986: [iter 60 : loss : 0.4210 = 0.0056 + 0.4004 + 0.0149, time: 322.604777]
2023-06-11 13:44:32.988: epoch 60:	0.00636328  	0.10184438  	0.04800553  	0.03624685  	0.03666195  
2023-06-11 13:50:10.723: [iter 61 : loss : 0.4209 = 0.0055 + 0.4004 + 0.0149, time: 333.284968]
2023-06-11 13:50:59.055: epoch 61:	0.00638171  	0.10214256  	0.04817649  	0.03643269  	0.03684867  
2023-06-11 13:50:59.055: Found a better model.
2023-06-11 13:50:59.055: Save model to file as pretrain.
2023-06-11 13:56:31.836: [iter 62 : loss : 0.4209 = 0.0055 + 0.4004 + 0.0149, time: 324.026991]
2023-06-11 13:57:21.012: epoch 62:	0.00637296  	0.10200020  	0.04816353  	0.03640908  	0.03680862  
2023-06-11 14:02:54.152: [iter 63 : loss : 0.4207 = 0.0054 + 0.4004 + 0.0149, time: 328.571833]
2023-06-11 14:03:42.810: epoch 63:	0.00637426  	0.10198297  	0.04813102  	0.03635630  	0.03675029  
2023-06-11 14:09:04.673: [iter 64 : loss : 0.4208 = 0.0055 + 0.4004 + 0.0149, time: 317.300662]
2023-06-11 14:09:53.917: epoch 64:	0.00638617  	0.10219091  	0.04824751  	0.03648048  	0.03688225  
2023-06-11 14:09:53.917: Found a better model.
2023-06-11 14:09:53.917: Save model to file as pretrain.
2023-06-11 14:15:20.008: [iter 65 : loss : 0.4208 = 0.0055 + 0.4004 + 0.0149, time: 317.414476]
2023-06-11 14:16:08.374: epoch 65:	0.00640833  	0.10256498  	0.04831667  	0.03646926  	0.03687487  
2023-06-11 14:16:08.374: Found a better model.
2023-06-11 14:16:08.374: Save model to file as pretrain.
2023-06-11 14:21:45.776: [iter 66 : loss : 0.4207 = 0.0054 + 0.4004 + 0.0149, time: 328.605317]
2023-06-11 14:22:33.824: epoch 66:	0.00640404  	0.10246263  	0.04836841  	0.03656585  	0.03697105  
2023-06-11 14:27:58.856: [iter 67 : loss : 0.4207 = 0.0054 + 0.4004 + 0.0149, time: 320.466496]
2023-06-11 14:28:47.624: epoch 67:	0.00641726  	0.10272972  	0.04849088  	0.03665090  	0.03706703  
2023-06-11 14:28:47.624: Found a better model.
2023-06-11 14:28:47.624: Save model to file as pretrain.
2023-06-11 14:34:10.619: [iter 68 : loss : 0.4207 = 0.0054 + 0.4004 + 0.0149, time: 314.168753]
2023-06-11 14:34:59.504: epoch 68:	0.00640553  	0.10247511  	0.04840683  	0.03658840  	0.03700309  
2023-06-11 14:40:30.189: [iter 69 : loss : 0.4206 = 0.0053 + 0.4004 + 0.0149, time: 326.101331]
2023-06-11 14:41:18.188: epoch 69:	0.00642563  	0.10275973  	0.04849545  	0.03661413  	0.03703539  
2023-06-11 14:41:18.188: Found a better model.
2023-06-11 14:41:18.188: Save model to file as pretrain.
2023-06-11 14:46:46.272: [iter 70 : loss : 0.4206 = 0.0053 + 0.4004 + 0.0149, time: 322.539089]
2023-06-11 14:47:36.325: epoch 70:	0.00641297  	0.10252941  	0.04848395  	0.03669900  	0.03711226  
2023-06-11 14:53:06.258: [iter 71 : loss : 0.4206 = 0.0053 + 0.4004 + 0.0149, time: 325.390077]
2023-06-11 14:53:55.080: epoch 71:	0.00642433  	0.10270880  	0.04850256  	0.03666490  	0.03708847  
2023-06-11 14:59:19.316: [iter 72 : loss : 0.4206 = 0.0053 + 0.4004 + 0.0149, time: 319.706528]
2023-06-11 15:00:08.271: epoch 72:	0.00642414  	0.10265187  	0.04850869  	0.03667941  	0.03709534  
2023-06-11 15:05:47.203: [iter 73 : loss : 0.4205 = 0.0052 + 0.4004 + 0.0149, time: 334.356397]
2023-06-11 15:06:36.214: epoch 73:	0.00644778  	0.10310569  	0.04867814  	0.03679044  	0.03720981  
2023-06-11 15:06:36.214: Found a better model.
2023-06-11 15:06:36.214: Save model to file as pretrain.
2023-06-11 15:12:17.538: [iter 74 : loss : 0.4206 = 0.0053 + 0.4004 + 0.0149, time: 335.709859]
2023-06-11 15:13:05.856: epoch 74:	0.00645299  	0.10321264  	0.04874557  	0.03684745  	0.03726849  
2023-06-11 15:13:05.856: Found a better model.
2023-06-11 15:13:05.856: Save model to file as pretrain.
2023-06-11 15:18:38.204: [iter 75 : loss : 0.4206 = 0.0053 + 0.4004 + 0.0149, time: 326.661218]
2023-06-11 15:19:25.435: epoch 75:	0.00644741  	0.10314851  	0.04875911  	0.03691315  	0.03732175  
2023-06-11 15:24:54.565: [iter 76 : loss : 0.4205 = 0.0053 + 0.4004 + 0.0149, time: 324.478806]
2023-06-11 15:25:42.268: epoch 76:	0.00643438  	0.10305531  	0.04872631  	0.03688962  	0.03730742  
2023-06-11 15:31:15.182: [iter 77 : loss : 0.4205 = 0.0053 + 0.4004 + 0.0149, time: 328.287318]
2023-06-11 15:32:05.210: epoch 77:	0.00645020  	0.10327221  	0.04877482  	0.03687213  	0.03727615  
2023-06-11 15:32:05.210: Found a better model.
2023-06-11 15:32:05.210: Save model to file as pretrain.
2023-06-11 15:37:36.329: [iter 78 : loss : 0.4205 = 0.0053 + 0.4004 + 0.0149, time: 325.494911]
2023-06-11 15:38:23.588: epoch 78:	0.00644797  	0.10324106  	0.04878378  	0.03686295  	0.03728585  
2023-06-11 15:43:57.090: [iter 79 : loss : 0.4204 = 0.0051 + 0.4004 + 0.0149, time: 328.785032]
2023-06-11 15:44:48.606: epoch 79:	0.00646230  	0.10344283  	0.04889453  	0.03696384  	0.03738740  
2023-06-11 15:44:48.606: Found a better model.
2023-06-11 15:44:48.606: Save model to file as pretrain.
2023-06-11 15:50:28.599: [iter 80 : loss : 0.4204 = 0.0052 + 0.4004 + 0.0149, time: 334.124053]
2023-06-11 15:51:18.166: epoch 80:	0.00645671  	0.10332796  	0.04886902  	0.03695071  	0.03737264  
2023-06-11 15:56:52.410: [iter 81 : loss : 0.4204 = 0.0051 + 0.4004 + 0.0149, time: 329.621823]
2023-06-11 15:57:42.975: epoch 81:	0.00646918  	0.10348012  	0.04885292  	0.03690261  	0.03733066  
2023-06-11 15:57:42.975: Found a better model.
2023-06-11 15:57:42.975: Save model to file as pretrain.
2023-06-11 16:03:13.599: [iter 82 : loss : 0.4204 = 0.0052 + 0.4004 + 0.0149, time: 325.000140]
2023-06-11 16:04:02.024: epoch 82:	0.00647384  	0.10363499  	0.04889977  	0.03693962  	0.03735895  
2023-06-11 16:04:02.024: Found a better model.
2023-06-11 16:04:02.024: Save model to file as pretrain.
2023-06-11 16:09:22.294: [iter 83 : loss : 0.4204 = 0.0052 + 0.4004 + 0.0149, time: 314.674945]
2023-06-11 16:10:11.377: epoch 83:	0.00647681  	0.10362814  	0.04894882  	0.03699272  	0.03740870  
2023-06-11 16:15:45.281: [iter 84 : loss : 0.4204 = 0.0052 + 0.4003 + 0.0149, time: 329.266017]
2023-06-11 16:16:32.731: epoch 84:	0.00649785  	0.10402392  	0.04905728  	0.03703782  	0.03745591  
2023-06-11 16:16:32.731: Found a better model.
2023-06-11 16:16:32.731: Save model to file as pretrain.
2023-06-11 16:22:04.471: [iter 85 : loss : 0.4203 = 0.0051 + 0.4003 + 0.0149, time: 326.143988]
2023-06-11 16:22:53.713: epoch 85:	0.00649804  	0.10397277  	0.04905991  	0.03706039  	0.03747439  
2023-06-11 16:28:32.859: [iter 86 : loss : 0.4204 = 0.0051 + 0.4003 + 0.0149, time: 334.603200]
2023-06-11 16:29:21.432: epoch 86:	0.00649487  	0.10391940  	0.04910062  	0.03712353  	0.03753951  
2023-06-11 16:35:01.506: [iter 87 : loss : 0.4203 = 0.0051 + 0.4003 + 0.0149, time: 335.508322]
2023-06-11 16:35:50.769: epoch 87:	0.00649989  	0.10403427  	0.04910447  	0.03708728  	0.03751456  
2023-06-11 16:35:50.769: Found a better model.
2023-06-11 16:35:50.769: Save model to file as pretrain.
2023-06-11 16:41:16.875: [iter 88 : loss : 0.4204 = 0.0052 + 0.4003 + 0.0149, time: 320.516797]
2023-06-11 16:42:05.978: epoch 88:	0.00650902  	0.10413195  	0.04918164  	0.03713815  	0.03756532  
2023-06-11 16:42:05.978: Found a better model.
2023-06-11 16:42:05.978: Save model to file as pretrain.
2023-06-11 16:47:47.988: [iter 89 : loss : 0.4202 = 0.0050 + 0.4003 + 0.0149, time: 336.483897]
2023-06-11 16:48:35.932: epoch 89:	0.00650734  	0.10416761  	0.04918120  	0.03714142  	0.03756285  
2023-06-11 16:48:35.932: Found a better model.
2023-06-11 16:48:35.932: Save model to file as pretrain.
2023-06-11 16:54:05.387: [iter 90 : loss : 0.4203 = 0.0050 + 0.4003 + 0.0149, time: 323.539652]
2023-06-11 16:54:54.857: epoch 90:	0.00650213  	0.10412061  	0.04920168  	0.03718138  	0.03758880  
2023-06-11 17:00:23.256: [iter 91 : loss : 0.4204 = 0.0051 + 0.4003 + 0.0149, time: 323.868149]
2023-06-11 17:01:10.737: epoch 91:	0.00652428  	0.10437440  	0.04925101  	0.03718397  	0.03761078  
2023-06-11 17:01:10.737: Found a better model.
2023-06-11 17:01:10.737: Save model to file as pretrain.
2023-06-11 17:06:43.877: [iter 92 : loss : 0.4202 = 0.0050 + 0.4003 + 0.0149, time: 327.695767]
2023-06-11 17:07:32.741: epoch 92:	0.00652428  	0.10450743  	0.04927974  	0.03720073  	0.03762536  
2023-06-11 17:07:32.741: Found a better model.
2023-06-11 17:07:32.741: Save model to file as pretrain.
2023-06-11 17:13:23.011: [iter 93 : loss : 0.4203 = 0.0050 + 0.4003 + 0.0149, time: 344.760213]
2023-06-11 17:14:12.019: epoch 93:	0.00653285  	0.10461052  	0.04933833  	0.03725535  	0.03767267  
2023-06-11 17:14:12.020: Found a better model.
2023-06-11 17:14:12.020: Save model to file as pretrain.
2023-06-11 17:19:53.389: [iter 94 : loss : 0.4203 = 0.0051 + 0.4003 + 0.0149, time: 335.888196]
2023-06-11 17:20:42.484: epoch 94:	0.00654252  	0.10471595  	0.04936838  	0.03725025  	0.03768368  
2023-06-11 17:20:42.484: Found a better model.
2023-06-11 17:20:42.485: Save model to file as pretrain.
2023-06-11 17:26:22.121: [iter 95 : loss : 0.4202 = 0.0050 + 0.4003 + 0.0149, time: 334.155585]
2023-06-11 17:27:10.655: epoch 95:	0.00652893  	0.10449150  	0.04928795  	0.03717366  	0.03760684  
2023-06-11 17:32:43.968: [iter 96 : loss : 0.4203 = 0.0051 + 0.4003 + 0.0149, time: 328.831654]
2023-06-11 17:33:31.467: epoch 96:	0.00653136  	0.10452756  	0.04944181  	0.03738333  	0.03781750  
2023-06-11 17:38:48.773: [iter 97 : loss : 0.4203 = 0.0051 + 0.4003 + 0.0149, time: 312.752786]
2023-06-11 17:39:36.884: epoch 97:	0.00653490  	0.10457672  	0.04942625  	0.03734955  	0.03776968  
2023-06-11 17:45:14.653: [iter 98 : loss : 0.4202 = 0.0050 + 0.4003 + 0.0149, time: 333.282887]
2023-06-11 17:46:02.556: epoch 98:	0.00654253  	0.10473015  	0.04948197  	0.03737178  	0.03780311  
2023-06-11 17:46:02.557: Found a better model.
2023-06-11 17:46:02.557: Save model to file as pretrain.
2023-06-11 17:51:35.592: [iter 99 : loss : 0.4203 = 0.0050 + 0.4003 + 0.0149, time: 327.560944]
2023-06-11 17:52:24.112: epoch 99:	0.00654885  	0.10481920  	0.04952751  	0.03740038  	0.03783165  
2023-06-11 17:52:24.112: Found a better model.
2023-06-11 17:52:24.112: Save model to file as pretrain.
2023-06-11 17:57:56.596: [iter 100 : loss : 0.4202 = 0.0050 + 0.4003 + 0.0149, time: 326.984032]
2023-06-11 17:58:44.642: epoch 100:	0.00655090  	0.10484476  	0.04960123  	0.03748735  	0.03791540  
2023-06-11 17:58:44.642: Found a better model.
2023-06-11 17:58:44.643: Save model to file as pretrain.
2023-06-11 18:04:12.730: [iter 101 : loss : 0.4201 = 0.0049 + 0.4003 + 0.0149, time: 322.592445]
2023-06-11 18:05:02.583: epoch 101:	0.00653899  	0.10469756  	0.04956991  	0.03748153  	0.03790529  
2023-06-11 18:10:32.078: [iter 102 : loss : 0.4202 = 0.0050 + 0.4003 + 0.0149, time: 324.948466]
2023-06-11 18:11:20.770: epoch 102:	0.00653787  	0.10466810  	0.04950549  	0.03743014  	0.03784890  
2023-06-11 18:16:57.133: [iter 103 : loss : 0.4201 = 0.0049 + 0.4003 + 0.0149, time: 331.761039]
2023-06-11 18:17:45.460: epoch 103:	0.00653470  	0.10454461  	0.04943774  	0.03737596  	0.03779745  
2023-06-11 18:23:09.988: [iter 104 : loss : 0.4202 = 0.0050 + 0.4003 + 0.0149, time: 319.916867]
2023-06-11 18:23:57.499: epoch 104:	0.00652782  	0.10448622  	0.04945924  	0.03744071  	0.03785330  
2023-06-11 18:29:24.285: [iter 105 : loss : 0.4202 = 0.0050 + 0.4003 + 0.0149, time: 322.216279]
2023-06-11 18:30:15.317: epoch 105:	0.00653936  	0.10463338  	0.04944273  	0.03737565  	0.03778518  
2023-06-11 18:35:48.010: [iter 106 : loss : 0.4202 = 0.0050 + 0.4003 + 0.0149, time: 327.891063]
2023-06-11 18:36:36.188: epoch 106:	0.00654643  	0.10485308  	0.04955017  	0.03746804  	0.03788297  
2023-06-11 18:36:36.188: Found a better model.
2023-06-11 18:36:36.188: Save model to file as pretrain.
2023-06-11 18:42:21.969: [iter 107 : loss : 0.4202 = 0.0050 + 0.4003 + 0.0149, time: 340.195455]
2023-06-11 18:43:11.310: epoch 107:	0.00654345  	0.10468286  	0.04952759  	0.03747996  	0.03790961  
2023-06-11 18:48:57.260: [iter 108 : loss : 0.4202 = 0.0050 + 0.4003 + 0.0149, time: 341.357156]
2023-06-11 18:49:45.719: epoch 108:	0.00654457  	0.10471731  	0.04952488  	0.03746147  	0.03789661  
2023-06-11 18:55:14.478: [iter 109 : loss : 0.4202 = 0.0050 + 0.4003 + 0.0149, time: 324.202288]
2023-06-11 18:56:04.305: epoch 109:	0.00656598  	0.10508985  	0.04968132  	0.03756348  	0.03799823  
2023-06-11 18:56:04.305: Found a better model.
2023-06-11 18:56:04.305: Save model to file as pretrain.
2023-06-11 19:01:56.840: [iter 110 : loss : 0.4201 = 0.0049 + 0.4003 + 0.0149, time: 346.993147]
2023-06-11 19:02:46.666: epoch 110:	0.00657194  	0.10518713  	0.04970104  	0.03755433  	0.03797599  
2023-06-11 19:02:46.666: Found a better model.
2023-06-11 19:02:46.666: Save model to file as pretrain.
2023-06-11 19:08:30.780: [iter 111 : loss : 0.4201 = 0.0049 + 0.4003 + 0.0149, time: 338.507155]
2023-06-11 19:09:20.911: epoch 111:	0.00655128  	0.10483654  	0.04961329  	0.03751407  	0.03794406  
2023-06-11 19:15:01.858: [iter 112 : loss : 0.4201 = 0.0049 + 0.4003 + 0.0149, time: 336.402165]
2023-06-11 19:15:50.274: epoch 112:	0.00655369  	0.10496014  	0.04961822  	0.03748275  	0.03791011  
2023-06-11 19:21:29.766: [iter 113 : loss : 0.4201 = 0.0049 + 0.4003 + 0.0149, time: 334.916046]
2023-06-11 19:22:18.027: epoch 113:	0.00656058  	0.10497413  	0.04963026  	0.03753216  	0.03796541  
2023-06-11 19:27:52.620: [iter 114 : loss : 0.4200 = 0.0049 + 0.4003 + 0.0149, time: 330.019410]
2023-06-11 19:28:41.100: epoch 114:	0.00657138  	0.10511536  	0.04969185  	0.03757758  	0.03800308  
2023-06-11 19:34:21.205: [iter 115 : loss : 0.4201 = 0.0049 + 0.4003 + 0.0149, time: 335.553590]
2023-06-11 19:35:09.983: epoch 115:	0.00655574  	0.10493863  	0.04960074  	0.03745132  	0.03787604  
2023-06-11 19:40:49.365: [iter 116 : loss : 0.4201 = 0.0049 + 0.4003 + 0.0149, time: 334.834499]
2023-06-11 19:41:37.475: epoch 116:	0.00657287  	0.10519452  	0.04973756  	0.03757442  	0.03801344  
2023-06-11 19:41:37.475: Found a better model.
2023-06-11 19:41:37.475: Save model to file as pretrain.
2023-06-11 19:47:17.133: [iter 117 : loss : 0.4201 = 0.0050 + 0.4003 + 0.0149, time: 334.174900]
2023-06-11 19:48:06.396: epoch 117:	0.00657361  	0.10521556  	0.04975531  	0.03759791  	0.03802507  
2023-06-11 19:48:06.397: Found a better model.
2023-06-11 19:48:06.397: Save model to file as pretrain.
2023-06-11 19:53:37.839: [iter 118 : loss : 0.4200 = 0.0048 + 0.4003 + 0.0149, time: 326.017017]
2023-06-11 19:54:26.793: epoch 118:	0.00657752  	0.10532375  	0.04974975  	0.03756455  	0.03798511  
2023-06-11 19:54:26.793: Found a better model.
2023-06-11 19:54:26.793: Save model to file as pretrain.
2023-06-11 20:00:07.097: [iter 119 : loss : 0.4201 = 0.0049 + 0.4003 + 0.0149, time: 334.853067]
2023-06-11 20:00:55.030: epoch 119:	0.00657789  	0.10529143  	0.04979812  	0.03762672  	0.03805196  
2023-06-11 20:06:31.684: [iter 120 : loss : 0.4200 = 0.0049 + 0.4003 + 0.0149, time: 332.162256]
2023-06-11 20:07:20.106: epoch 120:	0.00659000  	0.10553952  	0.04980471  	0.03757118  	0.03800181  
2023-06-11 20:07:20.107: Found a better model.
2023-06-11 20:07:20.107: Save model to file as pretrain.
2023-06-11 20:12:54.631: [iter 121 : loss : 0.4200 = 0.0049 + 0.4003 + 0.0149, time: 329.027211]
2023-06-11 20:13:43.689: epoch 121:	0.00659260  	0.10550668  	0.04976879  	0.03751427  	0.03793356  
2023-06-11 20:19:06.598: [iter 122 : loss : 0.4200 = 0.0049 + 0.4003 + 0.0149, time: 318.366348]
2023-06-11 20:19:57.107: epoch 122:	0.00658683  	0.10542808  	0.04977278  	0.03754499  	0.03797274  
2023-06-11 20:25:28.902: [iter 123 : loss : 0.4201 = 0.0049 + 0.4003 + 0.0149, time: 327.238786]
2023-06-11 20:26:16.891: epoch 123:	0.00659837  	0.10564066  	0.04981370  	0.03753747  	0.03795319  
2023-06-11 20:26:16.891: Found a better model.
2023-06-11 20:26:16.891: Save model to file as pretrain.
2023-06-11 20:32:04.503: [iter 124 : loss : 0.4200 = 0.0048 + 0.4003 + 0.0149, time: 342.129012]
2023-06-11 20:32:52.807: epoch 124:	0.00658719  	0.10551319  	0.04981345  	0.03759791  	0.03801797  
2023-06-11 20:38:17.814: [iter 125 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0149, time: 320.480985]
2023-06-11 20:39:06.176: epoch 125:	0.00657473  	0.10534258  	0.04977212  	0.03756414  	0.03799007  
2023-06-11 20:44:35.968: [iter 126 : loss : 0.4200 = 0.0049 + 0.4003 + 0.0149, time: 325.226674]
2023-06-11 20:45:24.981: epoch 126:	0.00659576  	0.10562152  	0.04980233  	0.03754313  	0.03796145  
2023-06-11 20:50:59.565: [iter 127 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0148, time: 330.007712]
2023-06-11 20:51:49.172: epoch 127:	0.00659743  	0.10556938  	0.04985353  	0.03762449  	0.03804874  
2023-06-11 20:57:19.549: [iter 128 : loss : 0.4200 = 0.0049 + 0.4003 + 0.0148, time: 325.786682]
2023-06-11 20:58:08.783: epoch 128:	0.00660339  	0.10563512  	0.04989075  	0.03766648  	0.03809429  
2023-06-11 21:03:46.538: [iter 129 : loss : 0.4200 = 0.0048 + 0.4003 + 0.0148, time: 333.174976]
2023-06-11 21:04:35.975: epoch 129:	0.00659557  	0.10554298  	0.04990465  	0.03769584  	0.03811903  
2023-06-11 21:09:57.455: [iter 130 : loss : 0.4200 = 0.0049 + 0.4003 + 0.0148, time: 316.790206]
2023-06-11 21:10:46.641: epoch 130:	0.00659762  	0.10559475  	0.04998740  	0.03779393  	0.03823126  
2023-06-11 21:16:24.514: [iter 131 : loss : 0.4200 = 0.0049 + 0.4003 + 0.0148, time: 333.280006]
2023-06-11 21:17:16.616: epoch 131:	0.00659073  	0.10552528  	0.04993447  	0.03776587  	0.03821226  
2023-06-11 21:22:53.163: [iter 132 : loss : 0.4200 = 0.0048 + 0.4003 + 0.0148, time: 331.681968]
2023-06-11 21:23:40.836: epoch 132:	0.00660395  	0.10567050  	0.04995345  	0.03774827  	0.03818630  
2023-06-11 21:23:40.836: Found a better model.
2023-06-11 21:23:40.836: Save model to file as pretrain.
2023-06-11 21:29:09.892: [iter 133 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0148, time: 323.398541]
2023-06-11 21:29:56.690: epoch 133:	0.00660991  	0.10576688  	0.04999670  	0.03777661  	0.03822247  
2023-06-11 21:29:56.690: Found a better model.
2023-06-11 21:29:56.690: Save model to file as pretrain.
2023-06-11 21:35:28.448: [iter 134 : loss : 0.4200 = 0.0049 + 0.4003 + 0.0148, time: 326.072866]
2023-06-11 21:36:16.680: epoch 134:	0.00660674  	0.10571416  	0.04993080  	0.03767459  	0.03812491  
2023-06-11 21:42:04.525: [iter 135 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0148, time: 343.187179]
2023-06-11 21:42:54.066: epoch 135:	0.00661568  	0.10587669  	0.04998777  	0.03769454  	0.03812867  
2023-06-11 21:42:54.067: Found a better model.
2023-06-11 21:42:54.067: Save model to file as pretrain.
2023-06-11 21:48:27.139: [iter 136 : loss : 0.4200 = 0.0049 + 0.4003 + 0.0148, time: 327.382670]
2023-06-11 21:49:15.760: epoch 136:	0.00662350  	0.10612496  	0.05010002  	0.03781052  	0.03823400  
2023-06-11 21:49:15.760: Found a better model.
2023-06-11 21:49:15.760: Save model to file as pretrain.
2023-06-11 21:54:52.376: [iter 137 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0148, time: 330.995947]
2023-06-11 21:55:41.498: epoch 137:	0.00660042  	0.10570816  	0.04997304  	0.03777508  	0.03820378  
2023-06-11 22:01:23.843: [iter 138 : loss : 0.4200 = 0.0049 + 0.4003 + 0.0148, time: 337.641321]
2023-06-11 22:02:11.230: epoch 138:	0.00661270  	0.10590966  	0.05010238  	0.03788730  	0.03832164  
2023-06-11 22:07:47.369: [iter 139 : loss : 0.4200 = 0.0048 + 0.4003 + 0.0148, time: 331.473195]
2023-06-11 22:08:35.088: epoch 139:	0.00661661  	0.10606733  	0.05014680  	0.03790553  	0.03834042  
2023-06-11 22:14:04.178: [iter 140 : loss : 0.4200 = 0.0049 + 0.4003 + 0.0148, time: 324.433899]
2023-06-11 22:14:52.758: epoch 140:	0.00663169  	0.10618949  	0.05023041  	0.03795497  	0.03840052  
2023-06-11 22:14:52.761: Found a better model.
2023-06-11 22:14:52.761: Save model to file as pretrain.
2023-06-11 22:20:29.497: [iter 141 : loss : 0.4200 = 0.0049 + 0.4003 + 0.0148, time: 331.132972]
2023-06-11 22:21:18.120: epoch 141:	0.00661903  	0.10600024  	0.05013536  	0.03786065  	0.03828981  
2023-06-11 22:26:46.215: [iter 142 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0148, time: 323.449980]
2023-06-11 22:27:35.460: epoch 142:	0.00661773  	0.10602774  	0.05012005  	0.03785426  	0.03829184  
2023-06-11 22:33:08.984: [iter 143 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0148, time: 328.914957]
2023-06-11 22:33:57.787: epoch 143:	0.00662462  	0.10609861  	0.05009767  	0.03782046  	0.03823094  
2023-06-11 22:39:34.256: [iter 144 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0148, time: 331.912334]
2023-06-11 22:40:22.733: epoch 144:	0.00661512  	0.10594913  	0.05012806  	0.03789745  	0.03831841  
2023-06-11 22:45:51.038: [iter 145 : loss : 0.4200 = 0.0049 + 0.4003 + 0.0148, time: 323.752836]
2023-06-11 22:46:39.906: epoch 145:	0.00661345  	0.10587611  	0.05010890  	0.03785026  	0.03828415  
2023-06-11 22:52:07.086: [iter 146 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0148, time: 322.647796]
2023-06-11 22:52:55.862: epoch 146:	0.00660935  	0.10575627  	0.05006544  	0.03782657  	0.03826052  
2023-06-11 22:58:25.147: [iter 147 : loss : 0.4200 = 0.0049 + 0.4003 + 0.0148, time: 324.747828]
2023-06-11 22:59:14.171: epoch 147:	0.00662313  	0.10602090  	0.05013861  	0.03786184  	0.03830465  
2023-06-11 23:04:41.143: [iter 148 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0148, time: 322.412041]
2023-06-11 23:05:30.468: epoch 148:	0.00663113  	0.10611447  	0.05013575  	0.03784069  	0.03828428  
2023-06-11 23:10:57.327: [iter 149 : loss : 0.4200 = 0.0048 + 0.4003 + 0.0148, time: 321.891240]
2023-06-11 23:11:45.167: epoch 149:	0.00662797  	0.10608104  	0.05018599  	0.03792545  	0.03835411  
2023-06-11 23:17:19.390: [iter 150 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0148, time: 329.705866]
2023-06-11 23:18:07.392: epoch 150:	0.00662424  	0.10603284  	0.05021676  	0.03798137  	0.03841021  
2023-06-11 23:23:43.164: [iter 151 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0148, time: 331.237510]
2023-06-11 23:24:30.977: epoch 151:	0.00663355  	0.10618217  	0.05024831  	0.03798520  	0.03841297  
2023-06-11 23:30:04.081: [iter 152 : loss : 0.4198 = 0.0047 + 0.4003 + 0.0148, time: 328.599658]
2023-06-11 23:30:52.016: epoch 152:	0.00663579  	0.10626905  	0.05027999  	0.03798331  	0.03841047  
2023-06-11 23:30:52.016: Found a better model.
2023-06-11 23:30:52.016: Save model to file as pretrain.
2023-06-11 23:36:22.279: [iter 153 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0148, time: 324.694690]
2023-06-11 23:37:10.408: epoch 153:	0.00664751  	0.10646279  	0.05030547  	0.03801576  	0.03842938  
2023-06-11 23:37:10.408: Found a better model.
2023-06-11 23:37:10.408: Save model to file as pretrain.
2023-06-11 23:42:43.824: [iter 154 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0148, time: 327.409542]
2023-06-11 23:43:33.615: epoch 154:	0.00665608  	0.10659800  	0.05040752  	0.03809948  	0.03851589  
2023-06-11 23:43:33.615: Found a better model.
2023-06-11 23:43:33.615: Save model to file as pretrain.
2023-06-11 23:49:14.119: [iter 155 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0148, time: 334.981098]
2023-06-11 23:50:03.573: epoch 155:	0.00666930  	0.10677905  	0.05034855  	0.03795480  	0.03837144  
2023-06-11 23:50:03.573: Found a better model.
2023-06-11 23:50:03.573: Save model to file as pretrain.
2023-06-11 23:56:23.125: [iter 156 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0148, time: 374.016603]
2023-06-11 23:57:12.710: epoch 156:	0.00666334  	0.10669351  	0.05036161  	0.03801645  	0.03844843  
2023-06-12 00:03:00.941: [iter 157 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0148, time: 343.510370]
2023-06-12 00:03:54.536: epoch 157:	0.00665999  	0.10668997  	0.05041307  	0.03807878  	0.03849434  
2023-06-12 00:09:22.893: [iter 158 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0148, time: 323.576260]
2023-06-12 00:10:12.882: epoch 158:	0.00667264  	0.10688579  	0.05039639  	0.03797109  	0.03839039  
2023-06-12 00:10:12.882: Found a better model.
2023-06-12 00:10:12.882: Save model to file as pretrain.
2023-06-12 00:15:54.516: [iter 159 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0148, time: 335.556562]
2023-06-12 00:16:43.167: epoch 159:	0.00665999  	0.10672186  	0.05041604  	0.03806062  	0.03847679  
2023-06-12 00:23:16.808: [iter 160 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0148, time: 389.054597]
2023-06-12 00:24:05.756: epoch 160:	0.00667041  	0.10685778  	0.05039625  	0.03802606  	0.03845229  
2023-06-12 00:30:34.953: [iter 161 : loss : 0.4198 = 0.0047 + 0.4003 + 0.0148, time: 384.640966]
2023-06-12 00:31:23.762: epoch 161:	0.00666668  	0.10683262  	0.05036312  	0.03798120  	0.03842478  
2023-06-12 00:37:14.330: [iter 162 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0148, time: 345.987253]
2023-06-12 00:38:02.363: epoch 162:	0.00667599  	0.10688277  	0.05046485  	0.03810102  	0.03855377  
2023-06-12 00:44:30.985: [iter 163 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0148, time: 383.992310]
2023-06-12 00:45:20.422: epoch 163:	0.00666686  	0.10664898  	0.05037325  	0.03799671  	0.03845577  
2023-06-12 00:51:12.661: [iter 164 : loss : 0.4198 = 0.0047 + 0.4003 + 0.0148, time: 347.657467]
2023-06-12 00:52:01.315: epoch 164:	0.00666147  	0.10652623  	0.05028569  	0.03791919  	0.03837381  
2023-06-12 00:57:18.744: [iter 165 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0148, time: 312.786655]
2023-06-12 00:58:08.437: epoch 165:	0.00666687  	0.10668787  	0.05035672  	0.03797987  	0.03842254  
2023-06-12 01:03:37.593: [iter 166 : loss : 0.4198 = 0.0048 + 0.4003 + 0.0148, time: 324.575719]
2023-06-12 01:04:25.777: epoch 166:	0.00666352  	0.10665320  	0.05035052  	0.03800471  	0.03845188  
2023-06-12 01:09:26.978: [iter 167 : loss : 0.4198 = 0.0048 + 0.4003 + 0.0148, time: 296.636948]
2023-06-12 01:10:16.600: epoch 167:	0.00667227  	0.10671779  	0.05043686  	0.03810894  	0.03854630  
2023-06-12 01:15:49.886: [iter 168 : loss : 0.4198 = 0.0047 + 0.4003 + 0.0148, time: 328.711431]
2023-06-12 01:16:37.630: epoch 168:	0.00667786  	0.10684232  	0.05041972  	0.03805187  	0.03848377  
2023-06-12 01:22:02.545: [iter 169 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0148, time: 320.322241]
2023-06-12 01:22:51.281: epoch 169:	0.00667711  	0.10690001  	0.05045422  	0.03808177  	0.03850289  
2023-06-12 01:22:51.281: Found a better model.
2023-06-12 01:22:51.281: Save model to file as pretrain.
2023-06-12 01:28:22.341: [iter 170 : loss : 0.4198 = 0.0047 + 0.4003 + 0.0148, time: 325.511472]
2023-06-12 01:29:11.632: epoch 170:	0.00667227  	0.10679438  	0.05045949  	0.03810996  	0.03853950  
2023-06-12 01:34:24.623: [iter 171 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0148, time: 308.467454]
2023-06-12 01:35:12.516: epoch 171:	0.00668567  	0.10705516  	0.05051417  	0.03810669  	0.03854078  
2023-06-12 01:35:12.516: Found a better model.
2023-06-12 01:35:12.516: Save model to file as pretrain.
2023-06-12 01:40:51.180: [iter 172 : loss : 0.4198 = 0.0048 + 0.4003 + 0.0148, time: 333.121975]
2023-06-12 01:41:39.505: epoch 172:	0.00669144  	0.10716696  	0.05050844  	0.03807915  	0.03850861  
2023-06-12 01:41:39.506: Found a better model.
2023-06-12 01:41:39.506: Save model to file as pretrain.
2023-06-12 01:47:13.729: [iter 173 : loss : 0.4198 = 0.0048 + 0.4003 + 0.0148, time: 328.720254]
2023-06-12 01:48:01.930: epoch 173:	0.00668865  	0.10708900  	0.05038705  	0.03790523  	0.03834209  
2023-06-12 01:53:31.789: [iter 174 : loss : 0.4198 = 0.0048 + 0.4003 + 0.0148, time: 325.303091]
2023-06-12 01:54:19.740: epoch 174:	0.00668883  	0.10709344  	0.05038603  	0.03790274  	0.03834718  
2023-06-12 01:59:41.601: [iter 175 : loss : 0.4198 = 0.0048 + 0.4003 + 0.0148, time: 317.276415]
2023-06-12 02:00:31.278: epoch 175:	0.00669256  	0.10713803  	0.05044571  	0.03795888  	0.03840017  
2023-06-12 02:05:54.467: [iter 176 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0148, time: 318.698210]
2023-06-12 02:06:42.128: epoch 176:	0.00668157  	0.10696834  	0.05048294  	0.03807591  	0.03850387  
2023-06-12 02:12:12.649: [iter 177 : loss : 0.4198 = 0.0047 + 0.4003 + 0.0148, time: 325.899302]
2023-06-12 02:13:01.560: epoch 177:	0.00669200  	0.10707014  	0.05053643  	0.03810529  	0.03855016  
2023-06-12 02:18:26.213: [iter 178 : loss : 0.4198 = 0.0047 + 0.4003 + 0.0148, time: 320.144200]
2023-06-12 02:19:14.841: epoch 178:	0.00670056  	0.10714810  	0.05060686  	0.03818201  	0.03863063  
2023-06-12 02:24:38.973: [iter 179 : loss : 0.4198 = 0.0047 + 0.4003 + 0.0148, time: 319.563427]
2023-06-12 02:25:27.402: epoch 179:	0.00668735  	0.10703642  	0.05057979  	0.03818156  	0.03862319  
2023-06-12 02:31:05.772: [iter 180 : loss : 0.4198 = 0.0048 + 0.4003 + 0.0148, time: 333.830809]
2023-06-12 02:31:55.332: epoch 180:	0.00668753  	0.10705373  	0.05056357  	0.03817178  	0.03860597  
2023-06-12 02:37:20.857: [iter 181 : loss : 0.4198 = 0.0047 + 0.4003 + 0.0148, time: 320.913352]
2023-06-12 02:38:09.644: epoch 181:	0.00669163  	0.10720348  	0.05059336  	0.03815881  	0.03859384  
2023-06-12 02:38:09.644: Found a better model.
2023-06-12 02:38:09.644: Save model to file as pretrain.
2023-06-12 02:43:39.975: [iter 182 : loss : 0.4198 = 0.0047 + 0.4003 + 0.0148, time: 324.871315]
2023-06-12 02:44:27.932: epoch 182:	0.00668307  	0.10704360  	0.05050224  	0.03808436  	0.03851958  
2023-06-12 02:50:30.055: [iter 183 : loss : 0.4198 = 0.0048 + 0.4003 + 0.0148, time: 357.552628]
2023-06-12 02:51:18.051: epoch 183:	0.00669516  	0.10712771  	0.05058475  	0.03814651  	0.03859262  
2023-06-12 02:56:50.166: [iter 184 : loss : 0.4198 = 0.0048 + 0.4003 + 0.0148, time: 327.502398]
2023-06-12 02:57:39.573: epoch 184:	0.00669796  	0.10710110  	0.05061496  	0.03820927  	0.03864950  
2023-06-12 03:03:25.832: [iter 185 : loss : 0.4198 = 0.0047 + 0.4003 + 0.0148, time: 341.695819]
2023-06-12 03:04:15.708: epoch 185:	0.00669349  	0.10715842  	0.05062281  	0.03819835  	0.03864137  
2023-06-12 03:09:47.299: [iter 186 : loss : 0.4198 = 0.0048 + 0.4003 + 0.0148, time: 326.970616]
2023-06-12 03:10:36.528: epoch 186:	0.00668716  	0.10701808  	0.05060198  	0.03820008  	0.03864141  
2023-06-12 03:16:02.768: [iter 187 : loss : 0.4198 = 0.0047 + 0.4003 + 0.0148, time: 321.422953]
2023-06-12 03:16:50.759: epoch 187:	0.00669311  	0.10704232  	0.05056879  	0.03814730  	0.03859258  
2023-06-12 03:22:27.664: [iter 188 : loss : 0.4198 = 0.0047 + 0.4003 + 0.0148, time: 332.306997]
2023-06-12 03:23:17.138: epoch 188:	0.00668995  	0.10699266  	0.05062433  	0.03823758  	0.03868449  
2023-06-12 03:28:49.020: [iter 189 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0148, time: 327.229986]
2023-06-12 03:29:39.392: epoch 189:	0.00669479  	0.10708441  	0.05059269  	0.03816175  	0.03862005  
2023-06-12 03:35:22.354: [iter 190 : loss : 0.4198 = 0.0047 + 0.4003 + 0.0148, time: 338.320112]
2023-06-12 03:36:12.269: epoch 190:	0.00669945  	0.10708120  	0.05063975  	0.03824426  	0.03869015  
2023-06-12 03:41:43.824: [iter 191 : loss : 0.4198 = 0.0047 + 0.4003 + 0.0148, time: 326.878242]
2023-06-12 03:42:32.190: epoch 191:	0.00670597  	0.10720185  	0.05067088  	0.03825488  	0.03870434  
2023-06-12 03:48:04.130: [iter 192 : loss : 0.4198 = 0.0047 + 0.4003 + 0.0148, time: 327.258771]
2023-06-12 03:48:54.355: epoch 192:	0.00671564  	0.10737223  	0.05069125  	0.03824149  	0.03867314  
2023-06-12 03:48:54.355: Found a better model.
2023-06-12 03:48:54.355: Save model to file as pretrain.
2023-06-12 03:54:27.591: [iter 193 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0148, time: 326.610609]
2023-06-12 03:55:16.385: epoch 193:	0.00670690  	0.10715389  	0.05060027  	0.03816388  	0.03860207  
2023-06-12 04:00:57.906: [iter 194 : loss : 0.4198 = 0.0047 + 0.4003 + 0.0148, time: 336.788644]
2023-06-12 04:01:47.184: epoch 194:	0.00669349  	0.10695282  	0.05055105  	0.03816867  	0.03859659  
2023-06-12 04:07:27.276: [iter 195 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0148, time: 335.456908]
2023-06-12 04:08:15.344: epoch 195:	0.00669554  	0.10703468  	0.05057599  	0.03818584  	0.03862176  
2023-06-12 04:13:40.317: [iter 196 : loss : 0.4198 = 0.0048 + 0.4003 + 0.0148, time: 320.298970]
2023-06-12 04:14:29.561: epoch 196:	0.00670373  	0.10713337  	0.05063296  	0.03822484  	0.03865117  
2023-06-12 04:19:40.942: [iter 197 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0148, time: 306.734752]
2023-06-12 04:20:30.610: epoch 197:	0.00671136  	0.10731477  	0.05063657  	0.03819607  	0.03862867  
2023-06-12 04:26:01.044: [iter 198 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0148, time: 325.767287]
2023-06-12 04:26:49.749: epoch 198:	0.00671229  	0.10733982  	0.05072759  	0.03831103  	0.03874560  
2023-06-12 04:32:26.537: [iter 199 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0148, time: 332.131640]
2023-06-12 04:33:15.107: epoch 199:	0.00670838  	0.10732583  	0.05074384  	0.03836802  	0.03879486  
2023-06-12 04:38:56.199: [iter 200 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0148, time: 336.432543]
2023-06-12 04:39:45.431: epoch 200:	0.00672122  	0.10750426  	0.05076422  	0.03832158  	0.03875452  
2023-06-12 04:39:45.434: Found a better model.
2023-06-12 04:39:45.434: Save model to file as pretrain.
2023-06-12 04:45:19.474: [iter 201 : loss : 0.4198 = 0.0048 + 0.4003 + 0.0148, time: 325.274648]
2023-06-12 04:46:08.900: epoch 201:	0.00671974  	0.10748544  	0.05074775  	0.03830411  	0.03874871  
2023-06-12 04:51:47.327: [iter 202 : loss : 0.4198 = 0.0047 + 0.4003 + 0.0148, time: 333.807790]
2023-06-12 04:52:36.120: epoch 202:	0.00672476  	0.10754555  	0.05078239  	0.03830915  	0.03875947  
2023-06-12 04:52:36.120: Found a better model.
2023-06-12 04:52:36.120: Save model to file as pretrain.
2023-06-12 04:58:01.504: [iter 203 : loss : 0.4198 = 0.0047 + 0.4003 + 0.0148, time: 316.587601]
2023-06-12 04:58:50.865: epoch 203:	0.00673202  	0.10772444  	0.05086254  	0.03836978  	0.03881890  
2023-06-12 04:58:50.865: Found a better model.
2023-06-12 04:58:50.865: Save model to file as pretrain.
2023-06-12 05:04:31.774: [iter 204 : loss : 0.4197 = 0.0046 + 0.4003 + 0.0148, time: 332.147765]
2023-06-12 05:05:20.221: epoch 204:	0.00672774  	0.10764063  	0.05084230  	0.03837092  	0.03881979  
2023-06-12 05:10:56.468: [iter 205 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0148, time: 331.690269]
2023-06-12 05:11:43.844: epoch 205:	0.00672700  	0.10767641  	0.05085664  	0.03838367  	0.03882781  
2023-06-12 05:17:15.295: [iter 206 : loss : 0.4197 = 0.0046 + 0.4003 + 0.0148, time: 326.827456]
2023-06-12 05:18:04.144: epoch 206:	0.00672476  	0.10758559  	0.05081036  	0.03833351  	0.03879607  
2023-06-12 05:23:34.168: [iter 207 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0148, time: 325.468060]
2023-06-12 05:24:22.873: epoch 207:	0.00673482  	0.10772604  	0.05088002  	0.03840505  	0.03884786  
2023-06-12 05:24:22.874: Found a better model.
2023-06-12 05:24:22.874: Save model to file as pretrain.
2023-06-12 05:30:08.369: [iter 208 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0148, time: 336.642701]
2023-06-12 05:30:58.005: epoch 208:	0.00671899  	0.10741186  	0.05071170  	0.03822929  	0.03869455  
2023-06-12 05:36:29.688: [iter 209 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0148, time: 326.851170]
2023-06-12 05:37:17.638: epoch 209:	0.00673425  	0.10773434  	0.05086413  	0.03835276  	0.03880705  
2023-06-12 05:37:17.638: Found a better model.
2023-06-12 05:37:17.638: Save model to file as pretrain.
2023-06-12 05:42:47.499: [iter 210 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0148, time: 321.138497]
2023-06-12 05:43:37.429: epoch 210:	0.00673369  	0.10769668  	0.05084432  	0.03835166  	0.03881132  
2023-06-12 05:49:16.397: [iter 211 : loss : 0.4198 = 0.0047 + 0.4003 + 0.0148, time: 334.439718]
2023-06-12 05:50:04.235: epoch 211:	0.00673220  	0.10767397  	0.05083900  	0.03834616  	0.03881424  
2023-06-12 05:55:38.636: [iter 212 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0148, time: 329.849447]
2023-06-12 05:56:28.032: epoch 212:	0.00673555  	0.10764805  	0.05083809  	0.03836162  	0.03882191  
2023-06-12 06:02:02.617: [iter 213 : loss : 0.4198 = 0.0048 + 0.4003 + 0.0148, time: 330.027043]
2023-06-12 06:02:51.830: epoch 213:	0.00672345  	0.10753722  	0.05077101  	0.03829475  	0.03875717  
2023-06-12 06:08:24.022: [iter 214 : loss : 0.4198 = 0.0047 + 0.4003 + 0.0148, time: 327.605792]
2023-06-12 06:09:12.526: epoch 214:	0.00670373  	0.10729972  	0.05067519  	0.03822146  	0.03867491  
2023-06-12 06:14:28.663: [iter 215 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0148, time: 311.573079]
2023-06-12 06:15:15.647: epoch 215:	0.00672271  	0.10759117  	0.05081424  	0.03833640  	0.03879549  
2023-06-12 06:20:40.547: [iter 216 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0148, time: 320.321846]
2023-06-12 06:21:29.009: epoch 216:	0.00672178  	0.10755929  	0.05094607  	0.03854996  	0.03899422  
2023-06-12 06:27:06.487: [iter 217 : loss : 0.4198 = 0.0048 + 0.4003 + 0.0148, time: 332.917533]
2023-06-12 06:27:55.466: epoch 217:	0.00672978  	0.10769875  	0.05092075  	0.03844713  	0.03889028  
2023-06-12 06:33:36.361: [iter 218 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0148, time: 336.280380]
2023-06-12 06:34:24.973: epoch 218:	0.00673462  	0.10764018  	0.05091886  	0.03845243  	0.03890145  
2023-06-12 06:39:50.617: [iter 219 : loss : 0.4197 = 0.0047 + 0.4002 + 0.0148, time: 321.031843]
2023-06-12 06:40:39.448: epoch 219:	0.00674319  	0.10788579  	0.05100968  	0.03851771  	0.03894925  
2023-06-12 06:40:39.448: Found a better model.
2023-06-12 06:40:39.448: Save model to file as pretrain.
2023-06-12 06:46:17.276: [iter 220 : loss : 0.4196 = 0.0046 + 0.4003 + 0.0148, time: 328.834312]
2023-06-12 06:47:06.432: epoch 220:	0.00673760  	0.10783814  	0.05091052  	0.03838993  	0.03882859  
2023-06-12 06:52:34.217: [iter 221 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0148, time: 323.194464]
2023-06-12 06:53:22.665: epoch 221:	0.00673220  	0.10774697  	0.05085562  	0.03833290  	0.03878339  
2023-06-12 06:58:55.185: [iter 222 : loss : 0.4198 = 0.0047 + 0.4003 + 0.0148, time: 327.924539]
2023-06-12 06:59:43.427: epoch 222:	0.00673089  	0.10763524  	0.05087830  	0.03839306  	0.03883807  
2023-06-12 07:05:20.692: [iter 223 : loss : 0.4198 = 0.0048 + 0.4003 + 0.0148, time: 332.675718]
2023-06-12 07:06:09.492: epoch 223:	0.00671675  	0.10750467  	0.05082925  	0.03836908  	0.03880518  
2023-06-12 07:11:35.051: [iter 224 : loss : 0.4196 = 0.0046 + 0.4003 + 0.0148, time: 320.976357]
2023-06-12 07:12:24.210: epoch 224:	0.00672103  	0.10753498  	0.05082252  	0.03836285  	0.03880759  
2023-06-12 07:17:51.134: [iter 225 : loss : 0.4198 = 0.0048 + 0.4003 + 0.0147, time: 322.310580]
2023-06-12 07:18:40.602: epoch 225:	0.00673091  	0.10767242  	0.05089274  	0.03842214  	0.03887150  
2023-06-12 07:24:13.489: [iter 226 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0148, time: 328.202056]
2023-06-12 07:25:01.510: epoch 226:	0.00673406  	0.10778430  	0.05093662  	0.03844433  	0.03889865  
2023-06-12 07:30:26.687: [iter 227 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0148, time: 320.546574]
2023-06-12 07:31:14.913: epoch 227:	0.00674133  	0.10784297  	0.05090841  	0.03839868  	0.03885140  
2023-06-12 07:36:47.493: [iter 228 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0148, time: 327.897723]
2023-06-12 07:37:37.168: epoch 228:	0.00673239  	0.10770770  	0.05091462  	0.03842505  	0.03887843  
2023-06-12 07:43:19.246: [iter 229 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0148, time: 337.513652]
2023-06-12 07:44:08.816: epoch 229:	0.00673239  	0.10769621  	0.05093358  	0.03846290  	0.03891281  
2023-06-12 07:49:47.166: [iter 230 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0148, time: 333.789091]
2023-06-12 07:50:34.465: epoch 230:	0.00673946  	0.10777983  	0.05091047  	0.03840711  	0.03885929  
2023-06-12 07:56:14.325: [iter 231 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 335.272830]
2023-06-12 07:57:01.656: epoch 231:	0.00673369  	0.10763378  	0.05095451  	0.03851919  	0.03897108  
2023-06-12 08:02:30.662: [iter 232 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 324.375971]
2023-06-12 08:03:18.667: epoch 232:	0.00673388  	0.10776698  	0.05097589  	0.03850542  	0.03896901  
2023-06-12 08:08:44.833: [iter 233 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0148, time: 321.628634]
2023-06-12 08:09:35.014: epoch 233:	0.00673406  	0.10767227  	0.05091705  	0.03846044  	0.03890895  
2023-06-12 08:14:58.862: [iter 234 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0148, time: 319.260869]
2023-06-12 08:15:48.926: epoch 234:	0.00674876  	0.10790545  	0.05097765  	0.03847353  	0.03895051  
2023-06-12 08:15:48.926: Found a better model.
2023-06-12 08:15:48.926: Save model to file as pretrain.
2023-06-12 08:21:35.370: [iter 235 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 340.660678]
2023-06-12 08:22:24.421: epoch 235:	0.00675453  	0.10796945  	0.05103612  	0.03852148  	0.03900184  
2023-06-12 08:22:24.421: Found a better model.
2023-06-12 08:22:24.421: Save model to file as pretrain.
2023-06-12 08:28:05.770: [iter 236 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 335.793597]
2023-06-12 08:28:55.610: epoch 236:	0.00675099  	0.10788629  	0.05105416  	0.03856817  	0.03905577  
2023-06-12 08:34:31.577: [iter 237 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 331.374408]
2023-06-12 08:35:20.391: epoch 237:	0.00675547  	0.10796548  	0.05108547  	0.03857419  	0.03905955  
2023-06-12 08:40:51.339: [iter 238 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 326.362497]
2023-06-12 08:41:39.859: epoch 238:	0.00674634  	0.10786878  	0.05104170  	0.03855468  	0.03902908  
2023-06-12 08:47:12.002: [iter 239 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 327.550623]
2023-06-12 08:48:00.777: epoch 239:	0.00675863  	0.10799436  	0.05117771  	0.03870875  	0.03918751  
2023-06-12 08:48:00.777: Found a better model.
2023-06-12 08:48:00.777: Save model to file as pretrain.
2023-06-12 08:53:43.828: [iter 240 : loss : 0.4198 = 0.0048 + 0.4003 + 0.0148, time: 337.492434]
2023-06-12 08:54:32.027: epoch 240:	0.00675994  	0.10804121  	0.05115233  	0.03866367  	0.03914533  
2023-06-12 08:54:32.027: Found a better model.
2023-06-12 08:54:32.027: Save model to file as pretrain.
2023-06-12 08:59:59.789: [iter 241 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 322.130294]
2023-06-12 09:00:48.542: epoch 241:	0.00675938  	0.10807526  	0.05115421  	0.03863060  	0.03911456  
2023-06-12 09:00:48.542: Found a better model.
2023-06-12 09:00:48.542: Save model to file as pretrain.
2023-06-12 09:06:21.611: [iter 242 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 327.479089]
2023-06-12 09:07:10.293: epoch 242:	0.00676143  	0.10815060  	0.05120514  	0.03870309  	0.03917229  
2023-06-12 09:07:10.293: Found a better model.
2023-06-12 09:07:10.293: Save model to file as pretrain.
2023-06-12 09:12:45.144: [iter 243 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 328.175490]
2023-06-12 09:13:32.779: epoch 243:	0.00676199  	0.10817377  	0.05117465  	0.03864988  	0.03911793  
2023-06-12 09:13:32.779: Found a better model.
2023-06-12 09:13:32.779: Save model to file as pretrain.
2023-06-12 09:19:13.629: [iter 244 : loss : 0.4196 = 0.0046 + 0.4003 + 0.0148, time: 332.150349]
2023-06-12 09:20:02.341: epoch 244:	0.00675417  	0.10811616  	0.05118547  	0.03867121  	0.03913179  
2023-06-12 09:25:33.124: [iter 245 : loss : 0.4196 = 0.0046 + 0.4003 + 0.0147, time: 326.110106]
2023-06-12 09:26:22.461: epoch 245:	0.00677091  	0.10835289  	0.05124060  	0.03868383  	0.03915224  
2023-06-12 09:26:22.461: Found a better model.
2023-06-12 09:26:22.461: Save model to file as pretrain.
2023-06-12 09:31:59.624: [iter 246 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0148, time: 328.552762]
2023-06-12 09:32:48.231: epoch 246:	0.00677092  	0.10839544  	0.05119199  	0.03859109  	0.03905531  
2023-06-12 09:32:48.231: Found a better model.
2023-06-12 09:32:48.231: Save model to file as pretrain.
2023-06-12 09:38:27.315: [iter 247 : loss : 0.4196 = 0.0046 + 0.4003 + 0.0147, time: 330.345199]
2023-06-12 09:39:15.224: epoch 247:	0.00677874  	0.10852023  	0.05127661  	0.03865963  	0.03913875  
2023-06-12 09:39:15.224: Found a better model.
2023-06-12 09:39:15.224: Save model to file as pretrain.
2023-06-12 09:45:01.332: [iter 248 : loss : 0.4196 = 0.0046 + 0.4003 + 0.0147, time: 337.289349]
2023-06-12 09:45:49.233: epoch 248:	0.00676664  	0.10833412  	0.05114205  	0.03854859  	0.03903042  
2023-06-12 09:51:22.499: [iter 249 : loss : 0.4196 = 0.0046 + 0.4003 + 0.0147, time: 328.589746]
2023-06-12 09:52:11.126: epoch 249:	0.00676851  	0.10836387  	0.05121638  	0.03865384  	0.03911215  
2023-06-12 09:57:55.590: [iter 250 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 339.780609]
2023-06-12 09:58:44.999: epoch 250:	0.00675063  	0.10809299  	0.05105451  	0.03851962  	0.03897086  
2023-06-12 10:04:12.765: [iter 251 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0148, time: 323.106989]
2023-06-12 10:05:02.559: epoch 251:	0.00675007  	0.10810822  	0.05110098  	0.03857264  	0.03904413  
2023-06-12 10:10:25.136: [iter 252 : loss : 0.4196 = 0.0046 + 0.4003 + 0.0147, time: 317.921082]
2023-06-12 10:11:14.179: epoch 252:	0.00674375  	0.10792910  	0.05106464  	0.03855142  	0.03901460  
2023-06-12 10:16:43.050: [iter 253 : loss : 0.4196 = 0.0046 + 0.4003 + 0.0147, time: 324.230529]
2023-06-12 10:17:32.875: epoch 253:	0.00676012  	0.10814695  	0.05117081  	0.03863086  	0.03908204  
2023-06-12 10:22:59.315: [iter 254 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 321.765268]
2023-06-12 10:23:47.964: epoch 254:	0.00676311  	0.10826568  	0.05122611  	0.03868891  	0.03913928  
2023-06-12 10:29:09.831: [iter 255 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 317.187646]
2023-06-12 10:29:59.833: epoch 255:	0.00676943  	0.10834709  	0.05120971  	0.03860742  	0.03906330  
2023-06-12 10:35:30.959: [iter 256 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 326.511521]
2023-06-12 10:36:19.879: epoch 256:	0.00675920  	0.10819373  	0.05118431  	0.03860456  	0.03906953  
2023-06-12 10:41:37.972: [iter 257 : loss : 0.4196 = 0.0046 + 0.4003 + 0.0147, time: 313.478537]
2023-06-12 10:42:28.047: epoch 257:	0.00676422  	0.10831080  	0.05112933  	0.03851462  	0.03895811  
2023-06-12 10:47:59.645: [iter 258 : loss : 0.4196 = 0.0046 + 0.4002 + 0.0147, time: 326.953066]
2023-06-12 10:48:48.780: epoch 258:	0.00675807  	0.10819367  	0.05115578  	0.03857782  	0.03903622  
2023-06-12 10:54:25.776: [iter 259 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0147, time: 332.386119]
2023-06-12 10:55:15.090: epoch 259:	0.00676664  	0.10840305  	0.05123017  	0.03863690  	0.03909238  
2023-06-12 11:00:43.076: [iter 260 : loss : 0.4197 = 0.0047 + 0.4002 + 0.0147, time: 323.405188]
2023-06-12 11:01:32.605: epoch 260:	0.00676441  	0.10832871  	0.05121243  	0.03862018  	0.03907693  
2023-06-12 11:07:12.565: [iter 261 : loss : 0.4197 = 0.0047 + 0.4002 + 0.0147, time: 335.356131]
2023-06-12 11:08:02.445: epoch 261:	0.00677502  	0.10841388  	0.05121353  	0.03858368  	0.03903953  
2023-06-12 11:13:40.664: [iter 262 : loss : 0.4196 = 0.0046 + 0.4003 + 0.0147, time: 333.602529]
2023-06-12 11:14:30.922: epoch 262:	0.00677687  	0.10848221  	0.05118418  	0.03854390  	0.03900202  
2023-06-12 11:20:18.094: [iter 263 : loss : 0.4196 = 0.0046 + 0.4003 + 0.0147, time: 342.570728]
2023-06-12 11:21:06.471: epoch 263:	0.00677855  	0.10849725  	0.05126562  	0.03863516  	0.03909465  
2023-06-12 11:27:09.131: [iter 264 : loss : 0.4196 = 0.0046 + 0.4003 + 0.0147, time: 358.112936]
2023-06-12 11:27:58.332: epoch 264:	0.00677725  	0.10850667  	0.05135537  	0.03878256  	0.03923605  
2023-06-12 11:33:35.164: [iter 265 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0147, time: 332.248384]
2023-06-12 11:34:24.771: epoch 265:	0.00677576  	0.10847831  	0.05128121  	0.03865676  	0.03911829  
2023-06-12 11:40:03.190: [iter 266 : loss : 0.4197 = 0.0047 + 0.4002 + 0.0147, time: 333.856810]
2023-06-12 11:40:53.784: epoch 266:	0.00676608  	0.10830296  	0.05125319  	0.03866709  	0.03913190  
2023-06-12 11:46:20.476: [iter 267 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 322.043015]
2023-06-12 11:47:08.966: epoch 267:	0.00675324  	0.10818403  	0.05127246  	0.03876115  	0.03921350  
2023-06-12 11:47:08.966: Early stopping is triggered at epoch: 267
2023-06-12 11:47:08.966: best_result@epoch 247:

2023-06-12 11:47:08.966: Loading from the saved model.
2023-06-12 11:47:58.425: 		0.00677874  	0.10852023  	0.05127661  	0.03865963  	0.03913875  
/home/Thesis/model/general_recommender/SGL.py:146: RuntimeWarning: divide by zero encountered in power
  d_inv = np.power(rowsum, -0.5).flatten()
