seed= 2021
load saved data...
Item degree grouping...
User degree grouping...
Data loading finished
Evaluate model with cpp
2023-06-03 20:48:32.860: Dataset name: ifashion
The number of users: 300000
The number of items: 81614
The number of ratings: 1607813
Average actions of users: 5.36
Average actions of items: 19.70
The sparsity of the dataset: 99.993433%
2023-06-03 20:48:32.860: 

NeuRec hyperparameters:
recommender=SGL
config_dir=./conf
gpu_id=1
gpu_mem=1.0
data.input.path=dataset
data.input.dataset=ifashion
data.column.format=UI
data.convert.separator=','
user_min=0
item_min=0
splitter=given
ratio=0.8
by_time=False
metric=["Precision", "Recall", "NDCG", "MAP", "MRR"]
topk=[20]
group_view=None
rec.evaluate.neg=0
test_batch_size=128
num_thread=8
start_testing_epoch=0
proj_path=./

SGL's hyperparameters:
seed=2021
aug_type=1
reg=1e-3
embed_size=64
n_layers=3
ssl_reg=0.02
ssl_ratio=0.4
ssl_temp=0.5
ssl_mode=both_side
ssl_loss_type=2
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=1024
num_negatives=1
init_method=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=20
pretrain=0
save_flag=1

Using debiased loss
2023-06-03 20:48:53.282: metrics:	Precision@20	Recall@20   	NDCG@20     	MAP@20      	MRR@20      
2023-06-03 20:49:54.648: 		0.00000502  	0.00008505  	0.00003216  	0.00001874  	0.00001874  
2023-06-03 20:53:45.515: [iter 1 : loss : 1.0846 = 0.6866 + 0.3980 + 0.0001, time: 229.262689]
2023-06-03 20:54:34.875: epoch 1:	0.00243453  	0.03883259  	0.01753247  	0.01295428  	0.01303231  
2023-06-03 20:54:34.875: Found a better model.
2023-06-03 20:54:34.875: Save model to file as pretrain.
2023-06-03 20:58:06.521: [iter 2 : loss : 0.7885 = 0.3690 + 0.4158 + 0.0036, time: 205.778792]
2023-06-03 20:58:56.329: epoch 2:	0.00323386  	0.05197927  	0.02286517  	0.01652819  	0.01663026  
2023-06-03 20:58:56.329: Found a better model.
2023-06-03 20:58:56.329: Save model to file as pretrain.
2023-06-03 21:02:42.879: [iter 3 : loss : 0.5928 = 0.1668 + 0.4184 + 0.0075, time: 220.669199]
2023-06-03 21:03:31.041: epoch 3:	0.00365296  	0.05848666  	0.02582400  	0.01869141  	0.01881622  
2023-06-03 21:03:31.042: Found a better model.
2023-06-03 21:03:31.042: Save model to file as pretrain.
2023-06-03 21:07:03.205: [iter 4 : loss : 0.5382 = 0.1141 + 0.4149 + 0.0092, time: 206.269946]
2023-06-03 21:07:52.084: epoch 4:	0.00401056  	0.06431390  	0.02843174  	0.02054938  	0.02069431  
2023-06-03 21:07:52.084: Found a better model.
2023-06-03 21:07:52.084: Save model to file as pretrain.
2023-06-03 21:11:21.079: [iter 5 : loss : 0.5086 = 0.0862 + 0.4122 + 0.0103, time: 203.082292]
2023-06-03 21:12:08.637: epoch 5:	0.00431623  	0.06931545  	0.03079070  	0.02232094  	0.02247985  
2023-06-03 21:12:08.637: Found a better model.
2023-06-03 21:12:08.637: Save model to file as pretrain.
2023-06-03 21:15:41.300: [iter 6 : loss : 0.4900 = 0.0686 + 0.4102 + 0.0112, time: 206.686064]
2023-06-03 21:16:31.142: epoch 6:	0.00454948  	0.07311522  	0.03260446  	0.02366557  	0.02383691  
2023-06-03 21:16:31.142: Found a better model.
2023-06-03 21:16:31.142: Save model to file as pretrain.
2023-06-03 21:20:03.991: [iter 7 : loss : 0.4773 = 0.0566 + 0.4087 + 0.0119, time: 206.991370]
2023-06-03 21:20:51.553: epoch 7:	0.00478663  	0.07700948  	0.03450585  	0.02511181  	0.02531092  
2023-06-03 21:20:51.554: Found a better model.
2023-06-03 21:20:51.554: Save model to file as pretrain.
2023-06-03 21:24:22.861: [iter 8 : loss : 0.4674 = 0.0473 + 0.4075 + 0.0126, time: 205.499971]
2023-06-03 21:25:12.047: epoch 8:	0.00496775  	0.07993619  	0.03597335  	0.02624940  	0.02645258  
2023-06-03 21:25:12.047: Found a better model.
2023-06-03 21:25:12.047: Save model to file as pretrain.
2023-06-03 21:28:44.746: [iter 9 : loss : 0.4600 = 0.0402 + 0.4066 + 0.0132, time: 206.802033]
2023-06-03 21:29:33.699: epoch 9:	0.00511164  	0.08222219  	0.03720388  	0.02725135  	0.02747396  
2023-06-03 21:29:33.699: Found a better model.
2023-06-03 21:29:33.699: Save model to file as pretrain.
2023-06-03 21:33:06.219: [iter 10 : loss : 0.4543 = 0.0348 + 0.4059 + 0.0137, time: 206.700166]
2023-06-03 21:33:54.415: epoch 10:	0.00522520  	0.08410953  	0.03813630  	0.02794288  	0.02818444  
2023-06-03 21:33:54.416: Found a better model.
2023-06-03 21:33:54.416: Save model to file as pretrain.
2023-06-03 21:37:25.016: [iter 11 : loss : 0.4493 = 0.0299 + 0.4053 + 0.0141, time: 205.588185]
2023-06-03 21:38:14.250: epoch 11:	0.00533539  	0.08576718  	0.03899895  	0.02863606  	0.02888686  
2023-06-03 21:38:14.250: Found a better model.
2023-06-03 21:38:14.250: Save model to file as pretrain.
2023-06-03 21:41:42.693: [iter 12 : loss : 0.4455 = 0.0263 + 0.4047 + 0.0145, time: 205.874240]
2023-06-03 21:42:30.638: epoch 12:	0.00543647  	0.08744107  	0.03982939  	0.02927423  	0.02953106  
2023-06-03 21:42:30.638: Found a better model.
2023-06-03 21:42:30.638: Save model to file as pretrain.
2023-06-03 21:45:59.959: [iter 13 : loss : 0.4423 = 0.0232 + 0.4043 + 0.0148, time: 206.743005]
2023-06-03 21:46:50.624: epoch 13:	0.00551112  	0.08854179  	0.04049354  	0.02986633  	0.03014101  
2023-06-03 21:46:50.624: Found a better model.
2023-06-03 21:46:50.624: Save model to file as pretrain.
2023-06-03 21:50:22.219: [iter 14 : loss : 0.4399 = 0.0210 + 0.4039 + 0.0150, time: 209.004093]
2023-06-03 21:51:16.940: epoch 14:	0.00559209  	0.08984786  	0.04117747  	0.03043162  	0.03071587  
2023-06-03 21:51:16.940: Found a better model.
2023-06-03 21:51:16.940: Save model to file as pretrain.
2023-06-03 21:55:07.871: [iter 15 : loss : 0.4378 = 0.0190 + 0.4036 + 0.0152, time: 228.309925]
2023-06-03 21:56:03.416: epoch 15:	0.00566859  	0.09109583  	0.04180549  	0.03093827  	0.03123161  
2023-06-03 21:56:03.416: Found a better model.
2023-06-03 21:56:03.416: Save model to file as pretrain.
2023-06-03 21:59:32.034: [iter 16 : loss : 0.4360 = 0.0173 + 0.4033 + 0.0154, time: 205.996131]
2023-06-03 22:00:20.396: epoch 16:	0.00570843  	0.09171075  	0.04217115  	0.03123732  	0.03153617  
2023-06-03 22:00:20.396: Found a better model.
2023-06-03 22:00:20.396: Save model to file as pretrain.
2023-06-03 22:03:48.828: [iter 17 : loss : 0.4341 = 0.0156 + 0.4030 + 0.0155, time: 204.297843]
2023-06-03 22:04:37.548: epoch 17:	0.00576613  	0.09257641  	0.04271917  	0.03173762  	0.03205217  
2023-06-03 22:04:37.548: Found a better model.
2023-06-03 22:04:37.548: Save model to file as pretrain.
2023-06-03 22:08:08.840: [iter 18 : loss : 0.4329 = 0.0145 + 0.4028 + 0.0155, time: 205.375764]
2023-06-03 22:08:58.784: epoch 18:	0.00579927  	0.09305600  	0.04294813  	0.03186834  	0.03219064  
2023-06-03 22:08:58.784: Found a better model.
2023-06-03 22:08:58.784: Save model to file as pretrain.
2023-06-03 22:12:30.282: [iter 19 : loss : 0.4315 = 0.0133 + 0.4026 + 0.0156, time: 205.883030]
2023-06-03 22:13:20.894: epoch 19:	0.00582830  	0.09355026  	0.04334619  	0.03229858  	0.03263346  
2023-06-03 22:13:20.894: Found a better model.
2023-06-03 22:13:20.894: Save model to file as pretrain.
2023-06-03 22:16:52.363: [iter 20 : loss : 0.4306 = 0.0125 + 0.4025 + 0.0156, time: 205.697471]
2023-06-03 22:17:40.992: epoch 20:	0.00586888  	0.09424359  	0.04371000  	0.03258640  	0.03291827  
2023-06-03 22:17:40.992: Found a better model.
2023-06-03 22:17:40.992: Save model to file as pretrain.
2023-06-03 22:21:13.274: [iter 21 : loss : 0.4298 = 0.0119 + 0.4023 + 0.0156, time: 206.162045]
2023-06-03 22:21:50.419: epoch 21:	0.00590909  	0.09486963  	0.04401954  	0.03285298  	0.03319039  
2023-06-03 22:21:50.430: Found a better model.
2023-06-03 22:21:50.430: Save model to file as pretrain.
2023-06-03 22:25:24.411: [iter 22 : loss : 0.4289 = 0.0112 + 0.4022 + 0.0156, time: 207.937600]
2023-06-03 22:26:15.024: epoch 22:	0.00594297  	0.09540821  	0.04427547  	0.03304017  	0.03336972  
2023-06-03 22:26:15.025: Found a better model.
2023-06-03 22:26:15.025: Save model to file as pretrain.
2023-06-03 22:29:47.933: [iter 23 : loss : 0.4282 = 0.0107 + 0.4021 + 0.0155, time: 206.890864]
2023-06-03 22:30:37.196: epoch 23:	0.00598020  	0.09586713  	0.04456523  	0.03328448  	0.03361996  
2023-06-03 22:30:37.196: Found a better model.
2023-06-03 22:30:37.197: Save model to file as pretrain.
2023-06-03 22:34:07.528: [iter 24 : loss : 0.4276 = 0.0102 + 0.4020 + 0.0155, time: 206.535419]
2023-06-03 22:34:57.429: epoch 24:	0.00600812  	0.09624252  	0.04480267  	0.03350354  	0.03383857  
2023-06-03 22:34:57.429: Found a better model.
2023-06-03 22:34:57.429: Save model to file as pretrain.
2023-06-03 22:38:26.488: [iter 25 : loss : 0.4269 = 0.0096 + 0.4019 + 0.0154, time: 206.466661]
2023-06-03 22:39:22.539: epoch 25:	0.00602525  	0.09661925  	0.04491536  	0.03354239  	0.03388659  
2023-06-03 22:39:22.548: Found a better model.
2023-06-03 22:39:22.548: Save model to file as pretrain.
2023-06-03 22:42:48.872: [iter 26 : loss : 0.4264 = 0.0093 + 0.4018 + 0.0154, time: 203.699041]
2023-06-03 22:43:36.943: epoch 26:	0.00605522  	0.09701663  	0.04517910  	0.03378623  	0.03414860  
2023-06-03 22:43:36.943: Found a better model.
2023-06-03 22:43:36.943: Save model to file as pretrain.
2023-06-03 22:47:03.538: [iter 27 : loss : 0.4259 = 0.0089 + 0.4017 + 0.0153, time: 204.023610]
2023-06-03 22:47:52.004: epoch 27:	0.00606620  	0.09711943  	0.04534134  	0.03396532  	0.03433523  
2023-06-03 22:47:52.004: Found a better model.
2023-06-03 22:47:52.004: Save model to file as pretrain.
2023-06-03 22:51:20.565: [iter 28 : loss : 0.4256 = 0.0087 + 0.4016 + 0.0153, time: 205.985194]
2023-06-03 22:52:05.412: epoch 28:	0.00608352  	0.09744196  	0.04551410  	0.03411436  	0.03446813  
2023-06-03 22:52:05.413: Found a better model.
2023-06-03 22:52:05.413: Save model to file as pretrain.
2023-06-03 22:55:34.032: [iter 29 : loss : 0.4252 = 0.0084 + 0.4016 + 0.0152, time: 206.050990]
2023-06-03 22:56:24.050: epoch 29:	0.00609710  	0.09771507  	0.04567844  	0.03427104  	0.03462892  
2023-06-03 22:56:24.050: Found a better model.
2023-06-03 22:56:24.050: Save model to file as pretrain.
2023-06-03 22:59:54.276: [iter 30 : loss : 0.4250 = 0.0083 + 0.4015 + 0.0152, time: 204.822079]
2023-06-03 23:00:43.982: epoch 30:	0.00612279  	0.09805524  	0.04588774  	0.03443590  	0.03479880  
2023-06-03 23:00:43.982: Found a better model.
2023-06-03 23:00:43.982: Save model to file as pretrain.
2023-06-03 23:04:18.509: [iter 31 : loss : 0.4246 = 0.0080 + 0.4014 + 0.0151, time: 208.753862]
2023-06-03 23:05:07.884: epoch 31:	0.00613637  	0.09831245  	0.04601693  	0.03452993  	0.03490568  
2023-06-03 23:05:07.884: Found a better model.
2023-06-03 23:05:07.884: Save model to file as pretrain.
2023-06-03 23:09:01.920: [iter 32 : loss : 0.4243 = 0.0078 + 0.4014 + 0.0151, time: 228.147946]
2023-06-03 23:09:50.419: epoch 32:	0.00615052  	0.09850533  	0.04616395  	0.03468580  	0.03506843  
2023-06-03 23:09:50.420: Found a better model.
2023-06-03 23:09:50.420: Save model to file as pretrain.
2023-06-03 23:13:23.076: [iter 33 : loss : 0.4241 = 0.0076 + 0.4013 + 0.0151, time: 206.805649]
2023-06-03 23:14:12.399: epoch 33:	0.00617435  	0.09886456  	0.04628399  	0.03473685  	0.03511720  
2023-06-03 23:14:12.400: Found a better model.
2023-06-03 23:14:12.400: Save model to file as pretrain.
2023-06-03 23:17:43.879: [iter 34 : loss : 0.4238 = 0.0074 + 0.4013 + 0.0151, time: 205.551850]
2023-06-03 23:18:33.398: epoch 34:	0.00617323  	0.09884851  	0.04629628  	0.03480271  	0.03517949  
2023-06-03 23:22:01.220: [iter 35 : loss : 0.4236 = 0.0073 + 0.4013 + 0.0150, time: 206.273799]
2023-06-03 23:22:51.445: epoch 35:	0.00618719  	0.09905221  	0.04639199  	0.03485529  	0.03524843  
2023-06-03 23:22:51.445: Found a better model.
2023-06-03 23:22:51.445: Save model to file as pretrain.
2023-06-03 23:26:26.978: [iter 36 : loss : 0.4235 = 0.0072 + 0.4012 + 0.0150, time: 209.556833]
2023-06-03 23:27:15.878: epoch 36:	0.00620915  	0.09934744  	0.04657000  	0.03500931  	0.03538237  
2023-06-03 23:27:15.878: Found a better model.
2023-06-03 23:27:15.878: Save model to file as pretrain.
2023-06-03 23:30:45.447: [iter 37 : loss : 0.4232 = 0.0070 + 0.4012 + 0.0150, time: 203.549323]
2023-06-03 23:31:32.372: epoch 37:	0.00621287  	0.09946854  	0.04663153  	0.03505827  	0.03544485  
2023-06-03 23:31:32.373: Found a better model.
2023-06-03 23:31:32.373: Save model to file as pretrain.
2023-06-03 23:35:00.598: [iter 38 : loss : 0.4230 = 0.0068 + 0.4012 + 0.0150, time: 202.388360]
2023-06-03 23:35:49.861: epoch 38:	0.00622050  	0.09958531  	0.04675809  	0.03521517  	0.03559840  
2023-06-03 23:35:49.861: Found a better model.
2023-06-03 23:35:49.862: Save model to file as pretrain.
2023-06-03 23:39:19.220: [iter 39 : loss : 0.4229 = 0.0068 + 0.4011 + 0.0150, time: 203.593587]
2023-06-03 23:40:05.917: epoch 39:	0.00623167  	0.09977051  	0.04684638  	0.03525024  	0.03563464  
2023-06-03 23:40:05.917: Found a better model.
2023-06-03 23:40:05.917: Save model to file as pretrain.
2023-06-03 23:43:38.981: [iter 40 : loss : 0.4228 = 0.0067 + 0.4011 + 0.0149, time: 207.076987]
2023-06-03 23:44:27.796: epoch 40:	0.00625848  	0.10027416  	0.04694344  	0.03525390  	0.03563683  
2023-06-03 23:44:27.796: Found a better model.
2023-06-03 23:44:27.796: Save model to file as pretrain.
2023-06-03 23:47:57.280: [iter 41 : loss : 0.4226 = 0.0066 + 0.4011 + 0.0149, time: 203.556388]
2023-06-03 23:48:46.450: epoch 41:	0.00625364  	0.10022710  	0.04698685  	0.03533451  	0.03572614  
2023-06-03 23:52:12.613: [iter 42 : loss : 0.4225 = 0.0065 + 0.4011 + 0.0149, time: 204.625167]
2023-06-03 23:53:02.142: epoch 42:	0.00625177  	0.10017948  	0.04708760  	0.03544278  	0.03584249  
2023-06-03 23:56:30.096: [iter 43 : loss : 0.4223 = 0.0063 + 0.4011 + 0.0149, time: 206.390117]
2023-06-03 23:57:19.542: epoch 43:	0.00626667  	0.10037646  	0.04722298  	0.03557389  	0.03597000  
2023-06-03 23:57:19.542: Found a better model.
2023-06-03 23:57:19.542: Save model to file as pretrain.
2023-06-04 00:00:51.462: [iter 44 : loss : 0.4223 = 0.0064 + 0.4010 + 0.0149, time: 207.352458]
2023-06-04 00:01:28.840: epoch 44:	0.00627839  	0.10057065  	0.04730122  	0.03562843  	0.03602126  
2023-06-04 00:01:28.840: Found a better model.
2023-06-04 00:01:28.840: Save model to file as pretrain.
2023-06-04 00:05:18.925: [iter 45 : loss : 0.4222 = 0.0062 + 0.4010 + 0.0149, time: 227.627768]
2023-06-04 00:06:08.279: epoch 45:	0.00627281  	0.10036874  	0.04727716  	0.03564912  	0.03604248  
2023-06-04 00:09:33.046: [iter 46 : loss : 0.4221 = 0.0062 + 0.4010 + 0.0149, time: 203.179458]
2023-06-04 00:10:22.427: epoch 46:	0.00628100  	0.10054542  	0.04733234  	0.03566303  	0.03605358  
2023-06-04 00:13:47.146: [iter 47 : loss : 0.4220 = 0.0061 + 0.4010 + 0.0149, time: 203.131141]
2023-06-04 00:14:36.427: epoch 47:	0.00628975  	0.10063772  	0.04742030  	0.03574761  	0.03614390  
2023-06-04 00:14:36.427: Found a better model.
2023-06-04 00:14:36.427: Save model to file as pretrain.
2023-06-04 00:18:05.643: [iter 48 : loss : 0.4220 = 0.0062 + 0.4010 + 0.0149, time: 206.621627]
2023-06-04 00:18:54.860: epoch 48:	0.00629217  	0.10070415  	0.04748600  	0.03583558  	0.03623193  
2023-06-04 00:18:54.860: Found a better model.
2023-06-04 00:18:54.860: Save model to file as pretrain.
2023-06-04 00:22:29.270: [iter 49 : loss : 0.4219 = 0.0060 + 0.4010 + 0.0149, time: 211.838200]
2023-06-04 00:23:24.025: epoch 49:	0.00630613  	0.10093337  	0.04748779  	0.03577418  	0.03616362  
2023-06-04 00:23:24.026: Found a better model.
2023-06-04 00:23:24.026: Save model to file as pretrain.
2023-06-04 00:26:49.851: [iter 50 : loss : 0.4219 = 0.0061 + 0.4010 + 0.0149, time: 203.232427]
2023-06-04 00:27:39.120: epoch 50:	0.00631561  	0.10106955  	0.04756720  	0.03582282  	0.03623216  
2023-06-04 00:27:39.120: Found a better model.
2023-06-04 00:27:39.120: Save model to file as pretrain.
2023-06-04 00:31:02.438: [iter 51 : loss : 0.4218 = 0.0060 + 0.4009 + 0.0149, time: 200.755114]
2023-06-04 00:31:47.176: epoch 51:	0.00630780  	0.10099934  	0.04756733  	0.03582655  	0.03624720  
2023-06-04 00:35:11.200: [iter 52 : loss : 0.4216 = 0.0058 + 0.4009 + 0.0149, time: 202.661149]
2023-06-04 00:36:00.628: epoch 52:	0.00631023  	0.10101072  	0.04759979  	0.03588402  	0.03627421  
2023-06-04 00:39:27.780: [iter 53 : loss : 0.4216 = 0.0058 + 0.4009 + 0.0149, time: 205.599796]
2023-06-04 00:40:23.871: epoch 53:	0.00631544  	0.10105564  	0.04766630  	0.03596855  	0.03637005  
2023-06-04 00:43:51.410: [iter 54 : loss : 0.4217 = 0.0059 + 0.4009 + 0.0149, time: 205.984085]
2023-06-04 00:44:38.757: epoch 54:	0.00632735  	0.10126363  	0.04774571  	0.03599879  	0.03639573  
2023-06-04 00:44:38.757: Found a better model.
2023-06-04 00:44:38.757: Save model to file as pretrain.
2023-06-04 00:48:06.610: [iter 55 : loss : 0.4216 = 0.0058 + 0.4009 + 0.0149, time: 205.270218]
2023-06-04 00:48:55.126: epoch 55:	0.00632642  	0.10132646  	0.04777494  	0.03599799  	0.03641280  
2023-06-04 00:48:55.127: Found a better model.
2023-06-04 00:48:55.127: Save model to file as pretrain.
2023-06-04 00:52:22.645: [iter 56 : loss : 0.4215 = 0.0057 + 0.4009 + 0.0149, time: 204.948484]
2023-06-04 00:53:10.728: epoch 56:	0.00633368  	0.10144021  	0.04777573  	0.03596982  	0.03636732  
2023-06-04 00:53:10.728: Found a better model.
2023-06-04 00:53:10.728: Save model to file as pretrain.
2023-06-04 00:56:42.608: [iter 57 : loss : 0.4214 = 0.0057 + 0.4009 + 0.0149, time: 209.306218]
2023-06-04 00:57:33.206: epoch 57:	0.00635602  	0.10171403  	0.04794871  	0.03611856  	0.03652065  
2023-06-04 00:57:33.206: Found a better model.
2023-06-04 00:57:33.206: Save model to file as pretrain.
2023-06-04 01:01:02.298: [iter 58 : loss : 0.4215 = 0.0057 + 0.4009 + 0.0149, time: 204.052199]
2023-06-04 01:01:51.563: epoch 58:	0.00635342  	0.10168879  	0.04800210  	0.03620087  	0.03660040  
2023-06-04 01:05:17.934: [iter 59 : loss : 0.4214 = 0.0056 + 0.4009 + 0.0148, time: 204.816244]
2023-06-04 01:06:07.239: epoch 59:	0.00634765  	0.10161161  	0.04792642  	0.03613168  	0.03651658  
2023-06-04 01:09:29.649: [iter 60 : loss : 0.4213 = 0.0056 + 0.4009 + 0.0149, time: 200.862810]
2023-06-04 01:10:19.231: epoch 60:	0.00636831  	0.10201108  	0.04800829  	0.03611881  	0.03650891  
2023-06-04 01:10:19.231: Found a better model.
2023-06-04 01:10:19.231: Save model to file as pretrain.
2023-06-04 01:13:46.112: [iter 61 : loss : 0.4213 = 0.0056 + 0.4009 + 0.0148, time: 201.147048]
2023-06-04 01:14:31.593: epoch 61:	0.00636886  	0.10195991  	0.04806904  	0.03622707  	0.03663903  
2023-06-04 01:17:57.477: [iter 62 : loss : 0.4214 = 0.0057 + 0.4009 + 0.0149, time: 204.328914]
2023-06-04 01:18:46.286: epoch 62:	0.00636998  	0.10197396  	0.04808027  	0.03621760  	0.03664888  
2023-06-04 01:22:12.354: [iter 63 : loss : 0.4211 = 0.0054 + 0.4009 + 0.0148, time: 204.519879]
2023-06-04 01:23:01.648: epoch 63:	0.00638040  	0.10216202  	0.04814447  	0.03623582  	0.03667171  
2023-06-04 01:23:01.648: Found a better model.
2023-06-04 01:23:01.648: Save model to file as pretrain.
2023-06-04 01:26:33.838: [iter 64 : loss : 0.4211 = 0.0054 + 0.4008 + 0.0148, time: 206.297376]
2023-06-04 01:27:23.107: epoch 64:	0.00637928  	0.10220227  	0.04815380  	0.03625956  	0.03667117  
2023-06-04 01:27:23.108: Found a better model.
2023-06-04 01:27:23.108: Save model to file as pretrain.
2023-06-04 01:30:51.932: [iter 65 : loss : 0.4212 = 0.0055 + 0.4008 + 0.0149, time: 203.046583]
2023-06-04 01:31:41.932: epoch 65:	0.00640478  	0.10256302  	0.04830495  	0.03634254  	0.03675744  
2023-06-04 01:31:41.932: Found a better model.
2023-06-04 01:31:41.932: Save model to file as pretrain.
2023-06-04 01:35:16.340: [iter 66 : loss : 0.4211 = 0.0054 + 0.4008 + 0.0148, time: 208.478089]
2023-06-04 01:36:06.556: epoch 66:	0.00641093  	0.10265981  	0.04828561  	0.03627948  	0.03670861  
2023-06-04 01:36:06.556: Found a better model.
2023-06-04 01:36:06.557: Save model to file as pretrain.
2023-06-04 01:39:38.582: [iter 67 : loss : 0.4211 = 0.0054 + 0.4008 + 0.0149, time: 206.290829]
2023-06-04 01:40:27.748: epoch 67:	0.00640721  	0.10265106  	0.04833879  	0.03636619  	0.03677277  
2023-06-04 01:43:54.796: [iter 68 : loss : 0.4212 = 0.0055 + 0.4008 + 0.0149, time: 205.463158]
2023-06-04 01:44:34.662: epoch 68:	0.00639809  	0.10250501  	0.04831094  	0.03638167  	0.03679534  
2023-06-04 01:48:00.307: [iter 69 : loss : 0.4211 = 0.0054 + 0.4008 + 0.0149, time: 204.252305]
2023-06-04 01:48:49.490: epoch 69:	0.00641353  	0.10268556  	0.04832511  	0.03631555  	0.03673497  
2023-06-04 01:48:49.490: Found a better model.
2023-06-04 01:48:49.490: Save model to file as pretrain.
2023-06-04 01:52:20.932: [iter 70 : loss : 0.4211 = 0.0054 + 0.4008 + 0.0149, time: 205.635743]
2023-06-04 01:53:10.075: epoch 70:	0.00641465  	0.10275672  	0.04836518  	0.03635370  	0.03676386  
2023-06-04 01:53:10.075: Found a better model.
2023-06-04 01:53:10.075: Save model to file as pretrain.
2023-06-04 01:57:02.554: [iter 71 : loss : 0.4209 = 0.0053 + 0.4008 + 0.0148, time: 226.750771]
2023-06-04 01:57:57.706: epoch 71:	0.00642061  	0.10282336  	0.04843591  	0.03643162  	0.03684111  
2023-06-04 01:57:57.706: Found a better model.
2023-06-04 01:57:57.706: Save model to file as pretrain.
2023-06-04 02:01:30.519: [iter 72 : loss : 0.4209 = 0.0053 + 0.4008 + 0.0148, time: 206.933108]
2023-06-04 02:02:25.995: epoch 72:	0.00642079  	0.10291530  	0.04852297  	0.03651509  	0.03692352  
2023-06-04 02:02:25.995: Found a better model.
2023-06-04 02:02:25.995: Save model to file as pretrain.
2023-06-04 02:05:56.913: [iter 73 : loss : 0.4209 = 0.0052 + 0.4008 + 0.0148, time: 205.255578]
2023-06-04 02:06:46.020: epoch 73:	0.00644238  	0.10318416  	0.04858811  	0.03653571  	0.03695625  
2023-06-04 02:06:46.020: Found a better model.
2023-06-04 02:06:46.021: Save model to file as pretrain.
2023-06-04 02:10:17.769: [iter 74 : loss : 0.4210 = 0.0053 + 0.4008 + 0.0148, time: 205.906000]
2023-06-04 02:11:13.660: epoch 74:	0.00645001  	0.10331331  	0.04870805  	0.03666118  	0.03707277  
2023-06-04 02:11:13.660: Found a better model.
2023-06-04 02:11:13.660: Save model to file as pretrain.
2023-06-04 02:15:05.917: [iter 75 : loss : 0.4209 = 0.0052 + 0.4008 + 0.0148, time: 226.348768]
2023-06-04 02:15:55.185: epoch 75:	0.00644573  	0.10326231  	0.04867083  	0.03661048  	0.03702147  
2023-06-04 02:19:20.895: [iter 76 : loss : 0.4208 = 0.0052 + 0.4008 + 0.0148, time: 204.126490]
2023-06-04 02:20:10.699: epoch 76:	0.00643903  	0.10324050  	0.04866775  	0.03663928  	0.03704498  
2023-06-04 02:23:37.655: [iter 77 : loss : 0.4209 = 0.0052 + 0.4008 + 0.0148, time: 205.339191]
2023-06-04 02:24:23.374: epoch 77:	0.00643959  	0.10313495  	0.04863130  	0.03658655  	0.03701204  
2023-06-04 02:27:51.196: [iter 78 : loss : 0.4208 = 0.0052 + 0.4008 + 0.0148, time: 206.231110]
2023-06-04 02:28:40.164: epoch 78:	0.00645300  	0.10336617  	0.04871889  	0.03666542  	0.03708005  
2023-06-04 02:28:40.165: Found a better model.
2023-06-04 02:28:40.165: Save model to file as pretrain.
2023-06-04 02:32:07.174: [iter 79 : loss : 0.4209 = 0.0052 + 0.4008 + 0.0148, time: 201.213174]
2023-06-04 02:32:54.555: epoch 79:	0.00644909  	0.10337614  	0.04872512  	0.03668481  	0.03710032  
2023-06-04 02:32:54.555: Found a better model.
2023-06-04 02:32:54.555: Save model to file as pretrain.
2023-06-04 02:36:24.040: [iter 80 : loss : 0.4209 = 0.0053 + 0.4008 + 0.0148, time: 203.657364]
2023-06-04 02:37:19.398: epoch 80:	0.00646026  	0.10352968  	0.04880497  	0.03672831  	0.03715029  
2023-06-04 02:37:19.399: Found a better model.
2023-06-04 02:37:19.399: Save model to file as pretrain.
2023-06-04 02:40:47.337: [iter 81 : loss : 0.4208 = 0.0052 + 0.4008 + 0.0148, time: 202.050838]
2023-06-04 02:41:36.651: epoch 81:	0.00646193  	0.10354599  	0.04882222  	0.03677054  	0.03717844  
2023-06-04 02:41:36.651: Found a better model.
2023-06-04 02:41:36.651: Save model to file as pretrain.
2023-06-04 02:45:04.351: [iter 82 : loss : 0.4207 = 0.0051 + 0.4008 + 0.0148, time: 201.765966]
2023-06-04 02:46:00.171: epoch 82:	0.00646770  	0.10368188  	0.04880292  	0.03667771  	0.03709863  
2023-06-04 02:46:00.171: Found a better model.
2023-06-04 02:46:00.171: Save model to file as pretrain.
2023-06-04 02:49:33.015: [iter 83 : loss : 0.4208 = 0.0052 + 0.4008 + 0.0148, time: 206.960527]
2023-06-04 02:50:21.923: epoch 83:	0.00647347  	0.10377147  	0.04886908  	0.03675958  	0.03716175  
2023-06-04 02:50:21.923: Found a better model.
2023-06-04 02:50:21.923: Save model to file as pretrain.
2023-06-04 02:53:54.474: [iter 84 : loss : 0.4207 = 0.0051 + 0.4008 + 0.0148, time: 206.748252]
2023-06-04 02:54:42.754: epoch 84:	0.00647571  	0.10385595  	0.04891931  	0.03681258  	0.03721309  
2023-06-04 02:54:42.754: Found a better model.
2023-06-04 02:54:42.754: Save model to file as pretrain.
2023-06-04 02:58:10.995: [iter 85 : loss : 0.4207 = 0.0051 + 0.4008 + 0.0148, time: 202.422684]
2023-06-04 02:58:59.303: epoch 85:	0.00649116  	0.10406945  	0.04893976  	0.03677870  	0.03718523  
2023-06-04 02:58:59.304: Found a better model.
2023-06-04 02:58:59.304: Save model to file as pretrain.
2023-06-04 03:02:31.474: [iter 86 : loss : 0.4207 = 0.0051 + 0.4008 + 0.0148, time: 206.303582]
2023-06-04 03:03:17.904: epoch 86:	0.00649470  	0.10407433  	0.04907826  	0.03696234  	0.03738764  
2023-06-04 03:03:17.904: Found a better model.
2023-06-04 03:03:17.904: Save model to file as pretrain.
2023-06-04 03:06:50.272: [iter 87 : loss : 0.4207 = 0.0051 + 0.4008 + 0.0148, time: 206.607335]
2023-06-04 03:07:40.606: epoch 87:	0.00650642  	0.10422999  	0.04907957  	0.03692861  	0.03735074  
2023-06-04 03:07:40.606: Found a better model.
2023-06-04 03:07:40.606: Save model to file as pretrain.
2023-06-04 03:11:12.526: [iter 88 : loss : 0.4207 = 0.0051 + 0.4008 + 0.0148, time: 206.118226]
2023-06-04 03:12:00.424: epoch 88:	0.00650680  	0.10421287  	0.04908384  	0.03692894  	0.03737221  
2023-06-04 03:15:25.926: [iter 89 : loss : 0.4207 = 0.0051 + 0.4008 + 0.0148, time: 203.969316]
2023-06-04 03:16:15.410: epoch 89:	0.00650344  	0.10414484  	0.04914241  	0.03700995  	0.03744663  
2023-06-04 03:19:41.630: [iter 90 : loss : 0.4206 = 0.0050 + 0.4008 + 0.0148, time: 204.665850]
2023-06-04 03:20:31.006: epoch 90:	0.00650325  	0.10419893  	0.04913231  	0.03703355  	0.03746463  
2023-06-04 03:23:57.476: [iter 91 : loss : 0.4206 = 0.0050 + 0.4008 + 0.0148, time: 204.874050]
2023-06-04 03:24:44.434: epoch 91:	0.00651628  	0.10443040  	0.04916212  	0.03698806  	0.03740630  
2023-06-04 03:24:44.434: Found a better model.
2023-06-04 03:24:44.434: Save model to file as pretrain.
2023-06-04 03:28:18.071: [iter 92 : loss : 0.4206 = 0.0050 + 0.4008 + 0.0148, time: 207.702413]
2023-06-04 03:29:07.193: epoch 92:	0.00651851  	0.10435262  	0.04913370  	0.03695774  	0.03738265  
2023-06-04 03:32:38.554: [iter 93 : loss : 0.4207 = 0.0051 + 0.4008 + 0.0148, time: 209.788649]
2023-06-04 03:33:24.637: epoch 93:	0.00651665  	0.10443693  	0.04916070  	0.03699405  	0.03741734  
2023-06-04 03:33:24.637: Found a better model.
2023-06-04 03:33:24.637: Save model to file as pretrain.
2023-06-04 03:36:55.264: [iter 94 : loss : 0.4206 = 0.0050 + 0.4008 + 0.0148, time: 204.888113]
2023-06-04 03:37:45.164: epoch 94:	0.00651609  	0.10434512  	0.04926189  	0.03716082  	0.03760125  
2023-06-04 03:41:11.869: [iter 95 : loss : 0.4207 = 0.0051 + 0.4008 + 0.0148, time: 205.168308]
2023-06-04 03:42:01.328: epoch 95:	0.00653192  	0.10459419  	0.04931670  	0.03714348  	0.03759788  
2023-06-04 03:42:01.328: Found a better model.
2023-06-04 03:42:01.328: Save model to file as pretrain.
2023-06-04 03:45:31.270: [iter 96 : loss : 0.4206 = 0.0050 + 0.4007 + 0.0148, time: 205.048394]
2023-06-04 03:46:21.487: epoch 96:	0.00653173  	0.10460665  	0.04932996  	0.03716440  	0.03760135  
2023-06-04 03:46:21.487: Found a better model.
2023-06-04 03:46:21.488: Save model to file as pretrain.
2023-06-04 03:49:51.406: [iter 97 : loss : 0.4206 = 0.0050 + 0.4008 + 0.0148, time: 207.360997]
2023-06-04 03:50:40.790: epoch 97:	0.00651367  	0.10430962  	0.04928873  	0.03718504  	0.03760967  
2023-06-04 03:54:08.511: [iter 98 : loss : 0.4206 = 0.0050 + 0.4008 + 0.0148, time: 206.155602]
2023-06-04 03:54:45.219: epoch 98:	0.00651777  	0.10437850  	0.04935732  	0.03726489  	0.03769048  
2023-06-04 03:58:11.039: [iter 99 : loss : 0.4206 = 0.0050 + 0.4008 + 0.0148, time: 204.276803]
2023-06-04 03:58:59.668: epoch 99:	0.00653080  	0.10460720  	0.04941430  	0.03729603  	0.03772588  
2023-06-04 03:58:59.668: Found a better model.
2023-06-04 03:58:59.668: Save model to file as pretrain.
2023-06-04 04:02:28.669: [iter 100 : loss : 0.4205 = 0.0049 + 0.4008 + 0.0148, time: 206.447680]
2023-06-04 04:03:16.861: epoch 100:	0.00653397  	0.10459948  	0.04945567  	0.03737267  	0.03779283  
2023-06-04 04:06:44.602: [iter 101 : loss : 0.4205 = 0.0050 + 0.4007 + 0.0148, time: 206.172317]
2023-06-04 04:07:33.299: epoch 101:	0.00654457  	0.10479804  	0.04946840  	0.03732761  	0.03774935  
2023-06-04 04:07:33.299: Found a better model.
2023-06-04 04:07:33.299: Save model to file as pretrain.
2023-06-04 04:11:03.667: [iter 102 : loss : 0.4206 = 0.0050 + 0.4007 + 0.0148, time: 207.815904]
2023-06-04 04:11:53.391: epoch 102:	0.00653638  	0.10462922  	0.04943739  	0.03731094  	0.03772847  
2023-06-04 04:15:19.287: [iter 103 : loss : 0.4206 = 0.0050 + 0.4008 + 0.0148, time: 204.292412]
2023-06-04 04:16:06.299: epoch 103:	0.00653582  	0.10465362  	0.04948753  	0.03739895  	0.03782625  
2023-06-04 04:19:33.446: [iter 104 : loss : 0.4205 = 0.0049 + 0.4007 + 0.0148, time: 205.539321]
2023-06-04 04:20:22.617: epoch 104:	0.00654476  	0.10484386  	0.04950789  	0.03736538  	0.03780156  
2023-06-04 04:20:22.618: Found a better model.
2023-06-04 04:20:22.618: Save model to file as pretrain.
2023-06-04 04:23:50.696: [iter 105 : loss : 0.4206 = 0.0050 + 0.4007 + 0.0148, time: 205.514564]
2023-06-04 04:24:36.603: epoch 105:	0.00655239  	0.10491417  	0.04955333  	0.03739963  	0.03784131  
2023-06-04 04:24:36.604: Found a better model.
2023-06-04 04:24:36.604: Save model to file as pretrain.
2023-06-04 04:28:02.616: [iter 106 : loss : 0.4205 = 0.0050 + 0.4007 + 0.0148, time: 203.545808]
2023-06-04 04:28:57.405: epoch 106:	0.00655257  	0.10488743  	0.04952276  	0.03734788  	0.03778695  
2023-06-04 04:32:26.056: [iter 107 : loss : 0.4205 = 0.0049 + 0.4007 + 0.0148, time: 207.078997]
2023-06-04 04:33:15.713: epoch 107:	0.00654252  	0.10472076  	0.04949054  	0.03731570  	0.03774462  
2023-06-04 04:36:43.667: [iter 108 : loss : 0.4206 = 0.0050 + 0.4007 + 0.0148, time: 206.397461]
2023-06-04 04:37:19.774: epoch 108:	0.00655742  	0.10493997  	0.04955893  	0.03737185  	0.03780640  
2023-06-04 04:37:19.774: Found a better model.
2023-06-04 04:37:19.774: Save model to file as pretrain.
2023-06-04 04:41:09.911: [iter 109 : loss : 0.4205 = 0.0049 + 0.4007 + 0.0148, time: 227.543777]
2023-06-04 04:42:04.506: epoch 109:	0.00655332  	0.10494142  	0.04959887  	0.03741339  	0.03785633  
2023-06-04 04:42:04.506: Found a better model.
2023-06-04 04:42:04.506: Save model to file as pretrain.
2023-06-04 04:45:33.397: [iter 110 : loss : 0.4205 = 0.0049 + 0.4007 + 0.0148, time: 206.265289]
2023-06-04 04:46:19.919: epoch 110:	0.00656188  	0.10512652  	0.04966008  	0.03744132  	0.03788114  
2023-06-04 04:46:19.919: Found a better model.
2023-06-04 04:46:19.919: Save model to file as pretrain.
2023-06-04 04:49:46.953: [iter 111 : loss : 0.4205 = 0.0050 + 0.4007 + 0.0148, time: 204.468316]
2023-06-04 04:50:35.790: epoch 111:	0.00657845  	0.10532167  	0.04971639  	0.03745290  	0.03789734  
2023-06-04 04:50:35.790: Found a better model.
2023-06-04 04:50:35.790: Save model to file as pretrain.
2023-06-04 04:54:04.622: [iter 112 : loss : 0.4204 = 0.0049 + 0.4007 + 0.0148, time: 206.230041]
2023-06-04 04:54:53.659: epoch 112:	0.00657734  	0.10545390  	0.04975216  	0.03751287  	0.03794300  
2023-06-04 04:54:53.659: Found a better model.
2023-06-04 04:54:53.659: Save model to file as pretrain.
2023-06-04 04:58:22.495: [iter 113 : loss : 0.4205 = 0.0049 + 0.4007 + 0.0148, time: 206.266753]
2023-06-04 04:59:12.232: epoch 113:	0.00656579  	0.10528419  	0.04974886  	0.03753595  	0.03798074  
2023-06-04 05:02:39.215: [iter 114 : loss : 0.4204 = 0.0049 + 0.4007 + 0.0148, time: 205.415186]
2023-06-04 05:03:28.036: epoch 114:	0.00658553  	0.10555975  	0.04980479  	0.03754955  	0.03796688  
2023-06-04 05:03:28.036: Found a better model.
2023-06-04 05:03:28.036: Save model to file as pretrain.
2023-06-04 05:06:55.775: [iter 115 : loss : 0.4204 = 0.0049 + 0.4007 + 0.0148, time: 205.175117]
2023-06-04 05:07:33.957: epoch 115:	0.00659130  	0.10566896  	0.04986084  	0.03760067  	0.03801439  
2023-06-04 05:07:33.957: Found a better model.
2023-06-04 05:07:33.957: Save model to file as pretrain.
2023-06-04 05:11:02.034: [iter 116 : loss : 0.4204 = 0.0049 + 0.4007 + 0.0148, time: 205.622254]
2023-06-04 05:11:51.539: epoch 116:	0.00659577  	0.10568405  	0.04983086  	0.03752841  	0.03795269  
2023-06-04 05:11:51.539: Found a better model.
2023-06-04 05:11:51.539: Save model to file as pretrain.
2023-06-04 05:15:42.390: [iter 117 : loss : 0.4205 = 0.0050 + 0.4007 + 0.0148, time: 228.295463]
2023-06-04 05:16:36.679: epoch 117:	0.00659949  	0.10569571  	0.04986387  	0.03757928  	0.03800175  
2023-06-04 05:16:36.679: Found a better model.
2023-06-04 05:16:36.679: Save model to file as pretrain.
2023-06-04 05:20:06.895: [iter 118 : loss : 0.4205 = 0.0050 + 0.4007 + 0.0148, time: 207.659673]
2023-06-04 05:20:55.993: epoch 118:	0.00660209  	0.10573719  	0.04985779  	0.03753605  	0.03796279  
2023-06-04 05:20:55.993: Found a better model.
2023-06-04 05:20:55.993: Save model to file as pretrain.
2023-06-04 05:24:21.798: [iter 119 : loss : 0.4204 = 0.0049 + 0.4007 + 0.0148, time: 203.236364]
2023-06-04 05:25:10.666: epoch 119:	0.00661586  	0.10590532  	0.04989730  	0.03752891  	0.03798647  
2023-06-04 05:25:10.666: Found a better model.
2023-06-04 05:25:10.666: Save model to file as pretrain.
2023-06-04 05:28:38.800: [iter 120 : loss : 0.4205 = 0.0050 + 0.4007 + 0.0148, time: 205.592144]
2023-06-04 05:29:15.321: epoch 120:	0.00660916  	0.10581338  	0.04985339  	0.03749340  	0.03794336  
2023-06-04 05:32:40.876: [iter 121 : loss : 0.4204 = 0.0049 + 0.4007 + 0.0148, time: 203.974820]
2023-06-04 05:33:30.271: epoch 121:	0.00660507  	0.10574161  	0.04989938  	0.03759095  	0.03803993  
2023-06-04 05:36:58.664: [iter 122 : loss : 0.4204 = 0.0049 + 0.4007 + 0.0148, time: 206.808018]
2023-06-04 05:37:47.352: epoch 122:	0.00660693  	0.10583406  	0.04996445  	0.03765918  	0.03811400  
2023-06-04 05:41:13.622: [iter 123 : loss : 0.4204 = 0.0049 + 0.4007 + 0.0148, time: 204.729780]
2023-06-04 05:42:02.745: epoch 123:	0.00660917  	0.10575804  	0.04994185  	0.03763961  	0.03808841  
2023-06-04 05:45:25.862: [iter 124 : loss : 0.4203 = 0.0048 + 0.4007 + 0.0148, time: 201.558200]
2023-06-04 05:46:15.082: epoch 124:	0.00660061  	0.10567120  	0.04994017  	0.03765186  	0.03809186  
2023-06-04 05:49:40.925: [iter 125 : loss : 0.4204 = 0.0049 + 0.4007 + 0.0148, time: 204.254218]
2023-06-04 05:50:26.401: epoch 125:	0.00661792  	0.10603847  	0.05004781  	0.03770077  	0.03815181  
2023-06-04 05:50:26.402: Found a better model.
2023-06-04 05:50:26.402: Save model to file as pretrain.
2023-06-04 05:53:55.847: [iter 126 : loss : 0.4203 = 0.0048 + 0.4007 + 0.0148, time: 206.868043]
2023-06-04 05:54:45.784: epoch 126:	0.00661438  	0.10596932  	0.05005723  	0.03776280  	0.03819422  
2023-06-04 05:58:10.652: [iter 127 : loss : 0.4203 = 0.0048 + 0.4007 + 0.0148, time: 203.299836]
2023-06-04 05:58:59.138: epoch 127:	0.00661717  	0.10594966  	0.05009735  	0.03780603  	0.03823951  
2023-06-04 06:02:24.811: [iter 128 : loss : 0.4204 = 0.0049 + 0.4007 + 0.0148, time: 204.133964]
2023-06-04 06:03:13.967: epoch 128:	0.00662257  	0.10605782  	0.05009828  	0.03774526  	0.03820729  
2023-06-04 06:03:13.967: Found a better model.
2023-06-04 06:03:13.967: Save model to file as pretrain.
2023-06-04 06:06:42.963: [iter 129 : loss : 0.4203 = 0.0048 + 0.4007 + 0.0148, time: 206.411599]
2023-06-04 06:07:32.110: epoch 129:	0.00662536  	0.10604058  	0.05006641  	0.03772986  	0.03818459  
2023-06-04 06:10:57.852: [iter 130 : loss : 0.4204 = 0.0049 + 0.4007 + 0.0148, time: 204.159132]
2023-06-04 06:11:45.718: epoch 130:	0.00661997  	0.10604102  	0.05009669  	0.03775342  	0.03820781  
2023-06-04 06:15:15.880: [iter 131 : loss : 0.4203 = 0.0049 + 0.4007 + 0.0148, time: 208.567308]
2023-06-04 06:16:04.173: epoch 131:	0.00664528  	0.10648376  	0.05022101  	0.03779589  	0.03825280  
2023-06-04 06:16:04.173: Found a better model.
2023-06-04 06:16:04.173: Save model to file as pretrain.
2023-06-04 06:19:33.672: [iter 132 : loss : 0.4203 = 0.0049 + 0.4007 + 0.0148, time: 206.331104]
2023-06-04 06:20:16.198: epoch 132:	0.00662406  	0.10612193  	0.05008958  	0.03772775  	0.03818941  
2023-06-04 06:23:44.290: [iter 133 : loss : 0.4203 = 0.0048 + 0.4007 + 0.0148, time: 206.677778]
2023-06-04 06:24:33.708: epoch 133:	0.00662424  	0.10606802  	0.05011715  	0.03777131  	0.03821392  
2023-06-04 06:27:59.292: [iter 134 : loss : 0.4203 = 0.0048 + 0.4007 + 0.0148, time: 203.994500]
2023-06-04 06:28:49.749: epoch 134:	0.00664230  	0.10637585  	0.05017067  	0.03777186  	0.03822815  
2023-06-04 06:32:12.139: [iter 135 : loss : 0.4203 = 0.0048 + 0.4007 + 0.0148, time: 200.802710]
2023-06-04 06:32:47.681: epoch 135:	0.00664342  	0.10633805  	0.05020097  	0.03780865  	0.03825599  
2023-06-04 06:36:10.162: [iter 136 : loss : 0.4203 = 0.0048 + 0.4007 + 0.0148, time: 201.052963]
2023-06-04 06:36:59.207: epoch 136:	0.00664026  	0.10634368  	0.05025193  	0.03790898  	0.03834727  
2023-06-04 06:40:25.219: [iter 137 : loss : 0.4203 = 0.0048 + 0.4007 + 0.0148, time: 204.420283]
2023-06-04 06:41:13.881: epoch 137:	0.00665478  	0.10656810  	0.05027645  	0.03784963  	0.03831555  
2023-06-04 06:41:13.881: Found a better model.
2023-06-04 06:41:13.881: Save model to file as pretrain.
2023-06-04 06:44:41.908: [iter 138 : loss : 0.4202 = 0.0048 + 0.4007 + 0.0148, time: 202.252130]
2023-06-04 06:45:30.965: epoch 138:	0.00665162  	0.10647357  	0.05025737  	0.03786148  	0.03831877  
2023-06-04 06:48:56.641: [iter 139 : loss : 0.4203 = 0.0048 + 0.4007 + 0.0148, time: 204.049705]
2023-06-04 06:49:45.887: epoch 139:	0.00666557  	0.10671751  	0.05034175  	0.03791256  	0.03837594  
2023-06-04 06:49:45.887: Found a better model.
2023-06-04 06:49:45.887: Save model to file as pretrain.
2023-06-04 06:53:20.597: [iter 140 : loss : 0.4203 = 0.0048 + 0.4007 + 0.0148, time: 208.785191]
2023-06-04 06:54:00.759: epoch 140:	0.00666110  	0.10665759  	0.05030627  	0.03785926  	0.03832198  
2023-06-04 06:57:28.321: [iter 141 : loss : 0.4203 = 0.0048 + 0.4007 + 0.0147, time: 206.177650]
2023-06-04 06:58:17.633: epoch 141:	0.00666967  	0.10678054  	0.05038666  	0.03797287  	0.03842677  
2023-06-04 06:58:17.634: Found a better model.
2023-06-04 06:58:17.634: Save model to file as pretrain.
2023-06-04 07:01:49.486: [iter 142 : loss : 0.4203 = 0.0048 + 0.4007 + 0.0148, time: 206.065927]
2023-06-04 07:02:38.312: epoch 142:	0.00666389  	0.10669071  	0.05038204  	0.03795427  	0.03841343  
2023-06-04 07:06:04.138: [iter 143 : loss : 0.4203 = 0.0048 + 0.4007 + 0.0148, time: 204.242114]
2023-06-04 07:06:52.583: epoch 143:	0.00666929  	0.10672497  	0.05044313  	0.03805298  	0.03852295  
2023-06-04 07:10:19.682: [iter 144 : loss : 0.4203 = 0.0049 + 0.4007 + 0.0148, time: 205.539164]
2023-06-04 07:11:09.354: epoch 144:	0.00667413  	0.10679826  	0.05044886  	0.03805523  	0.03851142  
2023-06-04 07:11:09.354: Found a better model.
2023-06-04 07:11:09.354: Save model to file as pretrain.
2023-06-04 07:14:41.461: [iter 145 : loss : 0.4202 = 0.0048 + 0.4007 + 0.0148, time: 206.278118]
2023-06-04 07:15:19.623: epoch 145:	0.00666203  	0.10662056  	0.05042573  	0.03808083  	0.03854426  
2023-06-04 07:18:44.347: [iter 146 : loss : 0.4202 = 0.0048 + 0.4007 + 0.0148, time: 203.362123]
2023-06-04 07:19:33.633: epoch 146:	0.00667674  	0.10690788  	0.05040725  	0.03796544  	0.03841342  
2023-06-04 07:19:33.633: Found a better model.
2023-06-04 07:19:33.633: Save model to file as pretrain.
2023-06-04 07:23:02.649: [iter 147 : loss : 0.4202 = 0.0048 + 0.4007 + 0.0148, time: 203.049699]
2023-06-04 07:23:51.545: epoch 147:	0.00667451  	0.10690372  	0.05043403  	0.03799238  	0.03843512  
2023-06-04 07:27:19.382: [iter 148 : loss : 0.4202 = 0.0048 + 0.4007 + 0.0148, time: 206.244772]
2023-06-04 07:27:56.209: epoch 148:	0.00666539  	0.10670494  	0.05046925  	0.03809891  	0.03854582  
2023-06-04 07:31:24.730: [iter 149 : loss : 0.4203 = 0.0049 + 0.4007 + 0.0147, time: 206.951477]
2023-06-04 07:32:13.724: epoch 149:	0.00667227  	0.10685559  	0.05044068  	0.03799273  	0.03845737  
2023-06-04 07:35:40.577: [iter 150 : loss : 0.4202 = 0.0048 + 0.4007 + 0.0147, time: 205.276469]
2023-06-04 07:36:30.961: epoch 150:	0.00668195  	0.10701451  	0.05050713  	0.03806071  	0.03852998  
2023-06-04 07:36:30.961: Found a better model.
2023-06-04 07:36:30.962: Save model to file as pretrain.
2023-06-04 07:40:25.075: [iter 151 : loss : 0.4202 = 0.0048 + 0.4007 + 0.0147, time: 228.360103]
2023-06-04 07:41:14.017: epoch 151:	0.00668325  	0.10703804  	0.05051697  	0.03804884  	0.03850972  
2023-06-04 07:41:14.018: Found a better model.
2023-06-04 07:41:14.018: Save model to file as pretrain.
2023-06-04 07:44:45.498: [iter 152 : loss : 0.4203 = 0.0049 + 0.4007 + 0.0148, time: 205.524694]
2023-06-04 07:45:35.362: epoch 152:	0.00668046  	0.10690715  	0.05049383  	0.03805203  	0.03852257  
2023-06-04 07:49:03.219: [iter 153 : loss : 0.4203 = 0.0049 + 0.4007 + 0.0147, time: 206.303060]
2023-06-04 07:49:52.769: epoch 153:	0.00668772  	0.10719538  	0.05055230  	0.03802273  	0.03850615  
2023-06-04 07:49:52.769: Found a better model.
2023-06-04 07:49:52.769: Save model to file as pretrain.
2023-06-04 07:53:28.864: [iter 154 : loss : 0.4202 = 0.0048 + 0.4007 + 0.0147, time: 210.181411]
2023-06-04 07:54:18.843: epoch 154:	0.00669423  	0.10715622  	0.05055052  	0.03802629  	0.03849808  
2023-06-04 07:57:41.305: [iter 155 : loss : 0.4202 = 0.0048 + 0.4007 + 0.0147, time: 200.913770]
2023-06-04 07:58:18.486: epoch 155:	0.00670336  	0.10728695  	0.05065665  	0.03812911  	0.03861791  
2023-06-04 07:58:18.486: Found a better model.
2023-06-04 07:58:18.486: Save model to file as pretrain.
2023-06-04 08:01:50.037: [iter 156 : loss : 0.4202 = 0.0048 + 0.4007 + 0.0147, time: 205.864857]
2023-06-04 08:02:40.086: epoch 156:	0.00669200  	0.10717908  	0.05061900  	0.03814528  	0.03861549  
2023-06-04 08:06:08.087: [iter 157 : loss : 0.4203 = 0.0048 + 0.4007 + 0.0147, time: 206.414933]
2023-06-04 08:06:56.885: epoch 157:	0.00669721  	0.10729021  	0.05068370  	0.03819662  	0.03867658  
2023-06-04 08:06:56.885: Found a better model.
2023-06-04 08:06:56.885: Save model to file as pretrain.
2023-06-04 08:10:30.687: [iter 158 : loss : 0.4202 = 0.0048 + 0.4007 + 0.0147, time: 207.962765]
2023-06-04 08:11:19.670: epoch 158:	0.00670782  	0.10743131  	0.05073069  	0.03823148  	0.03870286  
2023-06-04 08:11:19.670: Found a better model.
2023-06-04 08:11:19.670: Save model to file as pretrain.
2023-06-04 08:14:50.502: [iter 159 : loss : 0.4203 = 0.0048 + 0.4007 + 0.0147, time: 205.040963]
2023-06-04 08:15:39.906: epoch 159:	0.00670392  	0.10734046  	0.05073067  	0.03822703  	0.03870461  
2023-06-04 08:19:06.813: [iter 160 : loss : 0.4202 = 0.0048 + 0.4007 + 0.0147, time: 205.319180]
2023-06-04 08:19:56.353: epoch 160:	0.00670336  	0.10733192  	0.05070613  	0.03819646  	0.03866864  
2023-06-04 08:23:23.550: [iter 161 : loss : 0.4201 = 0.0047 + 0.4007 + 0.0147, time: 205.641243]
2023-06-04 08:24:12.871: epoch 161:	0.00670819  	0.10745165  	0.05078582  	0.03828747  	0.03876228  
2023-06-04 08:24:12.871: Found a better model.
2023-06-04 08:24:12.871: Save model to file as pretrain.
2023-06-04 08:27:39.561: [iter 162 : loss : 0.4202 = 0.0047 + 0.4007 + 0.0147, time: 200.878646]
2023-06-04 08:28:26.484: epoch 162:	0.00670838  	0.10738444  	0.05075163  	0.03826081  	0.03872032  
2023-06-04 08:31:51.346: [iter 163 : loss : 0.4202 = 0.0048 + 0.4007 + 0.0147, time: 203.287081]
2023-06-04 08:32:40.199: epoch 163:	0.00671713  	0.10757167  	0.05074487  	0.03819066  	0.03865192  
2023-06-04 08:32:40.200: Found a better model.
2023-06-04 08:32:40.200: Save model to file as pretrain.
2023-06-04 08:36:12.430: [iter 164 : loss : 0.4202 = 0.0047 + 0.4007 + 0.0147, time: 206.246594]
2023-06-04 08:37:00.049: epoch 164:	0.00670410  	0.10730197  	0.05062002  	0.03807088  	0.03852164  
2023-06-04 08:40:27.188: [iter 165 : loss : 0.4202 = 0.0048 + 0.4007 + 0.0147, time: 205.564187]
2023-06-04 08:41:16.017: epoch 165:	0.00671006  	0.10740444  	0.05077998  	0.03825724  	0.03871101  
2023-06-04 08:44:40.405: [iter 166 : loss : 0.4202 = 0.0048 + 0.4007 + 0.0147, time: 202.827776]
2023-06-04 08:45:29.720: epoch 166:	0.00670913  	0.10744049  	0.05069024  	0.03813335  	0.03859437  
2023-06-04 08:48:57.446: [iter 167 : loss : 0.4202 = 0.0048 + 0.4007 + 0.0147, time: 206.172070]
2023-06-04 08:49:33.943: epoch 167:	0.00671173  	0.10754877  	0.05079457  	0.03827899  	0.03873571  
2023-06-04 08:52:59.899: [iter 168 : loss : 0.4203 = 0.0049 + 0.4007 + 0.0147, time: 204.371641]
2023-06-04 08:53:48.694: epoch 168:	0.00670484  	0.10734300  	0.05080256  	0.03834323  	0.03878769  
2023-06-04 08:57:14.163: [iter 169 : loss : 0.4201 = 0.0047 + 0.4007 + 0.0147, time: 203.912002]
2023-06-04 08:58:03.382: epoch 169:	0.00670093  	0.10736810  	0.05075856  	0.03826729  	0.03870981  
2023-06-04 09:01:28.061: [iter 170 : loss : 0.4202 = 0.0048 + 0.4007 + 0.0147, time: 203.106086]
2023-06-04 09:02:17.531: epoch 170:	0.00671769  	0.10757282  	0.05083845  	0.03831835  	0.03877548  
2023-06-04 09:02:17.531: Found a better model.
2023-06-04 09:02:17.531: Save model to file as pretrain.
2023-06-04 09:05:49.269: [iter 171 : loss : 0.4201 = 0.0047 + 0.4007 + 0.0147, time: 206.609313]
2023-06-04 09:06:38.945: epoch 171:	0.00672830  	0.10769945  	0.05084324  	0.03828547  	0.03873539  
2023-06-04 09:06:38.945: Found a better model.
2023-06-04 09:06:38.945: Save model to file as pretrain.
2023-06-04 09:10:04.989: [iter 172 : loss : 0.4202 = 0.0048 + 0.4007 + 0.0147, time: 203.480852]
2023-06-04 09:10:59.683: epoch 172:	0.00671881  	0.10762964  	0.05078110  	0.03822985  	0.03866736  
2023-06-04 09:14:26.753: [iter 173 : loss : 0.4201 = 0.0047 + 0.4007 + 0.0147, time: 205.524306]
2023-06-04 09:15:16.424: epoch 173:	0.00671713  	0.10759211  	0.05087097  	0.03833261  	0.03879090  
2023-06-04 09:18:44.535: [iter 174 : loss : 0.4202 = 0.0048 + 0.4007 + 0.0147, time: 206.538457]
2023-06-04 09:19:32.596: epoch 174:	0.00672271  	0.10759343  	0.05081272  	0.03824619  	0.03869537  
2023-06-04 09:22:59.278: [iter 175 : loss : 0.4201 = 0.0047 + 0.4007 + 0.0147, time: 205.158242]
2023-06-04 09:23:49.817: epoch 175:	0.00671155  	0.10743922  	0.05074685  	0.03821125  	0.03866342  
2023-06-04 09:27:17.875: [iter 176 : loss : 0.4202 = 0.0048 + 0.4007 + 0.0147, time: 206.482440]
2023-06-04 09:28:06.261: epoch 176:	0.00670690  	0.10745650  	0.05071051  	0.03816614  	0.03860471  
2023-06-04 09:31:33.095: [iter 177 : loss : 0.4202 = 0.0048 + 0.4007 + 0.0147, time: 205.275840]
2023-06-04 09:32:22.443: epoch 177:	0.00670838  	0.10742058  	0.05077719  	0.03826866  	0.03873121  
2023-06-04 09:35:50.329: [iter 178 : loss : 0.4202 = 0.0048 + 0.4007 + 0.0147, time: 206.347883]
2023-06-04 09:36:39.125: epoch 178:	0.00670838  	0.10740478  	0.05079368  	0.03830127  	0.03876683  
2023-06-04 09:40:04.861: [iter 179 : loss : 0.4201 = 0.0047 + 0.4007 + 0.0147, time: 204.182053]
2023-06-04 09:40:46.109: epoch 179:	0.00670671  	0.10742810  	0.05076863  	0.03828526  	0.03872916  
2023-06-04 09:44:35.999: [iter 180 : loss : 0.4202 = 0.0047 + 0.4007 + 0.0147, time: 228.531143]
2023-06-04 09:45:25.358: epoch 180:	0.00670856  	0.10743044  	0.05075515  	0.03827152  	0.03870263  
2023-06-04 09:48:51.280: [iter 181 : loss : 0.4202 = 0.0048 + 0.4007 + 0.0147, time: 204.363991]
2023-06-04 09:49:40.015: epoch 181:	0.00671508  	0.10752833  	0.05077656  	0.03828530  	0.03874155  
2023-06-04 09:53:06.105: [iter 182 : loss : 0.4202 = 0.0048 + 0.4007 + 0.0147, time: 204.547666]
2023-06-04 09:53:54.979: epoch 182:	0.00672774  	0.10776604  	0.05082341  	0.03824801  	0.03870626  
2023-06-04 09:53:54.988: Found a better model.
2023-06-04 09:53:54.988: Save model to file as pretrain.
2023-06-04 09:57:45.882: [iter 183 : loss : 0.4201 = 0.0047 + 0.4007 + 0.0147, time: 228.332200]
2023-06-04 09:58:40.326: epoch 183:	0.00672215  	0.10764225  	0.05080675  	0.03825627  	0.03869478  
2023-06-04 10:02:06.558: [iter 184 : loss : 0.4201 = 0.0047 + 0.4007 + 0.0147, time: 204.682958]
2023-06-04 10:02:56.345: epoch 184:	0.00672848  	0.10774815  	0.05082647  	0.03827317  	0.03872221  
2023-06-04 10:06:21.720: [iter 185 : loss : 0.4201 = 0.0047 + 0.4007 + 0.0147, time: 203.793854]
2023-06-04 10:07:12.364: epoch 185:	0.00670745  	0.10748307  	0.05082730  	0.03837477  	0.03881483  
2023-06-04 10:10:38.442: [iter 186 : loss : 0.4201 = 0.0047 + 0.4007 + 0.0147, time: 204.482259]
2023-06-04 10:11:24.699: epoch 186:	0.00674189  	0.10795344  	0.05093746  	0.03837159  	0.03882625  
2023-06-04 10:11:24.699: Found a better model.
2023-06-04 10:11:24.699: Save model to file as pretrain.
2023-06-04 10:15:14.003: [iter 187 : loss : 0.4201 = 0.0047 + 0.4007 + 0.0147, time: 226.725300]
2023-06-04 10:16:08.899: epoch 187:	0.00672942  	0.10778037  	0.05095116  	0.03842546  	0.03888797  
2023-06-04 10:19:55.473: [iter 188 : loss : 0.4201 = 0.0047 + 0.4007 + 0.0147, time: 224.976710]
2023-06-04 10:20:32.790: epoch 188:	0.00673444  	0.10785554  	0.05093185  	0.03837502  	0.03883823  
2023-06-04 10:24:22.567: [iter 189 : loss : 0.4201 = 0.0047 + 0.4007 + 0.0147, time: 228.177451]
2023-06-04 10:25:11.202: epoch 189:	0.00672179  	0.10764345  	0.05083839  	0.03830288  	0.03874968  
2023-06-04 10:28:35.960: [iter 190 : loss : 0.4201 = 0.0047 + 0.4007 + 0.0147, time: 203.166265]
2023-06-04 10:29:22.617: epoch 190:	0.00674021  	0.10794073  	0.05093270  	0.03835091  	0.03881648  
2023-06-04 10:32:48.459: [iter 191 : loss : 0.4201 = 0.0047 + 0.4007 + 0.0147, time: 204.230145]
2023-06-04 10:33:37.320: epoch 191:	0.00673928  	0.10790109  	0.05092039  	0.03834782  	0.03883253  
2023-06-04 10:37:04.142: [iter 192 : loss : 0.4201 = 0.0047 + 0.4007 + 0.0147, time: 205.223239]
2023-06-04 10:37:53.527: epoch 192:	0.00673537  	0.10790876  	0.05093793  	0.03839851  	0.03886623  
2023-06-04 10:41:21.279: [iter 193 : loss : 0.4201 = 0.0047 + 0.4007 + 0.0147, time: 206.172433]
2023-06-04 10:41:57.910: epoch 193:	0.00675083  	0.10812230  	0.05098260  	0.03839060  	0.03885363  
2023-06-04 10:41:57.910: Found a better model.
2023-06-04 10:41:57.910: Save model to file as pretrain.
2023-06-04 10:45:25.092: [iter 194 : loss : 0.4201 = 0.0047 + 0.4007 + 0.0147, time: 204.587671]
2023-06-04 10:46:14.465: epoch 194:	0.00673593  	0.10788277  	0.05092775  	0.03838035  	0.03884103  
2023-06-04 10:49:39.416: [iter 195 : loss : 0.4201 = 0.0047 + 0.4007 + 0.0147, time: 203.342518]
2023-06-04 10:50:27.867: epoch 195:	0.00673742  	0.10788960  	0.05095785  	0.03840309  	0.03888108  
2023-06-04 10:53:54.470: [iter 196 : loss : 0.4201 = 0.0048 + 0.4007 + 0.0147, time: 205.001198]
2023-06-04 10:54:44.247: epoch 196:	0.00672961  	0.10780299  	0.05095034  	0.03841758  	0.03888565  
2023-06-04 10:58:16.211: [iter 197 : loss : 0.4202 = 0.0048 + 0.4007 + 0.0147, time: 210.358679]
2023-06-04 10:59:06.034: epoch 197:	0.00673928  	0.10791167  	0.05096027  	0.03841773  	0.03888360  
2023-06-04 11:02:31.628: [iter 198 : loss : 0.4201 = 0.0047 + 0.4007 + 0.0147, time: 203.991277]
2023-06-04 11:03:17.209: epoch 198:	0.00673798  	0.10793748  	0.05097923  	0.03842016  	0.03888964  
2023-06-04 11:06:41.725: [iter 199 : loss : 0.4201 = 0.0047 + 0.4007 + 0.0147, time: 202.945401]
2023-06-04 11:07:30.299: epoch 199:	0.00673556  	0.10788713  	0.05104059  	0.03849645  	0.03896685  
2023-06-04 11:10:55.306: [iter 200 : loss : 0.4201 = 0.0048 + 0.4007 + 0.0147, time: 203.429038]
2023-06-04 11:11:43.513: epoch 200:	0.00673686  	0.10795522  	0.05096569  	0.03839028  	0.03885550  
2023-06-04 11:15:11.114: [iter 201 : loss : 0.4201 = 0.0048 + 0.4007 + 0.0147, time: 206.054045]
2023-06-04 11:15:59.192: epoch 201:	0.00675417  	0.10822899  	0.05104573  	0.03840797  	0.03888018  
2023-06-04 11:15:59.192: Found a better model.
2023-06-04 11:15:59.192: Save model to file as pretrain.
2023-06-04 11:19:25.809: [iter 202 : loss : 0.4201 = 0.0047 + 0.4007 + 0.0147, time: 204.049331]
2023-06-04 11:20:14.330: epoch 202:	0.00675752  	0.10817112  	0.05104290  	0.03843183  	0.03889046  
2023-06-04 11:23:39.980: [iter 203 : loss : 0.4201 = 0.0047 + 0.4007 + 0.0147, time: 204.084152]
2023-06-04 11:24:29.146: epoch 203:	0.00676218  	0.10830531  	0.05109008  	0.03846689  	0.03894192  
2023-06-04 11:24:29.146: Found a better model.
2023-06-04 11:24:29.146: Save model to file as pretrain.
2023-06-04 11:27:57.746: [iter 204 : loss : 0.4201 = 0.0047 + 0.4007 + 0.0147, time: 206.031661]
2023-06-04 11:28:45.948: epoch 204:	0.00676330  	0.10829017  	0.05109413  	0.03849214  	0.03895918  
2023-06-04 11:32:13.696: [iter 205 : loss : 0.4200 = 0.0047 + 0.4007 + 0.0147, time: 206.176571]
2023-06-04 11:33:07.193: epoch 205:	0.00677037  	0.10847043  	0.05115440  	0.03854838  	0.03900251  
2023-06-04 11:33:07.193: Found a better model.
2023-06-04 11:33:07.193: Save model to file as pretrain.
2023-06-04 11:36:36.616: [iter 206 : loss : 0.4201 = 0.0048 + 0.4007 + 0.0147, time: 206.966403]
2023-06-04 11:37:25.775: epoch 206:	0.00675045  	0.10822195  	0.05115232  	0.03858966  	0.03906441  
2023-06-04 11:40:53.776: [iter 207 : loss : 0.4201 = 0.0047 + 0.4007 + 0.0147, time: 206.452338]
2023-06-04 11:41:42.396: epoch 207:	0.00675995  	0.10826236  	0.05113633  	0.03854104  	0.03901407  
2023-06-04 11:45:09.213: [iter 208 : loss : 0.4201 = 0.0047 + 0.4007 + 0.0147, time: 205.244627]
2023-06-04 11:45:58.210: epoch 208:	0.00675976  	0.10824689  	0.05109631  	0.03852824  	0.03899874  
2023-06-04 11:49:29.251: [iter 209 : loss : 0.4201 = 0.0047 + 0.4007 + 0.0147, time: 209.465212]
2023-06-04 11:50:18.453: epoch 209:	0.00676181  	0.10824282  	0.05110891  	0.03851015  	0.03898272  
2023-06-04 11:53:46.554: [iter 210 : loss : 0.4201 = 0.0047 + 0.4007 + 0.0147, time: 206.547327]
2023-06-04 11:54:25.364: epoch 210:	0.00675995  	0.10827342  	0.05106563  	0.03842857  	0.03890322  
2023-06-04 11:57:50.402: [iter 211 : loss : 0.4201 = 0.0047 + 0.4007 + 0.0147, time: 203.665024]
2023-06-04 11:58:38.718: epoch 211:	0.00675306  	0.10821858  	0.05110905  	0.03854523  	0.03901370  
2023-06-04 12:02:03.924: [iter 212 : loss : 0.4200 = 0.0047 + 0.4007 + 0.0147, time: 203.644037]
2023-06-04 12:02:52.925: epoch 212:	0.00675883  	0.10829108  	0.05104932  	0.03843091  	0.03889675  
2023-06-04 12:06:38.812: [iter 213 : loss : 0.4200 = 0.0047 + 0.4007 + 0.0147, time: 224.328225]
2023-06-04 12:07:28.061: epoch 213:	0.00675864  	0.10820512  	0.05096719  	0.03833300  	0.03879950  
2023-06-04 12:10:56.672: [iter 214 : loss : 0.4201 = 0.0048 + 0.4007 + 0.0147, time: 207.032074]
2023-06-04 12:11:46.463: epoch 214:	0.00676479  	0.10834163  	0.05103718  	0.03839688  	0.03884554  
2023-06-04 12:15:09.985: [iter 215 : loss : 0.4201 = 0.0048 + 0.4007 + 0.0147, time: 201.948699]
2023-06-04 12:15:50.052: epoch 215:	0.00674952  	0.10811254  	0.05096083  	0.03837543  	0.03882891  
2023-06-04 12:19:17.002: [iter 216 : loss : 0.4201 = 0.0048 + 0.4007 + 0.0147, time: 205.570979]
2023-06-04 12:20:07.777: epoch 216:	0.00676161  	0.10827120  	0.05107212  	0.03844740  	0.03891965  
2023-06-04 12:23:33.879: [iter 217 : loss : 0.4201 = 0.0047 + 0.4007 + 0.0147, time: 204.506536]
2023-06-04 12:24:22.141: epoch 217:	0.00677744  	0.10843071  	0.05115557  	0.03852542  	0.03899617  
2023-06-04 12:27:49.080: [iter 218 : loss : 0.4200 = 0.0047 + 0.4007 + 0.0147, time: 205.343755]
2023-06-04 12:28:38.665: epoch 218:	0.00676720  	0.10836851  	0.05113626  	0.03851910  	0.03898226  
2023-06-04 12:32:06.545: [iter 219 : loss : 0.4200 = 0.0047 + 0.4007 + 0.0147, time: 206.304214]
2023-06-04 12:32:55.968: epoch 219:	0.00676498  	0.10838542  	0.05106796  	0.03843660  	0.03887922  
2023-06-04 12:36:21.531: [iter 220 : loss : 0.4200 = 0.0047 + 0.4007 + 0.0147, time: 203.975569]
2023-06-04 12:37:08.355: epoch 220:	0.00676422  	0.10840464  	0.05106202  	0.03842406  	0.03888135  
2023-06-04 12:40:36.033: [iter 221 : loss : 0.4200 = 0.0047 + 0.4007 + 0.0147, time: 206.095539]
2023-06-04 12:41:25.469: epoch 221:	0.00677353  	0.10848273  	0.05112401  	0.03846863  	0.03893747  
2023-06-04 12:41:25.469: Found a better model.
2023-06-04 12:41:25.469: Save model to file as pretrain.
2023-06-04 12:44:50.440: [iter 222 : loss : 0.4200 = 0.0047 + 0.4007 + 0.0147, time: 202.390573]
2023-06-04 12:45:40.786: epoch 222:	0.00677111  	0.10842086  	0.05113389  	0.03851042  	0.03898517  
2023-06-04 12:49:09.764: [iter 223 : loss : 0.4201 = 0.0047 + 0.4007 + 0.0147, time: 207.404190]
2023-06-04 12:49:59.482: epoch 223:	0.00677875  	0.10848159  	0.05116710  	0.03855088  	0.03902185  
2023-06-04 12:53:22.167: [iter 224 : loss : 0.4201 = 0.0048 + 0.4007 + 0.0147, time: 201.113000]
2023-06-04 12:54:09.947: epoch 224:	0.00678061  	0.10856148  	0.05123772  	0.03861133  	0.03907038  
2023-06-04 12:54:09.956: Found a better model.
2023-06-04 12:54:09.956: Save model to file as pretrain.
2023-06-04 12:57:36.417: [iter 225 : loss : 0.4200 = 0.0047 + 0.4007 + 0.0147, time: 203.879949]
2023-06-04 12:58:12.816: epoch 225:	0.00677297  	0.10848320  	0.05120448  	0.03859976  	0.03904675  
2023-06-04 13:01:39.611: [iter 226 : loss : 0.4201 = 0.0047 + 0.4007 + 0.0147, time: 205.418273]
2023-06-04 13:02:29.443: epoch 226:	0.00678042  	0.10859280  	0.05121646  	0.03857523  	0.03902765  
2023-06-04 13:02:29.444: Found a better model.
2023-06-04 13:02:29.444: Save model to file as pretrain.
2023-06-04 13:06:00.579: [iter 227 : loss : 0.4201 = 0.0047 + 0.4007 + 0.0147, time: 208.551255]
2023-06-04 13:06:48.936: epoch 227:	0.00678377  	0.10863413  	0.05128350  	0.03868805  	0.03915026  
2023-06-04 13:06:48.936: Found a better model.
2023-06-04 13:06:48.936: Save model to file as pretrain.
2023-06-04 13:10:14.656: [iter 228 : loss : 0.4200 = 0.0046 + 0.4007 + 0.0147, time: 203.175963]
2023-06-04 13:11:03.860: epoch 228:	0.00677595  	0.10852265  	0.05122934  	0.03861402  	0.03908401  
2023-06-04 13:14:29.539: [iter 229 : loss : 0.4201 = 0.0047 + 0.4007 + 0.0147, time: 204.105762]
2023-06-04 13:15:18.676: epoch 229:	0.00677371  	0.10842887  	0.05118316  	0.03856552  	0.03902979  
2023-06-04 13:18:45.696: [iter 230 : loss : 0.4200 = 0.0047 + 0.4007 + 0.0147, time: 205.416733]
2023-06-04 13:19:25.745: epoch 230:	0.00677967  	0.10855439  	0.05118561  	0.03854837  	0.03899032  
2023-06-04 13:22:49.790: [iter 231 : loss : 0.4200 = 0.0047 + 0.4007 + 0.0147, time: 202.682150]
2023-06-04 13:23:38.945: epoch 231:	0.00677502  	0.10840629  	0.05115716  	0.03853073  	0.03898598  
2023-06-04 13:27:04.679: [iter 232 : loss : 0.4200 = 0.0047 + 0.4007 + 0.0147, time: 204.168994]
2023-06-04 13:27:54.455: epoch 232:	0.00678470  	0.10858891  	0.05131787  	0.03871227  	0.03916820  
2023-06-04 13:31:23.147: [iter 233 : loss : 0.4201 = 0.0047 + 0.4007 + 0.0147, time: 207.103110]
2023-06-04 13:31:59.577: epoch 233:	0.00678228  	0.10858086  	0.05128811  	0.03868396  	0.03914931  
2023-06-04 13:35:24.429: [iter 234 : loss : 0.4200 = 0.0047 + 0.4007 + 0.0147, time: 203.263525]
2023-06-04 13:36:12.970: epoch 234:	0.00677912  	0.10847849  	0.05126331  	0.03863915  	0.03910990  
2023-06-04 13:39:39.941: [iter 235 : loss : 0.4200 = 0.0047 + 0.4007 + 0.0147, time: 205.415195]
2023-06-04 13:40:29.754: epoch 235:	0.00678060  	0.10853002  	0.05132743  	0.03874879  	0.03921983  
2023-06-04 13:43:59.668: [iter 236 : loss : 0.4200 = 0.0047 + 0.4007 + 0.0147, time: 208.344658]
2023-06-04 13:44:48.924: epoch 236:	0.00678265  	0.10852394  	0.05134015  	0.03876191  	0.03921985  
2023-06-04 13:48:15.692: [iter 237 : loss : 0.4201 = 0.0047 + 0.4007 + 0.0147, time: 205.207882]
2023-06-04 13:49:03.943: epoch 237:	0.00677520  	0.10847994  	0.05124936  	0.03861847  	0.03908780  
2023-06-04 13:52:29.653: [iter 238 : loss : 0.4199 = 0.0046 + 0.4007 + 0.0147, time: 204.161197]
2023-06-04 13:53:07.680: epoch 238:	0.00677278  	0.10841932  	0.05122800  	0.03863395  	0.03909511  
2023-06-04 13:56:32.767: [iter 239 : loss : 0.4200 = 0.0046 + 0.4007 + 0.0147, time: 203.693898]
2023-06-04 13:57:21.599: epoch 239:	0.00678860  	0.10864515  	0.05125426  	0.03860662  	0.03906853  
2023-06-04 13:57:21.600: Found a better model.
2023-06-04 13:57:21.600: Save model to file as pretrain.
2023-06-04 14:01:12.366: [iter 240 : loss : 0.4201 = 0.0047 + 0.4007 + 0.0147, time: 228.175237]
2023-06-04 14:02:01.402: epoch 240:	0.00679158  	0.10866275  	0.05133734  	0.03868362  	0.03916703  
2023-06-04 14:02:01.402: Found a better model.
2023-06-04 14:02:01.402: Save model to file as pretrain.
2023-06-04 14:05:30.800: [iter 241 : loss : 0.4200 = 0.0047 + 0.4007 + 0.0147, time: 206.819916]
2023-06-04 14:06:20.387: epoch 241:	0.00680275  	0.10880065  	0.05138689  	0.03871903  	0.03917891  
2023-06-04 14:06:20.387: Found a better model.
2023-06-04 14:06:20.387: Save model to file as pretrain.
2023-06-04 14:09:50.195: [iter 242 : loss : 0.4200 = 0.0046 + 0.4007 + 0.0147, time: 207.240876]
2023-06-04 14:10:39.919: epoch 242:	0.00679475  	0.10865644  	0.05135472  	0.03871348  	0.03918281  
2023-06-04 14:14:07.857: [iter 243 : loss : 0.4200 = 0.0046 + 0.4007 + 0.0147, time: 206.373891]
2023-06-04 14:14:44.640: epoch 243:	0.00679587  	0.10876153  	0.05136532  	0.03869094  	0.03915433  
2023-06-04 14:18:10.393: [iter 244 : loss : 0.4199 = 0.0046 + 0.4007 + 0.0147, time: 204.155179]
2023-06-04 14:19:00.350: epoch 244:	0.00678265  	0.10849193  	0.05123657  	0.03862111  	0.03909111  
2023-06-04 14:22:28.512: [iter 245 : loss : 0.4200 = 0.0047 + 0.4007 + 0.0147, time: 206.572834]
2023-06-04 14:23:17.821: epoch 245:	0.00679084  	0.10860620  	0.05126071  	0.03861304  	0.03907700  
2023-06-04 14:26:42.639: [iter 246 : loss : 0.4200 = 0.0046 + 0.4007 + 0.0147, time: 203.239030]
2023-06-04 14:27:32.162: epoch 246:	0.00679290  	0.10861392  	0.05130424  	0.03868549  	0.03914394  
2023-06-04 14:30:57.920: [iter 247 : loss : 0.4199 = 0.0046 + 0.4007 + 0.0147, time: 204.166989]
2023-06-04 14:31:46.995: epoch 247:	0.00681076  	0.10896606  	0.05135266  	0.03867200  	0.03912975  
2023-06-04 14:31:46.996: Found a better model.
2023-06-04 14:31:46.996: Save model to file as pretrain.
2023-06-04 14:35:25.584: [iter 248 : loss : 0.4201 = 0.0047 + 0.4007 + 0.0147, time: 215.978086]
2023-06-04 14:36:02.359: epoch 248:	0.00680071  	0.10880175  	0.05138640  	0.03875802  	0.03922100  
2023-06-04 14:39:52.939: [iter 249 : loss : 0.4201 = 0.0048 + 0.4007 + 0.0147, time: 228.962050]
2023-06-04 14:40:42.326: epoch 249:	0.00680219  	0.10882026  	0.05137296  	0.03873396  	0.03920740  
2023-06-04 14:44:11.254: [iter 250 : loss : 0.4200 = 0.0046 + 0.4007 + 0.0147, time: 207.314404]
2023-06-04 14:44:58.648: epoch 250:	0.00680573  	0.10889482  	0.05142939  	0.03877521  	0.03925493  
2023-06-04 14:48:24.000: [iter 251 : loss : 0.4201 = 0.0047 + 0.4007 + 0.0147, time: 203.750760]
2023-06-04 14:49:12.975: epoch 251:	0.00680462  	0.10888375  	0.05141864  	0.03877588  	0.03927454  
2023-06-04 14:52:40.356: [iter 252 : loss : 0.4200 = 0.0047 + 0.4007 + 0.0147, time: 205.788159]
2023-06-04 14:53:29.711: epoch 252:	0.00680331  	0.10882596  	0.05138706  	0.03875787  	0.03924100  
2023-06-04 14:56:57.389: [iter 253 : loss : 0.4201 = 0.0047 + 0.4007 + 0.0147, time: 206.083798]
2023-06-04 14:57:46.680: epoch 253:	0.00679717  	0.10871457  	0.05142128  	0.03882523  	0.03930048  
2023-06-04 15:01:13.938: [iter 254 : loss : 0.4200 = 0.0047 + 0.4007 + 0.0147, time: 205.647655]
2023-06-04 15:02:04.137: epoch 254:	0.00682453  	0.10919276  	0.05150887  	0.03881937  	0.03929024  
2023-06-04 15:02:04.137: Found a better model.
2023-06-04 15:02:04.137: Save model to file as pretrain.
2023-06-04 15:05:54.812: [iter 255 : loss : 0.4200 = 0.0047 + 0.4007 + 0.0147, time: 228.053764]
2023-06-04 15:06:47.132: epoch 255:	0.00683774  	0.10935094  	0.05156963  	0.03883969  	0.03932472  
2023-06-04 15:06:47.132: Found a better model.
2023-06-04 15:06:47.132: Save model to file as pretrain.
2023-06-04 15:10:16.505: [iter 256 : loss : 0.4200 = 0.0046 + 0.4007 + 0.0147, time: 206.717635]
2023-06-04 15:11:06.242: epoch 256:	0.00680629  	0.10884274  	0.05139303  	0.03872103  	0.03920343  
2023-06-04 15:14:32.255: [iter 257 : loss : 0.4200 = 0.0047 + 0.4007 + 0.0147, time: 204.401713]
2023-06-04 15:15:19.336: epoch 257:	0.00679866  	0.10868704  	0.05138669  	0.03875764  	0.03924037  
2023-06-04 15:18:44.909: [iter 258 : loss : 0.4200 = 0.0047 + 0.4007 + 0.0146, time: 203.981595]
2023-06-04 15:19:34.466: epoch 258:	0.00681262  	0.10888644  	0.05151487  	0.03887612  	0.03935583  
2023-06-04 15:23:00.303: [iter 259 : loss : 0.4200 = 0.0047 + 0.4007 + 0.0147, time: 204.228418]
2023-06-04 15:23:48.157: epoch 259:	0.00682361  	0.10909928  	0.05149911  	0.03877867  	0.03925378  
2023-06-04 15:27:15.835: [iter 260 : loss : 0.4200 = 0.0047 + 0.4007 + 0.0146, time: 206.096618]
2023-06-04 15:28:05.561: epoch 260:	0.00682100  	0.10898214  	0.05147425  	0.03878254  	0.03925135  
2023-06-04 15:31:34.059: [iter 261 : loss : 0.4200 = 0.0047 + 0.4007 + 0.0147, time: 206.912789]
2023-06-04 15:32:24.140: epoch 261:	0.00683012  	0.10915661  	0.05148188  	0.03876191  	0.03922483  
2023-06-04 15:35:50.166: [iter 262 : loss : 0.4200 = 0.0047 + 0.4007 + 0.0147, time: 204.457190]
2023-06-04 15:36:26.043: epoch 262:	0.00682137  	0.10911348  	0.05146258  	0.03876599  	0.03923390  
2023-06-04 15:39:52.187: [iter 263 : loss : 0.4200 = 0.0047 + 0.4007 + 0.0146, time: 204.576360]
2023-06-04 15:40:41.111: epoch 263:	0.00681970  	0.10906273  	0.05145795  	0.03874584  	0.03919772  
2023-06-04 15:44:08.899: [iter 264 : loss : 0.4199 = 0.0046 + 0.4007 + 0.0147, time: 206.204150]
2023-06-04 15:44:58.453: epoch 264:	0.00682566  	0.10914491  	0.05149778  	0.03876778  	0.03924600  
2023-06-04 15:48:25.302: [iter 265 : loss : 0.4200 = 0.0047 + 0.4007 + 0.0147, time: 205.265431]
2023-06-04 15:49:14.453: epoch 265:	0.00681876  	0.10907470  	0.05147015  	0.03876053  	0.03921373  
2023-06-04 15:52:42.261: [iter 266 : loss : 0.4201 = 0.0047 + 0.4007 + 0.0147, time: 206.239287]
2023-06-04 15:53:30.852: epoch 266:	0.00681839  	0.10904080  	0.05145475  	0.03874286  	0.03921802  
2023-06-04 15:56:57.634: [iter 267 : loss : 0.4200 = 0.0047 + 0.4007 + 0.0147, time: 205.207363]
2023-06-04 15:57:45.745: epoch 267:	0.00682695  	0.10921933  	0.05146453  	0.03870641  	0.03918871  
2023-06-04 16:01:13.592: [iter 268 : loss : 0.4200 = 0.0047 + 0.4007 + 0.0146, time: 206.255936]
2023-06-04 16:02:04.106: epoch 268:	0.00681206  	0.10896729  	0.05136516  	0.03862306  	0.03909948  
2023-06-04 16:05:29.217: [iter 269 : loss : 0.4199 = 0.0046 + 0.4007 + 0.0147, time: 203.536892]
2023-06-04 16:06:17.537: epoch 269:	0.00680238  	0.10881422  	0.05140353  	0.03872690  	0.03918859  
2023-06-04 16:09:43.876: [iter 270 : loss : 0.4200 = 0.0046 + 0.4007 + 0.0147, time: 204.787691]
2023-06-04 16:10:33.982: epoch 270:	0.00681411  	0.10899472  	0.05143194  	0.03868492  	0.03915302  
2023-06-04 16:14:00.345: [iter 271 : loss : 0.4200 = 0.0047 + 0.4007 + 0.0146, time: 204.799121]
2023-06-04 16:14:49.820: epoch 271:	0.00681988  	0.10907999  	0.05153571  	0.03883236  	0.03930857  
2023-06-04 16:18:17.508: [iter 272 : loss : 0.4200 = 0.0047 + 0.4007 + 0.0146, time: 206.105024]
2023-06-04 16:19:04.727: epoch 272:	0.00681430  	0.10894682  	0.05147797  	0.03880455  	0.03927565  
2023-06-04 16:22:29.534: [iter 273 : loss : 0.4200 = 0.0047 + 0.4007 + 0.0146, time: 203.253759]
2023-06-04 16:23:18.992: epoch 273:	0.00680238  	0.10875764  	0.05141513  	0.03876303  	0.03924596  
2023-06-04 16:26:46.621: [iter 274 : loss : 0.4200 = 0.0047 + 0.4007 + 0.0146, time: 206.072822]
2023-06-04 16:27:33.259: epoch 274:	0.00680815  	0.10883694  	0.05153853  	0.03889412  	0.03937631  
2023-06-04 16:31:00.454: [iter 275 : loss : 0.4199 = 0.0046 + 0.4007 + 0.0147, time: 205.636352]
2023-06-04 16:31:49.482: epoch 275:	0.00680927  	0.10883639  	0.05149611  	0.03886602  	0.03935891  
2023-06-04 16:31:49.485: Early stopping is triggered at epoch: 275
2023-06-04 16:31:49.485: best_result@epoch 255:

2023-06-04 16:31:49.485: Loading from the saved model.
2023-06-04 16:32:46.199: 		0.00683774  	0.10935094  	0.05156963  	0.03883969  	0.03932472  
/home/Thesis/model/general_recommender/SGL.py:146: RuntimeWarning: divide by zero encountered in power
  d_inv = np.power(rowsum, -0.5).flatten()
