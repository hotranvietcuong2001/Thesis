seed= 2021
load saved data...
Item degree grouping...
User degree grouping...
Data loading finished
Evaluate model with cpp
2023-06-02 17:06:50.783: Dataset name: ifashion
The number of users: 300000
The number of items: 81614
The number of ratings: 1607813
Average actions of users: 5.36
Average actions of items: 19.70
The sparsity of the dataset: 99.993433%
2023-06-02 17:06:50.783: 

NeuRec hyperparameters:
recommender=SGL
config_dir=./conf
gpu_id=1
gpu_mem=1.0
data.input.path=dataset
data.input.dataset=ifashion
data.column.format=UI
data.convert.separator=','
user_min=0
item_min=0
splitter=given
ratio=0.8
by_time=False
metric=["Precision", "Recall", "NDCG", "MAP", "MRR"]
topk=[20]
group_view=None
rec.evaluate.neg=0
test_batch_size=128
num_thread=8
start_testing_epoch=0
proj_path=./

SGL's hyperparameters:
seed=2021
aug_type=1
reg=1e-3
embed_size=64
n_layers=3
ssl_reg=0.02
ssl_ratio=0.4
ssl_temp=0.5
ssl_mode=both_side
ssl_loss_type=1
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=1024
num_negatives=1
init_method=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=20
pretrain=0
save_flag=1

Using decoupled loss
2023-06-02 17:07:11.556: metrics:	Precision@20	Recall@20   	NDCG@20     	MAP@20      	MRR@20      
2023-06-02 17:08:12.961: 		0.00000800  	0.00013367  	0.00004247  	0.00001957  	0.00001957  
2023-06-02 17:11:41.850: [iter 1 : loss : 1.0845 = 0.6869 + 0.3976 + 0.0001, time: 207.382806]
2023-06-02 17:12:30.405: epoch 1:	0.00242672  	0.03871850  	0.01737572  	0.01279373  	0.01287349  
2023-06-02 17:12:30.405: Found a better model.
2023-06-02 17:12:30.405: Save model to file as pretrain.
2023-06-02 17:15:56.245: [iter 2 : loss : 0.7888 = 0.3699 + 0.4153 + 0.0036, time: 203.276549]
2023-06-02 17:16:45.970: epoch 2:	0.00325989  	0.05240158  	0.02296506  	0.01653259  	0.01665483  
2023-06-02 17:16:45.970: Found a better model.
2023-06-02 17:16:45.970: Save model to file as pretrain.
2023-06-02 17:20:11.773: [iter 3 : loss : 0.5919 = 0.1664 + 0.4180 + 0.0075, time: 203.249181]
2023-06-02 17:20:49.432: epoch 3:	0.00367639  	0.05893731  	0.02598095  	0.01875539  	0.01888200  
2023-06-02 17:20:49.432: Found a better model.
2023-06-02 17:20:49.432: Save model to file as pretrain.
2023-06-02 17:24:17.409: [iter 4 : loss : 0.5376 = 0.1139 + 0.4145 + 0.0092, time: 205.388248]
2023-06-02 17:25:06.192: epoch 4:	0.00403700  	0.06475014  	0.02874081  	0.02082543  	0.02097947  
2023-06-02 17:25:06.192: Found a better model.
2023-06-02 17:25:06.192: Save model to file as pretrain.
2023-06-02 17:28:35.061: [iter 5 : loss : 0.5084 = 0.0863 + 0.4118 + 0.0103, time: 206.268469]
2023-06-02 17:29:25.518: epoch 5:	0.00431976  	0.06932474  	0.03092757  	0.02246224  	0.02262532  
2023-06-02 17:29:25.519: Found a better model.
2023-06-02 17:29:25.519: Save model to file as pretrain.
2023-06-02 17:32:57.119: [iter 6 : loss : 0.4898 = 0.0688 + 0.4098 + 0.0112, time: 209.074772]
2023-06-02 17:33:46.845: epoch 6:	0.00456939  	0.07350892  	0.03281983  	0.02381607  	0.02399103  
2023-06-02 17:33:46.845: Found a better model.
2023-06-02 17:33:46.845: Save model to file as pretrain.
2023-06-02 17:37:32.238: [iter 7 : loss : 0.4770 = 0.0568 + 0.4083 + 0.0119, time: 222.862282]
2023-06-02 17:38:21.682: epoch 7:	0.00478682  	0.07704934  	0.03456476  	0.02514788  	0.02534233  
2023-06-02 17:38:21.682: Found a better model.
2023-06-02 17:38:21.682: Save model to file as pretrain.
2023-06-02 17:42:03.465: [iter 8 : loss : 0.4672 = 0.0474 + 0.4072 + 0.0126, time: 219.222614]
2023-06-02 17:42:53.156: epoch 8:	0.00495695  	0.07975170  	0.03591554  	0.02616775  	0.02638182  
2023-06-02 17:42:53.156: Found a better model.
2023-06-02 17:42:53.156: Save model to file as pretrain.
2023-06-02 17:46:44.081: [iter 9 : loss : 0.4598 = 0.0403 + 0.4063 + 0.0132, time: 228.306202]
2023-06-02 17:47:33.053: epoch 9:	0.00510345  	0.08214816  	0.03714275  	0.02715584  	0.02738462  
2023-06-02 17:47:33.053: Found a better model.
2023-06-02 17:47:33.053: Save model to file as pretrain.
2023-06-02 17:51:02.557: [iter 10 : loss : 0.4540 = 0.0349 + 0.4055 + 0.0137, time: 206.941274]
2023-06-02 17:51:53.745: epoch 10:	0.00521440  	0.08401731  	0.03806934  	0.02788267  	0.02812706  
2023-06-02 17:51:53.745: Found a better model.
2023-06-02 17:51:53.745: Save model to file as pretrain.
2023-06-02 17:55:19.536: [iter 11 : loss : 0.4490 = 0.0300 + 0.4049 + 0.0141, time: 203.266869]
2023-06-02 17:56:09.593: epoch 11:	0.00534693  	0.08602183  	0.03903377  	0.02861150  	0.02886378  
2023-06-02 17:56:09.593: Found a better model.
2023-06-02 17:56:09.593: Save model to file as pretrain.
2023-06-02 17:59:36.467: [iter 12 : loss : 0.4452 = 0.0263 + 0.4044 + 0.0145, time: 204.319134]
2023-06-02 18:00:23.121: epoch 12:	0.00541842  	0.08713421  	0.03979253  	0.02930606  	0.02957379  
2023-06-02 18:00:23.121: Found a better model.
2023-06-02 18:00:23.121: Save model to file as pretrain.
2023-06-02 18:03:51.900: [iter 13 : loss : 0.4420 = 0.0233 + 0.4039 + 0.0148, time: 206.238060]
2023-06-02 18:04:41.734: epoch 13:	0.00549864  	0.08840478  	0.04042342  	0.02982319  	0.03009320  
2023-06-02 18:04:41.735: Found a better model.
2023-06-02 18:04:41.744: Save model to file as pretrain.
2023-06-02 18:08:11.431: [iter 14 : loss : 0.4396 = 0.0210 + 0.4035 + 0.0151, time: 207.114093]
2023-06-02 18:09:00.512: epoch 14:	0.00556770  	0.08947331  	0.04107951  	0.03041628  	0.03070104  
2023-06-02 18:09:00.512: Found a better model.
2023-06-02 18:09:00.512: Save model to file as pretrain.
2023-06-02 18:12:52.082: [iter 15 : loss : 0.4375 = 0.0191 + 0.4032 + 0.0152, time: 229.001339]
2023-06-02 18:13:41.925: epoch 15:	0.00564290  	0.09054109  	0.04167322  	0.03091508  	0.03119487  
2023-06-02 18:13:41.925: Found a better model.
2023-06-02 18:13:41.925: Save model to file as pretrain.
2023-06-02 18:17:33.483: [iter 16 : loss : 0.4356 = 0.0173 + 0.4029 + 0.0154, time: 229.000186]
2023-06-02 18:18:22.689: epoch 16:	0.00568925  	0.09145179  	0.04215005  	0.03131046  	0.03161403  
2023-06-02 18:18:22.689: Found a better model.
2023-06-02 18:18:22.689: Save model to file as pretrain.
2023-06-02 18:21:52.608: [iter 17 : loss : 0.4337 = 0.0156 + 0.4027 + 0.0155, time: 207.352917]
2023-06-02 18:22:42.514: epoch 17:	0.00575068  	0.09235722  	0.04265726  	0.03172270  	0.03203673  
2023-06-02 18:22:42.515: Found a better model.
2023-06-02 18:22:42.515: Save model to file as pretrain.
2023-06-02 18:26:10.641: [iter 18 : loss : 0.4326 = 0.0145 + 0.4025 + 0.0156, time: 205.528235]
2023-06-02 18:27:00.300: epoch 18:	0.00580782  	0.09313341  	0.04304375  	0.03202663  	0.03234657  
2023-06-02 18:27:00.301: Found a better model.
2023-06-02 18:27:00.301: Save model to file as pretrain.
2023-06-02 18:30:49.769: [iter 19 : loss : 0.4312 = 0.0133 + 0.4022 + 0.0156, time: 226.886917]
2023-06-02 18:31:39.519: epoch 19:	0.00583686  	0.09352665  	0.04341121  	0.03241538  	0.03275688  
2023-06-02 18:31:39.519: Found a better model.
2023-06-02 18:31:39.519: Save model to file as pretrain.
2023-06-02 18:35:09.044: [iter 20 : loss : 0.4302 = 0.0125 + 0.4021 + 0.0156, time: 206.978402]
2023-06-02 18:35:59.186: epoch 20:	0.00587297  	0.09414763  	0.04370418  	0.03264714  	0.03296859  
2023-06-02 18:35:59.186: Found a better model.
2023-06-02 18:35:59.186: Save model to file as pretrain.
2023-06-02 18:39:50.809: [iter 21 : loss : 0.4294 = 0.0119 + 0.4019 + 0.0156, time: 229.005456]
2023-06-02 18:40:41.155: epoch 21:	0.00591299  	0.09466583  	0.04407608  	0.03298362  	0.03332315  
2023-06-02 18:40:41.155: Found a better model.
2023-06-02 18:40:41.155: Save model to file as pretrain.
2023-06-02 18:44:11.209: [iter 22 : loss : 0.4286 = 0.0112 + 0.4018 + 0.0156, time: 207.458941]
2023-06-02 18:45:00.882: epoch 22:	0.00594594  	0.09527981  	0.04428615  	0.03307897  	0.03341227  
2023-06-02 18:45:00.883: Found a better model.
2023-06-02 18:45:00.883: Save model to file as pretrain.
2023-06-02 18:48:29.886: [iter 23 : loss : 0.4278 = 0.0106 + 0.4017 + 0.0155, time: 206.416297]
2023-06-02 18:49:09.045: epoch 23:	0.00598149  	0.09570369  	0.04455289  	0.03330712  	0.03363910  
2023-06-02 18:49:09.045: Found a better model.
2023-06-02 18:49:09.045: Save model to file as pretrain.
2023-06-02 18:52:45.782: [iter 24 : loss : 0.4272 = 0.0102 + 0.4016 + 0.0155, time: 214.262928]
2023-06-02 18:53:35.216: epoch 24:	0.00599676  	0.09587672  	0.04471725  	0.03350375  	0.03385246  
2023-06-02 18:53:35.219: Found a better model.
2023-06-02 18:53:35.219: Save model to file as pretrain.
2023-06-02 18:57:26.079: [iter 25 : loss : 0.4265 = 0.0096 + 0.4015 + 0.0154, time: 228.287988]
2023-06-02 18:58:12.940: epoch 25:	0.00600979  	0.09617647  	0.04493542  	0.03369657  	0.03404811  
2023-06-02 18:58:12.940: Found a better model.
2023-06-02 18:58:12.940: Save model to file as pretrain.
2023-06-02 19:02:03.049: [iter 26 : loss : 0.4260 = 0.0092 + 0.4014 + 0.0154, time: 227.549970]
2023-06-02 19:02:52.951: epoch 26:	0.00602338  	0.09638240  	0.04512160  	0.03389676  	0.03424239  
2023-06-02 19:02:52.951: Found a better model.
2023-06-02 19:02:52.951: Save model to file as pretrain.
2023-06-02 19:06:24.281: [iter 27 : loss : 0.4255 = 0.0089 + 0.4013 + 0.0153, time: 208.749623]
2023-06-02 19:07:13.560: epoch 27:	0.00605874  	0.09694243  	0.04533494  	0.03402714  	0.03436714  
2023-06-02 19:07:13.560: Found a better model.
2023-06-02 19:07:13.560: Save model to file as pretrain.
2023-06-02 19:10:42.516: [iter 28 : loss : 0.4252 = 0.0087 + 0.4012 + 0.0153, time: 206.389096]
2023-06-02 19:11:32.609: epoch 28:	0.00606936  	0.09701656  	0.04553223  	0.03425274  	0.03461731  
2023-06-02 19:11:32.609: Found a better model.
2023-06-02 19:11:32.609: Save model to file as pretrain.
2023-06-02 19:15:00.425: [iter 29 : loss : 0.4248 = 0.0084 + 0.4012 + 0.0152, time: 205.271093]
2023-06-02 19:15:49.919: epoch 29:	0.00609560  	0.09749696  	0.04564723  	0.03429212  	0.03464234  
2023-06-02 19:15:49.919: Found a better model.
2023-06-02 19:15:49.919: Save model to file as pretrain.
2023-06-02 19:19:17.796: [iter 30 : loss : 0.4245 = 0.0082 + 0.4011 + 0.0152, time: 205.355938]
2023-06-02 19:20:05.054: epoch 30:	0.00611794  	0.09780826  	0.04582250  	0.03446015  	0.03483271  
2023-06-02 19:20:05.054: Found a better model.
2023-06-02 19:20:05.054: Save model to file as pretrain.
2023-06-02 19:23:33.725: [iter 31 : loss : 0.4242 = 0.0080 + 0.4010 + 0.0152, time: 206.105701]
2023-06-02 19:24:23.750: epoch 31:	0.00612557  	0.09793259  	0.04597947  	0.03463317  	0.03500870  
2023-06-02 19:24:23.750: Found a better model.
2023-06-02 19:24:23.750: Save model to file as pretrain.
2023-06-02 19:27:49.264: [iter 32 : loss : 0.4239 = 0.0078 + 0.4010 + 0.0151, time: 202.991081]
2023-06-02 19:28:37.495: epoch 32:	0.00616261  	0.09859679  	0.04616142  	0.03471135  	0.03505931  
2023-06-02 19:28:37.495: Found a better model.
2023-06-02 19:28:37.495: Save model to file as pretrain.
2023-06-02 19:32:02.925: [iter 33 : loss : 0.4236 = 0.0076 + 0.4009 + 0.0151, time: 202.907607]
2023-06-02 19:32:52.252: epoch 33:	0.00616727  	0.09863682  	0.04634578  	0.03494357  	0.03531604  
2023-06-02 19:32:52.253: Found a better model.
2023-06-02 19:32:52.253: Save model to file as pretrain.
2023-06-02 19:36:42.946: [iter 34 : loss : 0.4234 = 0.0074 + 0.4009 + 0.0151, time: 228.142410]
2023-06-02 19:37:32.048: epoch 34:	0.00617918  	0.09871851  	0.04641295  	0.03502952  	0.03539156  
2023-06-02 19:37:32.048: Found a better model.
2023-06-02 19:37:32.048: Save model to file as pretrain.
2023-06-02 19:41:01.910: [iter 35 : loss : 0.4231 = 0.0072 + 0.4009 + 0.0150, time: 207.343917]
2023-06-02 19:41:51.310: epoch 35:	0.00618849  	0.09898440  	0.04650860  	0.03506668  	0.03543582  
2023-06-02 19:41:51.310: Found a better model.
2023-06-02 19:41:51.311: Save model to file as pretrain.
2023-06-02 19:45:20.769: [iter 36 : loss : 0.4231 = 0.0072 + 0.4008 + 0.0150, time: 206.900132]
2023-06-02 19:46:09.782: epoch 36:	0.00621455  	0.09933368  	0.04667048  	0.03521013  	0.03558002  
2023-06-02 19:46:09.783: Found a better model.
2023-06-02 19:46:09.783: Save model to file as pretrain.
2023-06-02 19:49:39.391: [iter 37 : loss : 0.4228 = 0.0070 + 0.4008 + 0.0150, time: 207.095378]
2023-06-02 19:50:15.252: epoch 37:	0.00621790  	0.09933429  	0.04675825  	0.03530447  	0.03567886  
2023-06-02 19:50:15.252: Found a better model.
2023-06-02 19:50:15.252: Save model to file as pretrain.
2023-06-02 19:53:43.995: [iter 38 : loss : 0.4226 = 0.0069 + 0.4008 + 0.0150, time: 205.587496]
2023-06-02 19:54:33.520: epoch 38:	0.00621641  	0.09937073  	0.04678981  	0.03533722  	0.03571903  
2023-06-02 19:54:33.520: Found a better model.
2023-06-02 19:54:33.520: Save model to file as pretrain.
2023-06-02 19:58:25.976: [iter 39 : loss : 0.4225 = 0.0068 + 0.4008 + 0.0150, time: 226.704143]
2023-06-02 19:59:14.060: epoch 39:	0.00622702  	0.09945821  	0.04682388  	0.03538616  	0.03576568  
2023-06-02 19:59:14.060: Found a better model.
2023-06-02 19:59:14.061: Save model to file as pretrain.
2023-06-02 20:02:46.664: [iter 40 : loss : 0.4224 = 0.0067 + 0.4007 + 0.0149, time: 206.726030]
2023-06-02 20:03:36.032: epoch 40:	0.00624079  	0.09975089  	0.04690460  	0.03540612  	0.03579053  
2023-06-02 20:03:36.032: Found a better model.
2023-06-02 20:03:36.032: Save model to file as pretrain.
2023-06-02 20:07:07.822: [iter 41 : loss : 0.4222 = 0.0066 + 0.4007 + 0.0149, time: 206.146348]
2023-06-02 20:07:58.631: epoch 41:	0.00623986  	0.09969767  	0.04690560  	0.03541935  	0.03580454  
2023-06-02 20:11:26.191: [iter 42 : loss : 0.4221 = 0.0065 + 0.4007 + 0.0149, time: 206.022257]
2023-06-02 20:12:15.868: epoch 42:	0.00625308  	0.09982188  	0.04697913  	0.03546926  	0.03584907  
2023-06-02 20:12:15.868: Found a better model.
2023-06-02 20:12:15.868: Save model to file as pretrain.
2023-06-02 20:15:47.663: [iter 43 : loss : 0.4219 = 0.0063 + 0.4007 + 0.0149, time: 205.961781]
2023-06-02 20:16:37.370: epoch 43:	0.00624712  	0.09978522  	0.04698051  	0.03548693  	0.03587341  
2023-06-02 20:20:03.176: [iter 44 : loss : 0.4219 = 0.0063 + 0.4007 + 0.0149, time: 204.265548]
2023-06-02 20:20:42.978: epoch 44:	0.00626238  	0.09994143  	0.04704425  	0.03552414  	0.03590095  
2023-06-02 20:20:42.979: Found a better model.
2023-06-02 20:20:42.979: Save model to file as pretrain.
2023-06-02 20:24:13.825: [iter 45 : loss : 0.4218 = 0.0062 + 0.4006 + 0.0149, time: 205.111983]
2023-06-02 20:25:02.807: epoch 45:	0.00626462  	0.09998797  	0.04714731  	0.03566773  	0.03605049  
2023-06-02 20:25:02.807: Found a better model.
2023-06-02 20:25:02.807: Save model to file as pretrain.
2023-06-02 20:28:34.923: [iter 46 : loss : 0.4217 = 0.0062 + 0.4006 + 0.0149, time: 206.408339]
2023-06-02 20:29:24.257: epoch 46:	0.00628565  	0.10037918  	0.04725562  	0.03566388  	0.03604480  
2023-06-02 20:29:24.257: Found a better model.
2023-06-02 20:29:24.257: Save model to file as pretrain.
2023-06-02 20:32:53.871: [iter 47 : loss : 0.4217 = 0.0062 + 0.4006 + 0.0149, time: 203.795589]
2023-06-02 20:33:43.309: epoch 47:	0.00629869  	0.10064645  	0.04733270  	0.03570092  	0.03606472  
2023-06-02 20:33:43.310: Found a better model.
2023-06-02 20:33:43.310: Save model to file as pretrain.
2023-06-02 20:37:16.452: [iter 48 : loss : 0.4217 = 0.0062 + 0.4006 + 0.0149, time: 207.243875]
2023-06-02 20:38:05.981: epoch 48:	0.00629031  	0.10043750  	0.04728953  	0.03570014  	0.03608597  
2023-06-02 20:41:31.387: [iter 49 : loss : 0.4215 = 0.0061 + 0.4006 + 0.0149, time: 203.844712]
2023-06-02 20:42:17.860: epoch 49:	0.00629682  	0.10058475  	0.04728495  	0.03566935  	0.03606043  
2023-06-02 20:45:42.573: [iter 50 : loss : 0.4216 = 0.0061 + 0.4006 + 0.0149, time: 203.166644]
2023-06-02 20:46:31.579: epoch 50:	0.00630761  	0.10071196  	0.04738775  	0.03577841  	0.03617166  
2023-06-02 20:46:31.579: Found a better model.
2023-06-02 20:46:31.580: Save model to file as pretrain.
2023-06-02 20:50:02.498: [iter 51 : loss : 0.4214 = 0.0059 + 0.4006 + 0.0149, time: 205.144497]
2023-06-02 20:50:50.143: epoch 51:	0.00630576  	0.10066636  	0.04740159  	0.03579718  	0.03619417  
2023-06-02 20:54:15.152: [iter 52 : loss : 0.4212 = 0.0058 + 0.4005 + 0.0149, time: 203.471531]
2023-06-02 20:55:00.786: epoch 52:	0.00632065  	0.10082760  	0.04745568  	0.03579903  	0.03619716  
2023-06-02 20:55:00.786: Found a better model.
2023-06-02 20:55:00.786: Save model to file as pretrain.
2023-06-02 20:58:50.960: [iter 53 : loss : 0.4212 = 0.0058 + 0.4005 + 0.0149, time: 224.390954]
2023-06-02 20:59:40.533: epoch 53:	0.00632251  	0.10097744  	0.04752761  	0.03587718  	0.03625901  
2023-06-02 20:59:40.533: Found a better model.
2023-06-02 20:59:40.533: Save model to file as pretrain.
2023-06-02 21:03:29.955: [iter 54 : loss : 0.4213 = 0.0059 + 0.4005 + 0.0149, time: 223.639902]
2023-06-02 21:04:18.187: epoch 54:	0.00633498  	0.10120612  	0.04767482  	0.03598727  	0.03638082  
2023-06-02 21:04:18.187: Found a better model.
2023-06-02 21:04:18.187: Save model to file as pretrain.
2023-06-02 21:07:47.373: [iter 55 : loss : 0.4211 = 0.0057 + 0.4005 + 0.0149, time: 203.485314]
2023-06-02 21:08:35.553: epoch 55:	0.00634186  	0.10125806  	0.04770978  	0.03601575  	0.03640316  
2023-06-02 21:08:35.553: Found a better model.
2023-06-02 21:08:35.553: Save model to file as pretrain.
2023-06-02 21:12:29.755: [iter 56 : loss : 0.4211 = 0.0057 + 0.4005 + 0.0149, time: 228.465328]
2023-06-02 21:13:19.159: epoch 56:	0.00633889  	0.10121460  	0.04771078  	0.03603779  	0.03641984  
2023-06-02 21:16:52.279: [iter 57 : loss : 0.4210 = 0.0056 + 0.4005 + 0.0149, time: 211.583227]
2023-06-02 21:17:40.965: epoch 57:	0.00634987  	0.10149366  	0.04785433  	0.03615608  	0.03655420  
2023-06-02 21:17:40.965: Found a better model.
2023-06-02 21:17:40.965: Save model to file as pretrain.
2023-06-02 21:21:10.843: [iter 58 : loss : 0.4211 = 0.0057 + 0.4005 + 0.0149, time: 203.945034]
2023-06-02 21:21:56.760: epoch 58:	0.00634801  	0.10138354  	0.04783309  	0.03616678  	0.03655614  
2023-06-02 21:25:25.402: [iter 59 : loss : 0.4210 = 0.0056 + 0.4005 + 0.0148, time: 207.097481]
2023-06-02 21:26:14.232: epoch 59:	0.00635583  	0.10154539  	0.04779730  	0.03605228  	0.03644455  
2023-06-02 21:26:14.232: Found a better model.
2023-06-02 21:26:14.232: Save model to file as pretrain.
2023-06-02 21:29:48.646: [iter 60 : loss : 0.4209 = 0.0055 + 0.4005 + 0.0149, time: 208.729079]
2023-06-02 21:30:35.140: epoch 60:	0.00635955  	0.10162235  	0.04780930  	0.03602888  	0.03643438  
2023-06-02 21:30:35.140: Found a better model.
2023-06-02 21:30:35.141: Save model to file as pretrain.
2023-06-02 21:34:27.982: [iter 61 : loss : 0.4209 = 0.0056 + 0.4005 + 0.0148, time: 227.125525]
2023-06-02 21:35:18.333: epoch 61:	0.00636923  	0.10172640  	0.04793343  	0.03617768  	0.03656375  
2023-06-02 21:35:18.334: Found a better model.
2023-06-02 21:35:18.334: Save model to file as pretrain.
2023-06-02 21:38:50.225: [iter 62 : loss : 0.4210 = 0.0056 + 0.4005 + 0.0149, time: 206.015242]
2023-06-02 21:39:36.799: epoch 62:	0.00637984  	0.10193107  	0.04806958  	0.03628947  	0.03667868  
2023-06-02 21:39:36.799: Found a better model.
2023-06-02 21:39:36.799: Save model to file as pretrain.
2023-06-02 21:43:30.669: [iter 63 : loss : 0.4207 = 0.0053 + 0.4005 + 0.0149, time: 228.108106]
2023-06-02 21:44:19.884: epoch 63:	0.00636681  	0.10172113  	0.04805339  	0.03630863  	0.03670375  
2023-06-02 21:47:46.460: [iter 64 : loss : 0.4207 = 0.0054 + 0.4005 + 0.0148, time: 205.029680]
2023-06-02 21:48:34.338: epoch 64:	0.00637277  	0.10181925  	0.04805733  	0.03629837  	0.03668536  
2023-06-02 21:52:22.727: [iter 65 : loss : 0.4208 = 0.0055 + 0.4004 + 0.0149, time: 226.837975]
2023-06-02 21:53:12.166: epoch 65:	0.00638617  	0.10215313  	0.04811218  	0.03627716  	0.03667670  
2023-06-02 21:53:12.167: Found a better model.
2023-06-02 21:53:12.167: Save model to file as pretrain.
2023-06-02 21:56:41.027: [iter 66 : loss : 0.4207 = 0.0054 + 0.4004 + 0.0148, time: 203.081324]
2023-06-02 21:57:29.219: epoch 66:	0.00639361  	0.10211769  	0.04811814  	0.03624917  	0.03664433  
2023-06-02 22:00:53.521: [iter 67 : loss : 0.4207 = 0.0054 + 0.4004 + 0.0149, time: 202.772901]
2023-06-02 22:01:42.933: epoch 67:	0.00640069  	0.10231457  	0.04815689  	0.03624671  	0.03663887  
2023-06-02 22:01:42.933: Found a better model.
2023-06-02 22:01:42.933: Save model to file as pretrain.
2023-06-02 22:05:11.879: [iter 68 : loss : 0.4207 = 0.0054 + 0.4004 + 0.0149, time: 203.191145]
2023-06-02 22:06:01.038: epoch 68:	0.00640590  	0.10243361  	0.04826465  	0.03638515  	0.03677477  
2023-06-02 22:06:01.038: Found a better model.
2023-06-02 22:06:01.038: Save model to file as pretrain.
2023-06-02 22:09:53.601: [iter 69 : loss : 0.4207 = 0.0054 + 0.4004 + 0.0149, time: 226.683209]
2023-06-02 22:10:43.017: epoch 69:	0.00641633  	0.10252276  	0.04834709  	0.03646442  	0.03684319  
2023-06-02 22:10:43.018: Found a better model.
2023-06-02 22:10:43.018: Save model to file as pretrain.
2023-06-02 22:14:30.598: [iter 70 : loss : 0.4207 = 0.0054 + 0.4004 + 0.0149, time: 221.807383]
2023-06-02 22:15:19.639: epoch 70:	0.00643251  	0.10283653  	0.04848732  	0.03652494  	0.03692401  
2023-06-02 22:15:19.639: Found a better model.
2023-06-02 22:15:19.639: Save model to file as pretrain.
2023-06-02 22:18:51.846: [iter 71 : loss : 0.4205 = 0.0053 + 0.4004 + 0.0148, time: 206.337472]
2023-06-02 22:19:40.840: epoch 71:	0.00642620  	0.10280000  	0.04854850  	0.03663938  	0.03704105  
2023-06-02 22:23:05.401: [iter 72 : loss : 0.4206 = 0.0053 + 0.4004 + 0.0148, time: 202.982961]
2023-06-02 22:23:54.456: epoch 72:	0.00641391  	0.10257716  	0.04847562  	0.03662226  	0.03703485  
2023-06-02 22:27:21.478: [iter 73 : loss : 0.4205 = 0.0052 + 0.4004 + 0.0149, time: 205.449920]
2023-06-02 22:27:57.809: epoch 73:	0.00642172  	0.10262212  	0.04849089  	0.03661847  	0.03702014  
2023-06-02 22:31:42.440: [iter 74 : loss : 0.4206 = 0.0054 + 0.4004 + 0.0149, time: 223.244852]
2023-06-02 22:32:32.122: epoch 74:	0.00642228  	0.10262314  	0.04853173  	0.03667447  	0.03708010  
2023-06-02 22:36:19.532: [iter 75 : loss : 0.4205 = 0.0052 + 0.4004 + 0.0149, time: 225.851522]
2023-06-02 22:37:06.812: epoch 75:	0.00643680  	0.10286457  	0.04861601  	0.03673657  	0.03713718  
2023-06-02 22:37:06.812: Found a better model.
2023-06-02 22:37:06.812: Save model to file as pretrain.
2023-06-02 22:40:46.363: [iter 76 : loss : 0.4205 = 0.0052 + 0.4004 + 0.0148, time: 213.999590]
2023-06-02 22:41:35.162: epoch 76:	0.00642693  	0.10275600  	0.04857092  	0.03667738  	0.03708602  
2023-06-02 22:45:02.972: [iter 77 : loss : 0.4205 = 0.0052 + 0.4004 + 0.0149, time: 206.213009]
2023-06-02 22:45:53.012: epoch 77:	0.00641763  	0.10254904  	0.04852448  	0.03669525  	0.03708834  
2023-06-02 22:49:20.675: [iter 78 : loss : 0.4205 = 0.0052 + 0.4004 + 0.0148, time: 206.099138]
2023-06-02 22:50:10.714: epoch 78:	0.00642488  	0.10267852  	0.04856443  	0.03670502  	0.03709710  
2023-06-02 22:53:36.242: [iter 79 : loss : 0.4204 = 0.0052 + 0.4004 + 0.0148, time: 203.946320]
2023-06-02 22:54:25.633: epoch 79:	0.00643791  	0.10294092  	0.04863705  	0.03674660  	0.03714001  
2023-06-02 22:54:25.633: Found a better model.
2023-06-02 22:54:25.633: Save model to file as pretrain.
2023-06-02 22:57:56.568: [iter 80 : loss : 0.4204 = 0.0052 + 0.4004 + 0.0148, time: 205.072466]
2023-06-02 22:58:43.470: epoch 80:	0.00644648  	0.10307901  	0.04870309  	0.03679447  	0.03718362  
2023-06-02 22:58:43.470: Found a better model.
2023-06-02 22:58:43.470: Save model to file as pretrain.
2023-06-02 23:02:29.232: [iter 81 : loss : 0.4204 = 0.0052 + 0.4004 + 0.0148, time: 219.800444]
2023-06-02 23:03:18.218: epoch 81:	0.00645077  	0.10312667  	0.04873254  	0.03682851  	0.03721750  
2023-06-02 23:03:18.218: Found a better model.
2023-06-02 23:03:18.218: Save model to file as pretrain.
2023-06-02 23:06:50.353: [iter 82 : loss : 0.4204 = 0.0051 + 0.4004 + 0.0148, time: 206.310622]
2023-06-02 23:07:29.027: epoch 82:	0.00646640  	0.10339872  	0.04875821  	0.03679074  	0.03717579  
2023-06-02 23:07:29.027: Found a better model.
2023-06-02 23:07:29.027: Save model to file as pretrain.
2023-06-02 23:11:01.039: [iter 83 : loss : 0.4204 = 0.0052 + 0.4004 + 0.0148, time: 206.151356]
2023-06-02 23:11:50.829: epoch 83:	0.00646770  	0.10345037  	0.04879831  	0.03680721  	0.03720017  
2023-06-02 23:11:50.829: Found a better model.
2023-06-02 23:11:50.829: Save model to file as pretrain.
2023-06-02 23:15:22.699: [iter 84 : loss : 0.4203 = 0.0051 + 0.4004 + 0.0148, time: 206.065484]
2023-06-02 23:16:12.320: epoch 84:	0.00647999  	0.10364176  	0.04887978  	0.03687069  	0.03726356  
2023-06-02 23:16:12.320: Found a better model.
2023-06-02 23:16:12.320: Save model to file as pretrain.
2023-06-02 23:19:44.474: [iter 85 : loss : 0.4203 = 0.0051 + 0.4004 + 0.0148, time: 206.304455]
2023-06-02 23:20:32.921: epoch 85:	0.00647831  	0.10362482  	0.04887660  	0.03685340  	0.03727286  
2023-06-02 23:23:58.875: [iter 86 : loss : 0.4203 = 0.0051 + 0.4004 + 0.0148, time: 204.387555]
2023-06-02 23:24:54.695: epoch 86:	0.00649097  	0.10373550  	0.04895551  	0.03692814  	0.03733565  
2023-06-02 23:24:54.695: Found a better model.
2023-06-02 23:24:54.695: Save model to file as pretrain.
2023-06-02 23:28:46.471: [iter 87 : loss : 0.4203 = 0.0051 + 0.4004 + 0.0148, time: 225.831268]
2023-06-02 23:29:37.331: epoch 87:	0.00647962  	0.10356544  	0.04895028  	0.03698024  	0.03737882  
2023-06-02 23:33:03.336: [iter 88 : loss : 0.4203 = 0.0051 + 0.4004 + 0.0148, time: 204.407279]
2023-06-02 23:33:54.487: epoch 88:	0.00647124  	0.10350192  	0.04893236  	0.03697887  	0.03737295  
2023-06-02 23:37:20.699: [iter 89 : loss : 0.4204 = 0.0051 + 0.4004 + 0.0148, time: 204.637464]
2023-06-02 23:38:13.959: epoch 89:	0.00649301  	0.10377803  	0.04905032  	0.03705576  	0.03745468  
2023-06-02 23:38:14.017: Found a better model.
2023-06-02 23:38:14.017: Save model to file as pretrain.
2023-06-02 23:41:53.679: [iter 90 : loss : 0.4203 = 0.0051 + 0.4004 + 0.0148, time: 209.829722]
2023-06-02 23:42:57.392: epoch 90:	0.00648911  	0.10376196  	0.04902654  	0.03702722  	0.03744136  
2023-06-02 23:46:25.857: [iter 91 : loss : 0.4203 = 0.0050 + 0.4004 + 0.0148, time: 206.910506]
2023-06-02 23:47:11.550: epoch 91:	0.00648743  	0.10368372  	0.04900545  	0.03698797  	0.03740537  
2023-06-02 23:50:39.310: [iter 92 : loss : 0.4203 = 0.0051 + 0.4004 + 0.0148, time: 206.219166]
2023-06-02 23:51:28.972: epoch 92:	0.00648761  	0.10378054  	0.04904206  	0.03700831  	0.03742090  
2023-06-02 23:51:28.972: Found a better model.
2023-06-02 23:51:28.972: Save model to file as pretrain.
2023-06-02 23:55:17.721: [iter 93 : loss : 0.4203 = 0.0051 + 0.4004 + 0.0148, time: 225.187966]
2023-06-02 23:56:04.552: epoch 93:	0.00649432  	0.10390781  	0.04912288  	0.03709439  	0.03751087  
2023-06-02 23:56:04.552: Found a better model.
2023-06-02 23:56:04.552: Save model to file as pretrain.
2023-06-02 23:59:35.535: [iter 94 : loss : 0.4202 = 0.0050 + 0.4004 + 0.0148, time: 208.390460]
2023-06-03 00:00:25.978: epoch 94:	0.00648836  	0.10381669  	0.04911487  	0.03709464  	0.03751421  
2023-06-03 00:03:53.493: [iter 95 : loss : 0.4202 = 0.0050 + 0.4004 + 0.0148, time: 205.975605]
2023-06-03 00:04:42.592: epoch 95:	0.00649599  	0.10393056  	0.04921737  	0.03721764  	0.03763698  
2023-06-03 00:04:42.592: Found a better model.
2023-06-03 00:04:42.592: Save model to file as pretrain.
2023-06-03 00:08:08.001: [iter 96 : loss : 0.4202 = 0.0050 + 0.4004 + 0.0148, time: 202.878171]
2023-06-03 00:08:57.293: epoch 96:	0.00649543  	0.10388871  	0.04919541  	0.03718122  	0.03761187  
2023-06-03 00:12:24.050: [iter 97 : loss : 0.4202 = 0.0050 + 0.4004 + 0.0148, time: 205.223063]
2023-06-03 00:13:13.896: epoch 97:	0.00650288  	0.10405696  	0.04917889  	0.03712245  	0.03754958  
2023-06-03 00:13:13.896: Found a better model.
2023-06-03 00:13:13.896: Save model to file as pretrain.
2023-06-03 00:16:41.584: [iter 98 : loss : 0.4202 = 0.0050 + 0.4004 + 0.0148, time: 205.126189]
2023-06-03 00:17:20.158: epoch 98:	0.00650474  	0.10417643  	0.04921940  	0.03712151  	0.03754203  
2023-06-03 00:17:20.158: Found a better model.
2023-06-03 00:17:20.158: Save model to file as pretrain.
2023-06-03 00:20:47.372: [iter 99 : loss : 0.4202 = 0.0050 + 0.4004 + 0.0148, time: 204.781370]
2023-06-03 00:21:38.264: epoch 99:	0.00650957  	0.10422458  	0.04925472  	0.03717178  	0.03759357  
2023-06-03 00:21:38.264: Found a better model.
2023-06-03 00:21:38.264: Save model to file as pretrain.
2023-06-03 00:25:08.677: [iter 100 : loss : 0.4201 = 0.0049 + 0.4004 + 0.0148, time: 206.135858]
2023-06-03 00:25:57.916: epoch 100:	0.00651255  	0.10421509  	0.04930241  	0.03722407  	0.03765320  
2023-06-03 00:29:44.848: [iter 101 : loss : 0.4202 = 0.0050 + 0.4004 + 0.0148, time: 225.380419]
2023-06-03 00:30:33.983: epoch 101:	0.00652930  	0.10452017  	0.04932973  	0.03720269  	0.03762325  
2023-06-03 00:30:33.983: Found a better model.
2023-06-03 00:30:33.983: Save model to file as pretrain.
2023-06-03 00:34:28.156: [iter 102 : loss : 0.4202 = 0.0050 + 0.4004 + 0.0148, time: 228.161886]
2023-06-03 00:35:16.766: epoch 102:	0.00652651  	0.10447188  	0.04931055  	0.03715537  	0.03759178  
2023-06-03 00:38:42.334: [iter 103 : loss : 0.4202 = 0.0050 + 0.4004 + 0.0148, time: 204.033453]
2023-06-03 00:39:30.706: epoch 103:	0.00653452  	0.10455515  	0.04938476  	0.03727243  	0.03769109  
2023-06-03 00:39:30.706: Found a better model.
2023-06-03 00:39:30.706: Save model to file as pretrain.
2023-06-03 00:43:24.623: [iter 104 : loss : 0.4201 = 0.0049 + 0.4004 + 0.0148, time: 228.059424]
2023-06-03 00:44:14.087: epoch 104:	0.00651349  	0.10428259  	0.04938547  	0.03734065  	0.03776436  
2023-06-03 00:47:42.841: [iter 105 : loss : 0.4201 = 0.0050 + 0.4004 + 0.0148, time: 207.206662]
2023-06-03 00:48:32.726: epoch 105:	0.00652615  	0.10443054  	0.04942067  	0.03737712  	0.03780324  
2023-06-03 00:51:57.984: [iter 106 : loss : 0.4202 = 0.0050 + 0.4004 + 0.0148, time: 203.656226]
2023-06-03 00:52:47.001: epoch 106:	0.00654867  	0.10477030  	0.04947744  	0.03734826  	0.03778583  
2023-06-03 00:52:47.001: Found a better model.
2023-06-03 00:52:47.001: Save model to file as pretrain.
2023-06-03 00:56:17.336: [iter 107 : loss : 0.4201 = 0.0049 + 0.4004 + 0.0148, time: 204.651368]
2023-06-03 00:57:04.270: epoch 107:	0.00652875  	0.10443354  	0.04939407  	0.03730539  	0.03773206  
2023-06-03 01:00:48.652: [iter 108 : loss : 0.4201 = 0.0050 + 0.4004 + 0.0148, time: 222.798923]
2023-06-03 01:01:37.820: epoch 108:	0.00653713  	0.10451194  	0.04940591  	0.03730092  	0.03773034  
2023-06-03 01:05:02.446: [iter 109 : loss : 0.4201 = 0.0050 + 0.4004 + 0.0148, time: 203.071548]
2023-06-03 01:05:46.085: epoch 109:	0.00652576  	0.10436019  	0.04939691  	0.03731126  	0.03776790  
2023-06-03 01:09:14.480: [iter 110 : loss : 0.4201 = 0.0049 + 0.4004 + 0.0148, time: 207.030096]
2023-06-03 01:10:03.855: epoch 110:	0.00654401  	0.10466602  	0.04946817  	0.03731378  	0.03777214  
2023-06-03 01:13:26.088: [iter 111 : loss : 0.4202 = 0.0050 + 0.4004 + 0.0148, time: 200.678110]
2023-06-03 01:14:14.915: epoch 111:	0.00654904  	0.10477205  	0.04954723  	0.03740037  	0.03785889  
2023-06-03 01:14:14.915: Found a better model.
2023-06-03 01:14:14.915: Save model to file as pretrain.
2023-06-03 01:17:45.625: [iter 112 : loss : 0.4200 = 0.0049 + 0.4003 + 0.0148, time: 204.832688]
2023-06-03 01:18:32.106: epoch 112:	0.00653787  	0.10458404  	0.04948335  	0.03738094  	0.03782614  
2023-06-03 01:21:56.631: [iter 113 : loss : 0.4201 = 0.0049 + 0.4004 + 0.0148, time: 202.966315]
2023-06-03 01:22:47.028: epoch 113:	0.00655257  	0.10489254  	0.04955499  	0.03738943  	0.03783289  
2023-06-03 01:22:47.028: Found a better model.
2023-06-03 01:22:47.028: Save model to file as pretrain.
2023-06-03 01:26:16.550: [iter 114 : loss : 0.4200 = 0.0048 + 0.4004 + 0.0148, time: 203.734363]
2023-06-03 01:27:04.752: epoch 114:	0.00654587  	0.10477015  	0.04958415  	0.03748117  	0.03790628  
2023-06-03 01:30:31.368: [iter 115 : loss : 0.4200 = 0.0049 + 0.4004 + 0.0148, time: 205.062533]
2023-06-03 01:31:20.888: epoch 115:	0.00654271  	0.10480071  	0.04951957  	0.03737309  	0.03779194  
2023-06-03 01:34:46.470: [iter 116 : loss : 0.4201 = 0.0049 + 0.4003 + 0.0148, time: 204.034395]
2023-06-03 01:35:36.376: epoch 116:	0.00655556  	0.10494035  	0.04957817  	0.03738391  	0.03781268  
2023-06-03 01:35:36.376: Found a better model.
2023-06-03 01:35:36.376: Save model to file as pretrain.
2023-06-03 01:39:04.462: [iter 117 : loss : 0.4201 = 0.0049 + 0.4004 + 0.0148, time: 203.926305]
2023-06-03 01:39:52.466: epoch 117:	0.00655964  	0.10499201  	0.04962982  	0.03744835  	0.03786527  
2023-06-03 01:39:52.466: Found a better model.
2023-06-03 01:39:52.466: Save model to file as pretrain.
2023-06-03 01:43:17.806: [iter 118 : loss : 0.4201 = 0.0050 + 0.4004 + 0.0148, time: 202.784558]
2023-06-03 01:44:06.720: epoch 118:	0.00656114  	0.10503454  	0.04963497  	0.03743289  	0.03785530  
2023-06-03 01:44:06.721: Found a better model.
2023-06-03 01:44:06.721: Save model to file as pretrain.
2023-06-03 01:47:31.200: [iter 119 : loss : 0.4200 = 0.0049 + 0.4003 + 0.0148, time: 201.939007]
2023-06-03 01:48:18.936: epoch 119:	0.00655927  	0.10499895  	0.04963530  	0.03743779  	0.03784707  
2023-06-03 01:52:05.991: [iter 120 : loss : 0.4201 = 0.0050 + 0.4004 + 0.0148, time: 225.478238]
2023-06-03 01:52:54.644: epoch 120:	0.00656449  	0.10513153  	0.04965872  	0.03742968  	0.03786397  
2023-06-03 01:52:54.644: Found a better model.
2023-06-03 01:52:54.644: Save model to file as pretrain.
2023-06-03 01:56:23.376: [iter 121 : loss : 0.4200 = 0.0049 + 0.4003 + 0.0148, time: 206.144970]
2023-06-03 01:57:11.322: epoch 121:	0.00655667  	0.10498060  	0.04958103  	0.03736813  	0.03780156  
2023-06-03 02:00:35.747: [iter 122 : loss : 0.4201 = 0.0049 + 0.4003 + 0.0148, time: 202.899748]
2023-06-03 02:01:25.144: epoch 122:	0.00655760  	0.10497120  	0.04960534  	0.03741084  	0.03784314  
2023-06-03 02:04:51.934: [iter 123 : loss : 0.4200 = 0.0049 + 0.4003 + 0.0148, time: 205.245996]
2023-06-03 02:05:40.530: epoch 123:	0.00656802  	0.10511807  	0.04967292  	0.03742211  	0.03787678  
2023-06-03 02:09:06.001: [iter 124 : loss : 0.4200 = 0.0048 + 0.4003 + 0.0148, time: 203.900505]
2023-06-03 02:09:52.488: epoch 124:	0.00655704  	0.10490085  	0.04964054  	0.03746095  	0.03790656  
2023-06-03 02:13:18.708: [iter 125 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0148, time: 204.651819]
2023-06-03 02:14:08.016: epoch 125:	0.00655890  	0.10493573  	0.04966209  	0.03747915  	0.03793219  
2023-06-03 02:17:33.702: [iter 126 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0148, time: 204.112993]
2023-06-03 02:18:20.649: epoch 126:	0.00656989  	0.10522194  	0.04970733  	0.03747628  	0.03791843  
2023-06-03 02:18:20.649: Found a better model.
2023-06-03 02:18:20.649: Save model to file as pretrain.
2023-06-03 02:21:49.965: [iter 127 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0148, time: 203.701394]
2023-06-03 02:22:39.761: epoch 127:	0.00656710  	0.10519917  	0.04972192  	0.03750689  	0.03792776  
2023-06-03 02:26:04.383: [iter 128 : loss : 0.4200 = 0.0049 + 0.4003 + 0.0148, time: 203.044327]
2023-06-03 02:26:53.168: epoch 128:	0.00658720  	0.10551442  	0.04981447  	0.03754885  	0.03797738  
2023-06-03 02:26:53.168: Found a better model.
2023-06-03 02:26:53.168: Save model to file as pretrain.
2023-06-03 02:30:25.430: [iter 129 : loss : 0.4200 = 0.0049 + 0.4003 + 0.0148, time: 206.381212]
2023-06-03 02:31:14.067: epoch 129:	0.00660469  	0.10576019  	0.04989924  	0.03759316  	0.03802109  
2023-06-03 02:31:14.067: Found a better model.
2023-06-03 02:31:14.067: Save model to file as pretrain.
2023-06-03 02:34:43.869: [iter 130 : loss : 0.4200 = 0.0049 + 0.4003 + 0.0148, time: 203.835901]
2023-06-03 02:35:32.720: epoch 130:	0.00658142  	0.10542256  	0.04977430  	0.03751515  	0.03794405  
2023-06-03 02:39:00.248: [iter 131 : loss : 0.4199 = 0.0049 + 0.4003 + 0.0148, time: 205.949158]
2023-06-03 02:39:46.723: epoch 131:	0.00658049  	0.10543026  	0.04985847  	0.03761556  	0.03805006  
2023-06-03 02:43:11.371: [iter 132 : loss : 0.4200 = 0.0049 + 0.4003 + 0.0148, time: 203.082321]
2023-06-03 02:44:00.646: epoch 132:	0.00658049  	0.10539089  	0.04982353  	0.03758927  	0.03803667  
2023-06-03 02:47:27.347: [iter 133 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0148, time: 205.118404]
2023-06-03 02:48:16.145: epoch 133:	0.00658272  	0.10544740  	0.04979676  	0.03752759  	0.03797233  
2023-06-03 02:51:41.434: [iter 134 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0148, time: 203.712510]
2023-06-03 02:52:30.677: epoch 134:	0.00658402  	0.10539967  	0.04979896  	0.03752939  	0.03797756  
2023-06-03 02:55:56.157: [iter 135 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0148, time: 203.859177]
2023-06-03 02:56:45.226: epoch 135:	0.00658272  	0.10541222  	0.04982053  	0.03756884  	0.03801504  
2023-06-03 03:00:12.120: [iter 136 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0148, time: 205.299106]
2023-06-03 03:00:58.489: epoch 136:	0.00659705  	0.10569378  	0.04990357  	0.03763468  	0.03807022  
2023-06-03 03:04:24.937: [iter 137 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0148, time: 204.864627]
2023-06-03 03:05:14.489: epoch 137:	0.00658663  	0.10543766  	0.04983705  	0.03760819  	0.03805094  
2023-06-03 03:08:40.025: [iter 138 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0148, time: 203.940619]
2023-06-03 03:09:27.119: epoch 138:	0.00660394  	0.10572839  	0.05000421  	0.03775811  	0.03820550  
2023-06-03 03:12:51.479: [iter 139 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0148, time: 202.791707]
2023-06-03 03:13:40.914: epoch 139:	0.00659836  	0.10563817  	0.05001136  	0.03779845  	0.03825978  
2023-06-03 03:17:06.008: [iter 140 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0148, time: 203.498050]
2023-06-03 03:17:56.129: epoch 140:	0.00660078  	0.10560864  	0.05001546  	0.03782507  	0.03828969  
2023-06-03 03:21:34.295: [iter 141 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0148, time: 216.604208]
2023-06-03 03:22:22.762: epoch 141:	0.00661288  	0.10588993  	0.05005107  	0.03779865  	0.03824469  
2023-06-03 03:22:22.765: Found a better model.
2023-06-03 03:22:22.765: Save model to file as pretrain.
2023-06-03 03:26:04.050: [iter 142 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0148, time: 216.192970]
2023-06-03 03:26:52.626: epoch 142:	0.00660655  	0.10567747  	0.05002172  	0.03777904  	0.03823333  
2023-06-03 03:30:16.971: [iter 143 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0148, time: 202.772187]
2023-06-03 03:31:02.354: epoch 143:	0.00660971  	0.10578407  	0.05012106  	0.03789864  	0.03835611  
2023-06-03 03:34:29.233: [iter 144 : loss : 0.4199 = 0.0049 + 0.4003 + 0.0148, time: 205.307657]
2023-06-03 03:35:18.210: epoch 144:	0.00661548  	0.10589510  	0.05019932  	0.03798802  	0.03843036  
2023-06-03 03:35:18.211: Found a better model.
2023-06-03 03:35:18.211: Save model to file as pretrain.
2023-06-03 03:38:44.494: [iter 145 : loss : 0.4198 = 0.0048 + 0.4003 + 0.0148, time: 203.693997]
2023-06-03 03:39:30.718: epoch 145:	0.00662814  	0.10608824  	0.05024700  	0.03799614  	0.03844035  
2023-06-03 03:39:30.718: Found a better model.
2023-06-03 03:39:30.718: Save model to file as pretrain.
2023-06-03 03:42:58.299: [iter 146 : loss : 0.4198 = 0.0048 + 0.4003 + 0.0148, time: 205.042803]
2023-06-03 03:43:47.237: epoch 146:	0.00662517  	0.10598617  	0.05021897  	0.03796149  	0.03841938  
2023-06-03 03:47:12.832: [iter 147 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0148, time: 204.042843]
2023-06-03 03:48:02.388: epoch 147:	0.00662237  	0.10597755  	0.05018080  	0.03791937  	0.03837220  
2023-06-03 03:51:27.614: [iter 148 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0148, time: 203.689202]
2023-06-03 03:52:17.210: epoch 148:	0.00663020  	0.10613368  	0.05016368  	0.03784773  	0.03830888  
2023-06-03 03:52:17.211: Found a better model.
2023-06-03 03:52:17.211: Save model to file as pretrain.
2023-06-03 03:55:42.801: [iter 149 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0148, time: 203.052004]
2023-06-03 03:56:31.345: epoch 149:	0.00661716  	0.10596762  	0.05012939  	0.03784959  	0.03829280  
2023-06-03 03:59:56.564: [iter 150 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0148, time: 203.670700]
2023-06-03 04:00:39.140: epoch 150:	0.00661866  	0.10593358  	0.05012093  	0.03786514  	0.03829510  
2023-06-03 04:04:14.195: [iter 151 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0147, time: 213.701327]
2023-06-03 04:05:04.507: epoch 151:	0.00662759  	0.10608613  	0.05015346  	0.03785651  	0.03829629  
2023-06-03 04:08:50.121: [iter 152 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0148, time: 224.080149]
2023-06-03 04:09:39.520: epoch 152:	0.00662777  	0.10606875  	0.05013312  	0.03782263  	0.03825365  
2023-06-03 04:13:02.602: [iter 153 : loss : 0.4199 = 0.0049 + 0.4003 + 0.0147, time: 201.518930]
2023-06-03 04:13:51.908: epoch 153:	0.00661921  	0.10596947  	0.05017085  	0.03790481  	0.03833044  
2023-06-03 04:17:17.436: [iter 154 : loss : 0.4198 = 0.0047 + 0.4003 + 0.0147, time: 203.990000]
2023-06-03 04:18:06.285: epoch 154:	0.00662591  	0.10610504  	0.05020160  	0.03790153  	0.03833019  
2023-06-03 04:21:33.691: [iter 155 : loss : 0.4198 = 0.0048 + 0.4003 + 0.0147, time: 205.853648]
2023-06-03 04:22:20.696: epoch 155:	0.00663820  	0.10630099  	0.05030066  	0.03800117  	0.03844564  
2023-06-03 04:22:20.696: Found a better model.
2023-06-03 04:22:20.696: Save model to file as pretrain.
2023-06-03 04:25:46.005: [iter 156 : loss : 0.4198 = 0.0048 + 0.4003 + 0.0147, time: 202.732645]
2023-06-03 04:26:35.166: epoch 156:	0.00664453  	0.10642683  	0.05028146  	0.03793542  	0.03837954  
2023-06-03 04:26:35.166: Found a better model.
2023-06-03 04:26:35.166: Save model to file as pretrain.
2023-06-03 04:30:00.626: [iter 157 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0147, time: 202.880368]
2023-06-03 04:30:48.514: epoch 157:	0.00663541  	0.10633509  	0.05028600  	0.03794647  	0.03839623  
2023-06-03 04:34:16.051: [iter 158 : loss : 0.4198 = 0.0047 + 0.4003 + 0.0147, time: 206.016876]
2023-06-03 04:35:05.608: epoch 158:	0.00664490  	0.10638259  	0.05033073  	0.03800334  	0.03845656  
2023-06-03 04:38:33.125: [iter 159 : loss : 0.4198 = 0.0048 + 0.4003 + 0.0147, time: 205.938130]
2023-06-03 04:39:23.751: epoch 159:	0.00664359  	0.10625938  	0.05030153  	0.03799258  	0.03844736  
2023-06-03 04:42:51.225: [iter 160 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0147, time: 205.910391]
2023-06-03 04:43:39.284: epoch 160:	0.00663503  	0.10627467  	0.05026540  	0.03791013  	0.03835553  
2023-06-03 04:47:03.884: [iter 161 : loss : 0.4198 = 0.0047 + 0.4003 + 0.0147, time: 203.044414]
2023-06-03 04:47:53.716: epoch 161:	0.00664806  	0.10646483  	0.05032369  	0.03796742  	0.03842324  
2023-06-03 04:47:53.716: Found a better model.
2023-06-03 04:47:53.716: Save model to file as pretrain.
2023-06-03 04:51:22.639: [iter 162 : loss : 0.4198 = 0.0047 + 0.4003 + 0.0147, time: 206.373822]
2023-06-03 04:52:03.791: epoch 162:	0.00665029  	0.10651164  	0.05032374  	0.03795749  	0.03840547  
2023-06-03 04:52:03.792: Found a better model.
2023-06-03 04:52:03.792: Save model to file as pretrain.
2023-06-03 04:55:30.965: [iter 163 : loss : 0.4198 = 0.0048 + 0.4003 + 0.0147, time: 204.726305]
2023-06-03 04:56:20.977: epoch 163:	0.00665123  	0.10649695  	0.05037389  	0.03801501  	0.03845698  
2023-06-03 04:59:48.780: [iter 164 : loss : 0.4198 = 0.0048 + 0.4003 + 0.0147, time: 206.240869]
2023-06-03 05:00:37.340: epoch 164:	0.00664788  	0.10646210  	0.05036040  	0.03801494  	0.03845568  
2023-06-03 05:04:05.129: [iter 165 : loss : 0.4198 = 0.0048 + 0.4003 + 0.0147, time: 206.211481]
2023-06-03 05:04:53.886: epoch 165:	0.00664751  	0.10643504  	0.05040651  	0.03807427  	0.03852201  
2023-06-03 05:08:19.380: [iter 166 : loss : 0.4198 = 0.0047 + 0.4003 + 0.0147, time: 203.922292]
2023-06-03 05:09:09.576: epoch 166:	0.00665960  	0.10665172  	0.05043484  	0.03807634  	0.03853121  
2023-06-03 05:09:09.576: Found a better model.
2023-06-03 05:09:09.576: Save model to file as pretrain.
2023-06-03 05:12:36.193: [iter 167 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0147, time: 204.067118]
2023-06-03 05:13:21.663: epoch 167:	0.00665923  	0.10666359  	0.05048494  	0.03814392  	0.03860134  
2023-06-03 05:13:21.663: Found a better model.
2023-06-03 05:13:21.663: Save model to file as pretrain.
2023-06-03 05:16:51.206: [iter 168 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0147, time: 203.855836]
2023-06-03 05:17:40.180: epoch 168:	0.00665886  	0.10660311  	0.05042705  	0.03806328  	0.03851700  
2023-06-03 05:21:07.805: [iter 169 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 206.061668]
2023-06-03 05:21:57.175: epoch 169:	0.00666276  	0.10664023  	0.05043171  	0.03805184  	0.03850751  
2023-06-03 05:25:23.571: [iter 170 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0147, time: 204.861465]
2023-06-03 05:26:12.513: epoch 170:	0.00666835  	0.10679503  	0.05046024  	0.03806566  	0.03850478  
2023-06-03 05:26:12.514: Found a better model.
2023-06-03 05:26:12.514: Save model to file as pretrain.
2023-06-03 05:29:41.278: [iter 171 : loss : 0.4198 = 0.0047 + 0.4003 + 0.0147, time: 202.872119]
2023-06-03 05:30:30.959: epoch 171:	0.00665365  	0.10646232  	0.05037031  	0.03803978  	0.03849224  
2023-06-03 05:33:54.242: [iter 172 : loss : 0.4198 = 0.0048 + 0.4003 + 0.0147, time: 201.715052]
2023-06-03 05:34:31.041: epoch 172:	0.00668436  	0.10697968  	0.05055095  	0.03812829  	0.03858817  
2023-06-03 05:34:31.044: Found a better model.
2023-06-03 05:34:31.044: Save model to file as pretrain.
2023-06-03 05:38:25.654: [iter 173 : loss : 0.4198 = 0.0048 + 0.4003 + 0.0147, time: 228.950266]
2023-06-03 05:39:15.330: epoch 173:	0.00667951  	0.10687645  	0.05049660  	0.03808532  	0.03854410  
2023-06-03 05:42:44.146: [iter 174 : loss : 0.4198 = 0.0048 + 0.4003 + 0.0147, time: 207.268619]
2023-06-03 05:43:31.669: epoch 174:	0.00668287  	0.10695364  	0.05052984  	0.03812645  	0.03857134  
2023-06-03 05:46:56.155: [iter 175 : loss : 0.4197 = 0.0046 + 0.4003 + 0.0147, time: 202.939917]
2023-06-03 05:47:45.667: epoch 175:	0.00668715  	0.10709940  	0.05050825  	0.03806520  	0.03851387  
2023-06-03 05:47:45.667: Found a better model.
2023-06-03 05:47:45.667: Save model to file as pretrain.
2023-06-03 05:51:40.685: [iter 176 : loss : 0.4199 = 0.0048 + 0.4003 + 0.0147, time: 229.157366]
2023-06-03 05:52:27.783: epoch 176:	0.00668287  	0.10702004  	0.05055551  	0.03811605  	0.03856394  
2023-06-03 05:55:53.122: [iter 177 : loss : 0.4198 = 0.0048 + 0.4003 + 0.0147, time: 203.798546]
2023-06-03 05:56:42.868: epoch 177:	0.00667970  	0.10699704  	0.05051627  	0.03805757  	0.03850748  
2023-06-03 06:00:08.406: [iter 178 : loss : 0.4198 = 0.0048 + 0.4003 + 0.0147, time: 203.975346]
2023-06-03 06:00:56.707: epoch 178:	0.00667897  	0.10697727  	0.05051073  	0.03808826  	0.03854296  
2023-06-03 06:04:23.454: [iter 179 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 205.192174]
2023-06-03 06:05:10.798: epoch 179:	0.00667654  	0.10693420  	0.05055383  	0.03815118  	0.03858244  
2023-06-03 06:08:36.268: [iter 180 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 203.890337]
2023-06-03 06:09:25.661: epoch 180:	0.00667598  	0.10689905  	0.05055538  	0.03814551  	0.03859195  
2023-06-03 06:12:52.377: [iter 181 : loss : 0.4198 = 0.0048 + 0.4003 + 0.0147, time: 205.142498]
2023-06-03 06:13:38.721: epoch 181:	0.00669013  	0.10709311  	0.05059119  	0.03816345  	0.03860946  
2023-06-03 06:17:04.248: [iter 182 : loss : 0.4198 = 0.0047 + 0.4003 + 0.0147, time: 203.984055]
2023-06-03 06:17:53.410: epoch 182:	0.00668492  	0.10703782  	0.05051547  	0.03809924  	0.03854103  
2023-06-03 06:21:19.128: [iter 183 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 204.121732]
2023-06-03 06:22:07.362: epoch 183:	0.00666166  	0.10677172  	0.05048221  	0.03810589  	0.03854510  
2023-06-03 06:25:37.184: [iter 184 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 208.271468]
2023-06-03 06:26:14.591: epoch 184:	0.00666873  	0.10690534  	0.05044120  	0.03801133  	0.03844452  
2023-06-03 06:29:42.568: [iter 185 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 206.384023]
2023-06-03 06:30:32.160: epoch 185:	0.00668138  	0.10697398  	0.05051581  	0.03808141  	0.03854356  
2023-06-03 06:33:59.909: [iter 186 : loss : 0.4198 = 0.0047 + 0.4003 + 0.0147, time: 206.172709]
2023-06-03 06:34:47.862: epoch 186:	0.00668213  	0.10699371  	0.05060224  	0.03819764  	0.03864940  
2023-06-03 06:38:14.768: [iter 187 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 205.298946]
2023-06-03 06:39:04.996: epoch 187:	0.00668232  	0.10696065  	0.05060145  	0.03821031  	0.03866354  
2023-06-03 06:42:30.476: [iter 188 : loss : 0.4198 = 0.0048 + 0.4003 + 0.0147, time: 203.921814]
2023-06-03 06:43:18.584: epoch 188:	0.00669293  	0.10717738  	0.05066845  	0.03825331  	0.03869112  
2023-06-03 06:43:18.584: Found a better model.
2023-06-03 06:43:18.585: Save model to file as pretrain.
2023-06-03 06:46:47.979: [iter 189 : loss : 0.4198 = 0.0047 + 0.4003 + 0.0147, time: 205.866491]
2023-06-03 06:47:24.423: epoch 189:	0.00668548  	0.10703841  	0.05067419  	0.03828479  	0.03872202  
2023-06-03 06:50:49.911: [iter 190 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 203.902503]
2023-06-03 06:51:37.795: epoch 190:	0.00667785  	0.10703099  	0.05062002  	0.03820827  	0.03864168  
2023-06-03 06:55:04.756: [iter 191 : loss : 0.4198 = 0.0048 + 0.4003 + 0.0147, time: 205.385742]
2023-06-03 06:55:53.549: epoch 191:	0.00668920  	0.10724219  	0.05074796  	0.03834086  	0.03879932  
2023-06-03 06:55:53.549: Found a better model.
2023-06-03 06:55:53.549: Save model to file as pretrain.
2023-06-03 06:59:33.472: [iter 192 : loss : 0.4197 = 0.0046 + 0.4003 + 0.0147, time: 217.183586]
2023-06-03 07:00:22.995: epoch 192:	0.00669888  	0.10728907  	0.05075502  	0.03834487  	0.03879716  
2023-06-03 07:00:22.995: Found a better model.
2023-06-03 07:00:22.995: Save model to file as pretrain.
2023-06-03 07:03:49.669: [iter 193 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 204.096189]
2023-06-03 07:04:39.452: epoch 193:	0.00670484  	0.10740790  	0.05077375  	0.03834588  	0.03879700  
2023-06-03 07:04:39.452: Found a better model.
2023-06-03 07:04:39.452: Save model to file as pretrain.
2023-06-03 07:08:05.887: [iter 194 : loss : 0.4198 = 0.0048 + 0.4003 + 0.0147, time: 203.832742]
2023-06-03 07:08:51.697: epoch 194:	0.00670782  	0.10737906  	0.05081810  	0.03842147  	0.03887573  
2023-06-03 07:12:22.054: [iter 195 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 208.779120]
2023-06-03 07:13:11.128: epoch 195:	0.00670260  	0.10733151  	0.05071563  	0.03827039  	0.03874036  
2023-06-03 07:16:36.988: [iter 196 : loss : 0.4198 = 0.0048 + 0.4003 + 0.0147, time: 204.276047]
2023-06-03 07:17:24.395: epoch 196:	0.00670055  	0.10721698  	0.05064934  	0.03819481  	0.03866389  
2023-06-03 07:20:50.905: [iter 197 : loss : 0.4198 = 0.0048 + 0.4003 + 0.0147, time: 204.926706]
2023-06-03 07:21:41.396: epoch 197:	0.00669516  	0.10709945  	0.05058137  	0.03813776  	0.03861645  
2023-06-03 07:25:05.851: [iter 198 : loss : 0.4198 = 0.0048 + 0.4003 + 0.0147, time: 202.868327]
2023-06-03 07:25:54.898: epoch 198:	0.00670354  	0.10727267  	0.05072186  	0.03828212  	0.03874377  
2023-06-03 07:29:17.831: [iter 199 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 201.352470]
2023-06-03 07:29:54.259: epoch 199:	0.00671582  	0.10753524  	0.05077626  	0.03828751  	0.03874556  
2023-06-03 07:29:54.259: Found a better model.
2023-06-03 07:29:54.259: Save model to file as pretrain.
2023-06-03 07:33:23.124: [iter 200 : loss : 0.4198 = 0.0048 + 0.4003 + 0.0147, time: 206.277050]
2023-06-03 07:34:11.750: epoch 200:	0.00671378  	0.10750015  	0.05069860  	0.03819242  	0.03863299  
2023-06-03 07:37:36.204: [iter 201 : loss : 0.4198 = 0.0048 + 0.4003 + 0.0147, time: 202.879047]
2023-06-03 07:38:25.245: epoch 201:	0.00672215  	0.10770274  	0.05086015  	0.03833854  	0.03878644  
2023-06-03 07:38:25.246: Found a better model.
2023-06-03 07:38:25.246: Save model to file as pretrain.
2023-06-03 07:41:50.841: [iter 202 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 203.005397]
2023-06-03 07:42:28.100: epoch 202:	0.00673182  	0.10774469  	0.05086365  	0.03831890  	0.03877816  
2023-06-03 07:42:28.100: Found a better model.
2023-06-03 07:42:28.100: Save model to file as pretrain.
2023-06-03 07:45:54.725: [iter 203 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 204.056221]
2023-06-03 07:46:44.455: epoch 203:	0.00672792  	0.10774505  	0.05094501  	0.03845603  	0.03891008  
2023-06-03 07:46:44.455: Found a better model.
2023-06-03 07:46:44.455: Save model to file as pretrain.
2023-06-03 07:50:18.600: [iter 204 : loss : 0.4197 = 0.0046 + 0.4003 + 0.0147, time: 208.809721]
2023-06-03 07:51:06.689: epoch 204:	0.00673387  	0.10781489  	0.05093530  	0.03840800  	0.03887073  
2023-06-03 07:51:06.689: Found a better model.
2023-06-03 07:51:06.689: Save model to file as pretrain.
2023-06-03 07:55:01.373: [iter 205 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 228.793318]
2023-06-03 07:55:51.078: epoch 205:	0.00672625  	0.10773642  	0.05085129  	0.03833422  	0.03877170  
2023-06-03 07:59:16.777: [iter 206 : loss : 0.4197 = 0.0048 + 0.4003 + 0.0147, time: 204.127966]
2023-06-03 08:00:06.681: epoch 206:	0.00673946  	0.10798382  	0.05099483  	0.03844314  	0.03891385  
2023-06-03 08:00:06.681: Found a better model.
2023-06-03 08:00:06.681: Save model to file as pretrain.
2023-06-03 08:03:36.566: [iter 207 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 203.971583]
2023-06-03 08:04:25.078: epoch 207:	0.00672587  	0.10775553  	0.05087850  	0.03835023  	0.03881374  
2023-06-03 08:08:12.051: [iter 208 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 225.390332]
2023-06-03 08:09:01.895: epoch 208:	0.00672234  	0.10771224  	0.05084057  	0.03832726  	0.03878209  
2023-06-03 08:12:30.838: [iter 209 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 207.384801]
2023-06-03 08:13:21.192: epoch 209:	0.00671750  	0.10759971  	0.05081832  	0.03830838  	0.03876621  
2023-06-03 08:16:48.839: [iter 210 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 206.089567]
2023-06-03 08:17:38.698: epoch 210:	0.00672234  	0.10768940  	0.05090816  	0.03839549  	0.03885183  
2023-06-03 08:21:03.406: [iter 211 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 203.149654]
2023-06-03 08:21:50.822: epoch 211:	0.00671824  	0.10758770  	0.05084645  	0.03834661  	0.03880198  
2023-06-03 08:25:16.392: [iter 212 : loss : 0.4196 = 0.0046 + 0.4003 + 0.0147, time: 203.987362]
2023-06-03 08:26:05.892: epoch 212:	0.00671750  	0.10759765  	0.05083357  	0.03833183  	0.03880424  
2023-06-03 08:29:32.080: [iter 213 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 204.601104]
2023-06-03 08:30:21.712: epoch 213:	0.00671787  	0.10762221  	0.05083506  	0.03834199  	0.03879891  
2023-06-03 08:33:51.112: [iter 214 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 207.857390]
2023-06-03 08:34:40.868: epoch 214:	0.00673388  	0.10789540  	0.05089595  	0.03838050  	0.03882180  
2023-06-03 08:38:07.897: [iter 215 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 205.475198]
2023-06-03 08:38:57.384: epoch 215:	0.00672048  	0.10760278  	0.05080178  	0.03830269  	0.03874596  
2023-06-03 08:42:24.889: [iter 216 : loss : 0.4197 = 0.0048 + 0.4003 + 0.0147, time: 205.938654]
2023-06-03 08:43:09.883: epoch 216:	0.00672774  	0.10761490  	0.05078293  	0.03824310  	0.03869750  
2023-06-03 08:46:36.682: [iter 217 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 205.206398]
2023-06-03 08:47:26.906: epoch 217:	0.00673891  	0.10789839  	0.05087510  	0.03830105  	0.03874246  
2023-06-03 08:50:51.696: [iter 218 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 203.225522]
2023-06-03 08:51:40.486: epoch 218:	0.00674225  	0.10794843  	0.05084892  	0.03825017  	0.03870512  
2023-06-03 08:55:05.133: [iter 219 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0147, time: 203.074301]
2023-06-03 08:55:52.810: epoch 219:	0.00673704  	0.10795700  	0.05082131  	0.03821506  	0.03868046  
2023-06-03 08:59:20.626: [iter 220 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0147, time: 206.259614]
2023-06-03 09:00:10.726: epoch 220:	0.00672569  	0.10772754  	0.05077897  	0.03823246  	0.03870167  
2023-06-03 09:03:37.778: [iter 221 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0147, time: 205.465125]
2023-06-03 09:04:26.005: epoch 221:	0.00672588  	0.10779324  	0.05077734  	0.03821536  	0.03867904  
2023-06-03 09:07:52.718: [iter 222 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 205.165434]
2023-06-03 09:08:42.923: epoch 222:	0.00671136  	0.10763907  	0.05074872  	0.03820439  	0.03867735  
2023-06-03 09:12:10.772: [iter 223 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 206.295154]
2023-06-03 09:12:59.989: epoch 223:	0.00671806  	0.10770701  	0.05077240  	0.03822018  	0.03866993  
2023-06-03 09:16:24.515: [iter 224 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 202.934361]
2023-06-03 09:17:11.299: epoch 224:	0.00672960  	0.10787710  	0.05083818  	0.03825396  	0.03871356  
2023-06-03 09:20:36.735: [iter 225 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 203.850632]
2023-06-03 09:21:26.784: epoch 225:	0.00673090  	0.10801022  	0.05088008  	0.03828340  	0.03874727  
2023-06-03 09:21:26.784: Found a better model.
2023-06-03 09:21:26.784: Save model to file as pretrain.
2023-06-03 09:24:53.791: [iter 226 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 204.262339]
2023-06-03 09:25:42.880: epoch 226:	0.00673612  	0.10805432  	0.05094175  	0.03835951  	0.03880680  
2023-06-03 09:25:42.880: Found a better model.
2023-06-03 09:25:42.880: Save model to file as pretrain.
2023-06-03 09:29:11.556: [iter 227 : loss : 0.4197 = 0.0048 + 0.4003 + 0.0147, time: 206.090286]
2023-06-03 09:29:59.646: epoch 227:	0.00675529  	0.10828428  	0.05093864  	0.03826578  	0.03871946  
2023-06-03 09:29:59.656: Found a better model.
2023-06-03 09:29:59.656: Save model to file as pretrain.
2023-06-03 09:33:26.541: [iter 228 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0147, time: 204.320913]
2023-06-03 09:34:15.980: epoch 228:	0.00675045  	0.10824092  	0.05099549  	0.03834400  	0.03880407  
2023-06-03 09:37:41.356: [iter 229 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 203.835054]
2023-06-03 09:38:29.225: epoch 229:	0.00674077  	0.10815652  	0.05095213  	0.03833455  	0.03877864  
2023-06-03 09:41:54.070: [iter 230 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 203.300774]
2023-06-03 09:42:43.660: epoch 230:	0.00674114  	0.10808305  	0.05096361  	0.03835260  	0.03879758  
2023-06-03 09:46:09.062: [iter 231 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0147, time: 203.861209]
2023-06-03 09:46:58.650: epoch 231:	0.00674561  	0.10818145  	0.05103318  	0.03843361  	0.03887846  
2023-06-03 09:50:25.581: [iter 232 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0147, time: 205.373006]
2023-06-03 09:51:15.332: epoch 232:	0.00673854  	0.10812251  	0.05102129  	0.03844463  	0.03888508  
2023-06-03 09:54:41.014: [iter 233 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 204.128030]
2023-06-03 09:55:30.304: epoch 233:	0.00675119  	0.10827496  	0.05105320  	0.03843619  	0.03888347  
2023-06-03 09:58:54.846: [iter 234 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 202.980570]
2023-06-03 09:59:41.778: epoch 234:	0.00675771  	0.10829173  	0.05108757  	0.03847363  	0.03892379  
2023-06-03 09:59:41.778: Found a better model.
2023-06-03 09:59:41.780: Save model to file as pretrain.
2023-06-03 10:03:10.942: [iter 235 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0147, time: 206.608214]
2023-06-03 10:04:00.590: epoch 235:	0.00675567  	0.10826692  	0.05108210  	0.03846464  	0.03892687  
2023-06-03 10:07:50.267: [iter 236 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 228.136551]
2023-06-03 10:08:40.821: epoch 236:	0.00675474  	0.10821174  	0.05110630  	0.03851343  	0.03897010  
2023-06-03 10:12:09.634: [iter 237 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 207.288893]
2023-06-03 10:12:59.392: epoch 237:	0.00675585  	0.10822407  	0.05115065  	0.03853042  	0.03900073  
2023-06-03 10:16:50.173: [iter 238 : loss : 0.4196 = 0.0046 + 0.4003 + 0.0147, time: 229.208005]
2023-06-03 10:17:39.329: epoch 238:	0.00674784  	0.10814606  	0.05109520  	0.03848831  	0.03896742  
2023-06-03 10:21:03.840: [iter 239 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0147, time: 202.930532]
2023-06-03 10:21:42.953: epoch 239:	0.00673891  	0.10805841  	0.05104851  	0.03849775  	0.03894910  
2023-06-03 10:25:10.752: [iter 240 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 206.215822]
2023-06-03 10:25:59.735: epoch 240:	0.00674822  	0.10815783  	0.05102805  	0.03840251  	0.03886244  
2023-06-03 10:29:49.775: [iter 241 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 228.480392]
2023-06-03 10:30:38.638: epoch 241:	0.00676385  	0.10832161  	0.05118742  	0.03858289  	0.03903141  
2023-06-03 10:30:38.638: Found a better model.
2023-06-03 10:30:38.638: Save model to file as pretrain.
2023-06-03 10:34:26.483: [iter 242 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0147, time: 225.318088]
2023-06-03 10:35:16.324: epoch 242:	0.00678210  	0.10871206  	0.05122666  	0.03852521  	0.03898853  
2023-06-03 10:35:16.324: Found a better model.
2023-06-03 10:35:16.324: Save model to file as pretrain.
2023-06-03 10:39:08.212: [iter 243 : loss : 0.4196 = 0.0046 + 0.4003 + 0.0147, time: 229.300713]
2023-06-03 10:39:55.148: epoch 243:	0.00677968  	0.10869133  	0.05119257  	0.03850897  	0.03896951  
2023-06-03 10:43:22.754: [iter 244 : loss : 0.4196 = 0.0046 + 0.4003 + 0.0147, time: 206.046624]
2023-06-03 10:44:12.628: epoch 244:	0.00677149  	0.10855078  	0.05112146  	0.03843144  	0.03890122  
2023-06-03 10:47:39.452: [iter 245 : loss : 0.4196 = 0.0046 + 0.4003 + 0.0147, time: 205.253788]
2023-06-03 10:48:28.629: epoch 245:	0.00675957  	0.10831838  	0.05111274  	0.03849021  	0.03894746  
2023-06-03 10:51:54.059: [iter 246 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0147, time: 203.861781]
2023-06-03 10:52:40.950: epoch 246:	0.00677316  	0.10845983  	0.05115282  	0.03853060  	0.03898472  
2023-06-03 10:56:08.969: [iter 247 : loss : 0.4196 = 0.0046 + 0.4003 + 0.0147, time: 206.417906]
2023-06-03 10:56:58.786: epoch 247:	0.00677130  	0.10848186  	0.05120891  	0.03857096  	0.03903395  
2023-06-03 11:00:24.393: [iter 248 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 203.975121]
2023-06-03 11:01:13.842: epoch 248:	0.00678545  	0.10874109  	0.05127006  	0.03859278  	0.03906002  
2023-06-03 11:01:13.842: Found a better model.
2023-06-03 11:01:13.842: Save model to file as pretrain.
2023-06-03 11:04:40.614: [iter 249 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 204.173619]
2023-06-03 11:05:21.427: epoch 249:	0.00677669  	0.10856520  	0.05128012  	0.03863630  	0.03910334  
2023-06-03 11:08:47.090: [iter 250 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0147, time: 204.079883]
2023-06-03 11:09:36.762: epoch 250:	0.00676609  	0.10834070  	0.05118415  	0.03855955  	0.03901749  
2023-06-03 11:13:04.467: [iter 251 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 206.104964]
2023-06-03 11:13:56.122: epoch 251:	0.00676795  	0.10842863  	0.05110940  	0.03843740  	0.03888977  
2023-06-03 11:17:20.583: [iter 252 : loss : 0.4196 = 0.0046 + 0.4003 + 0.0147, time: 202.919418]
2023-06-03 11:18:10.856: epoch 252:	0.00677819  	0.10861113  	0.05121589  	0.03855776  	0.03902061  
2023-06-03 11:21:36.590: [iter 253 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 204.153143]
2023-06-03 11:22:26.302: epoch 253:	0.00678228  	0.10856681  	0.05121033  	0.03856657  	0.03903369  
2023-06-03 11:25:50.696: [iter 254 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0147, time: 202.810445]
2023-06-03 11:26:37.093: epoch 254:	0.00677725  	0.10846598  	0.05127448  	0.03868967  	0.03917021  
2023-06-03 11:30:02.621: [iter 255 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0147, time: 203.918842]
2023-06-03 11:30:52.875: epoch 255:	0.00678414  	0.10870475  	0.05128597  	0.03864580  	0.03911868  
2023-06-03 11:34:19.896: [iter 256 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0147, time: 205.429631]
2023-06-03 11:35:09.476: epoch 256:	0.00677800  	0.10856564  	0.05120460  	0.03857231  	0.03903317  
2023-06-03 11:38:35.043: [iter 257 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0147, time: 203.992814]
2023-06-03 11:39:22.102: epoch 257:	0.00677334  	0.10849637  	0.05119620  	0.03857124  	0.03904535  
2023-06-03 11:42:48.906: [iter 258 : loss : 0.4196 = 0.0046 + 0.4003 + 0.0146, time: 205.222835]
2023-06-03 11:43:38.339: epoch 258:	0.00678210  	0.10869955  	0.05126151  	0.03861228  	0.03908112  
2023-06-03 11:47:06.162: [iter 259 : loss : 0.4196 = 0.0046 + 0.4003 + 0.0147, time: 206.268191]
2023-06-03 11:47:55.468: epoch 259:	0.00677855  	0.10863730  	0.05120965  	0.03857236  	0.03903643  
2023-06-03 11:51:23.121: [iter 260 : loss : 0.4195 = 0.0046 + 0.4003 + 0.0147, time: 206.081490]
2023-06-03 11:52:12.428: epoch 260:	0.00678619  	0.10868332  	0.05122170  	0.03853402  	0.03900468  
2023-06-03 11:55:38.088: [iter 261 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0147, time: 204.099990]
2023-06-03 11:56:28.543: epoch 261:	0.00679010  	0.10878409  	0.05123961  	0.03855472  	0.03904435  
2023-06-03 11:56:28.543: Found a better model.
2023-06-03 11:56:28.543: Save model to file as pretrain.
2023-06-03 12:00:19.483: [iter 262 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0147, time: 228.394473]
2023-06-03 12:01:07.236: epoch 262:	0.00677279  	0.10855535  	0.05116547  	0.03851474  	0.03899383  
2023-06-03 12:04:56.175: [iter 263 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0147, time: 227.375160]
2023-06-03 12:05:45.450: epoch 263:	0.00676200  	0.10841975  	0.05114968  	0.03850939  	0.03898669  
2023-06-03 12:09:35.405: [iter 264 : loss : 0.4196 = 0.0046 + 0.4003 + 0.0147, time: 228.376207]
2023-06-03 12:10:25.615: epoch 264:	0.00677577  	0.10867354  	0.05121427  	0.03852781  	0.03900162  
2023-06-03 12:13:51.367: [iter 265 : loss : 0.4196 = 0.0046 + 0.4003 + 0.0147, time: 204.195691]
2023-06-03 12:14:40.659: epoch 265:	0.00676812  	0.10840484  	0.05106380  	0.03836373  	0.03886445  
2023-06-03 12:18:08.257: [iter 266 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0147, time: 206.024590]
2023-06-03 12:18:54.136: epoch 266:	0.00679158  	0.10881482  	0.05121853  	0.03848929  	0.03897931  
2023-06-03 12:18:54.136: Found a better model.
2023-06-03 12:18:54.136: Save model to file as pretrain.
2023-06-03 12:22:18.508: [iter 267 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0147, time: 201.911567]
2023-06-03 12:23:08.792: epoch 267:	0.00677092  	0.10846622  	0.05111786  	0.03843083  	0.03891580  
2023-06-03 12:26:33.896: [iter 268 : loss : 0.4196 = 0.0046 + 0.4003 + 0.0146, time: 203.530901]
2023-06-03 12:27:22.778: epoch 268:	0.00677334  	0.10863069  	0.05115879  	0.03845304  	0.03892117  
2023-06-03 12:30:48.266: [iter 269 : loss : 0.4196 = 0.0046 + 0.4003 + 0.0147, time: 203.884034]
2023-06-03 12:31:34.324: epoch 269:	0.00675976  	0.10838503  	0.05115664  	0.03852398  	0.03897493  
2023-06-03 12:34:58.817: [iter 270 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0147, time: 202.927146]
2023-06-03 12:35:48.356: epoch 270:	0.00676348  	0.10852264  	0.05118886  	0.03853343  	0.03899141  
2023-06-03 12:39:17.341: [iter 271 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0147, time: 207.421639]
2023-06-03 12:40:07.731: epoch 271:	0.00676999  	0.10853609  	0.05128236  	0.03865742  	0.03911527  
2023-06-03 12:43:32.377: [iter 272 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0146, time: 203.077401]
2023-06-03 12:44:25.712: epoch 272:	0.00677427  	0.10862099  	0.05124462  	0.03857586  	0.03904786  
2023-06-03 12:47:52.633: [iter 273 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0147, time: 205.359188]
2023-06-03 12:48:41.929: epoch 273:	0.00677725  	0.10864718  	0.05127933  	0.03863537  	0.03911292  
2023-06-03 12:52:08.769: [iter 274 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0146, time: 205.290638]
2023-06-03 12:52:54.828: epoch 274:	0.00677074  	0.10862621  	0.05133313  	0.03873444  	0.03920121  
2023-06-03 12:56:20.607: [iter 275 : loss : 0.4195 = 0.0046 + 0.4003 + 0.0147, time: 204.208075]
2023-06-03 12:57:11.806: epoch 275:	0.00677819  	0.10875031  	0.05129050  	0.03866679  	0.03914535  
2023-06-03 13:00:38.102: [iter 276 : loss : 0.4196 = 0.0046 + 0.4003 + 0.0147, time: 204.679125]
2023-06-03 13:01:29.620: epoch 276:	0.00678284  	0.10883301  	0.05138801  	0.03877430  	0.03925345  
2023-06-03 13:01:29.620: Found a better model.
2023-06-03 13:01:29.620: Save model to file as pretrain.
2023-06-03 13:05:04.504: [iter 277 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0146, time: 211.884972]
2023-06-03 13:05:54.954: epoch 277:	0.00678303  	0.10874911  	0.05134954  	0.03870654  	0.03919490  
2023-06-03 13:09:33.422: [iter 278 : loss : 0.4195 = 0.0046 + 0.4003 + 0.0147, time: 216.886814]
2023-06-03 13:10:23.690: epoch 278:	0.00679233  	0.10892979  	0.05144424  	0.03876968  	0.03925393  
2023-06-03 13:10:23.691: Found a better model.
2023-06-03 13:10:23.691: Save model to file as pretrain.
2023-06-03 13:13:50.650: [iter 279 : loss : 0.4196 = 0.0046 + 0.4003 + 0.0146, time: 204.210348]
2023-06-03 13:14:29.377: epoch 279:	0.00678322  	0.10886693  	0.05136864  	0.03868625  	0.03915926  
2023-06-03 13:17:54.003: [iter 280 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0146, time: 203.024927]
2023-06-03 13:18:50.166: epoch 280:	0.00679513  	0.10894452  	0.05146578  	0.03877496  	0.03925367  
2023-06-03 13:18:50.166: Found a better model.
2023-06-03 13:18:50.166: Save model to file as pretrain.
2023-06-03 13:22:15.039: [iter 281 : loss : 0.4196 = 0.0046 + 0.4003 + 0.0147, time: 202.276501]
2023-06-03 13:23:05.053: epoch 281:	0.00679382  	0.10891587  	0.05142839  	0.03876404  	0.03924078  
2023-06-03 13:26:32.729: [iter 282 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0146, time: 206.073681]
2023-06-03 13:27:23.005: epoch 282:	0.00680182  	0.10908943  	0.05152165  	0.03883291  	0.03932796  
2023-06-03 13:27:23.005: Found a better model.
2023-06-03 13:27:23.005: Save model to file as pretrain.
2023-06-03 13:30:50.722: [iter 283 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0146, time: 205.119652]
2023-06-03 13:31:41.165: epoch 283:	0.00681523  	0.10930748  	0.05153733  	0.03877500  	0.03928403  
2023-06-03 13:31:41.165: Found a better model.
2023-06-03 13:31:41.166: Save model to file as pretrain.
2023-06-03 13:35:12.066: [iter 284 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0146, time: 206.039121]
2023-06-03 13:35:53.640: epoch 284:	0.00680052  	0.10904769  	0.05143864  	0.03871031  	0.03921151  
2023-06-03 13:39:16.399: [iter 285 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0147, time: 201.369669]
2023-06-03 13:40:06.942: epoch 285:	0.00681337  	0.10923004  	0.05142015  	0.03867466  	0.03916090  
2023-06-03 13:43:36.483: [iter 286 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0147, time: 207.983792]
2023-06-03 13:44:26.709: epoch 286:	0.00679271  	0.10896667  	0.05140233  	0.03871761  	0.03919934  
2023-06-03 13:47:52.841: [iter 287 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0146, time: 204.555685]
2023-06-03 13:48:40.828: epoch 287:	0.00679215  	0.10887051  	0.05141113  	0.03874161  	0.03921689  
2023-06-03 13:52:06.277: [iter 288 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0146, time: 203.883627]
2023-06-03 13:52:55.648: epoch 288:	0.00680053  	0.10909458  	0.05146677  	0.03876628  	0.03925739  
2023-06-03 13:56:19.553: [iter 289 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0146, time: 202.327559]
2023-06-03 13:57:09.695: epoch 289:	0.00680313  	0.10906771  	0.05146824  	0.03878542  	0.03927692  
2023-06-03 14:00:36.242: [iter 290 : loss : 0.4196 = 0.0046 + 0.4003 + 0.0146, time: 204.985552]
2023-06-03 14:01:26.423: epoch 290:	0.00679383  	0.10892997  	0.05146574  	0.03885906  	0.03933387  
2023-06-03 14:05:11.807: [iter 291 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0146, time: 223.824335]
2023-06-03 14:06:02.416: epoch 291:	0.00680034  	0.10903307  	0.05155712  	0.03893817  	0.03943071  
2023-06-03 14:09:52.356: [iter 292 : loss : 0.4195 = 0.0046 + 0.4003 + 0.0146, time: 228.380426]
2023-06-03 14:10:44.986: epoch 292:	0.00678731  	0.10888462  	0.05145325  	0.03883862  	0.03931399  
2023-06-03 14:14:22.690: [iter 293 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0146, time: 216.077852]
2023-06-03 14:15:14.490: epoch 293:	0.00680127  	0.10898438  	0.05144474  	0.03877167  	0.03925297  
2023-06-03 14:18:39.156: [iter 294 : loss : 0.4195 = 0.0046 + 0.4003 + 0.0146, time: 203.108386]
2023-06-03 14:19:29.073: epoch 294:	0.00678899  	0.10883389  	0.05147600  	0.03891074  	0.03937967  
2023-06-03 14:22:57.004: [iter 295 : loss : 0.4196 = 0.0046 + 0.4003 + 0.0146, time: 206.326283]
2023-06-03 14:23:46.168: epoch 295:	0.00678489  	0.10886080  	0.05141957  	0.03881981  	0.03928553  
2023-06-03 14:27:11.847: [iter 296 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0146, time: 204.115538]
2023-06-03 14:27:53.444: epoch 296:	0.00677875  	0.10874616  	0.05134858  	0.03874611  	0.03921742  
2023-06-03 14:31:20.441: [iter 297 : loss : 0.4196 = 0.0046 + 0.4003 + 0.0146, time: 205.610594]
2023-06-03 14:32:09.606: epoch 297:	0.00680611  	0.10920290  	0.05148972  	0.03881716  	0.03929232  
2023-06-03 14:35:36.357: [iter 298 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0146, time: 205.165075]
2023-06-03 14:36:26.502: epoch 298:	0.00680370  	0.10912971  	0.05147742  	0.03880415  	0.03927587  
2023-06-03 14:39:51.248: [iter 299 : loss : 0.4197 = 0.0047 + 0.4003 + 0.0146, time: 203.191919]
2023-06-03 14:40:38.247: epoch 299:	0.00681039  	0.10918476  	0.05154739  	0.03889562  	0.03937449  
2023-06-03 14:44:05.997: [iter 300 : loss : 0.4195 = 0.0046 + 0.4003 + 0.0146, time: 206.161511]
2023-06-03 14:44:55.923: epoch 300:	0.00682156  	0.10942195  	0.05149477  	0.03874496  	0.03921715  
2023-06-03 14:44:55.923: Found a better model.
2023-06-03 14:44:55.923: Save model to file as pretrain.
2023-06-03 14:48:28.168: [iter 301 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0146, time: 206.312713]
2023-06-03 14:49:16.329: epoch 301:	0.00681169  	0.10928415  	0.05157211  	0.03891031  	0.03938311  
2023-06-03 14:52:43.006: [iter 302 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0146, time: 205.111922]
2023-06-03 14:53:33.425: epoch 302:	0.00681765  	0.10941263  	0.05160245  	0.03887350  	0.03935082  
2023-06-03 14:57:00.554: [iter 303 : loss : 0.4195 = 0.0046 + 0.4003 + 0.0146, time: 205.510411]
2023-06-03 14:57:52.565: epoch 303:	0.00681449  	0.10937496  	0.05164012  	0.03893109  	0.03942680  
2023-06-03 15:01:18.794: [iter 304 : loss : 0.4195 = 0.0046 + 0.4003 + 0.0146, time: 204.625633]
2023-06-03 15:02:14.969: epoch 304:	0.00681467  	0.10946921  	0.05167357  	0.03896364  	0.03944194  
2023-06-03 15:02:14.970: Found a better model.
2023-06-03 15:02:14.970: Save model to file as pretrain.
2023-06-03 15:05:44.597: [iter 305 : loss : 0.4195 = 0.0046 + 0.4003 + 0.0146, time: 203.782244]
2023-06-03 15:06:35.513: epoch 305:	0.00679940  	0.10919600  	0.05168650  	0.03906286  	0.03954897  
2023-06-03 15:09:58.081: [iter 306 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0146, time: 200.971396]
2023-06-03 15:10:45.910: epoch 306:	0.00679885  	0.10907965  	0.05167641  	0.03909454  	0.03957671  
2023-06-03 15:14:10.626: [iter 307 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0146, time: 203.096079]
2023-06-03 15:15:02.321: epoch 307:	0.00679755  	0.10905154  	0.05155560  	0.03893411  	0.03940663  
2023-06-03 15:18:29.481: [iter 308 : loss : 0.4195 = 0.0046 + 0.4003 + 0.0146, time: 205.537985]
2023-06-03 15:19:20.710: epoch 308:	0.00679568  	0.10897502  	0.05160380  	0.03901447  	0.03948554  
2023-06-03 15:22:46.293: [iter 309 : loss : 0.4196 = 0.0046 + 0.4003 + 0.0146, time: 203.960023]
2023-06-03 15:23:25.434: epoch 309:	0.00679680  	0.10903912  	0.05157862  	0.03897290  	0.03946313  
2023-06-03 15:26:53.330: [iter 310 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0146, time: 206.312263]
2023-06-03 15:27:45.661: epoch 310:	0.00681522  	0.10924576  	0.05170074  	0.03905024  	0.03955599  
2023-06-03 15:31:13.647: [iter 311 : loss : 0.4195 = 0.0046 + 0.4003 + 0.0146, time: 206.379682]
2023-06-03 15:32:04.639: epoch 311:	0.00680257  	0.10907515  	0.05157067  	0.03893969  	0.03941935  
2023-06-03 15:35:30.183: [iter 312 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0146, time: 203.937313]
2023-06-03 15:36:22.011: epoch 312:	0.00680573  	0.10914251  	0.05164257  	0.03901485  	0.03950441  
2023-06-03 15:40:12.598: [iter 313 : loss : 0.4195 = 0.0046 + 0.4003 + 0.0146, time: 229.003833]
2023-06-03 15:41:04.136: epoch 313:	0.00680424  	0.10910268  	0.05159116  	0.03894760  	0.03942044  
2023-06-03 15:44:31.444: [iter 314 : loss : 0.4195 = 0.0046 + 0.4003 + 0.0146, time: 205.715414]
2023-06-03 15:45:28.051: epoch 314:	0.00680182  	0.10896495  	0.05157326  	0.03894723  	0.03943158  
2023-06-03 15:48:54.451: [iter 315 : loss : 0.4195 = 0.0046 + 0.4003 + 0.0146, time: 204.816745]
2023-06-03 15:49:53.216: epoch 315:	0.00679940  	0.10896271  	0.05160920  	0.03900569  	0.03946894  
2023-06-03 15:53:25.472: [iter 316 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0146, time: 210.533557]
2023-06-03 15:54:16.487: epoch 316:	0.00681318  	0.10913748  	0.05161327  	0.03901233  	0.03947681  
2023-06-03 15:57:46.985: [iter 317 : loss : 0.4196 = 0.0046 + 0.4003 + 0.0146, time: 208.774336]
2023-06-03 15:58:46.479: epoch 317:	0.00681727  	0.10928201  	0.05159787  	0.03895914  	0.03942949  
2023-06-03 16:02:16.256: [iter 318 : loss : 0.4195 = 0.0046 + 0.4003 + 0.0146, time: 208.041768]
2023-06-03 16:03:14.117: epoch 318:	0.00680834  	0.10913312  	0.05160055  	0.03899853  	0.03946818  
2023-06-03 16:06:43.466: [iter 319 : loss : 0.4195 = 0.0046 + 0.4003 + 0.0146, time: 207.636076]
2023-06-03 16:07:42.745: epoch 319:	0.00680536  	0.10907835  	0.05162932  	0.03902347  	0.03948570  
2023-06-03 16:11:09.392: [iter 320 : loss : 0.4195 = 0.0045 + 0.4003 + 0.0146, time: 204.935019]
2023-06-03 16:12:00.399: epoch 320:	0.00681150  	0.10916185  	0.05164378  	0.03898949  	0.03946078  
2023-06-03 16:15:24.972: [iter 321 : loss : 0.4195 = 0.0046 + 0.4003 + 0.0146, time: 203.012194]
2023-06-03 16:16:13.923: epoch 321:	0.00681318  	0.10919017  	0.05170139  	0.03906982  	0.03952381  
2023-06-03 16:19:40.644: [iter 322 : loss : 0.4195 = 0.0046 + 0.4003 + 0.0146, time: 205.163325]
2023-06-03 16:20:33.012: epoch 322:	0.00682230  	0.10936832  	0.05168216  	0.03900721  	0.03947172  
2023-06-03 16:23:58.698: [iter 323 : loss : 0.4196 = 0.0047 + 0.4003 + 0.0146, time: 204.125894]
2023-06-03 16:24:48.656: epoch 323:	0.00681373  	0.10918167  	0.05166293  	0.03904175  	0.03950686  
2023-06-03 16:28:25.385: [iter 324 : loss : 0.4195 = 0.0046 + 0.4003 + 0.0146, time: 215.146168]
2023-06-03 16:29:16.110: epoch 324:	0.00682006  	0.10931675  	0.05160978  	0.03889648  	0.03936560  
2023-06-03 16:29:16.110: Early stopping is triggered at epoch: 324
2023-06-03 16:29:16.110: best_result@epoch 304:

2023-06-03 16:29:16.110: Loading from the saved model.
2023-06-03 16:30:07.973: 		0.00681467  	0.10946921  	0.05167357  	0.03896364  	0.03944194  
/home/Thesis/model/general_recommender/SGL.py:146: RuntimeWarning: divide by zero encountered in power
  d_inv = np.power(rowsum, -0.5).flatten()

seed= 2021
load saved data...
Item degree grouping...
User degree grouping...
Data loading finished
Evaluate model with cpp
2023-06-03 16:37:59.437: Dataset name: ifashion
The number of users: 300000
The number of items: 81614
The number of ratings: 1607813
Average actions of users: 5.36
Average actions of items: 19.70
The sparsity of the dataset: 99.993433%
2023-06-03 16:37:59.437: 

NeuRec hyperparameters:
recommender=SGL
config_dir=./conf
gpu_id=1
gpu_mem=1.0
data.input.path=dataset
data.input.dataset=ifashion
data.column.format=UI
data.convert.separator=','
user_min=0
item_min=0
splitter=given
ratio=0.8
by_time=False
metric=["Precision", "Recall", "NDCG", "MAP", "MRR"]
topk=[20]
group_view=None
rec.evaluate.neg=0
test_batch_size=128
num_thread=8
start_testing_epoch=0
proj_path=./

SGL's hyperparameters:
seed=2021
aug_type=1
reg=1e-3
embed_size=64
n_layers=3
ssl_reg=0.02
ssl_ratio=0.4
ssl_temp=0.5
ssl_mode=both_side
ssl_loss_type=1
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=1024
num_negatives=1
init_method=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=50
pretrain=1
save_flag=1

2023-06-03 16:38:20.666: metrics:	Precision@20	Recall@20   	NDCG@20     	MAP@20      	MRR@20      
0.00002     	0.00012     	0.00053     	0.00125     	0.00300     	0.00582     	0.01077     	0.01888     	0.02698     	0.04212     
2023-06-03 16:39:49.342: 		0.00681467  	0.10946921  	0.05167357  	0.03896364  	0.03944194  
2023-06-03 16:41:08.751: [iter 1 : loss : 0.0191 = 0.0043 + 0.0000 + 0.0148, time: 77.850605]
0.00002     	0.00010     	0.00042     	0.00105     	0.00267     	0.00524     	0.01029     	0.01847     	0.02741     	0.04357     
2023-06-03 16:42:28.078: epoch 1:	0.00680165  	0.10923731  	0.05147925  	0.03879052  	0.03925984  
2023-06-03 16:43:46.134: [iter 2 : loss : 0.0190 = 0.0044 + 0.0000 + 0.0146, time: 76.468648]
0.00002     	0.00009     	0.00043     	0.00104     	0.00266     	0.00521     	0.01014     	0.01847     	0.02762     	0.04373     
2023-06-03 16:45:05.640: epoch 2:	0.00681245  	0.10941093  	0.05153722  	0.03881168  	0.03928320  
2023-06-03 16:46:24.653: [iter 3 : loss : 0.0189 = 0.0045 + 0.0000 + 0.0144, time: 77.424258]
0.00001     	0.00009     	0.00044     	0.00103     	0.00252     	0.00509     	0.01002     	0.01839     	0.02750     	0.04382     
2023-06-03 16:47:44.389: epoch 3:	0.00678601  	0.10892024  	0.05133623  	0.03869780  	0.03916068  
2023-06-03 16:49:03.037: [iter 4 : loss : 0.0189 = 0.0046 + 0.0000 + 0.0143, time: 77.092909]
0.00001     	0.00009     	0.00039     	0.00104     	0.00255     	0.00505     	0.00996     	0.01828     	0.02743     	0.04403     
2023-06-03 16:50:21.645: epoch 4:	0.00677987  	0.10884503  	0.05124867  	0.03857295  	0.03903799  
2023-06-03 16:51:40.427: [iter 5 : loss : 0.0188 = 0.0046 + 0.0000 + 0.0142, time: 77.191156]
0.00001     	0.00009     	0.00040     	0.00105     	0.00256     	0.00496     	0.00999     	0.01812     	0.02759     	0.04425     
2023-06-03 16:52:46.138: epoch 5:	0.00679476  	0.10903656  	0.05129861  	0.03859562  	0.03905723  
2023-06-03 16:54:03.726: [iter 6 : loss : 0.0188 = 0.0046 + 0.0000 + 0.0142, time: 76.015550]
0.00001     	0.00008     	0.00040     	0.00103     	0.00248     	0.00493     	0.00982     	0.01791     	0.02749     	0.04469     
2023-06-03 16:55:20.935: epoch 6:	0.00678416  	0.10884805  	0.05121241  	0.03855248  	0.03900149  
2023-06-03 16:56:38.792: [iter 7 : loss : 0.0188 = 0.0047 + 0.0000 + 0.0141, time: 76.300373]
0.00001     	0.00008     	0.00041     	0.00099     	0.00249     	0.00492     	0.00980     	0.01797     	0.02753     	0.04469     
2023-06-03 16:57:57.953: epoch 7:	0.00678304  	0.10888940  	0.05129018  	0.03863418  	0.03908756  
2023-06-03 16:59:16.452: [iter 8 : loss : 0.0188 = 0.0047 + 0.0000 + 0.0141, time: 76.947751]
0.00001     	0.00009     	0.00037     	0.00097     	0.00244     	0.00489     	0.00982     	0.01785     	0.02755     	0.04474     
2023-06-03 17:00:35.234: epoch 8:	0.00677429  	0.10871654  	0.05119406  	0.03851626  	0.03897116  
2023-06-03 17:01:52.743: [iter 9 : loss : 0.0188 = 0.0047 + 0.0000 + 0.0141, time: 75.897181]
0.00001     	0.00008     	0.00037     	0.00098     	0.00237     	0.00489     	0.00977     	0.01783     	0.02748     	0.04492     
2023-06-03 17:03:10.886: epoch 9:	0.00677484  	0.10869500  	0.05118793  	0.03856714  	0.03900542  
2023-06-03 17:04:29.728: [iter 10 : loss : 0.0188 = 0.0048 + 0.0000 + 0.0140, time: 77.267607]
0.00001     	0.00008     	0.00036     	0.00096     	0.00238     	0.00490     	0.00973     	0.01785     	0.02749     	0.04474     
2023-06-03 17:05:48.712: epoch 10:	0.00676219  	0.10849147  	0.05109967  	0.03849418  	0.03893320  
2023-06-03 17:07:09.039: [iter 11 : loss : 0.0188 = 0.0047 + 0.0000 + 0.0140, time: 78.775254]
0.00001     	0.00008     	0.00036     	0.00098     	0.00237     	0.00485     	0.00972     	0.01791     	0.02749     	0.04502     
2023-06-03 17:08:24.241: epoch 11:	0.00678136  	0.10880195  	0.05114773  	0.03848566  	0.03892355  
2023-06-03 17:10:03.334: [iter 12 : loss : 0.0188 = 0.0048 + 0.0000 + 0.0140, time: 97.528363]
0.00000     	0.00008     	0.00035     	0.00093     	0.00244     	0.00492     	0.00961     	0.01781     	0.02767     	0.04480     
2023-06-03 17:11:17.923: epoch 12:	0.00677019  	0.10861246  	0.05116995  	0.03855921  	0.03899239  
2023-06-03 17:12:41.283: [iter 13 : loss : 0.0187 = 0.0047 + 0.0000 + 0.0140, time: 81.788765]
0.00001     	0.00009     	0.00034     	0.00093     	0.00239     	0.00482     	0.00957     	0.01778     	0.02772     	0.04495     
2023-06-03 17:13:47.501: epoch 13:	0.00677559  	0.10860186  	0.05111980  	0.03848722  	0.03892432  
2023-06-03 17:15:05.855: [iter 14 : loss : 0.0188 = 0.0048 + 0.0000 + 0.0140, time: 76.983271]
0.00000     	0.00009     	0.00036     	0.00092     	0.00237     	0.00482     	0.00956     	0.01790     	0.02771     	0.04477     
2023-06-03 17:16:24.403: epoch 14:	0.00676887  	0.10848901  	0.05113777  	0.03853225  	0.03898685  
2023-06-03 17:17:42.414: [iter 15 : loss : 0.0188 = 0.0049 + 0.0000 + 0.0140, time: 76.415220]
0.00000     	0.00008     	0.00034     	0.00094     	0.00235     	0.00477     	0.00960     	0.01789     	0.02753     	0.04496     
2023-06-03 17:19:00.555: epoch 15:	0.00676683  	0.10846146  	0.05116038  	0.03858693  	0.03903818  
2023-06-03 17:20:16.882: [iter 16 : loss : 0.0188 = 0.0049 + 0.0000 + 0.0139, time: 74.756645]
0.00001     	0.00008     	0.00035     	0.00092     	0.00235     	0.00479     	0.00951     	0.01762     	0.02765     	0.04516     
2023-06-03 17:21:36.385: epoch 16:	0.00676218  	0.10843906  	0.05112958  	0.03855382  	0.03899039  
2023-06-03 17:22:55.034: [iter 17 : loss : 0.0186 = 0.0047 + 0.0000 + 0.0139, time: 77.056077]
0.00000     	0.00009     	0.00035     	0.00090     	0.00237     	0.00483     	0.00935     	0.01761     	0.02765     	0.04530     
2023-06-03 17:24:14.934: epoch 17:	0.00676311  	0.10845584  	0.05109426  	0.03849646  	0.03893283  
2023-06-03 17:25:33.187: [iter 18 : loss : 0.0187 = 0.0048 + 0.0000 + 0.0139, time: 76.685914]
0.00001     	0.00009     	0.00035     	0.00097     	0.00237     	0.00475     	0.00928     	0.01771     	0.02752     	0.04529     
2023-06-03 17:26:39.315: epoch 18:	0.00675995  	0.10833319  	0.05107640  	0.03848683  	0.03892244  
2023-06-03 17:27:57.809: [iter 19 : loss : 0.0187 = 0.0048 + 0.0000 + 0.0139, time: 76.889619]
0.00001     	0.00008     	0.00035     	0.00092     	0.00232     	0.00476     	0.00929     	0.01773     	0.02756     	0.04518     
2023-06-03 17:29:12.859: epoch 19:	0.00675380  	0.10821167  	0.05100827  	0.03844189  	0.03888986  
2023-06-03 17:30:29.228: [iter 20 : loss : 0.0187 = 0.0048 + 0.0000 + 0.0139, time: 74.965258]
0.00001     	0.00008     	0.00033     	0.00090     	0.00238     	0.00472     	0.00934     	0.01773     	0.02764     	0.04534     
2023-06-03 17:31:48.399: epoch 20:	0.00676255  	0.10845956  	0.05112756  	0.03854831  	0.03899360  
2023-06-03 17:33:07.445: [iter 21 : loss : 0.0187 = 0.0049 + 0.0000 + 0.0139, time: 77.393331]
0.00001     	0.00009     	0.00035     	0.00088     	0.00235     	0.00472     	0.00934     	0.01782     	0.02761     	0.04545     
2023-06-03 17:34:26.613: epoch 21:	0.00677316  	0.10861976  	0.05113858  	0.03852763  	0.03898099  
2023-06-03 17:35:42.805: [iter 22 : loss : 0.0188 = 0.0049 + 0.0000 + 0.0139, time: 74.566477]
0.00001     	0.00008     	0.00034     	0.00091     	0.00237     	0.00467     	0.00937     	0.01790     	0.02784     	0.04526     
2023-06-03 17:37:02.117: epoch 22:	0.00678433  	0.10875674  	0.05122270  	0.03862540  	0.03908220  
2023-06-03 17:38:21.167: [iter 23 : loss : 0.0187 = 0.0048 + 0.0000 + 0.0139, time: 77.447411]
0.00001     	0.00008     	0.00034     	0.00088     	0.00234     	0.00466     	0.00948     	0.01793     	0.02769     	0.04521     
2023-06-03 17:39:38.997: epoch 23:	0.00678097  	0.10862277  	0.05120914  	0.03860738  	0.03906669  
2023-06-03 17:40:57.828: [iter 24 : loss : 0.0187 = 0.0049 + 0.0000 + 0.0139, time: 77.241085]
0.00001     	0.00009     	0.00032     	0.00092     	0.00233     	0.00469     	0.00947     	0.01800     	0.02762     	0.04521     
2023-06-03 17:42:13.801: epoch 24:	0.00677818  	0.10864414  	0.05114861  	0.03850932  	0.03897618  
2023-06-03 17:43:31.603: [iter 25 : loss : 0.0186 = 0.0048 + 0.0000 + 0.0139, time: 76.217447]
0.00001     	0.00009     	0.00034     	0.00086     	0.00228     	0.00462     	0.00928     	0.01789     	0.02772     	0.04547     
2023-06-03 17:44:47.117: epoch 25:	0.00676962  	0.10854749  	0.05108485  	0.03843841  	0.03889324  
2023-06-03 17:46:05.787: [iter 26 : loss : 0.0187 = 0.0048 + 0.0000 + 0.0139, time: 77.067709]
0.00001     	0.00008     	0.00032     	0.00088     	0.00230     	0.00452     	0.00934     	0.01788     	0.02776     	0.04547     
2023-06-03 17:47:21.741: epoch 26:	0.00677222  	0.10855518  	0.05111524  	0.03849873  	0.03896472  
2023-06-03 17:48:37.904: [iter 27 : loss : 0.0187 = 0.0048 + 0.0000 + 0.0138, time: 74.589616]
0.00001     	0.00008     	0.00034     	0.00089     	0.00234     	0.00463     	0.00941     	0.01773     	0.02765     	0.04548     
2023-06-03 17:49:56.002: epoch 27:	0.00677260  	0.10856284  	0.05099741  	0.03830662  	0.03876254  
2023-06-03 17:51:13.464: [iter 28 : loss : 0.0188 = 0.0049 + 0.0000 + 0.0138, time: 75.882869]
0.00001     	0.00007     	0.00032     	0.00089     	0.00234     	0.00464     	0.00945     	0.01774     	0.02781     	0.04545     
2023-06-03 17:52:31.998: epoch 28:	0.00678041  	0.10871207  	0.05103992  	0.03833793  	0.03881073  
2023-06-03 17:53:50.387: [iter 29 : loss : 0.0188 = 0.0049 + 0.0000 + 0.0138, time: 76.841597]
0.00000     	0.00008     	0.00031     	0.00088     	0.00242     	0.00468     	0.00948     	0.01769     	0.02766     	0.04552     
2023-06-03 17:55:09.212: epoch 29:	0.00678712  	0.10871987  	0.05103645  	0.03834580  	0.03882303  
2023-06-03 17:56:26.111: [iter 30 : loss : 0.0188 = 0.0049 + 0.0000 + 0.0138, time: 75.315129]
0.00000     	0.00008     	0.00029     	0.00091     	0.00236     	0.00466     	0.00940     	0.01770     	0.02771     	0.04553     
2023-06-03 17:57:44.662: epoch 30:	0.00678004  	0.10865273  	0.05117190  	0.03857286  	0.03904130  
2023-06-03 17:59:01.363: [iter 31 : loss : 0.0187 = 0.0049 + 0.0000 + 0.0138, time: 75.148393]
0.00000     	0.00008     	0.00030     	0.00089     	0.00235     	0.00469     	0.00939     	0.01775     	0.02787     	0.04550     
2023-06-03 18:00:05.355: epoch 31:	0.00678879  	0.10883941  	0.05128371  	0.03866074  	0.03914133  
2023-06-03 18:01:23.066: [iter 32 : loss : 0.0187 = 0.0049 + 0.0000 + 0.0138, time: 76.135689]
0.00001     	0.00008     	0.00030     	0.00087     	0.00236     	0.00476     	0.00934     	0.01771     	0.02761     	0.04563     
2023-06-03 18:02:40.404: epoch 32:	0.00678414  	0.10865808  	0.05114562  	0.03849740  	0.03896379  
2023-06-03 18:03:59.005: [iter 33 : loss : 0.0188 = 0.0050 + 0.0000 + 0.0138, time: 77.039385]
0.00000     	0.00008     	0.00033     	0.00091     	0.00231     	0.00477     	0.00941     	0.01783     	0.02752     	0.04557     
2023-06-03 18:05:18.062: epoch 33:	0.00678265  	0.10873670  	0.05114701  	0.03848008  	0.03895120  
2023-06-03 18:06:36.778: [iter 34 : loss : 0.0187 = 0.0049 + 0.0000 + 0.0138, time: 77.155622]
0.00000     	0.00008     	0.00030     	0.00091     	0.00236     	0.00474     	0.00953     	0.01791     	0.02746     	0.04553     
2023-06-03 18:07:56.209: epoch 34:	0.00679307  	0.10882086  	0.05114045  	0.03849662  	0.03896299  
2023-06-03 18:09:15.044: [iter 35 : loss : 0.0187 = 0.0049 + 0.0000 + 0.0138, time: 77.233019]
0.00000     	0.00008     	0.00030     	0.00090     	0.00236     	0.00469     	0.00952     	0.01786     	0.02755     	0.04557     
2023-06-03 18:10:32.723: epoch 35:	0.00678972  	0.10882447  	0.05110940  	0.03843808  	0.03890205  
2023-06-03 18:11:51.413: [iter 36 : loss : 0.0188 = 0.0050 + 0.0000 + 0.0138, time: 77.121988]
0.00000     	0.00007     	0.00030     	0.00090     	0.00239     	0.00470     	0.00958     	0.01790     	0.02773     	0.04513     
2023-06-03 18:13:08.797: epoch 36:	0.00679270  	0.10871198  	0.05114558  	0.03849411  	0.03896569  
2023-06-03 18:14:24.890: [iter 37 : loss : 0.0187 = 0.0049 + 0.0000 + 0.0138, time: 74.557346]
0.00000     	0.00007     	0.00029     	0.00089     	0.00236     	0.00471     	0.00956     	0.01782     	0.02774     	0.04527     
2023-06-03 18:15:40.274: epoch 37:	0.00679195  	0.10872155  	0.05116626  	0.03855820  	0.03903663  
2023-06-03 18:16:56.482: [iter 38 : loss : 0.0187 = 0.0049 + 0.0000 + 0.0138, time: 74.664139]
0.00000     	0.00007     	0.00030     	0.00089     	0.00233     	0.00463     	0.00944     	0.01781     	0.02779     	0.04541     
2023-06-03 18:18:10.331: epoch 38:	0.00678898  	0.10868141  	0.05114099  	0.03852734  	0.03898525  
2023-06-03 18:19:28.029: [iter 39 : loss : 0.0187 = 0.0049 + 0.0000 + 0.0138, time: 76.160091]
0.00000     	0.00007     	0.00032     	0.00087     	0.00232     	0.00467     	0.00941     	0.01785     	0.02781     	0.04539     
2023-06-03 18:20:40.583: epoch 39:	0.00678954  	0.10870702  	0.05113214  	0.03853705  	0.03900342  
2023-06-03 18:21:58.327: [iter 40 : loss : 0.0188 = 0.0050 + 0.0000 + 0.0138, time: 76.385082]
0.00000     	0.00008     	0.00033     	0.00089     	0.00231     	0.00468     	0.00941     	0.01792     	0.02763     	0.04523     
2023-06-03 18:23:16.762: epoch 40:	0.00677520  	0.10846883  	0.05111860  	0.03858024  	0.03904744  
2023-06-03 18:24:35.020: [iter 41 : loss : 0.0187 = 0.0049 + 0.0000 + 0.0138, time: 76.709581]
0.00000     	0.00007     	0.00034     	0.00089     	0.00234     	0.00462     	0.00944     	0.01785     	0.02768     	0.04544     
2023-06-03 18:25:52.258: epoch 41:	0.00678433  	0.10866768  	0.05110026  	0.03847834  	0.03895189  
2023-06-03 18:27:10.497: [iter 42 : loss : 0.0188 = 0.0050 + 0.0000 + 0.0138, time: 76.686698]
0.00000     	0.00007     	0.00031     	0.00087     	0.00230     	0.00467     	0.00956     	0.01777     	0.02773     	0.04542     
2023-06-03 18:28:28.281: epoch 42:	0.00679140  	0.10869662  	0.05115533  	0.03853183  	0.03901010  
2023-06-03 18:29:43.683: [iter 43 : loss : 0.0186 = 0.0048 + 0.0000 + 0.0138, time: 73.827595]
0.00000     	0.00007     	0.00033     	0.00089     	0.00231     	0.00467     	0.00944     	0.01758     	0.02773     	0.04564     
2023-06-03 18:30:59.384: epoch 43:	0.00678526  	0.10865515  	0.05111202  	0.03849472  	0.03896980  
2023-06-03 18:32:16.910: [iter 44 : loss : 0.0187 = 0.0049 + 0.0000 + 0.0138, time: 75.926890]
0.00000     	0.00007     	0.00029     	0.00091     	0.00228     	0.00470     	0.00952     	0.01771     	0.02769     	0.04549     
2023-06-03 18:33:19.787: epoch 44:	0.00678936  	0.10866313  	0.05107620  	0.03843596  	0.03891303  
2023-06-03 18:34:36.042: [iter 45 : loss : 0.0187 = 0.0049 + 0.0000 + 0.0138, time: 74.691034]
0.00000     	0.00008     	0.00029     	0.00089     	0.00222     	0.00460     	0.00949     	0.01787     	0.02760     	0.04572     
2023-06-03 18:35:53.157: epoch 45:	0.00679587  	0.10876694  	0.05109640  	0.03843421  	0.03890434  
2023-06-03 18:37:11.398: [iter 46 : loss : 0.0187 = 0.0049 + 0.0000 + 0.0138, time: 76.698496]
0.00000     	0.00008     	0.00027     	0.00087     	0.00226     	0.00469     	0.00947     	0.01792     	0.02773     	0.04546     
2023-06-03 18:38:29.704: epoch 46:	0.00679121  	0.10876638  	0.05112987  	0.03846825  	0.03892731  
2023-06-03 18:39:46.870: [iter 47 : loss : 0.0188 = 0.0050 + 0.0000 + 0.0138, time: 75.569701]
0.00000     	0.00008     	0.00027     	0.00087     	0.00230     	0.00472     	0.00950     	0.01789     	0.02772     	0.04550     
2023-06-03 18:41:05.086: epoch 47:	0.00679494  	0.10885403  	0.05102897  	0.03829399  	0.03876118  
2023-06-03 18:42:23.329: [iter 48 : loss : 0.0188 = 0.0050 + 0.0000 + 0.0138, time: 76.663726]
0.00000     	0.00007     	0.00029     	0.00092     	0.00232     	0.00469     	0.00957     	0.01790     	0.02776     	0.04506     
2023-06-03 18:43:40.230: epoch 48:	0.00678395  	0.10857848  	0.05099567  	0.03835236  	0.03881543  
2023-06-03 18:44:57.758: [iter 49 : loss : 0.0188 = 0.0050 + 0.0000 + 0.0138, time: 75.951012]
0.00001     	0.00007     	0.00031     	0.00090     	0.00230     	0.00463     	0.00948     	0.01793     	0.02782     	0.04531     
2023-06-03 18:46:15.225: epoch 49:	0.00679699  	0.10876926  	0.05109971  	0.03845036  	0.03892213  
2023-06-03 18:47:32.562: [iter 50 : loss : 0.0189 = 0.0051 + 0.0000 + 0.0138, time: 75.758722]
0.00000     	0.00007     	0.00031     	0.00090     	0.00232     	0.00476     	0.00962     	0.01796     	0.02754     	0.04551     
2023-06-03 18:48:35.175: epoch 50:	0.00680592  	0.10898916  	0.05115755  	0.03845816  	0.03893583  
2023-06-03 18:48:35.175: Early stopping is triggered at epoch: 50
2023-06-03 18:48:35.175: best_result@epoch 0:

2023-06-03 18:48:35.175: Loading from the saved model.
0.00002     	0.00012     	0.00053     	0.00125     	0.00300     	0.00582     	0.01077     	0.01888     	0.02698     	0.04212     
2023-06-03 18:49:52.974: 		0.00681467  	0.10946921  	0.05167357  	0.03896364  	0.03944194  
/home/Thesis/model/general_recommender/SGL.py:146: RuntimeWarning: divide by zero encountered in power
  d_inv = np.power(rowsum, -0.5).flatten()
