seed= 2021
load saved data...
Item degree grouping...
User degree grouping...
Data loading finished
Evaluate model with cpp
2023-06-10 08:12:26.281: Dataset name: ifashion
The number of users: 300000
The number of items: 81614
The number of ratings: 1607813
Average actions of users: 5.36
Average actions of items: 19.70
The sparsity of the dataset: 99.993433%
2023-06-10 08:12:26.282: 

NeuRec hyperparameters:
recommender=SGL
config_dir=./conf
gpu_id=0
gpu_mem=1.0
data.input.path=dataset
data.input.dataset=ifashion
data.column.format=UI
data.convert.separator=','
user_min=0
item_min=0
splitter=given
ratio=0.8
by_time=False
metric=["Precision", "Recall", "NDCG", "MAP", "MRR"]
topk=[20]
group_view=None
rec.evaluate.neg=0
test_batch_size=128
num_thread=8
start_testing_epoch=0
proj_path=./

SGL's hyperparameters:
seed=2021
aug_type=2
reg=1e-3
embed_size=64
n_layers=3
ssl_reg=0.02
ssl_ratio=0.4
ssl_temp=0.5
ssl_mode=both_side
ssl_loss_type=0
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=1024
num_negatives=1
init_method=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=20
pretrain=0
save_flag=1

Using default loss
2023-06-10 08:12:46.293: metrics:	Precision@20	Recall@20   	NDCG@20     	MAP@20      	MRR@20      
2023-06-10 08:13:56.713: 		0.00000688  	0.00010468  	0.00003754  	0.00002068  	0.00002068  
2023-06-10 08:19:24.422: [iter 1 : loss : 1.0700 = 0.6717 + 0.3981 + 0.0002, time: 323.060952]
2023-06-10 08:20:13.815: epoch 1:	0.00291462  	0.04686867  	0.02094448  	0.01527820  	0.01538225  
2023-06-10 08:20:13.816: Found a better model.
2023-06-10 08:20:13.816: Save model to file as pretrain.
2023-06-10 08:25:40.717: [iter 2 : loss : 0.7281 = 0.3066 + 0.4166 + 0.0048, time: 321.424533]
2023-06-10 08:26:30.461: epoch 2:	0.00347539  	0.05580522  	0.02478947  	0.01802126  	0.01815200  
2023-06-10 08:26:30.461: Found a better model.
2023-06-10 08:26:30.461: Save model to file as pretrain.
2023-06-10 08:31:56.554: [iter 3 : loss : 0.5788 = 0.1541 + 0.4164 + 0.0083, time: 320.700716]
2023-06-10 08:32:46.292: epoch 3:	0.00389049  	0.06241686  	0.02775811  	0.02016193  	0.02031347  
2023-06-10 08:32:46.292: Found a better model.
2023-06-10 08:32:46.292: Save model to file as pretrain.
2023-06-10 08:38:15.202: [iter 4 : loss : 0.5307 = 0.1079 + 0.4130 + 0.0098, time: 323.510373]
2023-06-10 08:39:03.602: epoch 4:	0.00422017  	0.06776230  	0.03020784  	0.02193709  	0.02210733  
2023-06-10 08:39:03.603: Found a better model.
2023-06-10 08:39:03.603: Save model to file as pretrain.
2023-06-10 08:44:26.091: [iter 5 : loss : 0.5039 = 0.0826 + 0.4105 + 0.0108, time: 317.059024]
2023-06-10 08:45:14.035: epoch 5:	0.00452807  	0.07280511  	0.03250958  	0.02358432  	0.02377132  
2023-06-10 08:45:14.035: Found a better model.
2023-06-10 08:45:14.035: Save model to file as pretrain.
2023-06-10 08:50:27.865: [iter 6 : loss : 0.4863 = 0.0660 + 0.4086 + 0.0117, time: 308.439761]
2023-06-10 08:51:16.226: epoch 6:	0.00474083  	0.07629808  	0.03418273  	0.02484265  	0.02504469  
2023-06-10 08:51:16.226: Found a better model.
2023-06-10 08:51:16.226: Save model to file as pretrain.
2023-06-10 08:56:56.588: [iter 7 : loss : 0.4736 = 0.0540 + 0.4072 + 0.0124, time: 334.923155]
2023-06-10 08:57:45.506: epoch 7:	0.00493350  	0.07935876  	0.03570119  	0.02601053  	0.02622732  
2023-06-10 08:57:45.506: Found a better model.
2023-06-10 08:57:45.506: Save model to file as pretrain.
2023-06-10 09:03:27.432: [iter 8 : loss : 0.4645 = 0.0453 + 0.4061 + 0.0130, time: 336.018178]
2023-06-10 09:04:16.524: epoch 8:	0.00509415  	0.08196001  	0.03696646  	0.02698757  	0.02721301  
2023-06-10 09:04:16.524: Found a better model.
2023-06-10 09:04:16.524: Save model to file as pretrain.
2023-06-10 09:09:55.123: [iter 9 : loss : 0.4575 = 0.0387 + 0.4053 + 0.0136, time: 329.787108]
2023-06-10 09:10:44.782: epoch 9:	0.00522222  	0.08402759  	0.03808212  	0.02790950  	0.02814429  
2023-06-10 09:10:44.782: Found a better model.
2023-06-10 09:10:44.783: Save model to file as pretrain.
2023-06-10 09:16:24.176: [iter 10 : loss : 0.4520 = 0.0334 + 0.4045 + 0.0141, time: 330.844651]
2023-06-10 09:17:13.350: epoch 10:	0.00533837  	0.08584610  	0.03907317  	0.02873101  	0.02897565  
2023-06-10 09:17:13.350: Found a better model.
2023-06-10 09:17:13.350: Save model to file as pretrain.
2023-06-10 09:22:44.372: [iter 11 : loss : 0.4474 = 0.0290 + 0.4040 + 0.0145, time: 322.147894]
2023-06-10 09:23:33.943: epoch 11:	0.00543350  	0.08738286  	0.03987205  	0.02936805  	0.02962363  
2023-06-10 09:23:33.943: Found a better model.
2023-06-10 09:23:33.943: Save model to file as pretrain.
2023-06-10 09:29:15.164: [iter 12 : loss : 0.4435 = 0.0253 + 0.4035 + 0.0148, time: 332.326575]
2023-06-10 09:30:07.121: epoch 12:	0.00552508  	0.08878031  	0.04062174  	0.02996654  	0.03023024  
2023-06-10 09:30:07.121: Found a better model.
2023-06-10 09:30:07.121: Save model to file as pretrain.
2023-06-10 09:35:43.758: [iter 13 : loss : 0.4406 = 0.0224 + 0.4031 + 0.0151, time: 327.721068]
2023-06-10 09:36:33.988: epoch 13:	0.00559135  	0.08988052  	0.04123604  	0.03050417  	0.03077393  
2023-06-10 09:36:33.988: Found a better model.
2023-06-10 09:36:33.988: Save model to file as pretrain.
2023-06-10 09:42:16.970: [iter 14 : loss : 0.4379 = 0.0199 + 0.4027 + 0.0153, time: 334.244349]
2023-06-10 09:43:05.373: epoch 14:	0.00567250  	0.09115393  	0.04190879  	0.03104571  	0.03132627  
2023-06-10 09:43:05.373: Found a better model.
2023-06-10 09:43:05.373: Save model to file as pretrain.
2023-06-10 09:48:55.863: [iter 15 : loss : 0.4360 = 0.0182 + 0.4024 + 0.0155, time: 341.566576]
2023-06-10 09:49:45.172: epoch 15:	0.00574193  	0.09214423  	0.04250541  	0.03155329  	0.03183971  
2023-06-10 09:49:45.172: Found a better model.
2023-06-10 09:49:45.172: Save model to file as pretrain.
2023-06-10 09:55:35.090: [iter 16 : loss : 0.4342 = 0.0164 + 0.4021 + 0.0156, time: 340.988574]
2023-06-10 09:56:24.506: epoch 16:	0.00579014  	0.09288725  	0.04287322  	0.03185378  	0.03214774  
2023-06-10 09:56:24.507: Found a better model.
2023-06-10 09:56:24.507: Save model to file as pretrain.
2023-06-10 10:02:02.884: [iter 17 : loss : 0.4327 = 0.0151 + 0.4019 + 0.0157, time: 329.454083]
2023-06-10 10:02:51.874: epoch 17:	0.00582662  	0.09350181  	0.04322961  	0.03214320  	0.03245531  
2023-06-10 10:02:51.875: Found a better model.
2023-06-10 10:02:51.875: Save model to file as pretrain.
2023-06-10 10:08:27.222: [iter 18 : loss : 0.4314 = 0.0140 + 0.4017 + 0.0158, time: 326.210866]
2023-06-10 10:09:17.423: epoch 18:	0.00587706  	0.09437882  	0.04367195  	0.03248840  	0.03281145  
2023-06-10 10:09:17.423: Found a better model.
2023-06-10 10:09:17.423: Save model to file as pretrain.
2023-06-10 10:15:13.986: [iter 19 : loss : 0.4302 = 0.0129 + 0.4015 + 0.0158, time: 347.752080]
2023-06-10 10:16:03.299: epoch 19:	0.00591503  	0.09490614  	0.04397745  	0.03276236  	0.03309076  
2023-06-10 10:16:03.300: Found a better model.
2023-06-10 10:16:03.300: Save model to file as pretrain.
2023-06-10 10:21:43.452: [iter 20 : loss : 0.4292 = 0.0121 + 0.4014 + 0.0158, time: 331.082964]
2023-06-10 10:22:32.649: epoch 20:	0.00594165  	0.09525303  	0.04426082  	0.03301973  	0.03336125  
2023-06-10 10:22:32.649: Found a better model.
2023-06-10 10:22:32.649: Save model to file as pretrain.
2023-06-10 10:28:13.007: [iter 21 : loss : 0.4285 = 0.0114 + 0.4013 + 0.0158, time: 331.323398]
2023-06-10 10:29:03.697: epoch 21:	0.00599731  	0.09598887  	0.04464365  	0.03334375  	0.03368025  
2023-06-10 10:29:03.697: Found a better model.
2023-06-10 10:29:03.697: Save model to file as pretrain.
2023-06-10 10:34:36.313: [iter 22 : loss : 0.4278 = 0.0109 + 0.4011 + 0.0157, time: 323.522241]
2023-06-10 10:35:25.146: epoch 22:	0.00602598  	0.09647336  	0.04496185  	0.03362614  	0.03397901  
2023-06-10 10:35:25.146: Found a better model.
2023-06-10 10:35:25.146: Save model to file as pretrain.
2023-06-10 10:41:03.755: [iter 23 : loss : 0.4271 = 0.0104 + 0.4010 + 0.0157, time: 329.327309]
2023-06-10 10:41:52.584: epoch 23:	0.00606563  	0.09718317  	0.04526052  	0.03383078  	0.03419183  
2023-06-10 10:41:52.584: Found a better model.
2023-06-10 10:41:52.584: Save model to file as pretrain.
2023-06-10 10:47:31.561: [iter 24 : loss : 0.4264 = 0.0098 + 0.4009 + 0.0156, time: 330.011312]
2023-06-10 10:48:20.678: epoch 24:	0.00608517  	0.09756079  	0.04537499  	0.03387713  	0.03424270  
2023-06-10 10:48:20.678: Found a better model.
2023-06-10 10:48:20.678: Save model to file as pretrain.
2023-06-10 10:54:02.457: [iter 25 : loss : 0.4258 = 0.0094 + 0.4009 + 0.0156, time: 332.832095]
2023-06-10 10:54:50.019: epoch 25:	0.00610695  	0.09779463  	0.04552315  	0.03399602  	0.03435266  
2023-06-10 10:54:50.019: Found a better model.
2023-06-10 10:54:50.019: Save model to file as pretrain.
2023-06-10 11:00:17.480: [iter 26 : loss : 0.4253 = 0.0090 + 0.4008 + 0.0155, time: 318.394594]
2023-06-10 11:01:06.498: epoch 26:	0.00614139  	0.09826258  	0.04573947  	0.03417911  	0.03454853  
2023-06-10 11:01:06.498: Found a better model.
2023-06-10 11:01:06.498: Save model to file as pretrain.
2023-06-10 11:06:47.311: [iter 27 : loss : 0.4250 = 0.0088 + 0.4007 + 0.0154, time: 331.838415]
2023-06-10 11:07:35.718: epoch 27:	0.00614437  	0.09828747  	0.04591876  	0.03440977  	0.03478699  
2023-06-10 11:07:35.719: Found a better model.
2023-06-10 11:07:35.719: Save model to file as pretrain.
2023-06-10 11:13:11.916: [iter 28 : loss : 0.4245 = 0.0084 + 0.4007 + 0.0154, time: 326.815184]
2023-06-10 11:14:00.561: epoch 28:	0.00615050  	0.09845143  	0.04606139  	0.03456477  	0.03493674  
2023-06-10 11:14:00.561: Found a better model.
2023-06-10 11:14:00.561: Save model to file as pretrain.
2023-06-10 11:19:41.690: [iter 29 : loss : 0.4243 = 0.0083 + 0.4006 + 0.0153, time: 331.839262]
2023-06-10 11:20:30.566: epoch 29:	0.00617321  	0.09874383  	0.04621687  	0.03467205  	0.03504913  
2023-06-10 11:20:30.566: Found a better model.
2023-06-10 11:20:30.566: Save model to file as pretrain.
2023-06-10 11:26:14.094: [iter 30 : loss : 0.4238 = 0.0080 + 0.4006 + 0.0153, time: 333.978228]
2023-06-10 11:27:03.822: epoch 30:	0.00619742  	0.09919554  	0.04645897  	0.03487028  	0.03524452  
2023-06-10 11:27:03.822: Found a better model.
2023-06-10 11:27:03.822: Save model to file as pretrain.
2023-06-10 11:32:43.183: [iter 31 : loss : 0.4236 = 0.0079 + 0.4005 + 0.0152, time: 329.600580]
2023-06-10 11:33:31.951: epoch 31:	0.00621193  	0.09940262  	0.04655392  	0.03491263  	0.03529452  
2023-06-10 11:33:31.951: Found a better model.
2023-06-10 11:33:31.952: Save model to file as pretrain.
2023-06-10 11:39:33.289: [iter 32 : loss : 0.4233 = 0.0076 + 0.4005 + 0.0152, time: 351.897782]
2023-06-10 11:40:22.556: epoch 32:	0.00622012  	0.09961875  	0.04667480  	0.03502190  	0.03539873  
2023-06-10 11:40:22.556: Found a better model.
2023-06-10 11:40:22.556: Save model to file as pretrain.
2023-06-10 11:46:00.258: [iter 33 : loss : 0.4230 = 0.0074 + 0.4005 + 0.0152, time: 327.362012]
2023-06-10 11:46:50.872: epoch 33:	0.00621696  	0.09948105  	0.04669719  	0.03510865  	0.03546720  
2023-06-10 11:52:53.285: [iter 34 : loss : 0.4229 = 0.0073 + 0.4004 + 0.0151, time: 357.904866]
2023-06-10 11:53:42.699: epoch 34:	0.00622459  	0.09954097  	0.04673816  	0.03515155  	0.03554440  
2023-06-10 11:59:15.758: [iter 35 : loss : 0.4226 = 0.0071 + 0.4004 + 0.0151, time: 328.506097]
2023-06-10 12:00:04.862: epoch 35:	0.00623706  	0.09961008  	0.04684516  	0.03528797  	0.03567846  
2023-06-10 12:05:39.585: [iter 36 : loss : 0.4225 = 0.0070 + 0.4004 + 0.0151, time: 330.232650]
2023-06-10 12:06:29.336: epoch 36:	0.00624599  	0.09977756  	0.04692609  	0.03534529  	0.03573441  
2023-06-10 12:06:29.336: Found a better model.
2023-06-10 12:06:29.336: Save model to file as pretrain.
2023-06-10 12:12:16.090: [iter 37 : loss : 0.4223 = 0.0069 + 0.4003 + 0.0151, time: 329.906770]
2023-06-10 12:13:06.709: epoch 37:	0.00626516  	0.10005800  	0.04703684  	0.03541601  	0.03579252  
2023-06-10 12:13:06.709: Found a better model.
2023-06-10 12:13:06.709: Save model to file as pretrain.
2023-06-10 12:18:59.366: [iter 38 : loss : 0.4221 = 0.0068 + 0.4003 + 0.0150, time: 342.659048]
2023-06-10 12:19:50.457: epoch 38:	0.00629253  	0.10044028  	0.04723473  	0.03555648  	0.03595204  
2023-06-10 12:19:50.458: Found a better model.
2023-06-10 12:19:50.458: Save model to file as pretrain.
2023-06-10 12:25:29.972: [iter 39 : loss : 0.4220 = 0.0067 + 0.4003 + 0.0150, time: 329.718704]
2023-06-10 12:26:20.874: epoch 39:	0.00629104  	0.10039438  	0.04732689  	0.03568118  	0.03608414  
2023-06-10 12:31:49.546: [iter 40 : loss : 0.4218 = 0.0065 + 0.4003 + 0.0150, time: 324.187201]
2023-06-10 12:32:38.522: epoch 40:	0.00629421  	0.10048319  	0.04736206  	0.03573370  	0.03613659  
2023-06-10 12:32:38.522: Found a better model.
2023-06-10 12:32:38.528: Save model to file as pretrain.
2023-06-10 12:38:20.848: [iter 41 : loss : 0.4217 = 0.0064 + 0.4003 + 0.0150, time: 332.764018]
2023-06-10 12:39:11.524: epoch 41:	0.00627820  	0.10039406  	0.04736320  	0.03576474  	0.03615041  
2023-06-10 12:44:37.953: [iter 42 : loss : 0.4217 = 0.0064 + 0.4002 + 0.0150, time: 321.939158]
2023-06-10 12:45:27.183: epoch 42:	0.00628900  	0.10042483  	0.04741158  	0.03582383  	0.03621874  
2023-06-10 12:50:49.409: [iter 43 : loss : 0.4215 = 0.0063 + 0.4002 + 0.0150, time: 317.711145]
2023-06-10 12:51:39.252: epoch 43:	0.00631487  	0.10089342  	0.04754874  	0.03586956  	0.03626834  
2023-06-10 12:51:39.252: Found a better model.
2023-06-10 12:51:39.252: Save model to file as pretrain.
2023-06-10 12:57:10.006: [iter 44 : loss : 0.4215 = 0.0064 + 0.4002 + 0.0150, time: 321.225353]
2023-06-10 12:57:59.545: epoch 44:	0.00631319  	0.10082416  	0.04757911  	0.03589741  	0.03629549  
2023-06-10 13:03:32.284: [iter 45 : loss : 0.4214 = 0.0062 + 0.4002 + 0.0149, time: 328.242769]
2023-06-10 13:04:22.032: epoch 45:	0.00632920  	0.10107265  	0.04764130  	0.03592400  	0.03632752  
2023-06-10 13:04:22.032: Found a better model.
2023-06-10 13:04:22.032: Save model to file as pretrain.
2023-06-10 13:09:42.712: [iter 46 : loss : 0.4212 = 0.0061 + 0.4002 + 0.0149, time: 310.861495]
2023-06-10 13:10:33.027: epoch 46:	0.00633013  	0.10109692  	0.04770597  	0.03599826  	0.03641298  
2023-06-10 13:10:33.027: Found a better model.
2023-06-10 13:10:33.028: Save model to file as pretrain.
2023-06-10 13:16:11.036: [iter 47 : loss : 0.4212 = 0.0061 + 0.4002 + 0.0149, time: 328.449763]
2023-06-10 13:17:00.920: epoch 47:	0.00632548  	0.10101811  	0.04770518  	0.03602725  	0.03643698  
2023-06-10 13:22:25.562: [iter 48 : loss : 0.4212 = 0.0061 + 0.4002 + 0.0149, time: 320.059735]
2023-06-10 13:23:16.406: epoch 48:	0.00633014  	0.10121001  	0.04768358  	0.03595147  	0.03635313  
2023-06-10 13:23:16.406: Found a better model.
2023-06-10 13:23:16.406: Save model to file as pretrain.
2023-06-10 13:28:43.807: [iter 49 : loss : 0.4211 = 0.0061 + 0.4001 + 0.0149, time: 317.731007]
2023-06-10 13:29:32.282: epoch 49:	0.00634726  	0.10147036  	0.04782164  	0.03604951  	0.03644729  
2023-06-10 13:29:32.282: Found a better model.
2023-06-10 13:29:32.282: Save model to file as pretrain.
2023-06-10 13:35:14.081: [iter 50 : loss : 0.4210 = 0.0060 + 0.4001 + 0.0149, time: 332.425103]
2023-06-10 13:36:02.124: epoch 50:	0.00634540  	0.10143877  	0.04780618  	0.03602515  	0.03642144  
2023-06-10 13:41:40.769: [iter 51 : loss : 0.4210 = 0.0060 + 0.4001 + 0.0149, time: 334.107329]
2023-06-10 13:42:28.350: epoch 51:	0.00634856  	0.10139267  	0.04791259  	0.03618271  	0.03657522  
2023-06-10 13:47:51.483: [iter 52 : loss : 0.4209 = 0.0059 + 0.4001 + 0.0149, time: 318.625042]
2023-06-10 13:48:40.644: epoch 52:	0.00635619  	0.10152458  	0.04790507  	0.03614242  	0.03654086  
2023-06-10 13:48:40.644: Found a better model.
2023-06-10 13:48:40.644: Save model to file as pretrain.
2023-06-10 13:54:14.842: [iter 53 : loss : 0.4208 = 0.0058 + 0.4001 + 0.0149, time: 324.390531]
2023-06-10 13:55:03.239: epoch 53:	0.00635935  	0.10155559  	0.04802411  	0.03629329  	0.03670361  
2023-06-10 13:55:03.239: Found a better model.
2023-06-10 13:55:03.239: Save model to file as pretrain.
2023-06-10 14:00:41.132: [iter 54 : loss : 0.4207 = 0.0057 + 0.4001 + 0.0149, time: 328.125576]
2023-06-10 14:01:30.960: epoch 54:	0.00637760  	0.10183686  	0.04815670  	0.03639294  	0.03680025  
2023-06-10 14:01:30.960: Found a better model.
2023-06-10 14:01:30.960: Save model to file as pretrain.
2023-06-10 14:07:05.133: [iter 55 : loss : 0.4207 = 0.0057 + 0.4001 + 0.0149, time: 324.404733]
2023-06-10 14:07:54.229: epoch 55:	0.00638188  	0.10193989  	0.04819663  	0.03641748  	0.03682593  
2023-06-10 14:07:54.230: Found a better model.
2023-06-10 14:07:54.230: Save model to file as pretrain.
2023-06-10 14:13:34.352: [iter 56 : loss : 0.4207 = 0.0057 + 0.4001 + 0.0149, time: 330.448457]
2023-06-10 14:14:22.758: epoch 56:	0.00638411  	0.10200256  	0.04827604  	0.03651699  	0.03692798  
2023-06-10 14:14:22.758: Found a better model.
2023-06-10 14:14:22.758: Save model to file as pretrain.
2023-06-10 14:19:55.006: [iter 57 : loss : 0.4206 = 0.0056 + 0.4001 + 0.0149, time: 322.853585]
2023-06-10 14:20:44.791: epoch 57:	0.00639603  	0.10224340  	0.04825201  	0.03642519  	0.03682775  
2023-06-10 14:20:44.791: Found a better model.
2023-06-10 14:20:44.791: Save model to file as pretrain.
2023-06-10 14:26:14.463: [iter 58 : loss : 0.4206 = 0.0056 + 0.4001 + 0.0149, time: 319.793243]
2023-06-10 14:27:03.348: epoch 58:	0.00637705  	0.10200949  	0.04830312  	0.03652795  	0.03694180  
2023-06-10 14:32:36.448: [iter 59 : loss : 0.4206 = 0.0057 + 0.4001 + 0.0149, time: 328.616185]
2023-06-10 14:33:24.685: epoch 59:	0.00639658  	0.10224399  	0.04833443  	0.03651720  	0.03693798  
2023-06-10 14:33:24.685: Found a better model.
2023-06-10 14:33:24.686: Save model to file as pretrain.
2023-06-10 14:38:52.873: [iter 60 : loss : 0.4206 = 0.0056 + 0.4001 + 0.0149, time: 318.686595]
2023-06-10 14:39:41.924: epoch 60:	0.00639827  	0.10224812  	0.04831825  	0.03651706  	0.03692283  
2023-06-10 14:39:41.924: Found a better model.
2023-06-10 14:39:41.924: Save model to file as pretrain.
2023-06-10 14:45:15.897: [iter 61 : loss : 0.4205 = 0.0055 + 0.4000 + 0.0149, time: 324.180678]
2023-06-10 14:46:05.140: epoch 61:	0.00641409  	0.10259792  	0.04848678  	0.03664679  	0.03706598  
2023-06-10 14:46:05.140: Found a better model.
2023-06-10 14:46:05.140: Save model to file as pretrain.
2023-06-10 14:51:41.527: [iter 62 : loss : 0.4205 = 0.0055 + 0.4001 + 0.0149, time: 326.674245]
2023-06-10 14:52:30.303: epoch 62:	0.00641297  	0.10250847  	0.04847606  	0.03663067  	0.03703914  
2023-06-10 14:58:02.099: [iter 63 : loss : 0.4204 = 0.0055 + 0.4000 + 0.0149, time: 327.304071]
2023-06-10 14:58:51.782: epoch 63:	0.00641185  	0.10254943  	0.04849905  	0.03665295  	0.03705889  
2023-06-10 15:04:39.292: [iter 64 : loss : 0.4204 = 0.0054 + 0.4000 + 0.0149, time: 343.039425]
2023-06-10 15:05:29.270: epoch 64:	0.00641874  	0.10272411  	0.04858835  	0.03672944  	0.03712373  
2023-06-10 15:05:29.270: Found a better model.
2023-06-10 15:05:29.270: Save model to file as pretrain.
2023-06-10 15:11:04.089: [iter 65 : loss : 0.4204 = 0.0055 + 0.4000 + 0.0149, time: 325.168296]
2023-06-10 15:11:52.932: epoch 65:	0.00642954  	0.10278957  	0.04861101  	0.03673664  	0.03715065  
2023-06-10 15:11:52.932: Found a better model.
2023-06-10 15:11:52.932: Save model to file as pretrain.
2023-06-10 15:17:23.860: [iter 66 : loss : 0.4203 = 0.0054 + 0.4000 + 0.0149, time: 321.363417]
2023-06-10 15:18:12.546: epoch 66:	0.00641874  	0.10263677  	0.04860201  	0.03674743  	0.03716081  
2023-06-10 15:23:30.596: [iter 67 : loss : 0.4203 = 0.0053 + 0.4000 + 0.0149, time: 313.525485]
2023-06-10 15:24:20.847: epoch 67:	0.00642860  	0.10279761  	0.04865279  	0.03675615  	0.03717624  
2023-06-10 15:24:20.847: Found a better model.
2023-06-10 15:24:20.847: Save model to file as pretrain.
2023-06-10 15:29:50.266: [iter 68 : loss : 0.4203 = 0.0054 + 0.4000 + 0.0149, time: 319.535602]
2023-06-10 15:30:39.377: epoch 68:	0.00643697  	0.10297967  	0.04874185  	0.03681435  	0.03723724  
2023-06-10 15:30:39.378: Found a better model.
2023-06-10 15:30:39.378: Save model to file as pretrain.
2023-06-10 15:36:14.843: [iter 69 : loss : 0.4202 = 0.0053 + 0.4000 + 0.0149, time: 325.618173]
2023-06-10 15:37:03.744: epoch 69:	0.00644330  	0.10298166  	0.04876466  	0.03687089  	0.03728743  
2023-06-10 15:37:03.744: Found a better model.
2023-06-10 15:37:03.744: Save model to file as pretrain.
2023-06-10 15:42:44.579: [iter 70 : loss : 0.4202 = 0.0053 + 0.4000 + 0.0149, time: 331.065900]
2023-06-10 15:43:33.690: epoch 70:	0.00647736  	0.10353708  	0.04892629  	0.03692305  	0.03736007  
2023-06-10 15:43:33.690: Found a better model.
2023-06-10 15:43:33.690: Save model to file as pretrain.
2023-06-10 15:49:21.685: [iter 71 : loss : 0.4202 = 0.0053 + 0.4000 + 0.0149, time: 338.106102]
2023-06-10 15:50:10.319: epoch 71:	0.00646899  	0.10344621  	0.04891019  	0.03688134  	0.03731665  
2023-06-10 15:55:51.134: [iter 72 : loss : 0.4202 = 0.0053 + 0.4000 + 0.0149, time: 336.278678]
2023-06-10 15:56:39.666: epoch 72:	0.00647066  	0.10352377  	0.04895853  	0.03695423  	0.03738251  
2023-06-10 16:02:13.224: [iter 73 : loss : 0.4201 = 0.0052 + 0.4000 + 0.0149, time: 328.963006]
2023-06-10 16:03:01.641: epoch 73:	0.00648128  	0.10362819  	0.04899362  	0.03695668  	0.03738604  
2023-06-10 16:03:01.641: Found a better model.
2023-06-10 16:03:01.641: Save model to file as pretrain.
2023-06-10 16:08:32.052: [iter 74 : loss : 0.4202 = 0.0053 + 0.4000 + 0.0149, time: 323.340012]
2023-06-10 16:09:20.710: epoch 74:	0.00648742  	0.10366971  	0.04898345  	0.03694268  	0.03736839  
2023-06-10 16:09:20.710: Found a better model.
2023-06-10 16:09:20.710: Save model to file as pretrain.
2023-06-10 16:14:50.872: [iter 75 : loss : 0.4202 = 0.0053 + 0.4000 + 0.0149, time: 323.700014]
2023-06-10 16:15:39.612: epoch 75:	0.00647513  	0.10344245  	0.04896017  	0.03699506  	0.03741782  
2023-06-10 16:21:10.840: [iter 76 : loss : 0.4202 = 0.0053 + 0.4000 + 0.0149, time: 326.641220]
2023-06-10 16:21:59.965: epoch 76:	0.00648109  	0.10368419  	0.04906828  	0.03707852  	0.03749198  
2023-06-10 16:21:59.965: Found a better model.
2023-06-10 16:21:59.965: Save model to file as pretrain.
2023-06-10 16:27:29.947: [iter 77 : loss : 0.4202 = 0.0053 + 0.4000 + 0.0149, time: 324.455249]
2023-06-10 16:28:18.174: epoch 77:	0.00647532  	0.10351995  	0.04902541  	0.03702487  	0.03744337  
2023-06-10 16:33:53.345: [iter 78 : loss : 0.4201 = 0.0052 + 0.4000 + 0.0149, time: 330.557501]
2023-06-10 16:34:42.618: epoch 78:	0.00648128  	0.10367281  	0.04900004  	0.03695658  	0.03738385  
2023-06-10 16:40:15.882: [iter 79 : loss : 0.4200 = 0.0051 + 0.4000 + 0.0149, time: 328.629589]
2023-06-10 16:41:04.748: epoch 79:	0.00648891  	0.10384132  	0.04911352  	0.03707911  	0.03751422  
2023-06-10 16:41:04.748: Found a better model.
2023-06-10 16:41:04.748: Save model to file as pretrain.
2023-06-10 16:46:34.610: [iter 80 : loss : 0.4201 = 0.0052 + 0.4000 + 0.0149, time: 324.207558]
2023-06-10 16:47:23.734: epoch 80:	0.00647588  	0.10356419  	0.04904161  	0.03703399  	0.03746949  
2023-06-10 16:52:43.888: [iter 81 : loss : 0.4201 = 0.0052 + 0.4000 + 0.0149, time: 315.554048]
2023-06-10 16:53:32.508: epoch 81:	0.00649691  	0.10396519  	0.04919465  	0.03716607  	0.03758655  
2023-06-10 16:53:32.508: Found a better model.
2023-06-10 16:53:32.508: Save model to file as pretrain.
2023-06-10 16:59:14.738: [iter 82 : loss : 0.4200 = 0.0052 + 0.4000 + 0.0149, time: 336.712655]
2023-06-10 17:00:03.528: epoch 82:	0.00649598  	0.10393955  	0.04923043  	0.03722931  	0.03765622  
2023-06-10 17:05:39.067: [iter 83 : loss : 0.4200 = 0.0051 + 0.4000 + 0.0149, time: 330.935696]
2023-06-10 17:06:26.868: epoch 83:	0.00650101  	0.10399871  	0.04922140  	0.03718563  	0.03761048  
2023-06-10 17:06:26.869: Found a better model.
2023-06-10 17:06:26.869: Save model to file as pretrain.
2023-06-10 17:11:59.050: [iter 84 : loss : 0.4200 = 0.0051 + 0.4000 + 0.0149, time: 326.710244]
2023-06-10 17:12:49.951: epoch 84:	0.00650623  	0.10410914  	0.04926848  	0.03722984  	0.03764451  
2023-06-10 17:12:49.956: Found a better model.
2023-06-10 17:12:49.956: Save model to file as pretrain.
2023-06-10 17:18:38.846: [iter 85 : loss : 0.4200 = 0.0051 + 0.4000 + 0.0149, time: 343.429578]
2023-06-10 17:19:34.848: epoch 85:	0.00651590  	0.10418513  	0.04935509  	0.03730929  	0.03775809  
2023-06-10 17:19:34.848: Found a better model.
2023-06-10 17:19:34.848: Save model to file as pretrain.
2023-06-10 17:25:12.334: [iter 86 : loss : 0.4200 = 0.0051 + 0.4000 + 0.0149, time: 332.004765]
2023-06-10 17:26:00.694: epoch 86:	0.00652204  	0.10429733  	0.04935811  	0.03728783  	0.03772069  
2023-06-10 17:26:00.694: Found a better model.
2023-06-10 17:26:00.695: Save model to file as pretrain.
2023-06-10 17:31:31.487: [iter 87 : loss : 0.4200 = 0.0051 + 0.4000 + 0.0149, time: 325.292402]
2023-06-10 17:32:19.944: epoch 87:	0.00652112  	0.10438238  	0.04942854  	0.03737386  	0.03779497  
2023-06-10 17:32:19.945: Found a better model.
2023-06-10 17:32:19.945: Save model to file as pretrain.
2023-06-10 17:37:53.829: [iter 88 : loss : 0.4200 = 0.0051 + 0.4000 + 0.0149, time: 328.419202]
2023-06-10 17:38:42.206: epoch 88:	0.00652261  	0.10435405  	0.04936059  	0.03725420  	0.03768145  
2023-06-10 17:44:12.384: [iter 89 : loss : 0.4199 = 0.0050 + 0.4000 + 0.0149, time: 325.700908]
2023-06-10 17:45:03.018: epoch 89:	0.00652056  	0.10434616  	0.04941355  	0.03733005  	0.03776496  
2023-06-10 17:50:40.607: [iter 90 : loss : 0.4199 = 0.0050 + 0.4000 + 0.0149, time: 332.834409]
2023-06-10 17:51:29.001: epoch 90:	0.00650921  	0.10418288  	0.04940126  	0.03736962  	0.03781015  
2023-06-10 17:56:52.345: [iter 91 : loss : 0.4200 = 0.0052 + 0.3999 + 0.0149, time: 318.749619]
2023-06-10 17:57:41.075: epoch 91:	0.00653396  	0.10449918  	0.04954261  	0.03749070  	0.03792079  
2023-06-10 17:57:41.075: Found a better model.
2023-06-10 17:57:41.075: Save model to file as pretrain.
2023-06-10 18:03:15.484: [iter 92 : loss : 0.4199 = 0.0050 + 0.3999 + 0.0149, time: 328.931059]
2023-06-10 18:04:03.644: epoch 92:	0.00654382  	0.10476907  	0.04957559  	0.03745269  	0.03789737  
2023-06-10 18:04:03.645: Found a better model.
2023-06-10 18:04:03.645: Save model to file as pretrain.
2023-06-10 18:09:33.640: [iter 93 : loss : 0.4199 = 0.0050 + 0.3999 + 0.0149, time: 324.511003]
2023-06-10 18:10:22.084: epoch 93:	0.00652502  	0.10446686  	0.04954098  	0.03748371  	0.03792942  
2023-06-10 18:15:58.486: [iter 94 : loss : 0.4199 = 0.0050 + 0.3999 + 0.0149, time: 331.892949]
2023-06-10 18:16:46.370: epoch 94:	0.00652540  	0.10447372  	0.04947904  	0.03738995  	0.03782043  
2023-06-10 18:22:18.425: [iter 95 : loss : 0.4199 = 0.0051 + 0.4000 + 0.0149, time: 327.571731]
2023-06-10 18:23:07.410: epoch 95:	0.00653136  	0.10454350  	0.04953067  	0.03741277  	0.03784669  
2023-06-10 18:28:49.497: [iter 96 : loss : 0.4199 = 0.0051 + 0.3999 + 0.0149, time: 337.588890]
2023-06-10 18:29:38.876: epoch 96:	0.00654345  	0.10471304  	0.04958495  	0.03745968  	0.03789703  
2023-06-10 18:35:05.205: [iter 97 : loss : 0.4199 = 0.0050 + 0.3999 + 0.0149, time: 321.795284]
2023-06-10 18:35:55.432: epoch 97:	0.00653880  	0.10460893  	0.04952992  	0.03741679  	0.03785328  
2023-06-10 18:41:29.205: [iter 98 : loss : 0.4198 = 0.0050 + 0.3999 + 0.0149, time: 329.308873]
2023-06-10 18:42:19.317: epoch 98:	0.00654121  	0.10465804  	0.04957277  	0.03745689  	0.03788132  
2023-06-10 18:47:54.113: [iter 99 : loss : 0.4198 = 0.0050 + 0.3999 + 0.0149, time: 330.223013]
2023-06-10 18:48:42.748: epoch 99:	0.00656076  	0.10492641  	0.04971230  	0.03756719  	0.03799364  
2023-06-10 18:48:42.748: Found a better model.
2023-06-10 18:48:42.748: Save model to file as pretrain.
2023-06-10 18:54:17.251: [iter 100 : loss : 0.4198 = 0.0050 + 0.3999 + 0.0149, time: 328.429132]
2023-06-10 18:55:07.345: epoch 100:	0.00655202  	0.10487246  	0.04967102  	0.03754721  	0.03799879  
2023-06-10 19:00:52.032: [iter 101 : loss : 0.4198 = 0.0049 + 0.3999 + 0.0149, time: 340.080575]
2023-06-10 19:01:41.063: epoch 101:	0.00657323  	0.10508390  	0.04974482  	0.03758486  	0.03802441  
2023-06-10 19:01:41.063: Found a better model.
2023-06-10 19:01:41.063: Save model to file as pretrain.
2023-06-10 19:07:20.175: [iter 102 : loss : 0.4198 = 0.0050 + 0.3999 + 0.0149, time: 333.633447]
2023-06-10 19:08:09.897: epoch 102:	0.00657435  	0.10522932  	0.04973533  	0.03752595  	0.03795705  
2023-06-10 19:08:09.897: Found a better model.
2023-06-10 19:08:09.897: Save model to file as pretrain.
2023-06-10 19:13:42.218: [iter 103 : loss : 0.4197 = 0.0049 + 0.3999 + 0.0149, time: 326.795876]
2023-06-10 19:14:36.760: epoch 103:	0.00657770  	0.10528114  	0.04976126  	0.03755164  	0.03798465  
2023-06-10 19:14:36.760: Found a better model.
2023-06-10 19:14:36.760: Save model to file as pretrain.
2023-06-10 19:20:02.079: [iter 104 : loss : 0.4198 = 0.0050 + 0.3999 + 0.0149, time: 319.817503]
2023-06-10 19:20:50.528: epoch 104:	0.00655853  	0.10491809  	0.04971047  	0.03759748  	0.03801290  
2023-06-10 19:26:18.639: [iter 105 : loss : 0.4198 = 0.0050 + 0.3999 + 0.0149, time: 323.543021]
2023-06-10 19:27:07.177: epoch 105:	0.00656392  	0.10497850  	0.04969040  	0.03753635  	0.03796638  
2023-06-10 19:32:38.301: [iter 106 : loss : 0.4198 = 0.0050 + 0.3999 + 0.0149, time: 326.565818]
2023-06-10 19:33:27.969: epoch 106:	0.00656318  	0.10501595  	0.04968132  	0.03749540  	0.03794042  
2023-06-10 19:39:00.436: [iter 107 : loss : 0.4198 = 0.0050 + 0.3999 + 0.0149, time: 327.868795]
2023-06-10 19:39:48.525: epoch 107:	0.00658031  	0.10526486  	0.04982972  	0.03764031  	0.03808668  
2023-06-10 19:45:25.712: [iter 108 : loss : 0.4199 = 0.0051 + 0.3999 + 0.0149, time: 332.571394]
2023-06-10 19:46:15.187: epoch 108:	0.00657211  	0.10506274  	0.04977662  	0.03762947  	0.03807012  
2023-06-10 19:52:00.949: [iter 109 : loss : 0.4198 = 0.0050 + 0.3999 + 0.0149, time: 341.199367]
2023-06-10 19:52:50.611: epoch 109:	0.00658421  	0.10536175  	0.04980087  	0.03757093  	0.03802193  
2023-06-10 19:52:50.611: Found a better model.
2023-06-10 19:52:50.611: Save model to file as pretrain.
2023-06-10 19:58:19.521: [iter 110 : loss : 0.4198 = 0.0049 + 0.3999 + 0.0149, time: 323.404717]
2023-06-10 19:59:09.096: epoch 110:	0.00657361  	0.10524036  	0.04977899  	0.03757060  	0.03801019  
2023-06-10 20:04:48.734: [iter 111 : loss : 0.4198 = 0.0050 + 0.3999 + 0.0149, time: 335.088346]
2023-06-10 20:05:37.484: epoch 111:	0.00657770  	0.10526104  	0.04984293  	0.03768757  	0.03812198  
2023-06-10 20:11:15.465: [iter 112 : loss : 0.4197 = 0.0049 + 0.3999 + 0.0149, time: 333.460912]
2023-06-10 20:12:04.002: epoch 112:	0.00658832  	0.10537539  	0.04982183  	0.03761289  	0.03804749  
2023-06-10 20:12:04.003: Found a better model.
2023-06-10 20:12:04.003: Save model to file as pretrain.
2023-06-10 20:17:41.443: [iter 113 : loss : 0.4197 = 0.0049 + 0.3999 + 0.0149, time: 331.874831]
2023-06-10 20:18:30.768: epoch 113:	0.00659706  	0.10554118  	0.04987707  	0.03767618  	0.03810573  
2023-06-10 20:18:30.768: Found a better model.
2023-06-10 20:18:30.768: Save model to file as pretrain.
2023-06-10 20:24:18.330: [iter 114 : loss : 0.4197 = 0.0049 + 0.3999 + 0.0149, time: 339.578896]
2023-06-10 20:25:07.829: epoch 114:	0.00657919  	0.10517862  	0.04981342  	0.03766372  	0.03810211  
2023-06-10 20:30:44.034: [iter 115 : loss : 0.4197 = 0.0049 + 0.3999 + 0.0149, time: 331.735054]
2023-06-10 20:31:37.457: epoch 115:	0.00656933  	0.10507707  	0.04981889  	0.03771093  	0.03814192  
2023-06-10 20:37:19.848: [iter 116 : loss : 0.4197 = 0.0049 + 0.3999 + 0.0149, time: 337.615154]
2023-06-10 20:38:07.941: epoch 116:	0.00658180  	0.10534990  	0.04988765  	0.03770724  	0.03815750  
2023-06-10 20:43:47.628: [iter 117 : loss : 0.4197 = 0.0049 + 0.3999 + 0.0149, time: 335.168802]
2023-06-10 20:44:37.602: epoch 117:	0.00659092  	0.10542981  	0.04986604  	0.03763305  	0.03808047  
2023-06-10 20:50:08.346: [iter 118 : loss : 0.4196 = 0.0048 + 0.3999 + 0.0149, time: 326.244130]
2023-06-10 20:50:58.640: epoch 118:	0.00658905  	0.10537785  	0.04988603  	0.03769941  	0.03812539  
2023-06-10 20:56:29.695: [iter 119 : loss : 0.4197 = 0.0049 + 0.3999 + 0.0149, time: 326.562137]
2023-06-10 20:57:17.321: epoch 119:	0.00658217  	0.10531596  	0.04986486  	0.03768180  	0.03812188  
2023-06-10 21:02:51.851: [iter 120 : loss : 0.4197 = 0.0049 + 0.3999 + 0.0149, time: 329.982992]
2023-06-10 21:03:40.142: epoch 120:	0.00661363  	0.10585751  	0.05004010  	0.03773069  	0.03817895  
2023-06-10 21:03:40.142: Found a better model.
2023-06-10 21:03:40.142: Save model to file as pretrain.
2023-06-10 21:09:24.432: [iter 121 : loss : 0.4196 = 0.0049 + 0.3999 + 0.0149, time: 335.354257]
2023-06-10 21:10:13.006: epoch 121:	0.00660209  	0.10569821  	0.04991693  	0.03763143  	0.03807621  
2023-06-10 21:15:45.310: [iter 122 : loss : 0.4196 = 0.0049 + 0.3999 + 0.0149, time: 327.743533]
2023-06-10 21:16:33.794: epoch 122:	0.00661288  	0.10580885  	0.05002897  	0.03772142  	0.03818532  
2023-06-10 21:22:02.535: [iter 123 : loss : 0.4196 = 0.0049 + 0.3999 + 0.0149, time: 324.203330]
2023-06-10 21:22:52.127: epoch 123:	0.00660971  	0.10579317  	0.04994342  	0.03762667  	0.03806400  
2023-06-10 21:28:30.516: [iter 124 : loss : 0.4196 = 0.0048 + 0.3999 + 0.0149, time: 333.824641]
2023-06-10 21:29:20.032: epoch 124:	0.00659612  	0.10561130  	0.04996285  	0.03769027  	0.03813818  
2023-06-10 21:34:54.429: [iter 125 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0149, time: 329.820436]
2023-06-10 21:35:44.563: epoch 125:	0.00659557  	0.10566743  	0.04998930  	0.03772552  	0.03814818  
2023-06-10 21:41:30.508: [iter 126 : loss : 0.4196 = 0.0048 + 0.3999 + 0.0148, time: 341.356234]
2023-06-10 21:42:21.007: epoch 126:	0.00659837  	0.10561486  	0.05004437  	0.03779983  	0.03823062  
2023-06-10 21:48:05.182: [iter 127 : loss : 0.4196 = 0.0048 + 0.3999 + 0.0148, time: 339.611618]
2023-06-10 21:48:54.561: epoch 127:	0.00660078  	0.10560981  	0.05002122  	0.03777870  	0.03821079  
2023-06-10 21:54:37.131: [iter 128 : loss : 0.4196 = 0.0049 + 0.3999 + 0.0148, time: 337.916443]
2023-06-10 21:55:26.414: epoch 128:	0.00661158  	0.10576314  	0.05010042  	0.03787530  	0.03831541  
2023-06-10 22:00:53.336: [iter 129 : loss : 0.4196 = 0.0049 + 0.3999 + 0.0148, time: 322.337104]
2023-06-10 22:01:42.137: epoch 129:	0.00660729  	0.10574115  	0.05008059  	0.03784218  	0.03827308  
2023-06-10 22:07:15.608: [iter 130 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 328.864695]
2023-06-10 22:08:04.375: epoch 130:	0.00661120  	0.10580748  	0.05005782  	0.03776299  	0.03819470  
2023-06-10 22:13:42.357: [iter 131 : loss : 0.4196 = 0.0049 + 0.3999 + 0.0148, time: 333.321575]
2023-06-10 22:14:32.895: epoch 131:	0.00661642  	0.10583100  	0.05013053  	0.03788371  	0.03833166  
2023-06-10 22:20:01.717: [iter 132 : loss : 0.4196 = 0.0048 + 0.3999 + 0.0148, time: 324.201424]
2023-06-10 22:20:50.641: epoch 132:	0.00660394  	0.10564026  	0.05012164  	0.03790144  	0.03835816  
2023-06-10 22:26:20.273: [iter 133 : loss : 0.4196 = 0.0048 + 0.3999 + 0.0148, time: 324.944808]
2023-06-10 22:27:09.913: epoch 133:	0.00661642  	0.10580832  	0.05014938  	0.03789793  	0.03835361  
2023-06-10 22:32:41.088: [iter 134 : loss : 0.4196 = 0.0049 + 0.3999 + 0.0148, time: 326.482468]
2023-06-10 22:33:30.220: epoch 134:	0.00663019  	0.10603413  	0.05017362  	0.03786648  	0.03829405  
2023-06-10 22:33:30.220: Found a better model.
2023-06-10 22:33:30.220: Save model to file as pretrain.
2023-06-10 22:39:21.623: [iter 135 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 342.453204]
2023-06-10 22:40:09.903: epoch 135:	0.00662740  	0.10613875  	0.05024637  	0.03791061  	0.03835204  
2023-06-10 22:40:09.903: Found a better model.
2023-06-10 22:40:09.903: Save model to file as pretrain.
2023-06-10 22:45:40.159: [iter 136 : loss : 0.4196 = 0.0049 + 0.3999 + 0.0148, time: 321.010967]
2023-06-10 22:46:28.842: epoch 136:	0.00662424  	0.10603216  	0.05019983  	0.03789124  	0.03832193  
2023-06-10 22:52:04.086: [iter 137 : loss : 0.4196 = 0.0048 + 0.3999 + 0.0148, time: 330.586561]
2023-06-10 22:52:53.959: epoch 137:	0.00661679  	0.10596328  	0.05021453  	0.03793597  	0.03836024  
2023-06-10 22:58:12.747: [iter 138 : loss : 0.4196 = 0.0049 + 0.3999 + 0.0148, time: 314.114203]
2023-06-10 22:59:01.858: epoch 138:	0.00663131  	0.10617923  	0.05030842  	0.03802201  	0.03843922  
2023-06-10 22:59:01.858: Found a better model.
2023-06-10 22:59:01.858: Save model to file as pretrain.
2023-06-10 23:04:40.534: [iter 139 : loss : 0.4196 = 0.0049 + 0.3999 + 0.0148, time: 329.564027]
2023-06-10 23:05:28.774: epoch 139:	0.00660972  	0.10588685  	0.05027011  	0.03806075  	0.03846785  
2023-06-10 23:10:56.723: [iter 140 : loss : 0.4196 = 0.0048 + 0.3999 + 0.0148, time: 323.349972]
2023-06-10 23:11:45.876: epoch 140:	0.00661996  	0.10602649  	0.05037892  	0.03816813  	0.03860561  
2023-06-10 23:17:21.589: [iter 141 : loss : 0.4196 = 0.0049 + 0.3999 + 0.0148, time: 331.108678]
2023-06-10 23:18:15.460: epoch 141:	0.00661214  	0.10582906  	0.05027822  	0.03807610  	0.03850105  
2023-06-10 23:23:47.642: [iter 142 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 327.280128]
2023-06-10 23:24:36.751: epoch 142:	0.00662237  	0.10598833  	0.05032818  	0.03810659  	0.03852252  
2023-06-10 23:30:05.903: [iter 143 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 324.541596]
2023-06-10 23:30:55.807: epoch 143:	0.00662721  	0.10622082  	0.05033613  	0.03805614  	0.03848455  
2023-06-10 23:30:55.807: Found a better model.
2023-06-10 23:30:55.807: Save model to file as pretrain.
2023-06-10 23:36:42.500: [iter 144 : loss : 0.4196 = 0.0048 + 0.3999 + 0.0148, time: 337.859591]
2023-06-10 23:37:33.027: epoch 144:	0.00661884  	0.10587548  	0.05033803  	0.03810563  	0.03854528  
2023-06-10 23:43:13.864: [iter 145 : loss : 0.4196 = 0.0049 + 0.3999 + 0.0148, time: 336.281144]
2023-06-10 23:44:03.248: epoch 145:	0.00662907  	0.10618947  	0.05037007  	0.03807116  	0.03852744  
2023-06-10 23:49:36.342: [iter 146 : loss : 0.4196 = 0.0049 + 0.3999 + 0.0148, time: 328.466534]
2023-06-10 23:50:25.911: epoch 146:	0.00663540  	0.10618024  	0.05038119  	0.03812951  	0.03856925  
2023-06-10 23:56:07.329: [iter 147 : loss : 0.4196 = 0.0049 + 0.3999 + 0.0148, time: 336.886157]
2023-06-10 23:56:56.712: epoch 147:	0.00664211  	0.10638601  	0.05041153  	0.03810292  	0.03853087  
2023-06-10 23:56:56.712: Found a better model.
2023-06-10 23:56:56.712: Save model to file as pretrain.
2023-06-11 00:02:34.534: [iter 148 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 328.905536]
2023-06-11 00:03:24.113: epoch 148:	0.00663281  	0.10619731  	0.05046663  	0.03819821  	0.03864307  
2023-06-11 00:09:10.262: [iter 149 : loss : 0.4196 = 0.0048 + 0.3999 + 0.0148, time: 341.504458]
2023-06-11 00:09:58.216: epoch 149:	0.00663765  	0.10635409  	0.05048738  	0.03820223  	0.03864248  
2023-06-11 00:15:39.175: [iter 150 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 336.462089]
2023-06-11 00:16:28.999: epoch 150:	0.00664658  	0.10653473  	0.05059589  	0.03830005  	0.03874249  
2023-06-11 00:16:28.999: Found a better model.
2023-06-11 00:16:28.999: Save model to file as pretrain.
2023-06-11 00:22:15.872: [iter 151 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 337.961963]
2023-06-11 00:23:05.062: epoch 151:	0.00664453  	0.10645635  	0.05052313  	0.03822811  	0.03867595  
2023-06-11 00:28:45.634: [iter 152 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 336.041309]
2023-06-11 00:29:34.723: epoch 152:	0.00664695  	0.10653407  	0.05050195  	0.03816582  	0.03860710  
2023-06-11 00:34:58.790: [iter 153 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 319.548123]
2023-06-11 00:35:47.996: epoch 153:	0.00664807  	0.10649559  	0.05053835  	0.03819570  	0.03864582  
2023-06-11 00:41:22.106: [iter 154 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 329.572816]
2023-06-11 00:42:10.721: epoch 154:	0.00665793  	0.10663472  	0.05055865  	0.03821286  	0.03863896  
2023-06-11 00:42:10.721: Found a better model.
2023-06-11 00:42:10.721: Save model to file as pretrain.
2023-06-11 00:47:48.637: [iter 155 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 328.763755]
2023-06-11 00:48:37.250: epoch 155:	0.00666165  	0.10663132  	0.05060260  	0.03827783  	0.03871391  
2023-06-11 00:54:20.286: [iter 156 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 338.431914]
2023-06-11 00:55:08.514: epoch 156:	0.00665458  	0.10651207  	0.05051013  	0.03817645  	0.03861623  
2023-06-11 01:00:42.279: [iter 157 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 329.198320]
2023-06-11 01:01:29.814: epoch 157:	0.00665347  	0.10652263  	0.05058377  	0.03829720  	0.03873571  
2023-06-11 01:06:50.160: [iter 158 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 315.803690]
2023-06-11 01:07:39.689: epoch 158:	0.00666314  	0.10670006  	0.05060110  	0.03825939  	0.03868902  
2023-06-11 01:07:39.689: Found a better model.
2023-06-11 01:07:39.689: Save model to file as pretrain.
2023-06-11 01:13:21.222: [iter 159 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 332.072615]
2023-06-11 01:14:11.852: epoch 159:	0.00665905  	0.10662419  	0.05056194  	0.03821616  	0.03865397  
2023-06-11 01:19:47.893: [iter 160 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 331.498333]
2023-06-11 01:20:36.709: epoch 160:	0.00665366  	0.10654165  	0.05048162  	0.03812881  	0.03856203  
2023-06-11 01:26:07.354: [iter 161 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 326.081814]
2023-06-11 01:26:55.834: epoch 161:	0.00665347  	0.10660055  	0.05055649  	0.03820854  	0.03864342  
2023-06-11 01:32:31.256: [iter 162 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 330.885126]
2023-06-11 01:33:20.619: epoch 162:	0.00666668  	0.10674424  	0.05060693  	0.03824294  	0.03869385  
2023-06-11 01:33:20.619: Found a better model.
2023-06-11 01:33:20.619: Save model to file as pretrain.
2023-06-11 01:38:50.773: [iter 163 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 320.639594]
2023-06-11 01:39:40.179: epoch 163:	0.00666296  	0.10668790  	0.05060218  	0.03821256  	0.03866593  
2023-06-11 01:45:09.159: [iter 164 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 324.369235]
2023-06-11 01:45:59.410: epoch 164:	0.00667264  	0.10691661  	0.05069178  	0.03832312  	0.03876741  
2023-06-11 01:45:59.410: Found a better model.
2023-06-11 01:45:59.410: Save model to file as pretrain.
2023-06-11 01:51:33.488: [iter 165 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 325.041521]
2023-06-11 01:52:21.755: epoch 165:	0.00668696  	0.10707554  	0.05075739  	0.03835416  	0.03880659  
2023-06-11 01:52:21.755: Found a better model.
2023-06-11 01:52:21.755: Save model to file as pretrain.
2023-06-11 01:58:01.632: [iter 166 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 330.922887]
2023-06-11 01:58:51.468: epoch 166:	0.00668641  	0.10703813  	0.05074742  	0.03834131  	0.03879888  
2023-06-11 02:04:33.340: [iter 167 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 337.329470]
2023-06-11 02:05:25.887: epoch 167:	0.00667282  	0.10685079  	0.05063060  	0.03824852  	0.03870057  
2023-06-11 02:11:08.970: [iter 168 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 338.324659]
2023-06-11 02:11:57.621: epoch 168:	0.00666668  	0.10682563  	0.05066554  	0.03831287  	0.03876624  
2023-06-11 02:17:35.549: [iter 169 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 333.386854]
2023-06-11 02:18:23.762: epoch 169:	0.00667301  	0.10679188  	0.05065064  	0.03826331  	0.03871318  
2023-06-11 02:23:59.488: [iter 170 : loss : 0.4195 = 0.0047 + 0.3999 + 0.0148, time: 331.147014]
2023-06-11 02:24:47.967: epoch 170:	0.00665439  	0.10650360  	0.05061457  	0.03830295  	0.03875708  
2023-06-11 02:30:11.509: [iter 171 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 319.051308]
2023-06-11 02:31:00.224: epoch 171:	0.00665383  	0.10648506  	0.05069313  	0.03841134  	0.03885846  
2023-06-11 02:36:43.454: [iter 172 : loss : 0.4194 = 0.0048 + 0.3999 + 0.0148, time: 338.673017]
2023-06-11 02:37:33.265: epoch 172:	0.00665868  	0.10663425  	0.05071196  	0.03840433  	0.03885456  
2023-06-11 02:43:12.908: [iter 173 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 335.150450]
2023-06-11 02:44:00.543: epoch 173:	0.00666705  	0.10673067  	0.05068254  	0.03834820  	0.03880370  
2023-06-11 02:49:28.210: [iter 174 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 323.153296]
2023-06-11 02:50:22.311: epoch 174:	0.00666538  	0.10670454  	0.05063412  	0.03827602  	0.03873120  
2023-06-11 02:55:47.027: [iter 175 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 320.112118]
2023-06-11 02:56:34.642: epoch 175:	0.00667804  	0.10685760  	0.05072333  	0.03837132  	0.03882091  
2023-06-11 03:02:10.329: [iter 176 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 331.117839]
2023-06-11 03:02:58.757: epoch 176:	0.00669050  	0.10704276  	0.05073133  	0.03831941  	0.03876361  
2023-06-11 03:08:33.915: [iter 177 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 330.637013]
2023-06-11 03:09:21.952: epoch 177:	0.00668120  	0.10687372  	0.05071194  	0.03835296  	0.03881055  
2023-06-11 03:15:01.761: [iter 178 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 335.322426]
2023-06-11 03:15:50.027: epoch 178:	0.00667115  	0.10677028  	0.05073062  	0.03841190  	0.03886899  
2023-06-11 03:21:33.043: [iter 179 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 338.407721]
2023-06-11 03:22:21.114: epoch 179:	0.00666053  	0.10650033  	0.05071405  	0.03843357  	0.03890008  
2023-06-11 03:28:01.586: [iter 180 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 335.853043]
2023-06-11 03:28:49.810: epoch 180:	0.00667320  	0.10680733  	0.05077078  	0.03845216  	0.03891143  
2023-06-11 03:34:28.478: [iter 181 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 334.126238]
2023-06-11 03:35:17.417: epoch 181:	0.00665440  	0.10654257  	0.05067538  	0.03837174  	0.03882625  
2023-06-11 03:40:51.807: [iter 182 : loss : 0.4194 = 0.0048 + 0.3999 + 0.0148, time: 329.860458]
2023-06-11 03:41:39.752: epoch 182:	0.00666017  	0.10654175  	0.05062791  	0.03830701  	0.03876429  
2023-06-11 03:47:16.734: [iter 183 : loss : 0.4194 = 0.0048 + 0.3999 + 0.0148, time: 332.401775]
2023-06-11 03:48:05.641: epoch 183:	0.00666705  	0.10657635  	0.05066781  	0.03835074  	0.03881375  
2023-06-11 03:53:37.388: [iter 184 : loss : 0.4194 = 0.0048 + 0.3999 + 0.0148, time: 327.135536]
2023-06-11 03:54:24.681: epoch 184:	0.00665961  	0.10657827  	0.05075359  	0.03849412  	0.03895032  
2023-06-11 04:00:04.103: [iter 185 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 334.852859]
2023-06-11 04:00:52.817: epoch 185:	0.00666576  	0.10669424  	0.05075425  	0.03846127  	0.03891222  
2023-06-11 04:00:52.817: Early stopping is triggered at epoch: 185
2023-06-11 04:00:52.817: best_result@epoch 165:

2023-06-11 04:00:52.817: Loading from the saved model.
2023-06-11 04:01:41.759: 		0.00668696  	0.10707554  	0.05075739  	0.03835416  	0.03880659  
/home/Thesis/model/general_recommender/SGL.py:146: RuntimeWarning: divide by zero encountered in power
  d_inv = np.power(rowsum, -0.5).flatten()
