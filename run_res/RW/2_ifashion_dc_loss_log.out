seed= 2021
load saved data...
Item degree grouping...
User degree grouping...
Data loading finished
Evaluate model with cpp
2023-06-12 11:48:39.962: Dataset name: ifashion
The number of users: 300000
The number of items: 81614
The number of ratings: 1607813
Average actions of users: 5.36
Average actions of items: 19.70
The sparsity of the dataset: 99.993433%
2023-06-12 11:48:39.962: 

NeuRec hyperparameters:
recommender=SGL
config_dir=./conf
gpu_id=0
gpu_mem=1.0
data.input.path=dataset
data.input.dataset=ifashion
data.column.format=UI
data.convert.separator=','
user_min=0
item_min=0
splitter=given
ratio=0.8
by_time=False
metric=["Precision", "Recall", "NDCG", "MAP", "MRR"]
topk=[20]
group_view=None
rec.evaluate.neg=0
test_batch_size=128
num_thread=8
start_testing_epoch=0
proj_path=./

SGL's hyperparameters:
seed=2021
aug_type=2
reg=1e-3
embed_size=64
n_layers=3
ssl_reg=0.02
ssl_ratio=0.4
ssl_temp=0.5
ssl_mode=both_side
ssl_loss_type=1
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=1024
num_negatives=1
init_method=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=20
pretrain=0
save_flag=1

Using decoupled loss
2023-06-12 11:49:00.688: metrics:	Precision@20	Recall@20   	NDCG@20     	MAP@20      	MRR@20      
2023-06-12 11:50:10.257: 		0.00000595  	0.00008753  	0.00002894  	0.00001486  	0.00001486  
2023-06-12 11:55:36.292: [iter 1 : loss : 1.0709 = 0.6727 + 0.3980 + 0.0002, time: 321.343261]
2023-06-12 11:56:25.384: epoch 1:	0.00288524  	0.04649846  	0.02087075  	0.01531201  	0.01541947  
2023-06-12 11:56:25.384: Found a better model.
2023-06-12 11:56:25.384: Save model to file as pretrain.
2023-06-12 12:02:01.818: [iter 2 : loss : 0.7319 = 0.3109 + 0.4162 + 0.0048, time: 327.714602]
2023-06-12 12:02:50.446: epoch 2:	0.00348655  	0.05610878  	0.02487267  	0.01806863  	0.01818245  
2023-06-12 12:02:50.446: Found a better model.
2023-06-12 12:02:50.446: Save model to file as pretrain.
2023-06-12 12:08:25.337: [iter 3 : loss : 0.5790 = 0.1546 + 0.4161 + 0.0083, time: 326.149637]
2023-06-12 12:09:15.822: epoch 3:	0.00394485  	0.06344508  	0.02814258  	0.02039698  	0.02053656  
2023-06-12 12:09:15.822: Found a better model.
2023-06-12 12:09:15.822: Save model to file as pretrain.
2023-06-12 12:14:49.305: [iter 4 : loss : 0.5297 = 0.1072 + 0.4126 + 0.0099, time: 324.916229]
2023-06-12 12:15:39.531: epoch 4:	0.00430580  	0.06929626  	0.03078063  	0.02225979  	0.02243971  
2023-06-12 12:15:39.531: Found a better model.
2023-06-12 12:15:39.531: Save model to file as pretrain.
2023-06-12 12:21:21.311: [iter 5 : loss : 0.5023 = 0.0814 + 0.4100 + 0.0110, time: 333.134066]
2023-06-12 12:22:10.144: epoch 5:	0.00462710  	0.07447362  	0.03325672  	0.02415222  	0.02433649  
2023-06-12 12:22:10.145: Found a better model.
2023-06-12 12:22:10.145: Save model to file as pretrain.
2023-06-12 12:27:52.580: [iter 6 : loss : 0.4845 = 0.0646 + 0.4082 + 0.0118, time: 333.835684]
2023-06-12 12:28:42.681: epoch 6:	0.00485327  	0.07810698  	0.03510127  	0.02561000  	0.02580867  
2023-06-12 12:28:42.681: Found a better model.
2023-06-12 12:28:42.681: Save model to file as pretrain.
2023-06-12 12:34:20.421: [iter 7 : loss : 0.4718 = 0.0525 + 0.4068 + 0.0126, time: 329.255573]
2023-06-12 12:35:08.945: epoch 7:	0.00502676  	0.08101264  	0.03651619  	0.02669028  	0.02690439  
2023-06-12 12:35:08.945: Found a better model.
2023-06-12 12:35:08.945: Save model to file as pretrain.
2023-06-12 12:40:42.773: [iter 8 : loss : 0.4630 = 0.0440 + 0.4058 + 0.0132, time: 325.029306]
2023-06-12 12:41:32.627: epoch 8:	0.00517736  	0.08342214  	0.03770283  	0.02760240  	0.02782831  
2023-06-12 12:41:32.628: Found a better model.
2023-06-12 12:41:32.628: Save model to file as pretrain.
2023-06-12 12:47:14.321: [iter 9 : loss : 0.4563 = 0.0376 + 0.4050 + 0.0137, time: 333.041588]
2023-06-12 12:48:02.695: epoch 9:	0.00530990  	0.08557343  	0.03874398  	0.02837998  	0.02862508  
2023-06-12 12:48:02.696: Found a better model.
2023-06-12 12:48:02.696: Save model to file as pretrain.
2023-06-12 12:53:36.374: [iter 10 : loss : 0.4509 = 0.0324 + 0.4043 + 0.0142, time: 325.117129]
2023-06-12 12:54:25.517: epoch 10:	0.00541693  	0.08719219  	0.03962465  	0.02911153  	0.02936350  
2023-06-12 12:54:25.517: Found a better model.
2023-06-12 12:54:25.517: Save model to file as pretrain.
2023-06-12 12:59:59.765: [iter 11 : loss : 0.4465 = 0.0282 + 0.4038 + 0.0146, time: 325.639979]
2023-06-12 13:00:48.280: epoch 11:	0.00550851  	0.08854847  	0.04041770  	0.02978067  	0.03005444  
2023-06-12 13:00:48.280: Found a better model.
2023-06-12 13:00:48.281: Save model to file as pretrain.
2023-06-12 13:06:31.234: [iter 12 : loss : 0.4429 = 0.0246 + 0.4033 + 0.0149, time: 334.304698]
2023-06-12 13:07:20.997: epoch 12:	0.00557738  	0.08970402  	0.04113480  	0.03043915  	0.03071584  
2023-06-12 13:07:20.997: Found a better model.
2023-06-12 13:07:20.997: Save model to file as pretrain.
2023-06-12 13:12:52.283: [iter 13 : loss : 0.4400 = 0.0219 + 0.4029 + 0.0152, time: 322.680169]
2023-06-12 13:13:40.672: epoch 13:	0.00564179  	0.09066067  	0.04169729  	0.03093485  	0.03121973  
2023-06-12 13:13:40.672: Found a better model.
2023-06-12 13:13:40.672: Save model to file as pretrain.
2023-06-12 13:19:29.797: [iter 14 : loss : 0.4375 = 0.0195 + 0.4026 + 0.0154, time: 340.588905]
2023-06-12 13:20:18.415: epoch 14:	0.00571811  	0.09178081  	0.04223067  	0.03134042  	0.03161550  
2023-06-12 13:20:18.415: Found a better model.
2023-06-12 13:20:18.415: Save model to file as pretrain.
2023-06-12 13:25:55.196: [iter 15 : loss : 0.4357 = 0.0179 + 0.4023 + 0.0155, time: 328.071002]
2023-06-12 13:26:45.148: epoch 15:	0.00577786  	0.09272139  	0.04276783  	0.03180588  	0.03210033  
2023-06-12 13:26:45.148: Found a better model.
2023-06-12 13:26:45.148: Save model to file as pretrain.
2023-06-12 13:32:27.515: [iter 16 : loss : 0.4339 = 0.0161 + 0.4021 + 0.0157, time: 333.715188]
2023-06-12 13:33:16.836: epoch 16:	0.00581732  	0.09325179  	0.04312028  	0.03211762  	0.03241893  
2023-06-12 13:33:16.837: Found a better model.
2023-06-12 13:33:16.837: Save model to file as pretrain.
2023-06-12 13:38:57.129: [iter 17 : loss : 0.4325 = 0.0149 + 0.4019 + 0.0157, time: 331.539588]
2023-06-12 13:39:47.729: epoch 17:	0.00586032  	0.09401674  	0.04357068  	0.03252418  	0.03283546  
2023-06-12 13:39:47.729: Found a better model.
2023-06-12 13:39:47.729: Save model to file as pretrain.
2023-06-12 13:45:31.178: [iter 18 : loss : 0.4313 = 0.0138 + 0.4017 + 0.0158, time: 334.716045]
2023-06-12 13:46:20.752: epoch 18:	0.00589271  	0.09452193  	0.04388710  	0.03278963  	0.03311361  
2023-06-12 13:46:20.752: Found a better model.
2023-06-12 13:46:20.752: Save model to file as pretrain.
2023-06-12 13:52:12.283: [iter 19 : loss : 0.4301 = 0.0128 + 0.4015 + 0.0158, time: 342.885678]
2023-06-12 13:53:00.832: epoch 19:	0.00591747  	0.09483702  	0.04412628  	0.03303092  	0.03337048  
2023-06-12 13:53:00.832: Found a better model.
2023-06-12 13:53:00.833: Save model to file as pretrain.
2023-06-12 13:58:46.780: [iter 20 : loss : 0.4291 = 0.0120 + 0.4014 + 0.0158, time: 337.395445]
2023-06-12 13:59:35.592: epoch 20:	0.00596102  	0.09552068  	0.04445611  	0.03323723  	0.03357617  
2023-06-12 13:59:35.592: Found a better model.
2023-06-12 13:59:35.592: Save model to file as pretrain.
2023-06-12 14:05:17.156: [iter 21 : loss : 0.4284 = 0.0114 + 0.4013 + 0.0158, time: 332.936721]
2023-06-12 14:06:04.839: epoch 21:	0.00600384  	0.09621421  	0.04477135  	0.03348545  	0.03382315  
2023-06-12 14:06:04.839: Found a better model.
2023-06-12 14:06:04.839: Save model to file as pretrain.
2023-06-12 14:11:38.191: [iter 22 : loss : 0.4276 = 0.0108 + 0.4011 + 0.0157, time: 324.591632]
2023-06-12 14:12:28.337: epoch 22:	0.00603400  	0.09674428  	0.04509414  	0.03378780  	0.03412896  
2023-06-12 14:12:28.337: Found a better model.
2023-06-12 14:12:28.337: Save model to file as pretrain.
2023-06-12 14:18:06.889: [iter 23 : loss : 0.4270 = 0.0103 + 0.4010 + 0.0157, time: 329.905640]
2023-06-12 14:18:56.320: epoch 23:	0.00606006  	0.09720903  	0.04534443  	0.03397981  	0.03431728  
2023-06-12 14:18:56.320: Found a better model.
2023-06-12 14:18:56.320: Save model to file as pretrain.
2023-06-12 14:24:30.901: [iter 24 : loss : 0.4264 = 0.0098 + 0.4009 + 0.0156, time: 325.765669]
2023-06-12 14:25:20.129: epoch 24:	0.00607234  	0.09735762  	0.04545774  	0.03406997  	0.03441616  
2023-06-12 14:25:20.130: Found a better model.
2023-06-12 14:25:20.130: Save model to file as pretrain.
2023-06-12 14:30:46.773: [iter 25 : loss : 0.4258 = 0.0094 + 0.4009 + 0.0155, time: 317.910702]
2023-06-12 14:31:34.943: epoch 25:	0.00610156  	0.09774150  	0.04560869  	0.03416515  	0.03452118  
2023-06-12 14:31:34.943: Found a better model.
2023-06-12 14:31:34.944: Save model to file as pretrain.
2023-06-12 14:37:10.026: [iter 26 : loss : 0.4253 = 0.0090 + 0.4008 + 0.0155, time: 326.345046]
2023-06-12 14:38:04.847: epoch 26:	0.00611347  	0.09788302  	0.04570410  	0.03424229  	0.03458791  
2023-06-12 14:38:04.847: Found a better model.
2023-06-12 14:38:04.847: Save model to file as pretrain.
2023-06-12 14:43:48.194: [iter 27 : loss : 0.4250 = 0.0089 + 0.4007 + 0.0154, time: 334.532640]
2023-06-12 14:44:43.472: epoch 27:	0.00612520  	0.09803902  	0.04597319  	0.03460103  	0.03495163  
2023-06-12 14:44:43.472: Found a better model.
2023-06-12 14:44:43.472: Save model to file as pretrain.
2023-06-12 14:50:15.291: [iter 28 : loss : 0.4245 = 0.0085 + 0.4007 + 0.0154, time: 322.999586]
2023-06-12 14:51:09.777: epoch 28:	0.00613674  	0.09819435  	0.04609654  	0.03472656  	0.03508468  
2023-06-12 14:51:09.777: Found a better model.
2023-06-12 14:51:09.777: Save model to file as pretrain.
2023-06-12 14:56:52.238: [iter 29 : loss : 0.4242 = 0.0083 + 0.4006 + 0.0153, time: 333.719169]
2023-06-12 14:57:47.646: epoch 29:	0.00615741  	0.09852684  	0.04625536  	0.03481724  	0.03517874  
2023-06-12 14:57:47.646: Found a better model.
2023-06-12 14:57:47.646: Save model to file as pretrain.
2023-06-12 15:03:19.480: [iter 30 : loss : 0.4239 = 0.0080 + 0.4006 + 0.0153, time: 323.070136]
2023-06-12 15:04:13.710: epoch 30:	0.00617564  	0.09884622  	0.04636835  	0.03486806  	0.03523980  
2023-06-12 15:04:13.710: Found a better model.
2023-06-12 15:04:13.710: Save model to file as pretrain.
2023-06-12 15:09:41.241: [iter 31 : loss : 0.4236 = 0.0078 + 0.4005 + 0.0152, time: 318.744604]
2023-06-12 15:10:35.690: epoch 31:	0.00619556  	0.09917859  	0.04650713  	0.03496226  	0.03534869  
2023-06-12 15:10:35.690: Found a better model.
2023-06-12 15:10:35.690: Save model to file as pretrain.
2023-06-12 15:16:11.537: [iter 32 : loss : 0.4233 = 0.0076 + 0.4005 + 0.0152, time: 327.038852]
2023-06-12 15:17:06.713: epoch 32:	0.00620729  	0.09934498  	0.04657402  	0.03497674  	0.03537132  
2023-06-12 15:17:06.713: Found a better model.
2023-06-12 15:17:06.713: Save model to file as pretrain.
2023-06-12 15:22:43.469: [iter 33 : loss : 0.4230 = 0.0074 + 0.4005 + 0.0152, time: 328.003748]
2023-06-12 15:23:38.018: epoch 33:	0.00620654  	0.09925969  	0.04663450  	0.03509142  	0.03548534  
2023-06-12 15:29:15.565: [iter 34 : loss : 0.4229 = 0.0073 + 0.4004 + 0.0151, time: 332.937521]
2023-06-12 15:30:09.925: epoch 34:	0.00621994  	0.09950887  	0.04672895  	0.03516474  	0.03555600  
2023-06-12 15:30:09.925: Found a better model.
2023-06-12 15:30:09.926: Save model to file as pretrain.
2023-06-12 15:35:59.159: [iter 35 : loss : 0.4227 = 0.0072 + 0.4004 + 0.0151, time: 340.599089]
2023-06-12 15:36:55.099: epoch 35:	0.00624749  	0.09990391  	0.04688425  	0.03524749  	0.03564303  
2023-06-12 15:36:55.099: Found a better model.
2023-06-12 15:36:55.099: Save model to file as pretrain.
2023-06-12 15:42:39.077: [iter 36 : loss : 0.4225 = 0.0071 + 0.4004 + 0.0151, time: 335.103809]
2023-06-12 15:43:34.245: epoch 36:	0.00624787  	0.09993188  	0.04697082  	0.03535413  	0.03575384  
2023-06-12 15:43:34.245: Found a better model.
2023-06-12 15:43:34.245: Save model to file as pretrain.
2023-06-12 15:49:10.113: [iter 37 : loss : 0.4224 = 0.0070 + 0.4003 + 0.0151, time: 327.250932]
2023-06-12 15:50:04.706: epoch 37:	0.00624917  	0.09991984  	0.04695886  	0.03531814  	0.03573208  
2023-06-12 15:55:51.716: [iter 38 : loss : 0.4222 = 0.0068 + 0.4003 + 0.0150, time: 342.395852]
2023-06-12 15:56:46.970: epoch 38:	0.00627150  	0.10027447  	0.04717429  	0.03551933  	0.03593984  
2023-06-12 15:56:46.970: Found a better model.
2023-06-12 15:56:46.970: Save model to file as pretrain.
2023-06-12 16:02:27.295: [iter 39 : loss : 0.4220 = 0.0067 + 0.4003 + 0.0150, time: 331.593924]
2023-06-12 16:03:22.284: epoch 39:	0.00627430  	0.10046859  	0.04727833  	0.03563182  	0.03604407  
2023-06-12 16:03:22.285: Found a better model.
2023-06-12 16:03:22.285: Save model to file as pretrain.
2023-06-12 16:09:00.018: [iter 40 : loss : 0.4218 = 0.0065 + 0.4003 + 0.0150, time: 329.105616]
2023-06-12 16:09:54.385: epoch 40:	0.00626946  	0.10029195  	0.04725146  	0.03564616  	0.03606232  
2023-06-12 16:15:26.296: [iter 41 : loss : 0.4217 = 0.0065 + 0.4003 + 0.0150, time: 327.247555]
2023-06-12 16:16:20.917: epoch 41:	0.00628137  	0.10050949  	0.04730692  	0.03566078  	0.03607829  
2023-06-12 16:16:20.917: Found a better model.
2023-06-12 16:16:20.917: Save model to file as pretrain.
2023-06-12 16:22:15.165: [iter 42 : loss : 0.4216 = 0.0064 + 0.4002 + 0.0150, time: 345.482806]
2023-06-12 16:23:09.976: epoch 42:	0.00628230  	0.10044758  	0.04727605  	0.03563223  	0.03604797  
2023-06-12 16:28:44.799: [iter 43 : loss : 0.4216 = 0.0064 + 0.4002 + 0.0150, time: 330.188972]
2023-06-12 16:29:39.242: epoch 43:	0.00630017  	0.10063923  	0.04730370  	0.03559986  	0.03602535  
2023-06-12 16:29:39.242: Found a better model.
2023-06-12 16:29:39.242: Save model to file as pretrain.
2023-06-12 16:35:19.215: [iter 44 : loss : 0.4215 = 0.0064 + 0.4002 + 0.0150, time: 331.219830]
2023-06-12 16:36:18.859: epoch 44:	0.00629756  	0.10066769  	0.04738820  	0.03571657  	0.03613526  
2023-06-12 16:36:18.859: Found a better model.
2023-06-12 16:36:18.859: Save model to file as pretrain.
2023-06-12 16:42:02.164: [iter 45 : loss : 0.4214 = 0.0062 + 0.4002 + 0.0150, time: 334.237120]
2023-06-12 16:42:57.306: epoch 45:	0.00630855  	0.10077155  	0.04743920  	0.03573156  	0.03616635  
2023-06-12 16:42:57.307: Found a better model.
2023-06-12 16:42:57.307: Save model to file as pretrain.
2023-06-12 16:48:38.315: [iter 46 : loss : 0.4212 = 0.0061 + 0.4002 + 0.0149, time: 332.290901]
2023-06-12 16:49:33.503: epoch 46:	0.00631897  	0.10098086  	0.04756425  	0.03586797  	0.03628506  
2023-06-12 16:49:33.504: Found a better model.
2023-06-12 16:49:33.504: Save model to file as pretrain.
2023-06-12 16:55:26.732: [iter 47 : loss : 0.4212 = 0.0061 + 0.4002 + 0.0149, time: 344.498576]
2023-06-12 16:56:22.227: epoch 47:	0.00632064  	0.10096368  	0.04757557  	0.03588346  	0.03630443  
2023-06-12 17:01:56.876: [iter 48 : loss : 0.4211 = 0.0060 + 0.4002 + 0.0149, time: 329.927212]
2023-06-12 17:02:52.393: epoch 48:	0.00632512  	0.10113215  	0.04761375  	0.03585801  	0.03629569  
2023-06-12 17:02:52.393: Found a better model.
2023-06-12 17:02:52.393: Save model to file as pretrain.
2023-06-12 17:08:29.378: [iter 49 : loss : 0.4212 = 0.0061 + 0.4002 + 0.0149, time: 327.576351]
2023-06-12 17:09:25.404: epoch 49:	0.00633703  	0.10129656  	0.04771747  	0.03599901  	0.03642082  
2023-06-12 17:09:25.404: Found a better model.
2023-06-12 17:09:25.405: Save model to file as pretrain.
2023-06-12 17:15:00.241: [iter 50 : loss : 0.4211 = 0.0060 + 0.4001 + 0.0149, time: 326.022806]
2023-06-12 17:15:55.064: epoch 50:	0.00633740  	0.10128291  	0.04779096  	0.03608758  	0.03650595  
2023-06-12 17:21:31.015: [iter 51 : loss : 0.4210 = 0.0060 + 0.4001 + 0.0149, time: 331.149002]
2023-06-12 17:22:25.348: epoch 51:	0.00634708  	0.10140860  	0.04778537  	0.03600897  	0.03644273  
2023-06-12 17:22:25.348: Found a better model.
2023-06-12 17:22:25.348: Save model to file as pretrain.
2023-06-12 17:28:01.463: [iter 52 : loss : 0.4210 = 0.0059 + 0.4001 + 0.0149, time: 327.385453]
2023-06-12 17:28:56.981: epoch 52:	0.00634745  	0.10151421  	0.04787025  	0.03610447  	0.03654224  
2023-06-12 17:28:56.982: Found a better model.
2023-06-12 17:28:56.982: Save model to file as pretrain.
2023-06-12 17:34:37.993: [iter 53 : loss : 0.4209 = 0.0059 + 0.4001 + 0.0149, time: 332.204721]
2023-06-12 17:35:30.713: epoch 53:	0.00635303  	0.10149346  	0.04783006  	0.03605153  	0.03649394  
2023-06-12 17:40:54.872: [iter 54 : loss : 0.4208 = 0.0057 + 0.4001 + 0.0149, time: 319.611890]
2023-06-12 17:41:43.643: epoch 54:	0.00636942  	0.10174342  	0.04789241  	0.03606181  	0.03649268  
2023-06-12 17:41:43.643: Found a better model.
2023-06-12 17:41:43.643: Save model to file as pretrain.
2023-06-12 17:47:20.875: [iter 55 : loss : 0.4207 = 0.0057 + 0.4001 + 0.0149, time: 328.637625]
2023-06-12 17:48:16.291: epoch 55:	0.00637351  	0.10181211  	0.04795556  	0.03612636  	0.03654516  
2023-06-12 17:48:16.291: Found a better model.
2023-06-12 17:48:16.292: Save model to file as pretrain.
2023-06-12 17:54:01.826: [iter 56 : loss : 0.4207 = 0.0057 + 0.4001 + 0.0149, time: 336.626612]
2023-06-12 17:54:58.060: epoch 56:	0.00637407  	0.10180944  	0.04800510  	0.03622624  	0.03664282  
2023-06-12 18:00:25.462: [iter 57 : loss : 0.4206 = 0.0056 + 0.4001 + 0.0149, time: 322.703740]
2023-06-12 18:01:19.458: epoch 57:	0.00638133  	0.10209297  	0.04813956  	0.03632070  	0.03673521  
2023-06-12 18:01:19.459: Found a better model.
2023-06-12 18:01:19.459: Save model to file as pretrain.
2023-06-12 18:06:54.202: [iter 58 : loss : 0.4206 = 0.0056 + 0.4001 + 0.0149, time: 325.937895]
2023-06-12 18:07:48.783: epoch 58:	0.00636942  	0.10188479  	0.04809778  	0.03631845  	0.03673232  
2023-06-12 18:13:34.657: [iter 59 : loss : 0.4206 = 0.0056 + 0.4001 + 0.0149, time: 341.255213]
2023-06-12 18:14:28.419: epoch 59:	0.00637463  	0.10198183  	0.04815852  	0.03635731  	0.03677505  
2023-06-12 18:19:51.797: [iter 60 : loss : 0.4206 = 0.0056 + 0.4001 + 0.0149, time: 318.646850]
2023-06-12 18:20:41.290: epoch 60:	0.00637631  	0.10213415  	0.04818687  	0.03637087  	0.03680269  
2023-06-12 18:20:41.290: Found a better model.
2023-06-12 18:20:41.290: Save model to file as pretrain.
2023-06-12 18:26:24.232: [iter 61 : loss : 0.4205 = 0.0055 + 0.4000 + 0.0149, time: 334.154734]
2023-06-12 18:27:52.229: epoch 61:	0.00638226  	0.10214950  	0.04819998  	0.03639334  	0.03682568  
2023-06-12 18:27:52.229: Found a better model.
2023-06-12 18:27:52.229: Save model to file as pretrain.
2023-06-12 18:33:33.320: [iter 62 : loss : 0.4205 = 0.0055 + 0.4001 + 0.0149, time: 332.344390]
2023-06-12 18:35:00.385: epoch 62:	0.00638021  	0.10202532  	0.04809496  	0.03624408  	0.03666111  
2023-06-12 18:40:33.568: [iter 63 : loss : 0.4204 = 0.0054 + 0.4000 + 0.0149, time: 328.505898]
2023-06-12 18:41:59.938: epoch 63:	0.00639566  	0.10227700  	0.04820477  	0.03634723  	0.03676267  
2023-06-12 18:41:59.938: Found a better model.
2023-06-12 18:41:59.938: Save model to file as pretrain.
2023-06-12 18:47:44.198: [iter 64 : loss : 0.4204 = 0.0055 + 0.4000 + 0.0149, time: 335.465706]
2023-06-12 18:49:09.824: epoch 64:	0.00639268  	0.10221332  	0.04821800  	0.03637518  	0.03680057  
2023-06-12 18:54:47.365: [iter 65 : loss : 0.4204 = 0.0055 + 0.4000 + 0.0149, time: 332.903836]
2023-06-12 18:56:14.642: epoch 65:	0.00640348  	0.10246074  	0.04829863  	0.03641494  	0.03683719  
2023-06-12 18:56:14.642: Found a better model.
2023-06-12 18:56:14.642: Save model to file as pretrain.
2023-06-12 19:01:56.992: [iter 66 : loss : 0.4203 = 0.0054 + 0.4000 + 0.0149, time: 333.573178]
2023-06-12 19:02:45.108: epoch 66:	0.00642023  	0.10266884  	0.04839463  	0.03648883  	0.03689975  
2023-06-12 19:02:45.108: Found a better model.
2023-06-12 19:02:45.108: Save model to file as pretrain.
2023-06-12 19:08:13.155: [iter 67 : loss : 0.4203 = 0.0054 + 0.4000 + 0.0149, time: 319.466248]
2023-06-12 19:09:01.226: epoch 67:	0.00641446  	0.10260144  	0.04839680  	0.03651959  	0.03692883  
2023-06-12 19:14:43.343: [iter 68 : loss : 0.4203 = 0.0053 + 0.4000 + 0.0149, time: 337.535977]
2023-06-12 19:15:32.461: epoch 68:	0.00643307  	0.10288759  	0.04844712  	0.03647954  	0.03690208  
2023-06-12 19:15:32.461: Found a better model.
2023-06-12 19:15:32.461: Save model to file as pretrain.
2023-06-12 19:21:18.830: [iter 69 : loss : 0.4203 = 0.0053 + 0.4000 + 0.0149, time: 337.845781]
2023-06-12 19:22:06.553: epoch 69:	0.00643196  	0.10287762  	0.04848367  	0.03651128  	0.03693447  
2023-06-12 19:27:48.428: [iter 70 : loss : 0.4203 = 0.0053 + 0.4000 + 0.0149, time: 337.303082]
2023-06-12 19:28:37.649: epoch 70:	0.00644741  	0.10311744  	0.04861279  	0.03665940  	0.03709190  
2023-06-12 19:28:37.649: Found a better model.
2023-06-12 19:28:37.649: Save model to file as pretrain.
2023-06-12 19:34:20.509: [iter 71 : loss : 0.4202 = 0.0053 + 0.4000 + 0.0149, time: 334.214106]
2023-06-12 19:35:08.941: epoch 71:	0.00644350  	0.10309426  	0.04861130  	0.03665112  	0.03707017  
2023-06-12 19:40:39.948: [iter 72 : loss : 0.4202 = 0.0053 + 0.4000 + 0.0149, time: 326.453486]
2023-06-12 19:41:29.526: epoch 72:	0.00644071  	0.10295273  	0.04862160  	0.03668860  	0.03712846  
2023-06-12 19:46:56.223: [iter 73 : loss : 0.4201 = 0.0052 + 0.4000 + 0.0149, time: 322.159240]
2023-06-12 19:47:45.070: epoch 73:	0.00645206  	0.10318207  	0.04870528  	0.03675596  	0.03717798  
2023-06-12 19:47:45.070: Found a better model.
2023-06-12 19:47:45.070: Save model to file as pretrain.
2023-06-12 19:53:22.159: [iter 74 : loss : 0.4202 = 0.0053 + 0.4000 + 0.0149, time: 328.400470]
2023-06-12 19:54:10.857: epoch 74:	0.00646062  	0.10334061  	0.04877146  	0.03683012  	0.03725637  
2023-06-12 19:54:10.857: Found a better model.
2023-06-12 19:54:10.857: Save model to file as pretrain.
2023-06-12 19:59:46.180: [iter 75 : loss : 0.4202 = 0.0053 + 0.4000 + 0.0149, time: 326.638367]
2023-06-12 20:00:35.656: epoch 75:	0.00646882  	0.10352547  	0.04884747  	0.03689050  	0.03730477  
2023-06-12 20:00:35.656: Found a better model.
2023-06-12 20:00:35.656: Save model to file as pretrain.
2023-06-12 20:06:13.696: [iter 76 : loss : 0.4202 = 0.0053 + 0.4000 + 0.0149, time: 329.366064]
2023-06-12 20:07:03.012: epoch 76:	0.00647086  	0.10353067  	0.04889329  	0.03694025  	0.03735166  
2023-06-12 20:07:03.012: Found a better model.
2023-06-12 20:07:03.012: Save model to file as pretrain.
2023-06-12 20:12:42.440: [iter 77 : loss : 0.4202 = 0.0053 + 0.4000 + 0.0149, time: 330.657519]
2023-06-12 20:13:32.054: epoch 77:	0.00647143  	0.10350289  	0.04888818  	0.03690602  	0.03731669  
2023-06-12 20:19:06.498: [iter 78 : loss : 0.4201 = 0.0052 + 0.4000 + 0.0149, time: 329.755089]
2023-06-12 20:19:55.032: epoch 78:	0.00647812  	0.10367108  	0.04896697  	0.03698242  	0.03740341  
2023-06-12 20:19:55.032: Found a better model.
2023-06-12 20:19:55.032: Save model to file as pretrain.
2023-06-12 20:25:30.825: [iter 79 : loss : 0.4200 = 0.0051 + 0.4000 + 0.0149, time: 327.018420]
2023-06-12 20:26:18.503: epoch 79:	0.00648409  	0.10380220  	0.04900844  	0.03699287  	0.03740223  
2023-06-12 20:26:18.503: Found a better model.
2023-06-12 20:26:18.503: Save model to file as pretrain.
2023-06-12 20:32:14.594: [iter 80 : loss : 0.4201 = 0.0052 + 0.4000 + 0.0149, time: 347.284034]
2023-06-12 20:33:04.171: epoch 80:	0.00649004  	0.10380247  	0.04887025  	0.03679752  	0.03722051  
2023-06-12 20:33:04.171: Found a better model.
2023-06-12 20:33:04.171: Save model to file as pretrain.
2023-06-12 20:38:45.684: [iter 81 : loss : 0.4200 = 0.0052 + 0.4000 + 0.0149, time: 332.773603]
2023-06-12 20:39:34.593: epoch 81:	0.00648725  	0.10378689  	0.04889177  	0.03682855  	0.03724720  
2023-06-12 20:45:24.440: [iter 82 : loss : 0.4200 = 0.0051 + 0.4000 + 0.0149, time: 345.257972]
2023-06-12 20:46:19.343: epoch 82:	0.00649563  	0.10384490  	0.04898183  	0.03694247  	0.03735001  
2023-06-12 20:46:19.343: Found a better model.
2023-06-12 20:46:19.343: Save model to file as pretrain.
2023-06-12 20:51:52.553: [iter 83 : loss : 0.4200 = 0.0052 + 0.4000 + 0.0149, time: 324.468594]
2023-06-12 20:52:46.686: epoch 83:	0.00649748  	0.10396177  	0.04901619  	0.03692224  	0.03736163  
2023-06-12 20:52:46.686: Found a better model.
2023-06-12 20:52:46.686: Save model to file as pretrain.
2023-06-12 20:58:14.525: [iter 84 : loss : 0.4200 = 0.0051 + 0.4000 + 0.0149, time: 318.983932]
2023-06-12 20:59:03.155: epoch 84:	0.00649842  	0.10394134  	0.04908149  	0.03702226  	0.03746503  
2023-06-12 21:04:49.489: [iter 85 : loss : 0.4199 = 0.0051 + 0.4000 + 0.0149, time: 341.762207]
2023-06-12 21:05:37.582: epoch 85:	0.00651312  	0.10414568  	0.04918624  	0.03710809  	0.03755835  
2023-06-12 21:05:37.582: Found a better model.
2023-06-12 21:05:37.582: Save model to file as pretrain.
2023-06-12 21:11:20.741: [iter 86 : loss : 0.4200 = 0.0051 + 0.4000 + 0.0149, time: 334.426305]
2023-06-12 21:12:09.692: epoch 86:	0.00652819  	0.10442388  	0.04930492  	0.03720226  	0.03765298  
2023-06-12 21:12:09.692: Found a better model.
2023-06-12 21:12:09.692: Save model to file as pretrain.
2023-06-12 21:17:51.324: [iter 87 : loss : 0.4200 = 0.0051 + 0.4000 + 0.0149, time: 332.951115]
2023-06-12 21:18:39.735: epoch 87:	0.00652298  	0.10434051  	0.04925714  	0.03711399  	0.03758267  
2023-06-12 21:24:16.736: [iter 88 : loss : 0.4200 = 0.0051 + 0.4000 + 0.0149, time: 332.399177]
2023-06-12 21:25:05.640: epoch 88:	0.00651033  	0.10411130  	0.04920107  	0.03710780  	0.03756060  
2023-06-12 21:30:29.651: [iter 89 : loss : 0.4199 = 0.0050 + 0.4000 + 0.0149, time: 319.389190]
2023-06-12 21:31:18.282: epoch 89:	0.00651386  	0.10415708  	0.04928296  	0.03721454  	0.03766473  
2023-06-12 21:36:53.236: [iter 90 : loss : 0.4199 = 0.0051 + 0.4000 + 0.0149, time: 330.419526]
2023-06-12 21:37:41.438: epoch 90:	0.00651237  	0.10423098  	0.04925170  	0.03717151  	0.03761851  
2023-06-12 21:43:09.541: [iter 91 : loss : 0.4200 = 0.0052 + 0.4000 + 0.0149, time: 323.513226]
2023-06-12 21:43:58.332: epoch 91:	0.00651405  	0.10425157  	0.04927615  	0.03719230  	0.03763835  
2023-06-12 21:49:26.611: [iter 92 : loss : 0.4198 = 0.0050 + 0.3999 + 0.0149, time: 323.725449]
2023-06-12 21:50:14.899: epoch 92:	0.00652652  	0.10448370  	0.04933002  	0.03719651  	0.03763470  
2023-06-12 21:50:14.899: Found a better model.
2023-06-12 21:50:14.899: Save model to file as pretrain.
2023-06-12 21:55:50.848: [iter 93 : loss : 0.4199 = 0.0050 + 0.3999 + 0.0149, time: 327.245502]
2023-06-12 21:56:38.294: epoch 93:	0.00653155  	0.10453864  	0.04936015  	0.03724518  	0.03769819  
2023-06-12 21:56:38.294: Found a better model.
2023-06-12 21:56:38.294: Save model to file as pretrain.
2023-06-12 22:02:19.202: [iter 94 : loss : 0.4199 = 0.0050 + 0.3999 + 0.0149, time: 332.337834]
2023-06-12 22:03:08.961: epoch 94:	0.00653937  	0.10469231  	0.04938764  	0.03721391  	0.03765000  
2023-06-12 22:03:08.961: Found a better model.
2023-06-12 22:03:08.961: Save model to file as pretrain.
2023-06-12 22:08:56.904: [iter 95 : loss : 0.4199 = 0.0051 + 0.3999 + 0.0149, time: 339.456757]
2023-06-12 22:09:49.014: epoch 95:	0.00654681  	0.10487441  	0.04946304  	0.03725049  	0.03769671  
2023-06-12 22:09:49.015: Found a better model.
2023-06-12 22:09:49.015: Save model to file as pretrain.
2023-06-12 22:15:38.498: [iter 96 : loss : 0.4199 = 0.0050 + 0.3999 + 0.0149, time: 340.624414]
2023-06-12 22:16:27.103: epoch 96:	0.00654067  	0.10477877  	0.04946727  	0.03729596  	0.03772899  
2023-06-12 22:22:05.986: [iter 97 : loss : 0.4199 = 0.0051 + 0.3999 + 0.0149, time: 334.390484]
2023-06-12 22:22:54.012: epoch 97:	0.00654756  	0.10482144  	0.04955659  	0.03740839  	0.03785041  
2023-06-12 22:28:14.224: [iter 98 : loss : 0.4198 = 0.0050 + 0.3999 + 0.0149, time: 315.711046]
2023-06-12 22:29:02.261: epoch 98:	0.00654941  	0.10488637  	0.04956590  	0.03740054  	0.03784611  
2023-06-12 22:29:02.261: Found a better model.
2023-06-12 22:29:02.261: Save model to file as pretrain.
2023-06-12 22:34:38.713: [iter 99 : loss : 0.4199 = 0.0050 + 0.3999 + 0.0149, time: 327.802369]
2023-06-12 22:35:27.219: epoch 99:	0.00655557  	0.10500424  	0.04970592  	0.03756589  	0.03799375  
2023-06-12 22:35:27.219: Found a better model.
2023-06-12 22:35:27.219: Save model to file as pretrain.
2023-06-12 22:41:02.503: [iter 100 : loss : 0.4198 = 0.0050 + 0.3999 + 0.0149, time: 326.647298]
2023-06-12 22:41:50.741: epoch 100:	0.00654961  	0.10487579  	0.04965263  	0.03754292  	0.03798720  
2023-06-12 22:47:21.346: [iter 101 : loss : 0.4198 = 0.0050 + 0.3999 + 0.0149, time: 326.086962]
2023-06-12 22:48:10.897: epoch 101:	0.00654682  	0.10486486  	0.04962603  	0.03748321  	0.03791342  
2023-06-12 22:53:33.734: [iter 102 : loss : 0.4198 = 0.0050 + 0.3999 + 0.0149, time: 318.300320]
2023-06-12 22:54:21.885: epoch 102:	0.00656301  	0.10513955  	0.04971781  	0.03754425  	0.03798101  
2023-06-12 22:54:21.885: Found a better model.
2023-06-12 22:54:21.885: Save model to file as pretrain.
2023-06-12 22:59:59.329: [iter 103 : loss : 0.4197 = 0.0049 + 0.3999 + 0.0149, time: 328.699799]
2023-06-12 23:00:47.510: epoch 103:	0.00656171  	0.10506863  	0.04964877  	0.03750911  	0.03793660  
2023-06-12 23:06:21.983: [iter 104 : loss : 0.4198 = 0.0050 + 0.3999 + 0.0149, time: 329.902208]
2023-06-12 23:07:10.410: epoch 104:	0.00657120  	0.10523930  	0.04972763  	0.03757406  	0.03800862  
2023-06-12 23:07:10.410: Found a better model.
2023-06-12 23:07:10.410: Save model to file as pretrain.
2023-06-12 23:12:49.846: [iter 105 : loss : 0.4198 = 0.0049 + 0.3999 + 0.0149, time: 330.733972]
2023-06-12 23:13:38.008: epoch 105:	0.00656840  	0.10512778  	0.04972965  	0.03759140  	0.03803829  
2023-06-12 23:19:12.733: [iter 106 : loss : 0.4198 = 0.0050 + 0.3999 + 0.0149, time: 330.109247]
2023-06-12 23:20:01.891: epoch 106:	0.00658088  	0.10528421  	0.04976040  	0.03760017  	0.03803983  
2023-06-12 23:20:01.891: Found a better model.
2023-06-12 23:20:01.891: Save model to file as pretrain.
2023-06-12 23:25:37.874: [iter 107 : loss : 0.4198 = 0.0050 + 0.3999 + 0.0149, time: 327.365076]
2023-06-12 23:26:25.290: epoch 107:	0.00657845  	0.10527298  	0.04974646  	0.03756535  	0.03800101  
2023-06-12 23:31:58.344: [iter 108 : loss : 0.4199 = 0.0051 + 0.3999 + 0.0149, time: 328.481197]
2023-06-12 23:32:47.855: epoch 108:	0.00656691  	0.10512381  	0.04966135  	0.03746293  	0.03790405  
2023-06-12 23:38:19.057: [iter 109 : loss : 0.4198 = 0.0050 + 0.3999 + 0.0149, time: 326.653008]
2023-06-12 23:39:07.400: epoch 109:	0.00657920  	0.10532768  	0.04974215  	0.03752422  	0.03795916  
2023-06-12 23:39:07.400: Found a better model.
2023-06-12 23:39:07.400: Save model to file as pretrain.
2023-06-12 23:44:35.836: [iter 110 : loss : 0.4198 = 0.0050 + 0.3999 + 0.0149, time: 319.704759]
2023-06-12 23:45:24.001: epoch 110:	0.00657771  	0.10526614  	0.04968170  	0.03744465  	0.03788085  
2023-06-12 23:50:57.821: [iter 111 : loss : 0.4197 = 0.0049 + 0.3999 + 0.0149, time: 329.169685]
2023-06-12 23:51:47.002: epoch 111:	0.00658367  	0.10536127  	0.04969327  	0.03744043  	0.03785984  
2023-06-12 23:51:47.002: Found a better model.
2023-06-12 23:51:47.002: Save model to file as pretrain.
2023-06-12 23:57:26.067: [iter 112 : loss : 0.4197 = 0.0049 + 0.3999 + 0.0149, time: 330.495534]
2023-06-12 23:58:15.375: epoch 112:	0.00659112  	0.10550812  	0.04978254  	0.03751407  	0.03793515  
2023-06-12 23:58:15.375: Found a better model.
2023-06-12 23:58:15.375: Save model to file as pretrain.
2023-06-13 00:03:56.192: [iter 113 : loss : 0.4197 = 0.0049 + 0.3999 + 0.0149, time: 332.085756]
2023-06-13 00:04:44.708: epoch 113:	0.00658869  	0.10541721  	0.04966728  	0.03739009  	0.03782483  
2023-06-13 00:10:20.284: [iter 114 : loss : 0.4196 = 0.0049 + 0.3999 + 0.0149, time: 331.010345]
2023-06-13 00:11:08.033: epoch 114:	0.00659707  	0.10557205  	0.04984789  	0.03757807  	0.03803146  
2023-06-13 00:11:08.033: Found a better model.
2023-06-13 00:11:08.033: Save model to file as pretrain.
2023-06-13 00:16:50.356: [iter 115 : loss : 0.4197 = 0.0049 + 0.3999 + 0.0149, time: 333.617359]
2023-06-13 00:17:39.710: epoch 115:	0.00658962  	0.10540485  	0.04981558  	0.03758096  	0.03802452  
2023-06-13 00:23:08.380: [iter 116 : loss : 0.4197 = 0.0050 + 0.3999 + 0.0149, time: 324.100421]
2023-06-13 00:23:56.728: epoch 116:	0.00659912  	0.10565007  	0.04987387  	0.03757274  	0.03802989  
2023-06-13 00:23:56.729: Found a better model.
2023-06-13 00:23:56.729: Save model to file as pretrain.
2023-06-13 00:29:29.552: [iter 117 : loss : 0.4197 = 0.0050 + 0.3999 + 0.0149, time: 324.247511]
2023-06-13 00:30:18.347: epoch 117:	0.00660024  	0.10562404  	0.04981140  	0.03748612  	0.03794288  
2023-06-13 00:35:58.215: [iter 118 : loss : 0.4196 = 0.0048 + 0.3999 + 0.0149, time: 335.406208]
2023-06-13 00:36:45.518: epoch 118:	0.00660749  	0.10581597  	0.04981330  	0.03745058  	0.03789705  
2023-06-13 00:36:45.518: Found a better model.
2023-06-13 00:36:45.518: Save model to file as pretrain.
2023-06-13 00:42:22.665: [iter 119 : loss : 0.4197 = 0.0049 + 0.3999 + 0.0149, time: 328.576720]
2023-06-13 00:43:12.116: epoch 119:	0.00661326  	0.10581616  	0.04982650  	0.03744905  	0.03789669  
2023-06-13 00:43:12.116: Found a better model.
2023-06-13 00:43:12.116: Save model to file as pretrain.
2023-06-13 00:48:42.736: [iter 120 : loss : 0.4197 = 0.0049 + 0.3999 + 0.0149, time: 322.038605]
2023-06-13 00:49:32.219: epoch 120:	0.00661717  	0.10593282  	0.04991742  	0.03755186  	0.03799500  
2023-06-13 00:49:32.219: Found a better model.
2023-06-13 00:49:32.219: Save model to file as pretrain.
2023-06-13 00:55:04.228: [iter 121 : loss : 0.4196 = 0.0049 + 0.3999 + 0.0149, time: 323.454957]
2023-06-13 00:55:56.303: epoch 121:	0.00661047  	0.10583129  	0.04980489  	0.03743300  	0.03787290  
2023-06-13 01:01:43.725: [iter 122 : loss : 0.4197 = 0.0049 + 0.3999 + 0.0149, time: 342.648686]
2023-06-13 01:02:31.900: epoch 122:	0.00661791  	0.10587861  	0.04985027  	0.03748821  	0.03792226  
2023-06-13 01:08:05.908: [iter 123 : loss : 0.4197 = 0.0049 + 0.3999 + 0.0149, time: 329.473197]
2023-06-13 01:08:55.379: epoch 123:	0.00659501  	0.10557426  	0.04976844  	0.03742916  	0.03787571  
2023-06-13 01:14:27.150: [iter 124 : loss : 0.4196 = 0.0048 + 0.3999 + 0.0148, time: 327.162436]
2023-06-13 01:15:15.994: epoch 124:	0.00659967  	0.10569242  	0.04990579  	0.03762064  	0.03805941  
2023-06-13 01:20:20.265: [iter 125 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0149, time: 299.710829]
2023-06-13 01:21:09.184: epoch 125:	0.00660116  	0.10568731  	0.04988081  	0.03758704  	0.03802383  
2023-06-13 01:26:36.039: [iter 126 : loss : 0.4196 = 0.0048 + 0.3999 + 0.0148, time: 322.278796]
2023-06-13 01:27:24.816: epoch 126:	0.00660153  	0.10567410  	0.04987910  	0.03758371  	0.03802448  
2023-06-13 01:33:04.582: [iter 127 : loss : 0.4196 = 0.0048 + 0.3999 + 0.0148, time: 335.236586]
2023-06-13 01:33:53.155: epoch 127:	0.00659911  	0.10557579  	0.04987335  	0.03760865  	0.03806813  
2023-06-13 01:39:21.222: [iter 128 : loss : 0.4196 = 0.0048 + 0.3999 + 0.0148, time: 323.509185]
2023-06-13 01:40:09.546: epoch 128:	0.00659389  	0.10553091  	0.04986778  	0.03761132  	0.03806642  
2023-06-13 01:45:38.214: [iter 129 : loss : 0.4196 = 0.0049 + 0.3999 + 0.0148, time: 324.124314]
2023-06-13 01:46:27.908: epoch 129:	0.00662052  	0.10594355  	0.05004653  	0.03775756  	0.03820326  
2023-06-13 01:46:27.908: Found a better model.
2023-06-13 01:46:27.908: Save model to file as pretrain.
2023-06-13 01:52:06.726: [iter 130 : loss : 0.4196 = 0.0048 + 0.3999 + 0.0148, time: 330.100280]
2023-06-13 01:52:55.111: epoch 130:	0.00661475  	0.10583120  	0.05003297  	0.03774988  	0.03821006  
2023-06-13 01:58:17.754: [iter 131 : loss : 0.4196 = 0.0049 + 0.3999 + 0.0148, time: 317.997039]
2023-06-13 01:59:06.613: epoch 131:	0.00662033  	0.10595074  	0.04999876  	0.03767993  	0.03813872  
2023-06-13 01:59:06.613: Found a better model.
2023-06-13 01:59:06.613: Save model to file as pretrain.
2023-06-13 02:04:44.179: [iter 132 : loss : 0.4196 = 0.0048 + 0.3999 + 0.0148, time: 328.779618]
2023-06-13 02:05:31.777: epoch 132:	0.00661084  	0.10580436  	0.05001334  	0.03771395  	0.03817539  
2023-06-13 02:11:03.536: [iter 133 : loss : 0.4196 = 0.0048 + 0.3999 + 0.0148, time: 327.148677]
2023-06-13 02:11:52.701: epoch 133:	0.00662126  	0.10592440  	0.05005982  	0.03774713  	0.03820708  
2023-06-13 02:17:29.837: [iter 134 : loss : 0.4196 = 0.0049 + 0.3999 + 0.0148, time: 332.501363]
2023-06-13 02:18:18.781: epoch 134:	0.00661977  	0.10587973  	0.05000567  	0.03768186  	0.03812878  
2023-06-13 02:23:50.610: [iter 135 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 327.158932]
2023-06-13 02:24:39.149: epoch 135:	0.00663057  	0.10609566  	0.05008313  	0.03772804  	0.03818559  
2023-06-13 02:24:39.149: Found a better model.
2023-06-13 02:24:39.149: Save model to file as pretrain.
2023-06-13 02:30:11.198: [iter 136 : loss : 0.4196 = 0.0048 + 0.3999 + 0.0148, time: 323.249332]
2023-06-13 02:31:00.535: epoch 136:	0.00663392  	0.10625002  	0.05014494  	0.03776372  	0.03820243  
2023-06-13 02:31:00.535: Found a better model.
2023-06-13 02:31:00.535: Save model to file as pretrain.
2023-06-13 02:36:42.663: [iter 137 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 333.426811]
2023-06-13 02:37:32.005: epoch 137:	0.00663597  	0.10623507  	0.05013645  	0.03776307  	0.03820831  
2023-06-13 02:43:08.903: [iter 138 : loss : 0.4196 = 0.0049 + 0.3999 + 0.0148, time: 332.299404]
2023-06-13 02:43:57.346: epoch 138:	0.00664509  	0.10647781  	0.05017218  	0.03773886  	0.03818551  
2023-06-13 02:43:57.346: Found a better model.
2023-06-13 02:43:57.346: Save model to file as pretrain.
2023-06-13 02:49:41.405: [iter 139 : loss : 0.4196 = 0.0049 + 0.3999 + 0.0148, time: 335.340427]
2023-06-13 02:50:38.926: epoch 139:	0.00662760  	0.10616597  	0.05006245  	0.03766933  	0.03811443  
2023-06-13 02:57:04.955: [iter 140 : loss : 0.4196 = 0.0049 + 0.3999 + 0.0148, time: 380.976396]
2023-06-13 02:58:01.348: epoch 140:	0.00663020  	0.10613815  	0.05009210  	0.03772676  	0.03816379  
2023-06-13 03:04:40.116: [iter 141 : loss : 0.4196 = 0.0049 + 0.3999 + 0.0148, time: 393.744015]
2023-06-13 03:05:35.210: epoch 141:	0.00663075  	0.10615005  	0.05008128  	0.03771990  	0.03816885  
2023-06-13 03:12:01.131: [iter 142 : loss : 0.4195 = 0.0047 + 0.3999 + 0.0148, time: 380.850409]
2023-06-13 03:12:56.648: epoch 142:	0.00664304  	0.10633034  	0.05016982  	0.03781481  	0.03823958  
2023-06-13 03:19:21.069: [iter 143 : loss : 0.4196 = 0.0048 + 0.3999 + 0.0148, time: 379.443557]
2023-06-13 03:20:17.192: epoch 143:	0.00665960  	0.10663452  	0.05020934  	0.03774094  	0.03818100  
2023-06-13 03:20:17.192: Found a better model.
2023-06-13 03:20:17.192: Save model to file as pretrain.
2023-06-13 03:26:41.201: [iter 144 : loss : 0.4196 = 0.0049 + 0.3999 + 0.0148, time: 374.852637]
2023-06-13 03:27:37.465: epoch 144:	0.00664434  	0.10639413  	0.05020068  	0.03781094  	0.03824234  
2023-06-13 03:34:04.714: [iter 145 : loss : 0.4196 = 0.0049 + 0.3999 + 0.0148, time: 382.252017]
2023-06-13 03:35:00.565: epoch 145:	0.00664192  	0.10637593  	0.05022143  	0.03786985  	0.03831343  
2023-06-13 03:41:31.269: [iter 146 : loss : 0.4196 = 0.0049 + 0.3999 + 0.0148, time: 385.728914]
2023-06-13 03:42:27.807: epoch 146:	0.00665942  	0.10663949  	0.05023097  	0.03782205  	0.03826496  
2023-06-13 03:42:27.807: Found a better model.
2023-06-13 03:42:27.807: Save model to file as pretrain.
2023-06-13 03:48:43.152: [iter 147 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 366.414305]
2023-06-13 03:49:43.345: epoch 147:	0.00664546  	0.10648688  	0.05028912  	0.03792524  	0.03837257  
2023-06-13 03:56:11.379: [iter 148 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 382.933912]
2023-06-13 03:57:07.377: epoch 148:	0.00666203  	0.10666393  	0.05031085  	0.03791045  	0.03834666  
2023-06-13 03:57:07.377: Found a better model.
2023-06-13 03:57:07.377: Save model to file as pretrain.
2023-06-13 04:03:43.384: [iter 149 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 387.831282]
2023-06-13 04:04:38.828: epoch 149:	0.00666333  	0.10671688  	0.05036132  	0.03796546  	0.03841162  
2023-06-13 04:04:38.828: Found a better model.
2023-06-13 04:04:38.828: Save model to file as pretrain.
2023-06-13 04:11:06.344: [iter 150 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 381.563999]
2023-06-13 04:12:01.869: epoch 150:	0.00664750  	0.10642277  	0.05032396  	0.03798578  	0.03842853  
2023-06-13 04:18:37.825: [iter 151 : loss : 0.4196 = 0.0048 + 0.3999 + 0.0148, time: 391.013056]
2023-06-13 04:19:34.440: epoch 151:	0.00666054  	0.10665980  	0.05032926  	0.03792642  	0.03837233  
2023-06-13 04:26:01.061: [iter 152 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 381.635256]
2023-06-13 04:26:57.092: epoch 152:	0.00664677  	0.10644908  	0.05029141  	0.03789625  	0.03833210  
2023-06-13 04:33:40.488: [iter 153 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 398.489527]
2023-06-13 04:34:37.809: epoch 153:	0.00666091  	0.10667418  	0.05035399  	0.03794323  	0.03840566  
2023-06-13 04:41:03.652: [iter 154 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 380.868970]
2023-06-13 04:41:59.544: epoch 154:	0.00666222  	0.10664322  	0.05041382  	0.03800559  	0.03846546  
2023-06-13 04:48:22.352: [iter 155 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 377.819607]
2023-06-13 04:49:18.638: epoch 155:	0.00665608  	0.10660344  	0.05033256  	0.03793691  	0.03837342  
2023-06-13 04:55:44.443: [iter 156 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 380.839462]
2023-06-13 04:56:40.161: epoch 156:	0.00664416  	0.10650732  	0.05029074  	0.03789468  	0.03833928  
2023-06-13 05:02:58.168: [iter 157 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 373.047062]
2023-06-13 05:03:54.872: epoch 157:	0.00665105  	0.10653273  	0.05033315  	0.03794699  	0.03837097  
2023-06-13 05:10:19.965: [iter 158 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 380.177334]
2023-06-13 05:11:16.371: epoch 158:	0.00664230  	0.10633367  	0.05029337  	0.03795657  	0.03837114  
2023-06-13 05:17:54.718: [iter 159 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 393.382165]
2023-06-13 05:18:50.462: epoch 159:	0.00665180  	0.10652762  	0.05035669  	0.03798594  	0.03839004  
2023-06-13 05:25:14.065: [iter 160 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 378.603474]
2023-06-13 05:26:09.708: epoch 160:	0.00665217  	0.10656976  	0.05038977  	0.03802509  	0.03844706  
2023-06-13 05:32:30.602: [iter 161 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 375.822641]
2023-06-13 05:33:26.870: epoch 161:	0.00664640  	0.10648485  	0.05031694  	0.03794026  	0.03836603  
2023-06-13 05:39:56.011: [iter 162 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 384.081163]
2023-06-13 05:40:52.227: epoch 162:	0.00665385  	0.10657275  	0.05034119  	0.03795371  	0.03839423  
2023-06-13 05:47:02.167: [iter 163 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 364.996017]
2023-06-13 05:47:57.982: epoch 163:	0.00666092  	0.10666228  	0.05038649  	0.03796513  	0.03841663  
2023-06-13 05:54:29.692: [iter 164 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 386.670365]
2023-06-13 05:55:25.001: epoch 164:	0.00666892  	0.10682321  	0.05044190  	0.03802538  	0.03846951  
2023-06-13 05:55:25.001: Found a better model.
2023-06-13 05:55:25.001: Save model to file as pretrain.
2023-06-13 06:01:54.536: [iter 165 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 383.533074]
2023-06-13 06:02:50.865: epoch 165:	0.00667078  	0.10677022  	0.05048107  	0.03808839  	0.03851934  
2023-06-13 06:09:18.907: [iter 166 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 383.041776]
2023-06-13 06:10:14.192: epoch 166:	0.00666873  	0.10672952  	0.05047077  	0.03810917  	0.03855523  
2023-06-13 06:16:39.386: [iter 167 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 380.081508]
2023-06-13 06:17:34.833: epoch 167:	0.00665980  	0.10657915  	0.05040509  	0.03803309  	0.03846371  
2023-06-13 06:24:00.459: [iter 168 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 380.555324]
2023-06-13 06:24:57.873: epoch 168:	0.00666240  	0.10666526  	0.05049532  	0.03816716  	0.03859401  
2023-06-13 06:31:33.084: [iter 169 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 390.111467]
2023-06-13 06:32:29.936: epoch 169:	0.00667134  	0.10684520  	0.05050143  	0.03812042  	0.03854226  
2023-06-13 06:32:29.936: Found a better model.
2023-06-13 06:32:29.936: Save model to file as pretrain.
2023-06-13 06:38:52.738: [iter 170 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 376.820647]
2023-06-13 06:39:48.650: epoch 170:	0.00665868  	0.10664298  	0.05046872  	0.03815127  	0.03857621  
2023-06-13 06:46:32.961: [iter 171 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 399.306463]
2023-06-13 06:47:33.284: epoch 171:	0.00667618  	0.10689963  	0.05055375  	0.03818414  	0.03860936  
2023-06-13 06:47:33.284: Found a better model.
2023-06-13 06:47:33.284: Save model to file as pretrain.
2023-06-13 06:53:57.832: [iter 172 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 376.820070]
2023-06-13 06:54:52.683: epoch 172:	0.00667637  	0.10686391  	0.05064150  	0.03829852  	0.03873458  
2023-06-13 07:01:26.624: [iter 173 : loss : 0.4194 = 0.0048 + 0.3999 + 0.0148, time: 389.009623]
2023-06-13 07:02:21.718: epoch 173:	0.00666725  	0.10674889  	0.05051315  	0.03816997  	0.03859083  
2023-06-13 07:08:49.684: [iter 174 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 383.009428]
2023-06-13 07:09:44.818: epoch 174:	0.00667822  	0.10689618  	0.05053452  	0.03812848  	0.03855346  
2023-06-13 07:16:18.487: [iter 175 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 388.799325]
2023-06-13 07:17:14.596: epoch 175:	0.00669944  	0.10724179  	0.05073082  	0.03831635  	0.03874891  
2023-06-13 07:17:14.596: Found a better model.
2023-06-13 07:17:14.596: Save model to file as pretrain.
2023-06-13 07:23:57.288: [iter 176 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 393.745347]
2023-06-13 07:24:53.938: epoch 176:	0.00669665  	0.10708620  	0.05068526  	0.03827079  	0.03870993  
2023-06-13 07:31:27.903: [iter 177 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 389.034324]
2023-06-13 07:32:24.714: epoch 177:	0.00668214  	0.10685894  	0.05061265  	0.03824684  	0.03869530  
2023-06-13 07:39:02.778: [iter 178 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 393.070434]
2023-06-13 07:39:59.049: epoch 178:	0.00668865  	0.10695281  	0.05059395  	0.03816965  	0.03860286  
2023-06-13 07:46:19.268: [iter 179 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 375.240714]
2023-06-13 07:47:15.963: epoch 179:	0.00668288  	0.10686080  	0.05065525  	0.03825322  	0.03869591  
2023-06-13 07:53:33.743: [iter 180 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 372.816219]
2023-06-13 07:54:29.060: epoch 180:	0.00668399  	0.10687833  	0.05071382  	0.03834787  	0.03879946  
2023-06-13 08:00:52.700: [iter 181 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 378.674957]
2023-06-13 08:01:48.757: epoch 181:	0.00668604  	0.10703896  	0.05075654  	0.03836410  	0.03881161  
2023-06-13 08:08:25.766: [iter 182 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 392.026829]
2023-06-13 08:09:20.740: epoch 182:	0.00669851  	0.10722941  	0.05076225  	0.03832048  	0.03878372  
2023-06-13 08:15:45.962: [iter 183 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 380.226044]
2023-06-13 08:16:41.820: epoch 183:	0.00671099  	0.10734638  	0.05084933  	0.03838788  	0.03884527  
2023-06-13 08:16:41.820: Found a better model.
2023-06-13 08:16:41.820: Save model to file as pretrain.
2023-06-13 08:23:06.180: [iter 184 : loss : 0.4195 = 0.0048 + 0.3999 + 0.0148, time: 375.258710]
2023-06-13 08:24:02.839: epoch 184:	0.00670057  	0.10723256  	0.05086896  	0.03847704  	0.03893789  
2023-06-13 08:30:29.205: [iter 185 : loss : 0.4194 = 0.0048 + 0.3999 + 0.0148, time: 381.341959]
2023-06-13 08:31:26.283: epoch 185:	0.00669052  	0.10702845  	0.05080037  	0.03844020  	0.03888774  
2023-06-13 08:37:54.781: [iter 186 : loss : 0.4194 = 0.0048 + 0.3999 + 0.0148, time: 383.476431]
2023-06-13 08:38:51.412: epoch 186:	0.00671285  	0.10736091  	0.05085517  	0.03842288  	0.03886201  
2023-06-13 08:38:51.413: Found a better model.
2023-06-13 08:38:51.413: Save model to file as pretrain.
2023-06-13 08:45:35.425: [iter 187 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 395.752142]
2023-06-13 08:46:31.472: epoch 187:	0.00670447  	0.10735943  	0.05086029  	0.03845489  	0.03890824  
2023-06-13 08:53:01.006: [iter 188 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 384.455962]
2023-06-13 08:53:55.512: epoch 188:	0.00670149  	0.10723203  	0.05084377  	0.03844510  	0.03891136  
2023-06-13 09:00:49.006: [iter 189 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 408.427197]
2023-06-13 09:01:44.293: epoch 189:	0.00671601  	0.10739478  	0.05086847  	0.03845620  	0.03888643  
2023-06-13 09:01:44.293: Found a better model.
2023-06-13 09:01:44.293: Save model to file as pretrain.
2023-06-13 09:08:17.142: [iter 190 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 386.807243]
2023-06-13 09:09:12.759: epoch 190:	0.00671899  	0.10739337  	0.05096169  	0.03857123  	0.03903132  
2023-06-13 09:15:51.041: [iter 191 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 393.261047]
2023-06-13 09:16:46.743: epoch 191:	0.00672216  	0.10748360  	0.05103593  	0.03863999  	0.03909891  
2023-06-13 09:16:46.743: Found a better model.
2023-06-13 09:16:46.743: Save model to file as pretrain.
2023-06-13 09:23:12.503: [iter 192 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 379.710341]
2023-06-13 09:24:10.228: epoch 192:	0.00671899  	0.10753518  	0.05104408  	0.03864094  	0.03908799  
2023-06-13 09:24:10.228: Found a better model.
2023-06-13 09:24:10.228: Save model to file as pretrain.
2023-06-13 09:30:24.067: [iter 193 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 367.724343]
2023-06-13 09:31:20.860: epoch 193:	0.00670093  	0.10731681  	0.05089234  	0.03848736  	0.03893777  
2023-06-13 09:37:46.538: [iter 194 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 380.637247]
2023-06-13 09:38:43.345: epoch 194:	0.00668772  	0.10712639  	0.05085556  	0.03851381  	0.03896038  
2023-06-13 09:45:11.179: [iter 195 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 382.731832]
2023-06-13 09:46:12.040: epoch 195:	0.00670150  	0.10734110  	0.05087369  	0.03847948  	0.03893107  
2023-06-13 09:52:34.238: [iter 196 : loss : 0.4194 = 0.0048 + 0.3999 + 0.0148, time: 376.858438]
2023-06-13 09:53:29.385: epoch 196:	0.00670708  	0.10734645  	0.05089056  	0.03847303  	0.03892425  
2023-06-13 09:59:59.614: [iter 197 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 385.190481]
2023-06-13 10:00:56.739: epoch 197:	0.00671862  	0.10750907  	0.05087350  	0.03838741  	0.03883787  
2023-06-13 10:07:08.593: [iter 198 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 366.684056]
2023-06-13 10:08:04.619: epoch 198:	0.00672550  	0.10757928  	0.05090021  	0.03840869  	0.03887076  
2023-06-13 10:08:04.619: Found a better model.
2023-06-13 10:08:04.619: Save model to file as pretrain.
2023-06-13 10:14:12.187: [iter 199 : loss : 0.4193 = 0.0047 + 0.3999 + 0.0148, time: 359.425647]
2023-06-13 10:15:07.647: epoch 199:	0.00673314  	0.10777909  	0.05091703  	0.03840034  	0.03884987  
2023-06-13 10:15:07.647: Found a better model.
2023-06-13 10:15:07.647: Save model to file as pretrain.
2023-06-13 10:21:31.188: [iter 200 : loss : 0.4193 = 0.0047 + 0.3999 + 0.0148, time: 377.507718]
2023-06-13 10:22:25.566: epoch 200:	0.00672625  	0.10769305  	0.05085606  	0.03832827  	0.03876349  
2023-06-13 10:28:37.858: [iter 201 : loss : 0.4194 = 0.0048 + 0.3999 + 0.0148, time: 367.269775]
2023-06-13 10:29:34.253: epoch 201:	0.00672178  	0.10762960  	0.05089623  	0.03840487  	0.03884829  
2023-06-13 10:35:49.435: [iter 202 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 370.124578]
2023-06-13 10:36:44.813: epoch 202:	0.00671675  	0.10752165  	0.05087714  	0.03839726  	0.03884783  
2023-06-13 10:42:56.066: [iter 203 : loss : 0.4193 = 0.0047 + 0.3999 + 0.0148, time: 366.248947]
2023-06-13 10:43:53.014: epoch 203:	0.00673723  	0.10787860  	0.05097152  	0.03845965  	0.03890619  
2023-06-13 10:43:53.015: Found a better model.
2023-06-13 10:43:53.015: Save model to file as pretrain.
2023-06-13 10:50:16.635: [iter 204 : loss : 0.4193 = 0.0047 + 0.3999 + 0.0148, time: 377.566753]
2023-06-13 10:51:12.148: epoch 204:	0.00672848  	0.10774793  	0.05096229  	0.03847621  	0.03893011  
2023-06-13 10:57:39.776: [iter 205 : loss : 0.4193 = 0.0047 + 0.3999 + 0.0148, time: 382.631696]
2023-06-13 10:58:36.077: epoch 205:	0.00672364  	0.10767161  	0.05093909  	0.03847390  	0.03891721  
2023-06-13 11:05:08.681: [iter 206 : loss : 0.4193 = 0.0046 + 0.3999 + 0.0148, time: 387.571077]
2023-06-13 11:06:05.959: epoch 206:	0.00672514  	0.10773166  	0.05093438  	0.03846893  	0.03891059  
2023-06-13 11:12:22.836: [iter 207 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 371.885656]
2023-06-13 11:13:17.404: epoch 207:	0.00672420  	0.10763907  	0.05103610  	0.03862328  	0.03908063  
2023-06-13 11:19:44.124: [iter 208 : loss : 0.4193 = 0.0047 + 0.3999 + 0.0148, time: 381.591659]
2023-06-13 11:20:39.545: epoch 208:	0.00671639  	0.10762618  	0.05103678  	0.03863701  	0.03906614  
2023-06-13 11:26:39.078: [iter 209 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 354.610007]
2023-06-13 11:27:35.313: epoch 209:	0.00671732  	0.10761218  	0.05102079  	0.03860285  	0.03905145  
2023-06-13 11:33:57.468: [iter 210 : loss : 0.4193 = 0.0047 + 0.3999 + 0.0148, time: 377.174301]
2023-06-13 11:34:53.204: epoch 210:	0.00672793  	0.10777308  	0.05105167  	0.03860282  	0.03904989  
2023-06-13 11:41:17.843: [iter 211 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 379.602700]
2023-06-13 11:42:14.188: epoch 211:	0.00673166  	0.10773201  	0.05105174  	0.03862716  	0.03907632  
2023-06-13 11:48:46.198: [iter 212 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 387.034884]
2023-06-13 11:49:41.425: epoch 212:	0.00673761  	0.10789660  	0.05111865  	0.03866403  	0.03911329  
2023-06-13 11:49:41.425: Found a better model.
2023-06-13 11:49:41.425: Save model to file as pretrain.
2023-06-13 11:56:09.563: [iter 213 : loss : 0.4194 = 0.0048 + 0.3999 + 0.0148, time: 382.147313]
2023-06-13 11:57:06.996: epoch 213:	0.00674244  	0.10795800  	0.05111367  	0.03861811  	0.03908142  
2023-06-13 11:57:06.996: Found a better model.
2023-06-13 11:57:06.996: Save model to file as pretrain.
2023-06-13 12:03:32.641: [iter 214 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 379.629223]
2023-06-13 12:04:27.956: epoch 214:	0.00673555  	0.10780352  	0.05102647  	0.03855769  	0.03902018  
2023-06-13 12:10:47.168: [iter 215 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 374.151975]
2023-06-13 12:11:42.437: epoch 215:	0.00673127  	0.10774539  	0.05109637  	0.03868522  	0.03913745  
2023-06-13 12:18:04.447: [iter 216 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 376.992865]
2023-06-13 12:19:01.095: epoch 216:	0.00673537  	0.10779945  	0.05113789  	0.03872852  	0.03916622  
2023-06-13 12:25:18.338: [iter 217 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 372.222082]
2023-06-13 12:26:14.715: epoch 217:	0.00674244  	0.10796542  	0.05124231  	0.03879929  	0.03925060  
2023-06-13 12:26:14.715: Found a better model.
2023-06-13 12:26:14.715: Save model to file as pretrain.
2023-06-13 12:32:41.029: [iter 218 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 380.305626]
2023-06-13 12:33:37.758: epoch 218:	0.00672848  	0.10772862  	0.05115093  	0.03873769  	0.03919847  
2023-06-13 12:40:01.826: [iter 219 : loss : 0.4193 = 0.0047 + 0.3999 + 0.0148, time: 378.767581]
2023-06-13 12:40:59.402: epoch 219:	0.00670335  	0.10725445  	0.05109537  	0.03879219  	0.03922813  
2023-06-13 12:47:21.392: [iter 220 : loss : 0.4192 = 0.0046 + 0.3999 + 0.0148, time: 376.928078]
2023-06-13 12:48:16.538: epoch 220:	0.00671322  	0.10747395  	0.05115224  	0.03882259  	0.03925808  
2023-06-13 12:54:29.858: [iter 221 : loss : 0.4193 = 0.0047 + 0.3999 + 0.0148, time: 368.220080]
2023-06-13 12:55:25.048: epoch 221:	0.00671173  	0.10736658  	0.05107766  	0.03875549  	0.03918991  
2023-06-13 13:01:57.043: [iter 222 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 386.967756]
2023-06-13 13:02:53.406: epoch 222:	0.00672066  	0.10754095  	0.05115433  	0.03878962  	0.03923793  
2023-06-13 13:09:25.666: [iter 223 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0148, time: 387.205493]
2023-06-13 13:10:21.832: epoch 223:	0.00672476  	0.10758755  	0.05115354  	0.03879669  	0.03923766  
2023-06-13 13:16:34.263: [iter 224 : loss : 0.4193 = 0.0046 + 0.3999 + 0.0148, time: 367.403826]
2023-06-13 13:17:29.285: epoch 224:	0.00672085  	0.10751620  	0.05111083  	0.03872950  	0.03917230  
2023-06-13 13:23:45.243: [iter 225 : loss : 0.4194 = 0.0047 + 0.3999 + 0.0147, time: 370.849783]
2023-06-13 13:24:41.089: epoch 225:	0.00672885  	0.10767664  	0.05111723  	0.03868600  	0.03914205  
2023-06-13 13:30:59.960: [iter 226 : loss : 0.4193 = 0.0047 + 0.3999 + 0.0148, time: 373.755456]
2023-06-13 13:31:57.060: epoch 226:	0.00673611  	0.10788997  	0.05116635  	0.03870601  	0.03916043  
2023-06-13 13:38:26.031: [iter 227 : loss : 0.4193 = 0.0047 + 0.3999 + 0.0148, time: 383.965267]
2023-06-13 13:39:20.833: epoch 227:	0.00672830  	0.10769274  	0.05111513  	0.03868449  	0.03914333  
2023-06-13 13:45:35.029: [iter 228 : loss : 0.4193 = 0.0047 + 0.3999 + 0.0147, time: 369.082435]
2023-06-13 13:46:31.250: epoch 228:	0.00672625  	0.10768154  	0.05114965  	0.03874480  	0.03922050  
2023-06-13 13:53:07.252: [iter 229 : loss : 0.4194 = 0.0048 + 0.3999 + 0.0147, time: 390.945434]
2023-06-13 13:54:03.188: epoch 229:	0.00673742  	0.10790367  	0.05118551  	0.03874533  	0.03919980  
2023-06-13 14:00:12.311: [iter 230 : loss : 0.4193 = 0.0047 + 0.3999 + 0.0148, time: 364.127665]
2023-06-13 14:01:08.136: epoch 230:	0.00674114  	0.10792805  	0.05120509  	0.03876889  	0.03921919  
2023-06-13 14:07:06.068: [iter 231 : loss : 0.4193 = 0.0047 + 0.3999 + 0.0147, time: 352.953343]
2023-06-13 14:08:01.313: epoch 231:	0.00673202  	0.10775648  	0.05115870  	0.03872985  	0.03920579  
2023-06-13 14:14:10.017: [iter 232 : loss : 0.4193 = 0.0047 + 0.3999 + 0.0147, time: 363.764496]
2023-06-13 14:15:06.538: epoch 232:	0.00672923  	0.10776395  	0.05110313  	0.03865515  	0.03911169  
2023-06-13 14:21:22.016: [iter 233 : loss : 0.4193 = 0.0046 + 0.3999 + 0.0148, time: 370.497880]
2023-06-13 14:22:17.743: epoch 233:	0.00673761  	0.10784155  	0.05120379  	0.03876527  	0.03923285  
2023-06-13 14:28:28.802: [iter 234 : loss : 0.4193 = 0.0047 + 0.3999 + 0.0148, time: 366.022355]
2023-06-13 14:29:24.601: epoch 234:	0.00673109  	0.10771447  	0.05112395  	0.03869500  	0.03916216  
2023-06-13 14:35:38.176: [iter 235 : loss : 0.4193 = 0.0047 + 0.3999 + 0.0147, time: 368.529077]
2023-06-13 14:36:33.441: epoch 235:	0.00674561  	0.10788844  	0.05118021  	0.03870659  	0.03917557  
2023-06-13 14:42:47.968: [iter 236 : loss : 0.4193 = 0.0047 + 0.3999 + 0.0147, time: 369.520991]
2023-06-13 14:43:44.725: epoch 236:	0.00674561  	0.10793598  	0.05125045  	0.03881426  	0.03927672  
2023-06-13 14:49:55.287: [iter 237 : loss : 0.4193 = 0.0046 + 0.3999 + 0.0147, time: 365.557069]
2023-06-13 14:50:51.333: epoch 237:	0.00674003  	0.10792039  	0.05116613  	0.03870516  	0.03916194  
2023-06-13 14:50:51.333: Early stopping is triggered at epoch: 237
2023-06-13 14:50:51.333: best_result@epoch 217:

2023-06-13 14:50:51.333: Loading from the saved model.
2023-06-13 14:51:48.115: 		0.00674244  	0.10796542  	0.05124233  	0.03879930  	0.03925061  
/home/Thesis/model/general_recommender/SGL.py:146: RuntimeWarning: divide by zero encountered in power
  d_inv = np.power(rowsum, -0.5).flatten()
