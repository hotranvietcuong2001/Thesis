seed= 2021
load saved data...
Item degree grouping...
User degree grouping...
Data loading finished
Evaluate model with cpp
2023-05-23 22:02:09.368: Dataset name: ifashion
The number of users: 300000
The number of items: 81614
The number of ratings: 1607813
Average actions of users: 5.36
Average actions of items: 19.70
The sparsity of the dataset: 99.993433%
2023-05-23 22:02:09.368: 

NeuRec hyperparameters:
recommender=SGL
config_dir=./conf
gpu_id=1
gpu_mem=0.5
data.input.path=dataset
data.input.dataset=ifashion
data.column.format=UI
data.convert.separator=','
user_min=0
item_min=0
splitter=given
ratio=0.8
by_time=False
metric=["Precision", "Recall", "NDCG", "MAP", "MRR"]
topk=[20]
group_view=None
rec.evaluate.neg=0
test_batch_size=128
num_thread=8
start_testing_epoch=0
proj_path=./

SGL's hyperparameters:
seed=2021
aug_type=1
reg=1e-3
embed_size=64
n_layers=3
ssl_reg=0.02
ssl_ratio=0.4
ssl_temp=0.5
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=512
num_negatives=1
init_method=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=50
pretrain=0
save_flag=1

2023-05-23 22:02:30.048: metrics:	Precision@20	Recall@20   	NDCG@20     	MAP@20      	MRR@20      
2023-05-23 22:03:33.267: 		0.00000558  	0.00009621  	0.00003600  	0.00002021  	0.00002021  
2023-05-23 22:09:09.325: [iter 1 : loss : 0.9906 = 0.5853 + 0.4042 + 0.0010, time: 334.469872]
2023-05-23 22:09:58.776: epoch 1:	0.00306596  	0.04922947  	0.02134424  	0.01521117  	0.01531035  
2023-05-23 22:09:58.777: Found a better model.
2023-05-23 22:09:58.777: Save model to file as pretrain.
2023-05-23 22:15:33.955: [iter 2 : loss : 0.6140 = 0.1890 + 0.4182 + 0.0068, time: 333.254467]
2023-05-23 22:16:22.597: epoch 2:	0.00368159  	0.05903217  	0.02583770  	0.01852515  	0.01866051  
2023-05-23 22:16:22.597: Found a better model.
2023-05-23 22:16:22.597: Save model to file as pretrain.
2023-05-23 22:22:38.769: [iter 3 : loss : 0.5311 = 0.1083 + 0.4135 + 0.0093, time: 373.594651]
2023-05-23 22:23:26.838: epoch 3:	0.00419132  	0.06723015  	0.02961624  	0.02128372  	0.02145282  
2023-05-23 22:23:26.838: Found a better model.
2023-05-23 22:23:26.838: Save model to file as pretrain.
2023-05-23 22:28:57.815: [iter 4 : loss : 0.4961 = 0.0752 + 0.4101 + 0.0108, time: 328.463614]
2023-05-23 22:29:45.452: epoch 4:	0.00456213  	0.07337248  	0.03262351  	0.02361571  	0.02379090  
2023-05-23 22:29:45.452: Found a better model.
2023-05-23 22:29:45.452: Save model to file as pretrain.
2023-05-23 22:35:18.257: [iter 5 : loss : 0.4760 = 0.0561 + 0.4079 + 0.0120, time: 330.309616]
2023-05-23 22:36:05.363: epoch 5:	0.00484359  	0.07793215  	0.03485287  	0.02530572  	0.02549322  
2023-05-23 22:36:05.363: Found a better model.
2023-05-23 22:36:05.364: Save model to file as pretrain.
2023-05-23 22:41:42.778: [iter 6 : loss : 0.4629 = 0.0436 + 0.4064 + 0.0129, time: 334.925453]
2023-05-23 22:42:31.460: epoch 6:	0.00504910  	0.08128975  	0.03659125  	0.02670608  	0.02691355  
2023-05-23 22:42:31.460: Found a better model.
2023-05-23 22:42:31.460: Save model to file as pretrain.
2023-05-23 22:48:46.001: [iter 7 : loss : 0.4542 = 0.0352 + 0.4053 + 0.0137, time: 372.077954]
2023-05-23 22:49:33.527: epoch 7:	0.00519578  	0.08358303  	0.03810050  	0.02807845  	0.02831868  
2023-05-23 22:49:33.527: Found a better model.
2023-05-23 22:49:33.527: Save model to file as pretrain.
2023-05-23 22:55:10.704: [iter 8 : loss : 0.4475 = 0.0289 + 0.4044 + 0.0142, time: 334.679190]
2023-05-23 22:55:58.900: epoch 8:	0.00534582  	0.08602900  	0.03940739  	0.02910880  	0.02935949  
2023-05-23 22:55:58.900: Found a better model.
2023-05-23 22:55:58.900: Save model to file as pretrain.
2023-05-23 23:01:36.070: [iter 9 : loss : 0.4427 = 0.0242 + 0.4038 + 0.0147, time: 334.652819]
2023-05-23 23:02:23.940: epoch 9:	0.00548132  	0.08802086  	0.04044463  	0.02995760  	0.03023787  
2023-05-23 23:02:23.940: Found a better model.
2023-05-23 23:02:23.940: Save model to file as pretrain.
2023-05-23 23:08:39.596: [iter 10 : loss : 0.4390 = 0.0209 + 0.4032 + 0.0150, time: 373.152341]
2023-05-23 23:09:24.394: epoch 10:	0.00558389  	0.08960319  	0.04123364  	0.03057943  	0.03087481  
2023-05-23 23:09:24.395: Found a better model.
2023-05-23 23:09:24.395: Save model to file as pretrain.
2023-05-23 23:14:57.278: [iter 11 : loss : 0.4358 = 0.0178 + 0.4028 + 0.0152, time: 330.362549]
2023-05-23 23:15:45.425: epoch 11:	0.00566858  	0.09091835  	0.04205013  	0.03128866  	0.03159650  
2023-05-23 23:15:45.425: Found a better model.
2023-05-23 23:15:45.425: Save model to file as pretrain.
2023-05-23 23:22:02.816: [iter 12 : loss : 0.4334 = 0.0157 + 0.4024 + 0.0153, time: 374.903145]
2023-05-23 23:22:50.071: epoch 12:	0.00574044  	0.09197772  	0.04261598  	0.03174210  	0.03204877  
2023-05-23 23:22:50.071: Found a better model.
2023-05-23 23:22:50.071: Save model to file as pretrain.
2023-05-23 23:29:08.027: [iter 13 : loss : 0.4315 = 0.0140 + 0.4021 + 0.0153, time: 375.475281]
2023-05-23 23:29:56.706: epoch 13:	0.00579349  	0.09274513  	0.04315625  	0.03228260  	0.03258828  
2023-05-23 23:29:56.706: Found a better model.
2023-05-23 23:29:56.706: Save model to file as pretrain.
2023-05-23 23:35:32.308: [iter 14 : loss : 0.4301 = 0.0129 + 0.4019 + 0.0153, time: 333.092681]
2023-05-23 23:36:20.440: epoch 14:	0.00585658  	0.09369866  	0.04370961  	0.03275535  	0.03308340  
2023-05-23 23:36:20.440: Found a better model.
2023-05-23 23:36:20.440: Save model to file as pretrain.
2023-05-23 23:41:51.414: [iter 15 : loss : 0.4290 = 0.0120 + 0.4017 + 0.0153, time: 328.475516]
2023-05-23 23:42:37.564: epoch 15:	0.00590517  	0.09462754  	0.04419941  	0.03314215  	0.03346732  
2023-05-23 23:42:37.564: Found a better model.
2023-05-23 23:42:37.564: Save model to file as pretrain.
2023-05-23 23:48:08.532: [iter 16 : loss : 0.4278 = 0.0110 + 0.4015 + 0.0153, time: 328.422511]
2023-05-23 23:48:56.123: epoch 16:	0.00594202  	0.09514557  	0.04448203  	0.03339324  	0.03371405  
2023-05-23 23:48:56.123: Found a better model.
2023-05-23 23:48:56.123: Save model to file as pretrain.
2023-05-23 23:54:33.199: [iter 17 : loss : 0.4268 = 0.0102 + 0.4014 + 0.0152, time: 334.513218]
2023-05-23 23:55:20.834: epoch 17:	0.00596249  	0.09539564  	0.04476045  	0.03368337  	0.03403578  
2023-05-23 23:55:20.834: Found a better model.
2023-05-23 23:55:20.834: Save model to file as pretrain.
2023-05-24 00:00:51.852: [iter 18 : loss : 0.4261 = 0.0097 + 0.4013 + 0.0152, time: 328.523865]
2023-05-24 00:01:36.544: epoch 18:	0.00598912  	0.09578422  	0.04502108  	0.03390146  	0.03425539  
2023-05-24 00:01:36.544: Found a better model.
2023-05-24 00:01:36.544: Save model to file as pretrain.
2023-05-24 00:07:52.979: [iter 19 : loss : 0.4254 = 0.0091 + 0.4011 + 0.0151, time: 373.902350]
2023-05-24 00:08:39.514: epoch 19:	0.00600234  	0.09604853  	0.04522160  	0.03411660  	0.03447595  
2023-05-24 00:08:39.515: Found a better model.
2023-05-24 00:08:39.515: Save model to file as pretrain.
2023-05-24 00:14:18.466: [iter 20 : loss : 0.4249 = 0.0088 + 0.4011 + 0.0151, time: 336.418644]
2023-05-24 00:15:05.562: epoch 20:	0.00601332  	0.09624583  	0.04528098  	0.03412958  	0.03449842  
2023-05-24 00:15:05.562: Found a better model.
2023-05-24 00:15:05.562: Save model to file as pretrain.
2023-05-24 00:20:36.573: [iter 21 : loss : 0.4244 = 0.0085 + 0.4010 + 0.0150, time: 328.397962]
2023-05-24 00:21:24.857: epoch 21:	0.00605558  	0.09691357  	0.04557756  	0.03435071  	0.03471566  
2023-05-24 00:21:24.857: Found a better model.
2023-05-24 00:21:24.857: Save model to file as pretrain.
2023-05-24 00:27:39.395: [iter 22 : loss : 0.4241 = 0.0082 + 0.4009 + 0.0150, time: 372.047662]
2023-05-24 00:28:28.989: epoch 22:	0.00606190  	0.09696598  	0.04567831  	0.03443191  	0.03479777  
2023-05-24 00:28:28.989: Found a better model.
2023-05-24 00:28:28.989: Save model to file as pretrain.
2023-05-24 00:34:43.768: [iter 23 : loss : 0.4237 = 0.0079 + 0.4008 + 0.0149, time: 372.146191]
2023-05-24 00:35:30.471: epoch 23:	0.00607884  	0.09723575  	0.04586096  	0.03463876  	0.03501130  
2023-05-24 00:35:30.471: Found a better model.
2023-05-24 00:35:30.471: Save model to file as pretrain.
2023-05-24 00:41:46.935: [iter 24 : loss : 0.4235 = 0.0078 + 0.4008 + 0.0149, time: 373.945088]
2023-05-24 00:42:32.074: epoch 24:	0.00609913  	0.09752761  	0.04592155  	0.03461419  	0.03498035  
2023-05-24 00:42:32.074: Found a better model.
2023-05-24 00:42:32.074: Save model to file as pretrain.
2023-05-24 00:48:32.988: [iter 25 : loss : 0.4231 = 0.0074 + 0.4007 + 0.0149, time: 358.375374]
2023-05-24 00:49:20.252: epoch 25:	0.00611589  	0.09781947  	0.04608142  	0.03477517  	0.03514579  
2023-05-24 00:49:20.252: Found a better model.
2023-05-24 00:49:20.252: Save model to file as pretrain.
2023-05-24 00:54:57.704: [iter 26 : loss : 0.4229 = 0.0073 + 0.4007 + 0.0149, time: 334.981909]
2023-05-24 00:55:46.170: epoch 26:	0.00611458  	0.09784333  	0.04616199  	0.03487563  	0.03524610  
2023-05-24 00:55:46.170: Found a better model.
2023-05-24 00:55:46.170: Save model to file as pretrain.
2023-05-24 01:01:25.372: [iter 27 : loss : 0.4226 = 0.0071 + 0.4007 + 0.0149, time: 336.679500]
2023-05-24 01:02:14.675: epoch 27:	0.00613878  	0.09825817  	0.04634559  	0.03498886  	0.03537451  
2023-05-24 01:02:14.675: Found a better model.
2023-05-24 01:02:14.675: Save model to file as pretrain.
2023-05-24 01:08:27.637: [iter 28 : loss : 0.4225 = 0.0070 + 0.4006 + 0.0149, time: 370.446547]
2023-05-24 01:09:00.258: epoch 28:	0.00615143  	0.09845302  	0.04652137  	0.03517487  	0.03557092  
2023-05-24 01:09:00.258: Found a better model.
2023-05-24 01:09:00.258: Save model to file as pretrain.
2023-05-24 01:15:16.225: [iter 29 : loss : 0.4224 = 0.0069 + 0.4006 + 0.0149, time: 373.542882]
2023-05-24 01:16:03.661: epoch 29:	0.00616595  	0.09862413  	0.04663831  	0.03527807  	0.03567801  
2023-05-24 01:16:03.661: Found a better model.
2023-05-24 01:16:03.661: Save model to file as pretrain.
2023-05-24 01:22:17.459: [iter 30 : loss : 0.4223 = 0.0068 + 0.4006 + 0.0149, time: 371.306173]
2023-05-24 01:23:05.750: epoch 30:	0.00615274  	0.09848333  	0.04665945  	0.03534781  	0.03575470  
2023-05-24 01:29:21.279: [iter 31 : loss : 0.4221 = 0.0067 + 0.4006 + 0.0149, time: 374.011060]
2023-05-24 01:30:09.137: epoch 31:	0.00618476  	0.09889451  	0.04681199  	0.03543131  	0.03584190  
2023-05-24 01:30:09.137: Found a better model.
2023-05-24 01:30:09.137: Save model to file as pretrain.
2023-05-24 01:36:26.405: [iter 32 : loss : 0.4220 = 0.0066 + 0.4005 + 0.0149, time: 374.757845]
2023-05-24 01:37:14.423: epoch 32:	0.00619853  	0.09910679  	0.04693718  	0.03552722  	0.03593792  
2023-05-24 01:37:14.423: Found a better model.
2023-05-24 01:37:14.423: Save model to file as pretrain.
2023-05-24 01:43:31.941: [iter 33 : loss : 0.4220 = 0.0066 + 0.4005 + 0.0149, time: 374.996089]
2023-05-24 01:44:19.344: epoch 33:	0.00619499  	0.09908096  	0.04689521  	0.03550080  	0.03590517  
2023-05-24 01:49:49.107: [iter 34 : loss : 0.4218 = 0.0064 + 0.4005 + 0.0149, time: 328.232958]
2023-05-24 01:50:35.053: epoch 34:	0.00621714  	0.09946506  	0.04708487  	0.03567722  	0.03607782  
2023-05-24 01:50:35.053: Found a better model.
2023-05-24 01:50:35.053: Save model to file as pretrain.
2023-05-24 01:56:51.500: [iter 35 : loss : 0.4216 = 0.0063 + 0.4005 + 0.0149, time: 373.943799]
2023-05-24 01:57:38.230: epoch 35:	0.00622459  	0.09963431  	0.04709674  	0.03560704  	0.03600627  
2023-05-24 01:57:38.230: Found a better model.
2023-05-24 01:57:38.231: Save model to file as pretrain.
2023-05-24 02:03:15.406: [iter 36 : loss : 0.4217 = 0.0063 + 0.4005 + 0.0149, time: 334.684484]
2023-05-24 02:04:03.760: epoch 36:	0.00625642  	0.10000201  	0.04728543  	0.03573151  	0.03614029  
2023-05-24 02:04:03.761: Found a better model.
2023-05-24 02:04:03.761: Save model to file as pretrain.
2023-05-24 02:09:34.757: [iter 37 : loss : 0.4215 = 0.0061 + 0.4005 + 0.0149, time: 328.528820]
2023-05-24 02:10:16.503: epoch 37:	0.00624767  	0.09992422  	0.04730007  	0.03582929  	0.03623677  
2023-05-24 02:15:49.608: [iter 38 : loss : 0.4215 = 0.0061 + 0.4004 + 0.0149, time: 331.801538]
2023-05-24 02:16:38.166: epoch 38:	0.00626181  	0.10018363  	0.04738075  	0.03580989  	0.03621792  
2023-05-24 02:16:38.166: Found a better model.
2023-05-24 02:16:38.166: Save model to file as pretrain.
2023-05-24 02:22:54.153: [iter 39 : loss : 0.4214 = 0.0060 + 0.4004 + 0.0149, time: 373.462962]
2023-05-24 02:23:42.488: epoch 39:	0.00627577  	0.10041272  	0.04749520  	0.03587414  	0.03627373  
2023-05-24 02:23:42.488: Found a better model.
2023-05-24 02:23:42.488: Save model to file as pretrain.
2023-05-24 02:30:01.323: [iter 40 : loss : 0.4214 = 0.0061 + 0.4004 + 0.0149, time: 376.317222]
2023-05-24 02:30:48.545: epoch 40:	0.00628248  	0.10057151  	0.04758854  	0.03599718  	0.03640655  
2023-05-24 02:30:48.547: Found a better model.
2023-05-24 02:30:48.547: Save model to file as pretrain.
2023-05-24 02:36:24.214: [iter 41 : loss : 0.4213 = 0.0060 + 0.4004 + 0.0149, time: 333.212911]
2023-05-24 02:37:10.090: epoch 41:	0.00628564  	0.10059461  	0.04759564  	0.03598614  	0.03639255  
2023-05-24 02:37:10.090: Found a better model.
2023-05-24 02:37:10.090: Save model to file as pretrain.
2023-05-24 02:42:41.685: [iter 42 : loss : 0.4213 = 0.0059 + 0.4004 + 0.0149, time: 329.100233]
2023-05-24 02:43:30.544: epoch 42:	0.00628080  	0.10041122  	0.04754128  	0.03594200  	0.03634911  
2023-05-24 02:49:05.683: [iter 43 : loss : 0.4211 = 0.0058 + 0.4004 + 0.0149, time: 333.618210]
2023-05-24 02:49:52.910: epoch 43:	0.00630779  	0.10083865  	0.04778153  	0.03613092  	0.03655604  
2023-05-24 02:49:52.910: Found a better model.
2023-05-24 02:49:52.910: Save model to file as pretrain.
2023-05-24 02:56:07.378: [iter 44 : loss : 0.4211 = 0.0058 + 0.4004 + 0.0149, time: 371.974758]
2023-05-24 02:56:54.810: epoch 44:	0.00629941  	0.10072089  	0.04779374  	0.03619676  	0.03661145  
2023-05-24 03:02:34.566: [iter 45 : loss : 0.4211 = 0.0057 + 0.4004 + 0.0149, time: 338.247295]
2023-05-24 03:03:20.349: epoch 45:	0.00630258  	0.10081632  	0.04780200  	0.03618411  	0.03659584  
2023-05-24 03:09:35.511: [iter 46 : loss : 0.4210 = 0.0057 + 0.4004 + 0.0150, time: 373.658825]
2023-05-24 03:10:23.386: epoch 46:	0.00631766  	0.10109982  	0.04787956  	0.03619372  	0.03661416  
2023-05-24 03:10:23.386: Found a better model.
2023-05-24 03:10:23.386: Save model to file as pretrain.
2023-05-24 03:16:04.086: [iter 47 : loss : 0.4211 = 0.0057 + 0.4004 + 0.0150, time: 338.163279]
2023-05-24 03:16:51.808: epoch 47:	0.00631580  	0.10095360  	0.04784373  	0.03616161  	0.03658191  
2023-05-24 03:22:28.014: [iter 48 : loss : 0.4210 = 0.0057 + 0.4004 + 0.0150, time: 334.685340]
2023-05-24 03:23:15.918: epoch 48:	0.00632064  	0.10122526  	0.04784277  	0.03608696  	0.03650292  
2023-05-24 03:23:15.918: Found a better model.
2023-05-24 03:23:15.919: Save model to file as pretrain.
2023-05-24 03:28:51.568: [iter 49 : loss : 0.4210 = 0.0057 + 0.4003 + 0.0150, time: 333.144953]
2023-05-24 03:29:37.581: epoch 49:	0.00632548  	0.10126701  	0.04795879  	0.03623691  	0.03666222  
2023-05-24 03:29:37.581: Found a better model.
2023-05-24 03:29:37.581: Save model to file as pretrain.
2023-05-24 03:35:54.077: [iter 50 : loss : 0.4210 = 0.0057 + 0.4003 + 0.0150, time: 373.969321]
2023-05-24 03:36:41.059: epoch 50:	0.00634261  	0.10157626  	0.04800856  	0.03625184  	0.03665329  
2023-05-24 03:36:41.068: Found a better model.
2023-05-24 03:36:41.068: Save model to file as pretrain.
2023-05-24 03:42:16.560: [iter 51 : loss : 0.4209 = 0.0056 + 0.4003 + 0.0150, time: 332.997565]
2023-05-24 03:43:03.437: epoch 51:	0.00634354  	0.10161142  	0.04801967  	0.03622825  	0.03664288  
2023-05-24 03:43:03.437: Found a better model.
2023-05-24 03:43:03.437: Save model to file as pretrain.
2023-05-24 03:48:34.071: [iter 52 : loss : 0.4208 = 0.0055 + 0.4003 + 0.0150, time: 328.125739]
2023-05-24 03:49:21.220: epoch 52:	0.00635061  	0.10166150  	0.04809766  	0.03630507  	0.03672767  
2023-05-24 03:49:21.220: Found a better model.
2023-05-24 03:49:21.220: Save model to file as pretrain.
2023-05-24 03:54:57.543: [iter 53 : loss : 0.4207 = 0.0054 + 0.4003 + 0.0150, time: 333.861118]
2023-05-24 03:55:42.371: epoch 53:	0.00635527  	0.10185275  	0.04823556  	0.03646825  	0.03689067  
2023-05-24 03:55:42.371: Found a better model.
2023-05-24 03:55:42.371: Save model to file as pretrain.
2023-05-24 04:01:19.545: [iter 54 : loss : 0.4209 = 0.0056 + 0.4003 + 0.0150, time: 334.666141]
2023-05-24 04:02:08.357: epoch 54:	0.00634894  	0.10169695  	0.04816349  	0.03643179  	0.03685459  
2023-05-24 04:08:21.812: [iter 55 : loss : 0.4208 = 0.0055 + 0.4003 + 0.0150, time: 371.937904]
2023-05-24 04:09:10.377: epoch 55:	0.00636011  	0.10196799  	0.04823454  	0.03642061  	0.03685947  
2023-05-24 04:09:10.377: Found a better model.
2023-05-24 04:09:10.377: Save model to file as pretrain.
2023-05-24 04:14:45.813: [iter 56 : loss : 0.4208 = 0.0055 + 0.4003 + 0.0150, time: 332.939412]
2023-05-24 04:15:34.263: epoch 56:	0.00637481  	0.10202651  	0.04836009  	0.03656711  	0.03701531  
2023-05-24 04:15:34.263: Found a better model.
2023-05-24 04:15:34.263: Save model to file as pretrain.
2023-05-24 04:21:22.266: [iter 57 : loss : 0.4207 = 0.0054 + 0.4003 + 0.0150, time: 345.493725]
2023-05-24 04:22:10.326: epoch 57:	0.00638431  	0.10226609  	0.04848360  	0.03669000  	0.03712375  
2023-05-24 04:22:10.326: Found a better model.
2023-05-24 04:22:10.326: Save model to file as pretrain.
2023-05-24 04:27:41.176: [iter 58 : loss : 0.4208 = 0.0055 + 0.4003 + 0.0150, time: 328.326377]
2023-05-24 04:28:29.994: epoch 58:	0.00638784  	0.10231420  	0.04850565  	0.03670502  	0.03712500  
2023-05-24 04:28:29.994: Found a better model.
2023-05-24 04:28:29.994: Save model to file as pretrain.
2023-05-24 04:34:42.769: [iter 59 : loss : 0.4207 = 0.0054 + 0.4003 + 0.0150, time: 370.256571]
2023-05-24 04:35:30.637: epoch 59:	0.00638002  	0.10224885  	0.04842238  	0.03662155  	0.03702713  
2023-05-24 04:41:00.825: [iter 60 : loss : 0.4206 = 0.0054 + 0.4003 + 0.0150, time: 328.701022]
2023-05-24 04:41:49.101: epoch 60:	0.00638859  	0.10238388  	0.04845202  	0.03659137  	0.03702977  
2023-05-24 04:41:49.101: Found a better model.
2023-05-24 04:41:49.101: Save model to file as pretrain.
2023-05-24 04:48:01.861: [iter 61 : loss : 0.4206 = 0.0053 + 0.4003 + 0.0150, time: 370.265589]
2023-05-24 04:48:49.686: epoch 61:	0.00640050  	0.10258506  	0.04853727  	0.03664236  	0.03706574  
2023-05-24 04:48:49.686: Found a better model.
2023-05-24 04:48:49.686: Save model to file as pretrain.
2023-05-24 04:55:04.291: [iter 62 : loss : 0.4207 = 0.0055 + 0.4003 + 0.0150, time: 372.079525]
2023-05-24 04:55:52.003: epoch 62:	0.00641651  	0.10272565  	0.04861474  	0.03671486  	0.03714539  
2023-05-24 04:55:52.003: Found a better model.
2023-05-24 04:55:52.003: Save model to file as pretrain.
2023-05-24 05:01:29.911: [iter 63 : loss : 0.4205 = 0.0052 + 0.4003 + 0.0150, time: 335.421032]
2023-05-24 05:02:18.223: epoch 63:	0.00642488  	0.10294292  	0.04868023  	0.03676607  	0.03719201  
2023-05-24 05:02:18.226: Found a better model.
2023-05-24 05:02:18.226: Save model to file as pretrain.
2023-05-24 05:08:33.205: [iter 64 : loss : 0.4205 = 0.0052 + 0.4003 + 0.0150, time: 372.464916]
2023-05-24 05:09:21.411: epoch 64:	0.00642432  	0.10288006  	0.04876446  	0.03687917  	0.03732442  
2023-05-24 05:14:54.502: [iter 65 : loss : 0.4206 = 0.0053 + 0.4003 + 0.0150, time: 331.590017]
2023-05-24 05:15:42.320: epoch 65:	0.00642898  	0.10302775  	0.04878368  	0.03688372  	0.03732567  
2023-05-24 05:15:42.320: Found a better model.
2023-05-24 05:15:42.320: Save model to file as pretrain.
2023-05-24 05:21:56.848: [iter 66 : loss : 0.4205 = 0.0053 + 0.4003 + 0.0150, time: 372.020133]
2023-05-24 05:22:45.225: epoch 66:	0.00643140  	0.10304401  	0.04878123  	0.03687850  	0.03730775  
2023-05-24 05:22:45.225: Found a better model.
2023-05-24 05:22:45.225: Save model to file as pretrain.
2023-05-24 05:28:17.933: [iter 67 : loss : 0.4205 = 0.0053 + 0.4003 + 0.0150, time: 330.246439]
2023-05-24 05:29:03.537: epoch 67:	0.00643382  	0.10306744  	0.04884330  	0.03692487  	0.03737033  
2023-05-24 05:29:03.537: Found a better model.
2023-05-24 05:29:03.537: Save model to file as pretrain.
2023-05-24 05:34:36.097: [iter 68 : loss : 0.4205 = 0.0053 + 0.4003 + 0.0150, time: 330.008881]
2023-05-24 05:35:24.464: epoch 68:	0.00643624  	0.10314857  	0.04889160  	0.03700381  	0.03742288  
2023-05-24 05:35:24.464: Found a better model.
2023-05-24 05:35:24.465: Save model to file as pretrain.
2023-05-24 05:41:00.886: [iter 69 : loss : 0.4205 = 0.0053 + 0.4003 + 0.0150, time: 333.898803]
2023-05-24 05:41:49.640: epoch 69:	0.00643308  	0.10308633  	0.04888796  	0.03697814  	0.03740782  
2023-05-24 05:47:27.277: [iter 70 : loss : 0.4205 = 0.0052 + 0.4003 + 0.0150, time: 336.121334]
2023-05-24 05:48:15.412: epoch 70:	0.00644945  	0.10337018  	0.04904536  	0.03711571  	0.03753157  
2023-05-24 05:48:15.412: Found a better model.
2023-05-24 05:48:15.412: Save model to file as pretrain.
2023-05-24 05:53:52.558: [iter 71 : loss : 0.4204 = 0.0052 + 0.4003 + 0.0150, time: 334.644398]
2023-05-24 05:54:37.155: epoch 71:	0.00645113  	0.10340853  	0.04907103  	0.03712312  	0.03756822  
2023-05-24 05:54:37.155: Found a better model.
2023-05-24 05:54:37.155: Save model to file as pretrain.
2023-05-24 06:00:14.214: [iter 72 : loss : 0.4205 = 0.0053 + 0.4003 + 0.0150, time: 334.582457]
2023-05-24 06:01:02.668: epoch 72:	0.00644313  	0.10319109  	0.04904266  	0.03714966  	0.03757335  
2023-05-24 06:06:40.585: [iter 73 : loss : 0.4204 = 0.0052 + 0.4003 + 0.0150, time: 336.390758]
2023-05-24 06:07:27.468: epoch 73:	0.00645857  	0.10351588  	0.04912901  	0.03716445  	0.03759682  
2023-05-24 06:07:27.468: Found a better model.
2023-05-24 06:07:27.468: Save model to file as pretrain.
2023-05-24 06:13:06.198: [iter 74 : loss : 0.4205 = 0.0053 + 0.4003 + 0.0150, time: 336.235043]
2023-05-24 06:13:44.769: epoch 74:	0.00647533  	0.10376596  	0.04920063  	0.03721595  	0.03765931  
2023-05-24 06:13:44.771: Found a better model.
2023-05-24 06:13:44.771: Save model to file as pretrain.
2023-05-24 06:19:58.720: [iter 75 : loss : 0.4204 = 0.0052 + 0.4003 + 0.0150, time: 371.534078]
2023-05-24 06:20:46.991: epoch 75:	0.00646603  	0.10362620  	0.04918618  	0.03722207  	0.03767079  
2023-05-24 06:26:24.168: [iter 76 : loss : 0.4204 = 0.0052 + 0.4003 + 0.0149, time: 335.610403]
2023-05-24 06:27:11.430: epoch 76:	0.00646323  	0.10354336  	0.04917932  	0.03723579  	0.03769019  
2023-05-24 06:32:47.404: [iter 77 : loss : 0.4204 = 0.0052 + 0.4003 + 0.0150, time: 334.422145]
2023-05-24 06:33:34.544: epoch 77:	0.00645113  	0.10333482  	0.04907696  	0.03714563  	0.03759161  
2023-05-24 06:39:09.029: [iter 78 : loss : 0.4204 = 0.0052 + 0.4003 + 0.0149, time: 332.943549]
2023-05-24 06:39:55.762: epoch 78:	0.00647533  	0.10374670  	0.04916893  	0.03717925  	0.03761295  
2023-05-24 06:45:29.522: [iter 79 : loss : 0.4204 = 0.0052 + 0.4003 + 0.0149, time: 332.194375]
2023-05-24 06:46:17.815: epoch 79:	0.00647216  	0.10361888  	0.04918643  	0.03721771  	0.03766932  
2023-05-24 06:51:55.698: [iter 80 : loss : 0.4204 = 0.0052 + 0.4003 + 0.0150, time: 336.345619]
2023-05-24 06:52:43.018: epoch 80:	0.00648258  	0.10390357  	0.04924475  	0.03722790  	0.03766710  
2023-05-24 06:52:43.019: Found a better model.
2023-05-24 06:52:43.019: Save model to file as pretrain.
2023-05-24 06:58:16.170: [iter 81 : loss : 0.4203 = 0.0051 + 0.4003 + 0.0150, time: 330.677629]
2023-05-24 06:58:54.334: epoch 81:	0.00648557  	0.10395875  	0.04927946  	0.03727047  	0.03772352  
2023-05-24 06:58:54.334: Found a better model.
2023-05-24 06:58:54.335: Save model to file as pretrain.
2023-05-24 07:05:08.212: [iter 82 : loss : 0.4203 = 0.0051 + 0.4003 + 0.0149, time: 371.481005]
2023-05-24 07:05:55.710: epoch 82:	0.00647682  	0.10380074  	0.04918659  	0.03718124  	0.03762173  
2023-05-24 07:11:28.834: [iter 83 : loss : 0.4204 = 0.0052 + 0.4003 + 0.0149, time: 331.618502]
2023-05-24 07:12:17.740: epoch 83:	0.00648855  	0.10390891  	0.04923880  	0.03720013  	0.03765361  
2023-05-24 07:17:50.845: [iter 84 : loss : 0.4203 = 0.0051 + 0.4003 + 0.0150, time: 331.577123]
2023-05-24 07:18:27.245: epoch 84:	0.00650362  	0.10419393  	0.04943690  	0.03739810  	0.03785676  
2023-05-24 07:18:27.245: Found a better model.
2023-05-24 07:18:27.245: Save model to file as pretrain.
2023-05-24 07:24:41.677: [iter 85 : loss : 0.4203 = 0.0051 + 0.4003 + 0.0149, time: 372.036251]
2023-05-24 07:25:29.778: epoch 85:	0.00649320  	0.10405239  	0.04931558  	0.03727298  	0.03772467  
2023-05-24 07:31:43.895: [iter 86 : loss : 0.4204 = 0.0052 + 0.4003 + 0.0149, time: 372.621053]
2023-05-24 07:32:32.346: epoch 86:	0.00649785  	0.10412543  	0.04940331  	0.03738312  	0.03781375  
2023-05-24 07:38:48.320: [iter 87 : loss : 0.4203 = 0.0051 + 0.4003 + 0.0149, time: 374.442925]
2023-05-24 07:39:36.407: epoch 87:	0.00651013  	0.10418983  	0.04946961  	0.03743200  	0.03787445  
2023-05-24 07:45:15.972: [iter 88 : loss : 0.4203 = 0.0051 + 0.4003 + 0.0149, time: 338.115679]
2023-05-24 07:46:04.351: epoch 88:	0.00652670  	0.10454481  	0.04953284  	0.03741091  	0.03787419  
2023-05-24 07:46:04.360: Found a better model.
2023-05-24 07:46:04.360: Save model to file as pretrain.
2023-05-24 07:51:53.918: [iter 89 : loss : 0.4203 = 0.0051 + 0.4003 + 0.0149, time: 347.030076]
2023-05-24 07:52:37.086: epoch 89:	0.00652037  	0.10439203  	0.04957923  	0.03755032  	0.03800234  
2023-05-24 07:58:15.054: [iter 90 : loss : 0.4202 = 0.0050 + 0.4003 + 0.0149, time: 336.458059]
2023-05-24 07:59:02.968: epoch 90:	0.00652521  	0.10461224  	0.04951634  	0.03743017  	0.03788685  
2023-05-24 07:59:02.968: Found a better model.
2023-05-24 07:59:02.968: Save model to file as pretrain.
2023-05-24 08:04:55.510: [iter 91 : loss : 0.4203 = 0.0051 + 0.4003 + 0.0149, time: 350.084098]
2023-05-24 08:05:42.303: epoch 91:	0.00653638  	0.10469590  	0.04963025  	0.03754511  	0.03799737  
2023-05-24 08:05:42.303: Found a better model.
2023-05-24 08:05:42.303: Save model to file as pretrain.
2023-05-24 08:11:19.331: [iter 92 : loss : 0.4203 = 0.0051 + 0.4003 + 0.0149, time: 334.573925]
2023-05-24 08:12:07.501: epoch 92:	0.00654364  	0.10487836  	0.04958718  	0.03741117  	0.03787383  
2023-05-24 08:12:07.501: Found a better model.
2023-05-24 08:12:07.501: Save model to file as pretrain.
2023-05-24 08:18:23.602: [iter 93 : loss : 0.4203 = 0.0051 + 0.4003 + 0.0149, time: 373.657341]
2023-05-24 08:19:00.468: epoch 93:	0.00653433  	0.10481829  	0.04951486  	0.03733784  	0.03779697  
2023-05-24 08:24:45.757: [iter 94 : loss : 0.4203 = 0.0051 + 0.4002 + 0.0149, time: 343.968200]
2023-05-24 08:25:32.765: epoch 94:	0.00654513  	0.10491131  	0.04965702  	0.03749223  	0.03793817  
2023-05-24 08:25:32.766: Found a better model.
2023-05-24 08:25:32.766: Save model to file as pretrain.
2023-05-24 08:31:05.644: [iter 95 : loss : 0.4203 = 0.0051 + 0.4003 + 0.0149, time: 330.384037]
2023-05-24 08:31:54.347: epoch 95:	0.00656374  	0.10517748  	0.04982273  	0.03765401  	0.03808349  
2023-05-24 08:31:54.347: Found a better model.
2023-05-24 08:31:54.347: Save model to file as pretrain.
2023-05-24 08:37:25.365: [iter 96 : loss : 0.4202 = 0.0051 + 0.4002 + 0.0149, time: 328.551224]
2023-05-24 08:38:12.219: epoch 96:	0.00657268  	0.10538269  	0.04992957  	0.03776932  	0.03821837  
2023-05-24 08:38:12.219: Found a better model.
2023-05-24 08:38:12.219: Save model to file as pretrain.
2023-05-24 08:43:45.116: [iter 97 : loss : 0.4202 = 0.0050 + 0.4003 + 0.0149, time: 330.378620]
2023-05-24 08:44:32.994: epoch 97:	0.00655407  	0.10511528  	0.04983222  	0.03769317  	0.03814000  
2023-05-24 08:50:25.082: [iter 98 : loss : 0.4202 = 0.0050 + 0.4003 + 0.0149, time: 350.587525]
2023-05-24 08:51:13.321: epoch 98:	0.00654829  	0.10494882  	0.04982975  	0.03771280  	0.03816134  
2023-05-24 08:57:29.092: [iter 99 : loss : 0.4202 = 0.0050 + 0.4003 + 0.0149, time: 374.250566]
2023-05-24 08:58:01.199: epoch 99:	0.00654755  	0.10487870  	0.04977361  	0.03765987  	0.03811493  
2023-05-24 09:04:14.541: [iter 100 : loss : 0.4202 = 0.0050 + 0.4003 + 0.0149, time: 372.029011]
2023-05-24 09:05:02.883: epoch 100:	0.00656691  	0.10523406  	0.04993231  	0.03778892  	0.03822688  
2023-05-24 09:10:41.070: [iter 101 : loss : 0.4202 = 0.0051 + 0.4002 + 0.0149, time: 336.654786]
2023-05-24 09:11:29.428: epoch 101:	0.00656988  	0.10528602  	0.04988428  	0.03771976  	0.03816826  
2023-05-24 09:17:03.301: [iter 102 : loss : 0.4202 = 0.0051 + 0.4002 + 0.0149, time: 332.366267]
2023-05-24 09:17:37.587: epoch 102:	0.00657249  	0.10535577  	0.04992324  	0.03776482  	0.03822796  
2023-05-24 09:23:13.557: [iter 103 : loss : 0.4202 = 0.0050 + 0.4003 + 0.0149, time: 334.633285]
2023-05-24 09:24:01.295: epoch 103:	0.00657695  	0.10540551  	0.04998114  	0.03778891  	0.03825509  
2023-05-24 09:24:01.296: Found a better model.
2023-05-24 09:24:01.296: Save model to file as pretrain.
2023-05-24 09:29:40.079: [iter 104 : loss : 0.4202 = 0.0050 + 0.4002 + 0.0149, time: 336.326334]
2023-05-24 09:30:28.154: epoch 104:	0.00656821  	0.10529374  	0.04993489  	0.03778816  	0.03823422  
2023-05-24 09:36:19.028: [iter 105 : loss : 0.4202 = 0.0050 + 0.4002 + 0.0149, time: 349.354064]
2023-05-24 09:37:01.429: epoch 105:	0.00657268  	0.10533290  	0.04994170  	0.03778888  	0.03823985  
2023-05-24 09:42:37.324: [iter 106 : loss : 0.4202 = 0.0050 + 0.4002 + 0.0149, time: 334.563248]
2023-05-24 09:43:24.947: epoch 106:	0.00656914  	0.10527360  	0.04993628  	0.03781190  	0.03827269  
2023-05-24 09:48:56.919: [iter 107 : loss : 0.4202 = 0.0050 + 0.4002 + 0.0149, time: 330.425721]
2023-05-24 09:49:45.344: epoch 107:	0.00658663  	0.10555387  	0.05000331  	0.03777507  	0.03823875  
2023-05-24 09:49:45.344: Found a better model.
2023-05-24 09:49:45.344: Save model to file as pretrain.
2023-05-24 09:56:01.704: [iter 108 : loss : 0.4202 = 0.0051 + 0.4002 + 0.0149, time: 373.917047]
2023-05-24 09:56:39.888: epoch 108:	0.00659408  	0.10555290  	0.04997223  	0.03774633  	0.03820271  
2023-05-24 10:02:39.017: [iter 109 : loss : 0.4202 = 0.0050 + 0.4002 + 0.0149, time: 357.790488]
2023-05-24 10:03:27.255: epoch 109:	0.00658142  	0.10544790  	0.04992019  	0.03766798  	0.03815165  
2023-05-24 10:09:41.159: [iter 110 : loss : 0.4202 = 0.0050 + 0.4002 + 0.0149, time: 372.366989]
2023-05-24 10:10:29.824: epoch 110:	0.00658776  	0.10548569  	0.04996125  	0.03771521  	0.03817366  
2023-05-24 10:16:28.631: [iter 111 : loss : 0.4202 = 0.0051 + 0.4002 + 0.0149, time: 357.293545]
2023-05-24 10:17:16.948: epoch 111:	0.00661102  	0.10598034  	0.05016492  	0.03787114  	0.03835144  
2023-05-24 10:17:16.948: Found a better model.
2023-05-24 10:17:16.948: Save model to file as pretrain.
2023-05-24 10:22:48.185: [iter 112 : loss : 0.4201 = 0.0050 + 0.4002 + 0.0149, time: 328.781594]
2023-05-24 10:23:35.363: epoch 112:	0.00660581  	0.10594413  	0.05011993  	0.03779312  	0.03827025  
2023-05-24 10:29:31.283: [iter 113 : loss : 0.4202 = 0.0050 + 0.4002 + 0.0149, time: 354.411998]
2023-05-24 10:30:18.216: epoch 113:	0.00660358  	0.10587537  	0.05019980  	0.03794122  	0.03842570  
2023-05-24 10:35:52.071: [iter 114 : loss : 0.4201 = 0.0050 + 0.4002 + 0.0149, time: 332.331711]
2023-05-24 10:36:39.759: epoch 114:	0.00661846  	0.10606863  	0.05016407  	0.03783753  	0.03830182  
2023-05-24 10:36:39.759: Found a better model.
2023-05-24 10:36:39.759: Save model to file as pretrain.
2023-05-24 10:42:28.619: [iter 115 : loss : 0.4201 = 0.0050 + 0.4002 + 0.0149, time: 346.364354]
2023-05-24 10:43:13.668: epoch 115:	0.00662145  	0.10617277  	0.05022299  	0.03791168  	0.03835250  
2023-05-24 10:43:13.668: Found a better model.
2023-05-24 10:43:13.668: Save model to file as pretrain.
2023-05-24 10:48:44.813: [iter 116 : loss : 0.4202 = 0.0050 + 0.4002 + 0.0149, time: 328.643274]
2023-05-24 10:49:34.021: epoch 116:	0.00661772  	0.10602943  	0.05014710  	0.03783605  	0.03829350  
2023-05-24 10:55:08.068: [iter 117 : loss : 0.4202 = 0.0051 + 0.4002 + 0.0149, time: 332.531300]
2023-05-24 10:55:57.013: epoch 117:	0.00663485  	0.10628028  	0.05024507  	0.03789485  	0.03834581  
2023-05-24 10:55:57.013: Found a better model.
2023-05-24 10:55:57.013: Save model to file as pretrain.
2023-05-24 11:02:12.541: [iter 118 : loss : 0.4202 = 0.0051 + 0.4002 + 0.0149, time: 373.109182]
2023-05-24 11:02:59.238: epoch 118:	0.00662294  	0.10607512  	0.05024869  	0.03797968  	0.03842761  
2023-05-24 11:09:12.423: [iter 119 : loss : 0.4201 = 0.0050 + 0.4002 + 0.0149, time: 371.715351]
2023-05-24 11:09:59.949: epoch 119:	0.00662629  	0.10615144  	0.05018390  	0.03787572  	0.03833225  
2023-05-24 11:15:36.640: [iter 120 : loss : 0.4202 = 0.0051 + 0.4002 + 0.0149, time: 335.274327]
2023-05-24 11:16:24.047: epoch 120:	0.00662462  	0.10616741  	0.05022104  	0.03790942  	0.03837381  
2023-05-24 11:21:58.618: [iter 121 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0149, time: 333.045783]
2023-05-24 11:22:47.746: epoch 121:	0.00662498  	0.10609176  	0.05018571  	0.03788382  	0.03833020  
2023-05-24 11:28:25.932: [iter 122 : loss : 0.4201 = 0.0050 + 0.4002 + 0.0149, time: 336.675458]
2023-05-24 11:29:14.857: epoch 122:	0.00662722  	0.10610711  	0.05022517  	0.03793826  	0.03839363  
2023-05-24 11:34:51.330: [iter 123 : loss : 0.4201 = 0.0050 + 0.4002 + 0.0149, time: 334.980268]
2023-05-24 11:35:40.362: epoch 123:	0.00662219  	0.10601903  	0.05021724  	0.03795906  	0.03841501  
2023-05-24 11:41:18.997: [iter 124 : loss : 0.4201 = 0.0050 + 0.4002 + 0.0149, time: 337.129319]
2023-05-24 11:41:52.370: epoch 124:	0.00663355  	0.10625760  	0.05035846  	0.03809153  	0.03854004  
2023-05-24 11:47:28.840: [iter 125 : loss : 0.4201 = 0.0049 + 0.4002 + 0.0149, time: 334.968571]
2023-05-24 11:48:17.462: epoch 125:	0.00663653  	0.10627295  	0.05031728  	0.03800648  	0.03846904  
2023-05-24 11:53:55.669: [iter 126 : loss : 0.4201 = 0.0050 + 0.4002 + 0.0149, time: 336.671530]
2023-05-24 11:54:43.317: epoch 126:	0.00663504  	0.10618781  	0.05034311  	0.03809547  	0.03855843  
2023-05-24 12:00:15.341: [iter 127 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0149, time: 330.512789]
2023-05-24 12:01:02.753: epoch 127:	0.00664676  	0.10644407  	0.05042185  	0.03812055  	0.03857998  
2023-05-24 12:01:02.753: Found a better model.
2023-05-24 12:01:02.753: Save model to file as pretrain.
2023-05-24 12:06:36.124: [iter 128 : loss : 0.4201 = 0.0050 + 0.4002 + 0.0149, time: 330.840938]
2023-05-24 12:07:25.240: epoch 128:	0.00664155  	0.10630694  	0.05042156  	0.03816498  	0.03862625  
2023-05-24 12:13:16.671: [iter 129 : loss : 0.4201 = 0.0049 + 0.4002 + 0.0149, time: 349.908905]
2023-05-24 12:14:04.568: epoch 129:	0.00665793  	0.10672975  	0.05050737  	0.03814489  	0.03861558  
2023-05-24 12:14:04.568: Found a better model.
2023-05-24 12:14:04.568: Save model to file as pretrain.
2023-05-24 12:19:39.413: [iter 130 : loss : 0.4201 = 0.0050 + 0.4002 + 0.0149, time: 332.320702]
2023-05-24 12:20:28.065: epoch 130:	0.00665346  	0.10655538  	0.05042968  	0.03808056  	0.03854526  
2023-05-24 12:26:04.135: [iter 131 : loss : 0.4201 = 0.0050 + 0.4002 + 0.0149, time: 334.526966]
2023-05-24 12:26:52.425: epoch 131:	0.00665960  	0.10665414  	0.05050989  	0.03816059  	0.03862917  
2023-05-24 12:32:26.934: [iter 132 : loss : 0.4201 = 0.0049 + 0.4002 + 0.0149, time: 332.917012]
2023-05-24 12:33:13.024: epoch 132:	0.00666463  	0.10678883  	0.05053171  	0.03816365  	0.03863785  
2023-05-24 12:33:13.024: Found a better model.
2023-05-24 12:33:13.024: Save model to file as pretrain.
2023-05-24 12:39:29.874: [iter 133 : loss : 0.4201 = 0.0050 + 0.4002 + 0.0149, time: 374.300887]
2023-05-24 12:40:18.426: epoch 133:	0.00665402  	0.10651203  	0.05046668  	0.03813162  	0.03858659  
2023-05-24 12:46:33.032: [iter 134 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0149, time: 373.038395]
2023-05-24 12:47:21.418: epoch 134:	0.00667059  	0.10682234  	0.05050548  	0.03809286  	0.03855992  
2023-05-24 12:47:21.418: Found a better model.
2023-05-24 12:47:21.418: Save model to file as pretrain.
2023-05-24 12:52:57.976: [iter 135 : loss : 0.4201 = 0.0050 + 0.4002 + 0.0149, time: 334.010738]
2023-05-24 12:53:46.475: epoch 135:	0.00666519  	0.10675592  	0.05049706  	0.03808102  	0.03854116  
2023-05-24 12:59:19.429: [iter 136 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0149, time: 331.388321]
2023-05-24 13:00:07.617: epoch 136:	0.00667841  	0.10698554  	0.05055139  	0.03813543  	0.03857864  
2023-05-24 13:00:07.618: Found a better model.
2023-05-24 13:00:07.618: Save model to file as pretrain.
2023-05-24 13:05:43.203: [iter 137 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0149, time: 333.061359]
2023-05-24 13:06:32.468: epoch 137:	0.00667878  	0.10688610  	0.05059059  	0.03820598  	0.03867188  
2023-05-24 13:12:04.686: [iter 138 : loss : 0.4201 = 0.0050 + 0.4002 + 0.0149, time: 330.668539]
2023-05-24 13:12:37.896: epoch 138:	0.00668511  	0.10701717  	0.05070527  	0.03835837  	0.03882684  
2023-05-24 13:12:37.897: Found a better model.
2023-05-24 13:12:37.897: Save model to file as pretrain.
2023-05-24 13:18:12.145: [iter 139 : loss : 0.4200 = 0.0050 + 0.4002 + 0.0149, time: 331.726753]
2023-05-24 13:19:00.738: epoch 139:	0.00667413  	0.10680944  	0.05069302  	0.03841127  	0.03887259  
2023-05-24 13:24:37.172: [iter 140 : loss : 0.4200 = 0.0050 + 0.4002 + 0.0149, time: 334.859553]
2023-05-24 13:25:24.275: epoch 140:	0.00666352  	0.10666418  	0.05054497  	0.03821125  	0.03867750  
2023-05-24 13:31:02.027: [iter 141 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0149, time: 336.070175]
2023-05-24 13:31:51.409: epoch 141:	0.00667004  	0.10683011  	0.05057330  	0.03821411  	0.03867387  
2023-05-24 13:38:10.228: [iter 142 : loss : 0.4201 = 0.0050 + 0.4002 + 0.0149, time: 377.316558]
2023-05-24 13:39:05.726: epoch 142:	0.00665365  	0.10647053  	0.05047728  	0.03818506  	0.03864799  
2023-05-24 13:45:20.942: [iter 143 : loss : 0.4201 = 0.0050 + 0.4002 + 0.0149, time: 373.700608]
2023-05-24 13:46:08.846: epoch 143:	0.00666036  	0.10661016  	0.05059425  	0.03828498  	0.03875640  
2023-05-24 13:51:45.525: [iter 144 : loss : 0.4201 = 0.0050 + 0.4002 + 0.0149, time: 335.156982]
2023-05-24 13:52:30.676: epoch 144:	0.00666333  	0.10674129  	0.05062598  	0.03832581  	0.03879319  
2023-05-24 13:58:49.878: [iter 145 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0149, time: 377.700968]
2023-05-24 13:59:38.452: epoch 145:	0.00666818  	0.10679185  	0.05063467  	0.03834330  	0.03881269  
2023-05-24 14:05:54.206: [iter 146 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0149, time: 374.317138]
2023-05-24 14:06:41.620: epoch 146:	0.00668809  	0.10714649  	0.05073511  	0.03838110  	0.03885898  
2023-05-24 14:06:41.620: Found a better model.
2023-05-24 14:06:41.620: Save model to file as pretrain.
2023-05-24 14:12:14.867: [iter 147 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0149, time: 330.753660]
2023-05-24 14:12:53.851: epoch 147:	0.00667878  	0.10692388  	0.05064366  	0.03828949  	0.03876387  
2023-05-24 14:18:27.946: [iter 148 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0149, time: 332.774692]
2023-05-24 14:19:16.798: epoch 148:	0.00666631  	0.10682936  	0.05056857  	0.03823085  	0.03869409  
2023-05-24 14:24:52.081: [iter 149 : loss : 0.4200 = 0.0050 + 0.4002 + 0.0149, time: 333.747396]
2023-05-24 14:25:28.179: epoch 149:	0.00667785  	0.10698903  	0.05066594  	0.03827620  	0.03875371  
2023-05-24 14:31:00.868: [iter 150 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0149, time: 331.179720]
2023-05-24 14:31:48.975: epoch 150:	0.00666650  	0.10674423  	0.05062132  	0.03829490  	0.03876682  
2023-05-24 14:38:06.104: [iter 151 : loss : 0.4201 = 0.0050 + 0.4002 + 0.0149, time: 375.608405]
2023-05-24 14:38:53.575: epoch 151:	0.00666724  	0.10672596  	0.05061165  	0.03828603  	0.03874251  
2023-05-24 14:45:11.023: [iter 152 : loss : 0.4201 = 0.0050 + 0.4002 + 0.0149, time: 375.966619]
2023-05-24 14:45:48.751: epoch 152:	0.00666482  	0.10671342  	0.05060149  	0.03826198  	0.03872713  
2023-05-24 14:51:25.350: [iter 153 : loss : 0.4201 = 0.0050 + 0.4002 + 0.0149, time: 335.088202]
2023-05-24 14:52:14.441: epoch 153:	0.00666072  	0.10668396  	0.05060121  	0.03830144  	0.03875606  
2023-05-24 14:57:51.156: [iter 154 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0148, time: 335.178127]
2023-05-24 14:58:39.134: epoch 154:	0.00666985  	0.10672012  	0.05067215  	0.03837233  	0.03881701  
2023-05-24 15:04:55.207: [iter 155 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0148, time: 374.565341]
2023-05-24 15:05:41.012: epoch 155:	0.00668827  	0.10698920  	0.05073941  	0.03840642  	0.03887123  
2023-05-24 15:11:20.200: [iter 156 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0148, time: 337.704256]
2023-05-24 15:12:08.728: epoch 156:	0.00668380  	0.10701621  	0.05074793  	0.03841158  	0.03887878  
2023-05-24 15:17:45.532: [iter 157 : loss : 0.4200 = 0.0050 + 0.4002 + 0.0148, time: 335.293108]
2023-05-24 15:18:34.453: epoch 157:	0.00669051  	0.10718910  	0.05076177  	0.03839890  	0.03885881  
2023-05-24 15:18:34.455: Found a better model.
2023-05-24 15:18:34.455: Save model to file as pretrain.
2023-05-24 15:24:10.732: [iter 158 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0149, time: 333.777769]
2023-05-24 15:24:58.999: epoch 158:	0.00669349  	0.10721017  	0.05075833  	0.03836771  	0.03883633  
2023-05-24 15:24:58.999: Found a better model.
2023-05-24 15:24:59.000: Save model to file as pretrain.
2023-05-24 15:31:19.402: [iter 159 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0149, time: 377.941368]
2023-05-24 15:32:06.901: epoch 159:	0.00669553  	0.10724083  	0.05084702  	0.03848791  	0.03894624  
2023-05-24 15:32:06.901: Found a better model.
2023-05-24 15:32:06.901: Save model to file as pretrain.
2023-05-24 15:38:25.578: [iter 160 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0149, time: 376.147580]
2023-05-24 15:39:13.816: epoch 160:	0.00669666  	0.10736097  	0.05091229  	0.03854315  	0.03900127  
2023-05-24 15:39:13.816: Found a better model.
2023-05-24 15:39:13.816: Save model to file as pretrain.
2023-05-24 15:45:31.982: [iter 161 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0149, time: 375.622637]
2023-05-24 15:46:18.636: epoch 161:	0.00669739  	0.10721221  	0.05086908  	0.03850959  	0.03897242  
2023-05-24 15:52:34.439: [iter 162 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0149, time: 374.294213]
2023-05-24 15:53:22.478: epoch 162:	0.00669665  	0.10716645  	0.05090309  	0.03854557  	0.03902644  
2023-05-24 15:59:40.995: [iter 163 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0149, time: 376.990301]
2023-05-24 16:00:29.518: epoch 163:	0.00668809  	0.10710533  	0.05087181  	0.03851123  	0.03899261  
2023-05-24 16:06:03.670: [iter 164 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0148, time: 332.680188]
2023-05-24 16:06:47.541: epoch 164:	0.00669200  	0.10723194  	0.05087828  	0.03848028  	0.03895443  
2023-05-24 16:12:23.460: [iter 165 : loss : 0.4200 = 0.0050 + 0.4002 + 0.0149, time: 334.584383]
2023-05-24 16:13:11.059: epoch 165:	0.00670876  	0.10749154  	0.05099820  	0.03857374  	0.03904499  
2023-05-24 16:13:11.070: Found a better model.
2023-05-24 16:13:11.070: Save model to file as pretrain.
2023-05-24 16:18:44.200: [iter 166 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0149, time: 330.609029]
2023-05-24 16:19:32.448: epoch 166:	0.00671062  	0.10738318  	0.05100523  	0.03865868  	0.03912441  
2023-05-24 16:25:07.339: [iter 167 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0148, time: 333.409380]
2023-05-24 16:25:56.187: epoch 167:	0.00670782  	0.10747082  	0.05103270  	0.03867003  	0.03912519  
2023-05-24 16:32:13.712: [iter 168 : loss : 0.4201 = 0.0050 + 0.4002 + 0.0148, time: 376.017551]
2023-05-24 16:33:03.317: epoch 168:	0.00671322  	0.10766176  	0.05106286  	0.03870243  	0.03914112  
2023-05-24 16:33:03.317: Found a better model.
2023-05-24 16:33:03.317: Save model to file as pretrain.
2023-05-24 16:38:37.754: [iter 169 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 331.875018]
2023-05-24 16:39:25.234: epoch 169:	0.00670392  	0.10747589  	0.05103089  	0.03868125  	0.03912245  
2023-05-24 16:45:00.151: [iter 170 : loss : 0.4200 = 0.0050 + 0.4002 + 0.0148, time: 333.386423]
2023-05-24 16:45:48.915: epoch 170:	0.00670206  	0.10733300  	0.05098352  	0.03861838  	0.03909605  
2023-05-24 16:51:25.335: [iter 171 : loss : 0.4199 = 0.0048 + 0.4002 + 0.0149, time: 334.947329]
2023-05-24 16:52:14.172: epoch 171:	0.00670559  	0.10745975  	0.05101050  	0.03862638  	0.03909582  
2023-05-24 16:57:40.417: [iter 172 : loss : 0.4200 = 0.0050 + 0.4002 + 0.0148, time: 324.723490]
2023-05-24 16:58:27.611: epoch 172:	0.00670522  	0.10737419  	0.05095112  	0.03857492  	0.03903251  
2023-05-24 17:04:01.176: [iter 173 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 332.057061]
2023-05-24 17:04:48.764: epoch 173:	0.00671006  	0.10744397  	0.05100924  	0.03863103  	0.03909541  
2023-05-24 17:10:20.793: [iter 174 : loss : 0.4200 = 0.0050 + 0.4002 + 0.0148, time: 330.532559]
2023-05-24 17:11:13.169: epoch 174:	0.00670932  	0.10754376  	0.05102061  	0.03861271  	0.03906146  
2023-05-24 17:17:01.151: [iter 175 : loss : 0.4199 = 0.0048 + 0.4002 + 0.0148, time: 346.493047]
2023-05-24 17:17:49.884: epoch 175:	0.00671825  	0.10766267  	0.05112577  	0.03875386  	0.03921440  
2023-05-24 17:17:49.884: Found a better model.
2023-05-24 17:17:49.884: Save model to file as pretrain.
2023-05-24 17:23:27.661: [iter 176 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0148, time: 335.260928]
2023-05-24 17:24:16.483: epoch 176:	0.00672011  	0.10781894  	0.05117052  	0.03878714  	0.03922210  
2023-05-24 17:24:16.492: Found a better model.
2023-05-24 17:24:16.492: Save model to file as pretrain.
2023-05-24 17:30:34.885: [iter 177 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 375.840671]
2023-05-24 17:31:21.157: epoch 177:	0.00672701  	0.10782809  	0.05118001  	0.03877200  	0.03922322  
2023-05-24 17:31:21.158: Found a better model.
2023-05-24 17:31:21.158: Save model to file as pretrain.
2023-05-24 17:37:07.188: [iter 178 : loss : 0.4200 = 0.0050 + 0.4002 + 0.0148, time: 343.470813]
2023-05-24 17:37:55.774: epoch 178:	0.00669945  	0.10740620  	0.05109308  	0.03873581  	0.03920636  
2023-05-24 17:43:32.653: [iter 179 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0148, time: 335.362921]
2023-05-24 17:44:21.295: epoch 179:	0.00671286  	0.10762987  	0.05110130  	0.03870884  	0.03917464  
2023-05-24 17:49:53.829: [iter 180 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0148, time: 331.077690]
2023-05-24 17:50:39.194: epoch 180:	0.00671695  	0.10767820  	0.05107877  	0.03864846  	0.03910195  
2023-05-24 17:56:11.606: [iter 181 : loss : 0.4200 = 0.0050 + 0.4002 + 0.0148, time: 330.907388]
2023-05-24 17:56:59.548: epoch 181:	0.00672755  	0.10767576  	0.05111641  	0.03866013  	0.03913865  
2023-05-24 18:02:32.136: [iter 182 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0148, time: 331.046096]
2023-05-24 18:03:20.801: epoch 182:	0.00672904  	0.10762500  	0.05107905  	0.03861601  	0.03910271  
2023-05-24 18:09:38.160: [iter 183 : loss : 0.4199 = 0.0048 + 0.4002 + 0.0148, time: 375.819853]
2023-05-24 18:10:15.462: epoch 183:	0.00670502  	0.10738944  	0.05101031  	0.03860317  	0.03907293  
2023-05-24 18:15:51.585: [iter 184 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 334.757942]
2023-05-24 18:16:39.455: epoch 184:	0.00672327  	0.10780440  	0.05108827  	0.03862089  	0.03908609  
2023-05-24 18:22:21.064: [iter 185 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 340.101875]
2023-05-24 18:23:10.023: epoch 185:	0.00672401  	0.10778213  	0.05110171  	0.03865156  	0.03911807  
2023-05-24 18:28:46.605: [iter 186 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0148, time: 335.017664]
2023-05-24 18:29:33.854: epoch 186:	0.00673388  	0.10778890  	0.05113867  	0.03872411  	0.03918869  
2023-05-24 18:35:08.488: [iter 187 : loss : 0.4199 = 0.0048 + 0.4002 + 0.0148, time: 333.098695]
2023-05-24 18:35:57.334: epoch 187:	0.00671545  	0.10751113  	0.05104924  	0.03867049  	0.03914111  
2023-05-24 18:41:29.558: [iter 188 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 330.685168]
2023-05-24 18:42:17.406: epoch 188:	0.00675250  	0.10813823  	0.05115048  	0.03865304  	0.03910550  
2023-05-24 18:42:17.406: Found a better model.
2023-05-24 18:42:17.406: Save model to file as pretrain.
2023-05-24 18:47:53.734: [iter 189 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0148, time: 333.757438]
2023-05-24 18:48:42.084: epoch 189:	0.00672495  	0.10776844  	0.05103916  	0.03861430  	0.03907866  
2023-05-24 18:54:20.694: [iter 190 : loss : 0.4199 = 0.0048 + 0.4002 + 0.0148, time: 337.046386]
2023-05-24 18:55:09.496: epoch 190:	0.00672811  	0.10775178  	0.05100518  	0.03854553  	0.03900985  
2023-05-24 19:00:41.648: [iter 191 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 330.575758]
2023-05-24 19:01:15.162: epoch 191:	0.00675454  	0.10819688  	0.05117491  	0.03865642  	0.03910661  
2023-05-24 19:01:15.162: Found a better model.
2023-05-24 19:01:15.163: Save model to file as pretrain.
2023-05-24 19:07:30.417: [iter 192 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 372.795479]
2023-05-24 19:08:19.528: epoch 192:	0.00674654  	0.10812300  	0.05124654  	0.03878771  	0.03923173  
2023-05-24 19:14:34.408: [iter 193 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 373.291296]
2023-05-24 19:15:22.466: epoch 193:	0.00677204  	0.10848164  	0.05134935  	0.03880972  	0.03924951  
2023-05-24 19:15:22.466: Found a better model.
2023-05-24 19:15:22.466: Save model to file as pretrain.
2023-05-24 19:21:40.697: [iter 194 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0148, time: 375.694637]
2023-05-24 19:22:29.463: epoch 194:	0.00674561  	0.10811620  	0.05123850  	0.03876376  	0.03921084  
2023-05-24 19:28:05.818: [iter 195 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 334.864619]
2023-05-24 19:28:40.894: epoch 195:	0.00673518  	0.10789214  	0.05112935  	0.03867142  	0.03913567  
2023-05-24 19:34:14.322: [iter 196 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0148, time: 332.073489]
2023-05-24 19:35:02.301: epoch 196:	0.00673239  	0.10781687  	0.05107115  	0.03861874  	0.03906334  
2023-05-24 19:40:39.166: [iter 197 : loss : 0.4200 = 0.0050 + 0.4002 + 0.0148, time: 335.304694]
2023-05-24 19:41:28.021: epoch 197:	0.00672271  	0.10766501  	0.05102400  	0.03860055  	0.03903742  
2023-05-24 19:47:01.615: [iter 198 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 332.040100]
2023-05-24 19:47:50.012: epoch 198:	0.00672979  	0.10780203  	0.05108079  	0.03860667  	0.03905600  
2023-05-24 19:54:08.694: [iter 199 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 377.125162]
2023-05-24 19:54:57.101: epoch 199:	0.00672402  	0.10775755  	0.05108369  	0.03865055  	0.03909678  
2023-05-24 20:01:12.551: [iter 200 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0148, time: 373.916731]
2023-05-24 20:02:00.798: epoch 200:	0.00673277  	0.10781589  	0.05106577  	0.03863167  	0.03908230  
2023-05-24 20:07:34.396: [iter 201 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0148, time: 332.108013]
2023-05-24 20:08:22.266: epoch 201:	0.00672830  	0.10785050  	0.05113640  	0.03871016  	0.03916442  
2023-05-24 20:14:39.611: [iter 202 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 375.867855]
2023-05-24 20:15:20.079: epoch 202:	0.00673704  	0.10798139  	0.05123752  	0.03880363  	0.03926564  
2023-05-24 20:21:38.228: [iter 203 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0148, time: 376.796646]
2023-05-24 20:22:28.191: epoch 203:	0.00674505  	0.10810054  	0.05125279  	0.03877481  	0.03925200  
2023-05-24 20:28:17.528: [iter 204 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 347.804907]
2023-05-24 20:29:04.311: epoch 204:	0.00673575  	0.10790146  	0.05119983  	0.03876648  	0.03923135  
2023-05-24 20:34:42.482: [iter 205 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 336.633832]
2023-05-24 20:35:29.454: epoch 205:	0.00672923  	0.10786504  	0.05117514  	0.03872908  	0.03918932  
2023-05-24 20:41:07.902: [iter 206 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 336.892460]
2023-05-24 20:42:03.723: epoch 206:	0.00675231  	0.10823806  	0.05130537  	0.03878567  	0.03924926  
2023-05-24 20:47:38.295: [iter 207 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 333.004917]
2023-05-24 20:48:26.845: epoch 207:	0.00674989  	0.10807851  	0.05131109  	0.03880873  	0.03927787  
2023-05-24 20:54:43.496: [iter 208 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 375.156666]
2023-05-24 20:55:31.522: epoch 208:	0.00673667  	0.10785375  	0.05118852  	0.03874565  	0.03923663  
2023-05-24 21:01:07.081: [iter 209 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 334.029877]
2023-05-24 21:01:52.674: epoch 209:	0.00672737  	0.10774137  	0.05110100  	0.03863775  	0.03911003  
2023-05-24 21:08:11.043: [iter 210 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 376.876784]
2023-05-24 21:09:00.106: epoch 210:	0.00675194  	0.10804966  	0.05122273  	0.03871609  	0.03920450  
2023-05-24 21:15:17.201: [iter 211 : loss : 0.4200 = 0.0049 + 0.4002 + 0.0148, time: 375.568899]
2023-05-24 21:16:06.205: epoch 211:	0.00674151  	0.10804674  	0.05126240  	0.03879406  	0.03927221  
2023-05-24 21:22:21.165: [iter 212 : loss : 0.4198 = 0.0048 + 0.4002 + 0.0148, time: 373.490575]
2023-05-24 21:23:09.000: epoch 212:	0.00675436  	0.10816716  	0.05126835  	0.03880606  	0.03927863  
2023-05-24 21:28:47.725: [iter 213 : loss : 0.4199 = 0.0049 + 0.4002 + 0.0148, time: 337.238774]
2023-05-24 21:29:33.650: epoch 213:	0.00674951  	0.10801498  	0.05119468  	0.03870840  	0.03918980  
2023-05-24 21:29:33.650: Early stopping is trigger at epoch: 213
2023-05-24 21:29:33.650: best_result@epoch 193:

2023-05-24 21:29:33.650: Loading from the saved model.
2023-05-24 21:30:17.205: 		0.00677204  	0.10848164  	0.05134935  	0.03880972  	0.03924951  
/home/Thesis/model/general_recommender/SGL.py:136: RuntimeWarning: divide by zero encountered in power
  d_inv = np.power(rowsum, -0.5).flatten()
