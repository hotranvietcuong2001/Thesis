seed= 2021
split and save data...
2023-06-06 15:58:16.041: amazon-book_given_u0_i0
2023-06-06 15:58:16.041: Dataset name: amazon-book
The number of users: 52643
The number of items: 91599
The number of ratings: 2984108
Average actions of users: 56.69
Average actions of items: 32.58
The sparsity of the dataset: 99.938115%
Item degree grouping...
User degree grouping...
Data loading finished
Evaluate model with cpp
2023-06-06 15:58:26.125: Dataset name: amazon-book
The number of users: 52643
The number of items: 91599
The number of ratings: 2984108
Average actions of users: 56.69
Average actions of items: 32.58
The sparsity of the dataset: 99.938115%
2023-06-06 15:58:26.125: 

NeuRec hyperparameters:
recommender=SGL
config_dir=./conf
gpu_id=0
gpu_mem=1.0
data.input.path=dataset
data.input.dataset=amazon-book
data.column.format=UI
data.convert.separator=','
user_min=0
item_min=0
splitter=given
ratio=0.8
by_time=False
metric=["Precision", "Recall", "NDCG", "MAP", "MRR"]
topk=[20]
group_view=None
rec.evaluate.neg=0
test_batch_size=128
num_thread=8
start_testing_epoch=0
proj_path=./

SGL's hyperparameters:
seed=2021
aug_type=2
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.5
ssl_ratio=0.1
ssl_temp=0.2
ssl_mode=both_side
ssl_loss_type=1
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
init_method=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=30
pretrain=0
save_flag=1

Using decoupled loss
2023-06-06 15:58:36.221: metrics:	Precision@20	Recall@20   	NDCG@20     	MAP@20      	MRR@20      
2023-06-06 15:59:12.864: 		0.00012348  	0.00023211  	0.00018509  	0.00041238  	0.00041287  
2023-06-06 16:17:46.930: [iter 1 : loss : 7.0267 = 0.6930 + 6.3336 + 0.0000, time: 1088.932957]
2023-06-06 16:18:17.246: epoch 1:	0.00268436  	0.00565590  	0.00455445  	0.00836517  	0.00896010  
2023-06-06 16:18:17.246: Found a better model.
2023-06-06 16:18:17.246: Save model to file as pretrain.
2023-06-06 16:35:53.350: [iter 2 : loss : 7.0168 = 0.6928 + 6.3240 + 0.0000, time: 1025.839010]
2023-06-06 16:36:23.186: epoch 2:	0.00327996  	0.00726211  	0.00588678  	0.01101970  	0.01174145  
2023-06-06 16:36:23.187: Found a better model.
2023-06-06 16:36:23.187: Save model to file as pretrain.
2023-06-06 16:54:04.764: [iter 3 : loss : 7.0154 = 0.6925 + 6.3229 + 0.0000, time: 1036.240496]
2023-06-06 16:54:35.168: epoch 3:	0.00377296  	0.00833310  	0.00696065  	0.01324677  	0.01435375  
2023-06-06 16:54:35.171: Found a better model.
2023-06-06 16:54:35.171: Save model to file as pretrain.
2023-06-06 17:12:11.657: [iter 4 : loss : 7.0143 = 0.6920 + 6.3223 + 0.0000, time: 1030.911125]
2023-06-06 17:12:41.212: epoch 4:	0.00402277  	0.00913312  	0.00747450  	0.01364522  	0.01495813  
2023-06-06 17:12:41.212: Found a better model.
2023-06-06 17:12:41.212: Save model to file as pretrain.
2023-06-06 17:30:16.515: [iter 5 : loss : 7.0131 = 0.6911 + 6.3220 + 0.0000, time: 1025.280041]
2023-06-06 17:30:45.942: epoch 5:	0.00266536  	0.00636227  	0.00491551  	0.00801460  	0.00872736  
2023-06-06 17:48:23.307: [iter 6 : loss : 7.0109 = 0.6889 + 6.3220 + 0.0000, time: 1033.417636]
2023-06-06 17:48:52.341: epoch 6:	0.00151314  	0.00366542  	0.00282125  	0.00384122  	0.00432043  
2023-06-06 18:06:08.884: [iter 7 : loss : 7.0058 = 0.6831 + 6.3227 + 0.0000, time: 1013.229165]
2023-06-06 18:06:38.006: epoch 7:	0.00223030  	0.00529335  	0.00422970  	0.00617471  	0.00693322  
2023-06-06 18:24:16.319: [iter 8 : loss : 6.9889 = 0.6633 + 6.3255 + 0.0001, time: 1035.020259]
2023-06-06 18:24:45.168: epoch 8:	0.00432766  	0.01063766  	0.00856022  	0.01313496  	0.01465626  
2023-06-06 18:24:45.169: Found a better model.
2023-06-06 18:24:45.169: Save model to file as pretrain.
2023-06-06 18:42:22.254: [iter 9 : loss : 6.9399 = 0.6079 + 6.3317 + 0.0003, time: 1032.598822]
2023-06-06 18:42:51.507: epoch 9:	0.00858466  	0.02058196  	0.01699057  	0.02870217  	0.03171830  
2023-06-06 18:42:51.507: Found a better model.
2023-06-06 18:42:51.507: Save model to file as pretrain.
2023-06-06 19:00:33.011: [iter 10 : loss : 6.8446 = 0.5026 + 6.3413 + 0.0007, time: 1033.162152]
2023-06-06 19:01:02.708: epoch 10:	0.01507702  	0.03567455  	0.02941203  	0.05154512  	0.05693896  
2023-06-06 19:01:02.709: Found a better model.
2023-06-06 19:01:02.709: Save model to file as pretrain.
2023-06-06 19:18:34.257: [iter 11 : loss : 6.7217 = 0.3691 + 6.3513 + 0.0013, time: 1025.570529]
2023-06-06 19:19:04.417: epoch 11:	0.01842191  	0.04334449  	0.03534080  	0.06154303  	0.06817991  
2023-06-06 19:19:04.417: Found a better model.
2023-06-06 19:19:04.417: Save model to file as pretrain.
2023-06-06 19:37:06.292: [iter 12 : loss : 6.6185 = 0.2606 + 6.3559 + 0.0020, time: 1054.990783]
2023-06-06 19:37:36.642: epoch 12:	0.01949224  	0.04622484  	0.03720882  	0.06438912  	0.07104414  
2023-06-06 19:37:36.643: Found a better model.
2023-06-06 19:37:36.643: Save model to file as pretrain.
2023-06-06 19:55:15.523: [iter 13 : loss : 6.5457 = 0.1876 + 6.3554 + 0.0028, time: 1031.528939]
2023-06-06 19:55:44.898: epoch 13:	0.01987802  	0.04756333  	0.03785550  	0.06495801  	0.07162756  
2023-06-06 19:55:44.898: Found a better model.
2023-06-06 19:55:44.898: Save model to file as pretrain.
2023-06-06 20:13:37.132: [iter 14 : loss : 6.4962 = 0.1400 + 6.3526 + 0.0035, time: 1047.386310]
2023-06-06 20:14:07.876: epoch 14:	0.01994451  	0.04784583  	0.03798877  	0.06483711  	0.07176126  
2023-06-06 20:14:07.880: Found a better model.
2023-06-06 20:14:07.880: Save model to file as pretrain.
2023-06-06 20:31:37.302: [iter 15 : loss : 6.4620 = 0.1085 + 6.3494 + 0.0041, time: 1024.950143]
2023-06-06 20:32:05.795: epoch 15:	0.01995210  	0.04804036  	0.03807537  	0.06509396  	0.07192828  
2023-06-06 20:32:05.796: Found a better model.
2023-06-06 20:32:05.796: Save model to file as pretrain.
2023-06-06 20:49:57.983: [iter 16 : loss : 6.4369 = 0.0863 + 6.3459 + 0.0048, time: 1048.063202]
2023-06-06 20:50:26.477: epoch 16:	0.01989032  	0.04806114  	0.03802374  	0.06493323  	0.07178585  
2023-06-06 20:50:26.477: Found a better model.
2023-06-06 20:50:26.477: Save model to file as pretrain.
2023-06-06 21:08:06.072: [iter 17 : loss : 6.4194 = 0.0709 + 6.3431 + 0.0053, time: 1034.703690]
2023-06-06 21:08:36.220: epoch 17:	0.01981997  	0.04789501  	0.03791162  	0.06491240  	0.07158014  
2023-06-06 21:26:33.172: [iter 18 : loss : 6.4063 = 0.0597 + 6.3407 + 0.0059, time: 1053.660476]
2023-06-06 21:27:03.916: epoch 18:	0.01966506  	0.04761558  	0.03767461  	0.06474701  	0.07129873  
2023-06-06 21:44:28.509: [iter 19 : loss : 6.3959 = 0.0510 + 6.3386 + 0.0063, time: 1020.460520]
2023-06-06 21:44:57.570: epoch 19:	0.01960709  	0.04750868  	0.03752448  	0.06442743  	0.07094272  
2023-06-06 22:02:39.123: [iter 20 : loss : 6.3882 = 0.0444 + 6.3369 + 0.0068, time: 1037.123484]
2023-06-06 22:03:08.325: epoch 20:	0.01943036  	0.04703828  	0.03720586  	0.06410893  	0.07056554  
2023-06-06 22:20:53.840: [iter 21 : loss : 6.3820 = 0.0392 + 6.3356 + 0.0072, time: 1040.978876]
2023-06-06 22:21:24.166: epoch 21:	0.01926129  	0.04667507  	0.03686965  	0.06362644  	0.07002134  
2023-06-06 22:39:11.973: [iter 22 : loss : 6.3771 = 0.0351 + 6.3343 + 0.0076, time: 1042.891120]
2023-06-06 22:39:43.813: epoch 22:	0.01907800  	0.04621739  	0.03654381  	0.06321668  	0.06948379  
2023-06-06 22:57:26.018: [iter 23 : loss : 6.3731 = 0.0318 + 6.3333 + 0.0080, time: 1037.761293]
2023-06-06 22:57:55.756: epoch 23:	0.01893268  	0.04584774  	0.03619002  	0.06265625  	0.06877305  
2023-06-06 23:15:33.641: [iter 24 : loss : 6.3699 = 0.0291 + 6.3324 + 0.0083, time: 1033.216638]
2023-06-06 23:16:02.365: epoch 24:	0.01878642  	0.04539921  	0.03592928  	0.06228521  	0.06846171  
2023-06-06 23:33:35.241: [iter 25 : loss : 6.3668 = 0.0266 + 6.3315 + 0.0087, time: 1028.858749]
2023-06-06 23:34:04.401: epoch 25:	0.01853854  	0.04471369  	0.03551185  	0.06196944  	0.06803669  
2023-06-06 23:51:58.123: [iter 26 : loss : 6.3647 = 0.0247 + 6.3310 + 0.0090, time: 1049.536927]
2023-06-06 23:52:26.664: epoch 26:	0.01839513  	0.04435953  	0.03520267  	0.06156379  	0.06744793  
2023-06-07 00:10:03.130: [iter 27 : loss : 6.3628 = 0.0232 + 6.3303 + 0.0092, time: 1032.051798]
2023-06-07 00:10:32.329: epoch 27:	0.01826121  	0.04401779  	0.03494124  	0.06122965  	0.06708034  
2023-06-07 00:28:43.737: [iter 28 : loss : 6.3612 = 0.0218 + 6.3298 + 0.0095, time: 1066.652759]
2023-06-07 00:29:12.655: epoch 28:	0.01806462  	0.04354377  	0.03461953  	0.06089016  	0.06667420  
2023-06-07 00:47:08.455: [iter 29 : loss : 6.3597 = 0.0206 + 6.3293 + 0.0097, time: 1050.831257]
2023-06-07 00:47:37.462: epoch 29:	0.01793924  	0.04314017  	0.03432782  	0.06043596  	0.06625264  
2023-06-07 01:05:26.249: [iter 30 : loss : 6.3585 = 0.0195 + 6.3290 + 0.0100, time: 1044.523325]
2023-06-07 01:05:55.335: epoch 30:	0.01784712  	0.04283484  	0.03412524  	0.06018866  	0.06604494  
2023-06-07 01:23:48.189: [iter 31 : loss : 6.3575 = 0.0188 + 6.3286 + 0.0102, time: 1048.192043]
2023-06-07 01:24:19.003: epoch 31:	0.01765621  	0.04240113  	0.03380892  	0.05979618  	0.06554087  
2023-06-07 01:42:16.212: [iter 32 : loss : 6.3564 = 0.0178 + 6.3282 + 0.0104, time: 1052.960367]
2023-06-07 01:42:44.954: epoch 32:	0.01754319  	0.04209910  	0.03352727  	0.05929720  	0.06497683  
2023-06-07 02:00:50.034: [iter 33 : loss : 6.3556 = 0.0170 + 6.3280 + 0.0106, time: 1061.449603]
2023-06-07 02:01:19.953: epoch 33:	0.01740643  	0.04175673  	0.03327944  	0.05908176  	0.06464867  