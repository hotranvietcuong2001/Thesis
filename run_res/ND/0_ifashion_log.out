seed= 2021
load saved data...
Item degree grouping...
User degree grouping...
Data loading finished
Evaluate model with cpp
2023-06-08 16:51:51.726: Dataset name: ifashion
The number of users: 300000
The number of items: 81614
The number of ratings: 1607813
Average actions of users: 5.36
Average actions of items: 19.70
The sparsity of the dataset: 99.993433%
2023-06-08 16:51:51.726: 

NeuRec hyperparameters:
recommender=SGL
config_dir=./conf
gpu_id=0
gpu_mem=1.0
data.input.path=dataset
data.input.dataset=ifashion
data.column.format=UI
data.convert.separator=','
user_min=0
item_min=0
splitter=given
ratio=0.8
by_time=False
metric=["Precision", "Recall", "NDCG", "MAP", "MRR"]
topk=[20]
group_view=None
rec.evaluate.neg=0
test_batch_size=128
num_thread=8
start_testing_epoch=0
proj_path=./

SGL's hyperparameters:
seed=2021
aug_type=0
reg=1e-3
embed_size=64
n_layers=3
ssl_reg=0.02
ssl_ratio=0.4
ssl_temp=0.5
ssl_mode=both_side
ssl_loss_type=0
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=1024
num_negatives=1
init_method=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=20
pretrain=0
save_flag=1

Using default loss
2023-06-08 16:52:12.633: metrics:	Precision@20	Recall@20   	NDCG@20     	MAP@20      	MRR@20      
2023-06-08 16:53:22.308: 		0.00000651  	0.00010226  	0.00003256  	0.00001556  	0.00001556  
2023-06-08 16:56:30.230: [iter 1 : loss : 1.0031 = 0.5988 + 0.4038 + 0.0006, time: 187.259654]
2023-06-08 16:57:40.470: epoch 1:	0.00244847  	0.03943047  	0.01701793  	0.01207817  	0.01213480  
2023-06-08 16:57:40.470: Found a better model.
2023-06-08 16:57:40.470: Save model to file as pretrain.
2023-06-08 17:00:50.090: [iter 2 : loss : 0.6905 = 0.2633 + 0.4232 + 0.0041, time: 184.745824]
2023-06-08 17:01:49.406: epoch 2:	0.00291331  	0.04681451  	0.02043412  	0.01469721  	0.01477263  
2023-06-08 17:01:49.406: Found a better model.
2023-06-08 17:01:49.406: Save model to file as pretrain.
2023-06-08 17:04:59.256: [iter 3 : loss : 0.5923 = 0.1666 + 0.4195 + 0.0062, time: 184.924891]
2023-06-08 17:06:07.163: epoch 3:	0.00335342  	0.05370868  	0.02358303  	0.01698379  	0.01709145  
2023-06-08 17:06:07.163: Found a better model.
2023-06-08 17:06:07.163: Save model to file as pretrain.
2023-06-08 17:09:17.243: [iter 4 : loss : 0.5458 = 0.1230 + 0.4152 + 0.0076, time: 185.123106]
2023-06-08 17:10:17.662: epoch 4:	0.00370614  	0.05944005  	0.02632450  	0.01906344  	0.01918601  
2023-06-08 17:10:17.663: Found a better model.
2023-06-08 17:10:17.663: Save model to file as pretrain.
2023-06-08 17:13:32.411: [iter 5 : loss : 0.5174 = 0.0964 + 0.4123 + 0.0087, time: 189.618657]
2023-06-08 17:14:40.823: epoch 5:	0.00397798  	0.06391197  	0.02842742  	0.02063170  	0.02076226  
2023-06-08 17:14:40.823: Found a better model.
2023-06-08 17:14:40.823: Save model to file as pretrain.
2023-06-08 17:17:51.641: [iter 6 : loss : 0.4984 = 0.0786 + 0.4101 + 0.0097, time: 186.102246]
2023-06-08 17:18:53.574: epoch 6:	0.00421459  	0.06772267  	0.03027542  	0.02203859  	0.02217916  
2023-06-08 17:18:53.574: Found a better model.
2023-06-08 17:18:53.574: Save model to file as pretrain.
2023-06-08 17:22:06.984: [iter 7 : loss : 0.4842 = 0.0651 + 0.4086 + 0.0105, time: 187.714187]
2023-06-08 17:23:07.582: epoch 7:	0.00442438  	0.07124072  	0.03190431  	0.02323823  	0.02339725  
2023-06-08 17:23:07.583: Found a better model.
2023-06-08 17:23:07.583: Save model to file as pretrain.
2023-06-08 17:26:32.566: [iter 8 : loss : 0.4736 = 0.0550 + 0.4073 + 0.0113, time: 199.718079]
2023-06-08 17:27:40.311: epoch 8:	0.00457293  	0.07369617  	0.03321236  	0.02428538  	0.02445410  
2023-06-08 17:27:40.312: Found a better model.
2023-06-08 17:27:40.312: Save model to file as pretrain.
2023-06-08 17:30:58.553: [iter 9 : loss : 0.4655 = 0.0472 + 0.4062 + 0.0120, time: 193.324229]
2023-06-08 17:31:53.191: epoch 9:	0.00474512  	0.07647534  	0.03453740  	0.02529265  	0.02547750  
2023-06-08 17:31:53.191: Found a better model.
2023-06-08 17:31:53.191: Save model to file as pretrain.
2023-06-08 17:35:11.435: [iter 10 : loss : 0.4588 = 0.0408 + 0.4054 + 0.0126, time: 184.296278]
2023-06-08 17:36:18.708: epoch 10:	0.00488603  	0.07868285  	0.03567832  	0.02618701  	0.02638716  
2023-06-08 17:36:18.709: Found a better model.
2023-06-08 17:36:18.709: Save model to file as pretrain.
2023-06-08 17:39:32.385: [iter 11 : loss : 0.4533 = 0.0354 + 0.4047 + 0.0131, time: 187.842825]
2023-06-08 17:40:32.674: epoch 11:	0.00500815  	0.08074181  	0.03668793  	0.02694375  	0.02715935  
2023-06-08 17:40:32.674: Found a better model.
2023-06-08 17:40:32.674: Save model to file as pretrain.
2023-06-08 17:43:52.087: [iter 12 : loss : 0.4489 = 0.0311 + 0.4041 + 0.0136, time: 191.351390]
2023-06-08 17:44:41.886: epoch 12:	0.00512356  	0.08247292  	0.03765544  	0.02774071  	0.02797726  
2023-06-08 17:44:41.886: Found a better model.
2023-06-08 17:44:41.886: Save model to file as pretrain.
2023-06-08 17:47:55.577: [iter 13 : loss : 0.4452 = 0.0276 + 0.4036 + 0.0140, time: 187.389225]
2023-06-08 17:48:56.860: epoch 13:	0.00523227  	0.08424389  	0.03854983  	0.02845420  	0.02870469  
2023-06-08 17:48:56.860: Found a better model.
2023-06-08 17:48:56.860: Save model to file as pretrain.
2023-06-08 17:52:20.417: [iter 14 : loss : 0.4423 = 0.0248 + 0.4031 + 0.0144, time: 198.325314]
2023-06-08 17:53:27.121: epoch 14:	0.00533875  	0.08592953  	0.03949306  	0.02927013  	0.02953083  
2023-06-08 17:53:27.121: Found a better model.
2023-06-08 17:53:27.121: Save model to file as pretrain.
2023-06-08 17:56:37.889: [iter 15 : loss : 0.4398 = 0.0224 + 0.4027 + 0.0147, time: 185.554071]
2023-06-08 17:57:36.730: epoch 15:	0.00541339  	0.08709540  	0.04011209  	0.02976852  	0.03004428  
2023-06-08 17:57:36.730: Found a better model.
2023-06-08 17:57:36.730: Save model to file as pretrain.
2023-06-08 18:00:46.867: [iter 16 : loss : 0.4372 = 0.0198 + 0.4023 + 0.0150, time: 185.211491]
2023-06-08 18:01:53.561: epoch 16:	0.00549623  	0.08842018  	0.04070928  	0.03019778  	0.03048368  
2023-06-08 18:01:53.561: Found a better model.
2023-06-08 18:01:53.561: Save model to file as pretrain.
2023-06-08 18:05:02.320: [iter 17 : loss : 0.4354 = 0.0182 + 0.4020 + 0.0152, time: 183.262601]
2023-06-08 18:06:21.796: epoch 17:	0.00555114  	0.08924553  	0.04119656  	0.03062614  	0.03090836  
2023-06-08 18:06:21.797: Found a better model.
2023-06-08 18:06:21.797: Save model to file as pretrain.
2023-06-08 18:09:30.467: [iter 18 : loss : 0.4337 = 0.0166 + 0.4018 + 0.0153, time: 183.484550]
2023-06-08 18:10:30.022: epoch 18:	0.00560493  	0.09010217  	0.04171301  	0.03107104  	0.03136024  
2023-06-08 18:10:30.022: Found a better model.
2023-06-08 18:10:30.022: Save model to file as pretrain.
2023-06-08 18:13:42.372: [iter 19 : loss : 0.4321 = 0.0152 + 0.4015 + 0.0155, time: 186.898709]
2023-06-08 18:14:31.103: epoch 19:	0.00566189  	0.09093118  	0.04213437  	0.03138291  	0.03168829  
2023-06-08 18:14:31.104: Found a better model.
2023-06-08 18:14:31.104: Save model to file as pretrain.
2023-06-08 18:17:39.998: [iter 20 : loss : 0.4313 = 0.0145 + 0.4013 + 0.0155, time: 183.413746]
2023-06-08 18:18:39.384: epoch 20:	0.00572890  	0.09187443  	0.04260072  	0.03178009  	0.03208628  
2023-06-08 18:18:39.384: Found a better model.
2023-06-08 18:18:39.384: Save model to file as pretrain.
2023-06-08 18:21:56.047: [iter 21 : loss : 0.4299 = 0.0132 + 0.4011 + 0.0156, time: 191.079315]
2023-06-08 18:22:46.038: epoch 21:	0.00577376  	0.09262910  	0.04303412  	0.03213444  	0.03244126  
2023-06-08 18:22:46.038: Found a better model.
2023-06-08 18:22:46.038: Save model to file as pretrain.
2023-06-08 18:25:56.201: [iter 22 : loss : 0.4290 = 0.0125 + 0.4010 + 0.0156, time: 184.803781]
2023-06-08 18:27:05.151: epoch 22:	0.00580708  	0.09316064  	0.04329130  	0.03234791  	0.03265242  
2023-06-08 18:27:05.151: Found a better model.
2023-06-08 18:27:05.151: Save model to file as pretrain.
2023-06-08 18:30:28.160: [iter 23 : loss : 0.4283 = 0.0119 + 0.4008 + 0.0156, time: 197.716940]
2023-06-08 18:31:36.363: epoch 23:	0.00581974  	0.09319901  	0.04352378  	0.03264636  	0.03296424  
2023-06-08 18:31:36.363: Found a better model.
2023-06-08 18:31:36.363: Save model to file as pretrain.
2023-06-08 18:34:59.934: [iter 24 : loss : 0.4274 = 0.0111 + 0.4007 + 0.0156, time: 197.978021]
2023-06-08 18:36:08.693: epoch 24:	0.00586441  	0.09392762  	0.04387397  	0.03290714  	0.03323687  
2023-06-08 18:36:08.693: Found a better model.
2023-06-08 18:36:08.693: Save model to file as pretrain.
2023-06-08 18:39:21.320: [iter 25 : loss : 0.4267 = 0.0106 + 0.4005 + 0.0156, time: 187.635897]
2023-06-08 18:40:27.845: epoch 25:	0.00588005  	0.09407481  	0.04406704  	0.03313275  	0.03346742  
2023-06-08 18:40:27.845: Found a better model.
2023-06-08 18:40:27.845: Save model to file as pretrain.
2023-06-08 18:43:37.432: [iter 26 : loss : 0.4261 = 0.0102 + 0.4004 + 0.0155, time: 184.207046]
2023-06-08 18:44:46.274: epoch 26:	0.00591392  	0.09461467  	0.04434459  	0.03338098  	0.03369897  
2023-06-08 18:44:46.274: Found a better model.
2023-06-08 18:44:46.274: Save model to file as pretrain.
2023-06-08 18:48:02.296: [iter 27 : loss : 0.4256 = 0.0098 + 0.4003 + 0.0155, time: 191.181273]
2023-06-08 18:48:50.436: epoch 27:	0.00592677  	0.09474874  	0.04448990  	0.03353547  	0.03385524  
2023-06-08 18:48:50.436: Found a better model.
2023-06-08 18:48:50.436: Save model to file as pretrain.
2023-06-08 18:52:13.868: [iter 28 : loss : 0.4250 = 0.0093 + 0.4002 + 0.0154, time: 198.057385]
2023-06-08 18:53:19.312: epoch 28:	0.00595710  	0.09527915  	0.04467938  	0.03362394  	0.03397181  
2023-06-08 18:53:19.313: Found a better model.
2023-06-08 18:53:19.313: Save model to file as pretrain.
2023-06-08 18:56:29.963: [iter 29 : loss : 0.4246 = 0.0090 + 0.4002 + 0.0154, time: 185.214486]
2023-06-08 18:57:28.978: epoch 29:	0.00597367  	0.09552849  	0.04486459  	0.03383924  	0.03416646  
2023-06-08 18:57:28.978: Found a better model.
2023-06-08 18:57:28.978: Save model to file as pretrain.
2023-06-08 19:00:38.867: [iter 30 : loss : 0.4243 = 0.0089 + 0.4001 + 0.0154, time: 184.551155]
2023-06-08 19:01:38.531: epoch 30:	0.00599359  	0.09575403  	0.04501461  	0.03397438  	0.03431403  
2023-06-08 19:01:38.531: Found a better model.
2023-06-08 19:01:38.531: Save model to file as pretrain.
2023-06-08 19:04:47.402: [iter 31 : loss : 0.4239 = 0.0086 + 0.4000 + 0.0153, time: 183.149595]
2023-06-08 19:05:56.784: epoch 31:	0.00601854  	0.09614278  	0.04520557  	0.03410965  	0.03445714  
2023-06-08 19:05:56.784: Found a better model.
2023-06-08 19:05:56.784: Save model to file as pretrain.
2023-06-08 19:09:03.704: [iter 32 : loss : 0.4235 = 0.0083 + 0.3999 + 0.0153, time: 181.992361]
2023-06-08 19:10:12.674: epoch 32:	0.00602356  	0.09614927  	0.04528760  	0.03418247  	0.03454114  
2023-06-08 19:10:12.674: Found a better model.
2023-06-08 19:10:12.674: Save model to file as pretrain.
2023-06-08 19:13:20.304: [iter 33 : loss : 0.4231 = 0.0080 + 0.3999 + 0.0152, time: 182.283531]
2023-06-08 19:14:20.479: epoch 33:	0.00605539  	0.09671808  	0.04552536  	0.03436295  	0.03471363  
2023-06-08 19:14:20.479: Found a better model.
2023-06-08 19:14:20.479: Save model to file as pretrain.
2023-06-08 19:17:29.264: [iter 34 : loss : 0.4229 = 0.0079 + 0.3998 + 0.0152, time: 183.525985]
2023-06-08 19:18:37.945: epoch 34:	0.00606433  	0.09679379  	0.04563665  	0.03449971  	0.03485217  
2023-06-08 19:18:37.945: Found a better model.
2023-06-08 19:18:37.945: Save model to file as pretrain.
2023-06-08 19:22:01.169: [iter 35 : loss : 0.4227 = 0.0077 + 0.3998 + 0.0152, time: 197.883301]
2023-06-08 19:23:10.809: epoch 35:	0.00607512  	0.09690160  	0.04569292  	0.03455352  	0.03490555  
2023-06-08 19:23:10.809: Found a better model.
2023-06-08 19:23:10.809: Save model to file as pretrain.
2023-06-08 19:26:34.083: [iter 36 : loss : 0.4224 = 0.0075 + 0.3997 + 0.0151, time: 197.401811]
2023-06-08 19:27:43.970: epoch 36:	0.00607233  	0.09685680  	0.04576618  	0.03469272  	0.03505636  
2023-06-08 19:31:00.180: [iter 37 : loss : 0.4221 = 0.0073 + 0.3996 + 0.0151, time: 195.532010]
2023-06-08 19:32:09.187: epoch 37:	0.00608350  	0.09708599  	0.04582853  	0.03472115  	0.03508436  
2023-06-08 19:32:09.187: Found a better model.
2023-06-08 19:32:09.187: Save model to file as pretrain.
2023-06-08 19:35:20.697: [iter 38 : loss : 0.4219 = 0.0072 + 0.3996 + 0.0151, time: 186.098958]
2023-06-08 19:36:09.823: epoch 38:	0.00609914  	0.09742236  	0.04592584  	0.03472720  	0.03509704  
2023-06-08 19:36:09.823: Found a better model.
2023-06-08 19:36:09.823: Save model to file as pretrain.
2023-06-08 19:39:32.198: [iter 39 : loss : 0.4217 = 0.0071 + 0.3996 + 0.0151, time: 197.207340]
2023-06-08 19:40:40.803: epoch 39:	0.00609987  	0.09738501  	0.04590248  	0.03468826  	0.03506799  
2023-06-08 19:43:54.300: [iter 40 : loss : 0.4217 = 0.0071 + 0.3996 + 0.0150, time: 192.829175]
2023-06-08 19:44:54.626: epoch 40:	0.00611663  	0.09765384  	0.04596504  	0.03471829  	0.03509960  
2023-06-08 19:44:54.626: Found a better model.
2023-06-08 19:44:54.626: Save model to file as pretrain.
2023-06-08 19:48:06.049: [iter 41 : loss : 0.4216 = 0.0070 + 0.3995 + 0.0150, time: 186.020889]
2023-06-08 19:48:55.867: epoch 41:	0.00612407  	0.09774487  	0.04608627  	0.03487454  	0.03525858  
2023-06-08 19:48:55.867: Found a better model.
2023-06-08 19:48:55.867: Save model to file as pretrain.
2023-06-08 19:52:03.824: [iter 42 : loss : 0.4213 = 0.0068 + 0.3995 + 0.0150, time: 182.585398]
2023-06-08 19:53:04.505: epoch 42:	0.00615125  	0.09807850  	0.04625124  	0.03497009  	0.03535849  
2023-06-08 19:53:04.505: Found a better model.
2023-06-08 19:53:04.505: Save model to file as pretrain.
2023-06-08 19:56:20.537: [iter 43 : loss : 0.4211 = 0.0067 + 0.3994 + 0.0150, time: 190.787012]
2023-06-08 19:57:30.520: epoch 43:	0.00616335  	0.09830119  	0.04632442  	0.03498933  	0.03537878  
2023-06-08 19:57:30.520: Found a better model.
2023-06-08 19:57:30.520: Save model to file as pretrain.
2023-06-08 20:00:39.605: [iter 44 : loss : 0.4211 = 0.0066 + 0.3994 + 0.0150, time: 183.294513]
2023-06-08 20:01:47.342: epoch 44:	0.00617284  	0.09843300  	0.04638945  	0.03503542  	0.03541625  
2023-06-08 20:01:47.342: Found a better model.
2023-06-08 20:01:47.342: Save model to file as pretrain.
2023-06-08 20:05:09.813: [iter 45 : loss : 0.4209 = 0.0065 + 0.3994 + 0.0150, time: 197.659971]
2023-06-08 20:06:09.594: epoch 45:	0.00617564  	0.09852269  	0.04643068  	0.03509449  	0.03546866  
2023-06-08 20:06:09.594: Found a better model.
2023-06-08 20:06:09.594: Save model to file as pretrain.
2023-06-08 20:09:44.665: [iter 46 : loss : 0.4209 = 0.0065 + 0.3994 + 0.0150, time: 209.698388]
2023-06-08 20:11:09.982: epoch 46:	0.00618494  	0.09874442  	0.04651834  	0.03514596  	0.03551675  
2023-06-08 20:11:09.982: Found a better model.
2023-06-08 20:11:09.983: Save model to file as pretrain.
2023-06-08 20:14:35.415: [iter 47 : loss : 0.4209 = 0.0065 + 0.3994 + 0.0150, time: 199.845515]
2023-06-08 20:15:44.908: epoch 47:	0.00619164  	0.09884365  	0.04661063  	0.03523328  	0.03560797  
2023-06-08 20:15:44.908: Found a better model.
2023-06-08 20:15:44.908: Save model to file as pretrain.
2023-06-08 20:19:12.835: [iter 48 : loss : 0.4206 = 0.0062 + 0.3993 + 0.0150, time: 202.217780]
2023-06-08 20:20:33.904: epoch 48:	0.00620616  	0.09912046  	0.04664745  	0.03521201  	0.03560078  
2023-06-08 20:20:33.904: Found a better model.
2023-06-08 20:20:33.904: Save model to file as pretrain.
2023-06-08 20:24:02.701: [iter 49 : loss : 0.4206 = 0.0063 + 0.3993 + 0.0150, time: 203.093993]
2023-06-08 20:25:25.406: epoch 49:	0.00619984  	0.09891675  	0.04659676  	0.03518606  	0.03557226  
2023-06-08 20:28:56.054: [iter 50 : loss : 0.4205 = 0.0062 + 0.3993 + 0.0150, time: 209.806649]
2023-06-08 20:30:14.839: epoch 50:	0.00620207  	0.09897184  	0.04664440  	0.03523561  	0.03562662  
2023-06-08 20:33:46.530: [iter 51 : loss : 0.4204 = 0.0061 + 0.3993 + 0.0150, time: 210.731314]
2023-06-08 20:35:07.798: epoch 51:	0.00620244  	0.09904061  	0.04668084  	0.03526685  	0.03565104  
2023-06-08 20:38:40.217: [iter 52 : loss : 0.4204 = 0.0062 + 0.3993 + 0.0149, time: 211.499649]
2023-06-08 20:40:02.553: epoch 52:	0.00620579  	0.09899016  	0.04670435  	0.03528654  	0.03568050  
2023-06-08 20:43:15.831: [iter 53 : loss : 0.4202 = 0.0060 + 0.3992 + 0.0149, time: 192.391260]
2023-06-08 20:44:38.974: epoch 53:	0.00621678  	0.09917668  	0.04680315  	0.03536369  	0.03577081  
2023-06-08 20:44:38.974: Found a better model.
2023-06-08 20:44:38.974: Save model to file as pretrain.
2023-06-08 20:47:57.772: [iter 54 : loss : 0.4203 = 0.0061 + 0.3992 + 0.0150, time: 193.252031]
2023-06-08 20:49:16.623: epoch 54:	0.00622347  	0.09929692  	0.04688017  	0.03540931  	0.03582561  
2023-06-08 20:49:16.623: Found a better model.
2023-06-08 20:49:16.623: Save model to file as pretrain.
2023-06-08 20:52:39.408: [iter 55 : loss : 0.4202 = 0.0061 + 0.3992 + 0.0149, time: 197.359482]
2023-06-08 20:54:02.695: epoch 55:	0.00621714  	0.09919652  	0.04686065  	0.03542200  	0.03582542  
2023-06-08 20:57:17.519: [iter 56 : loss : 0.4203 = 0.0061 + 0.3992 + 0.0149, time: 193.898191]
2023-06-08 20:58:34.619: epoch 56:	0.00622961  	0.09935470  	0.04693208  	0.03547718  	0.03589150  
2023-06-08 20:58:34.619: Found a better model.
2023-06-08 20:58:34.619: Save model to file as pretrain.
2023-06-08 21:02:11.440: [iter 57 : loss : 0.4200 = 0.0059 + 0.3992 + 0.0149, time: 211.259974]
2023-06-08 21:03:33.426: epoch 57:	0.00624134  	0.09959183  	0.04702524  	0.03554757  	0.03596570  
2023-06-08 21:03:33.426: Found a better model.
2023-06-08 21:03:33.426: Save model to file as pretrain.
2023-06-08 21:06:55.733: [iter 58 : loss : 0.4200 = 0.0059 + 0.3992 + 0.0149, time: 196.394275]
2023-06-08 21:08:17.430: epoch 58:	0.00623929  	0.09959045  	0.04701647  	0.03551703  	0.03594134  
2023-06-08 21:11:30.303: [iter 59 : loss : 0.4199 = 0.0058 + 0.3992 + 0.0149, time: 192.021724]
2023-06-08 21:12:51.109: epoch 59:	0.00625568  	0.09982800  	0.04716257  	0.03565396  	0.03607080  
2023-06-08 21:12:51.109: Found a better model.
2023-06-08 21:12:51.110: Save model to file as pretrain.
2023-06-08 21:16:17.820: [iter 60 : loss : 0.4198 = 0.0057 + 0.3992 + 0.0149, time: 201.181607]
2023-06-08 21:17:42.777: epoch 60:	0.00624879  	0.09978665  	0.04710985  	0.03562752  	0.03602851  
2023-06-08 21:21:13.833: [iter 61 : loss : 0.4198 = 0.0057 + 0.3991 + 0.0149, time: 210.161836]
2023-06-08 21:22:36.400: epoch 61:	0.00626163  	0.09989918  	0.04719039  	0.03569675  	0.03612281  
2023-06-08 21:22:36.400: Found a better model.
2023-06-08 21:22:36.400: Save model to file as pretrain.
2023-06-08 21:25:54.105: [iter 62 : loss : 0.4198 = 0.0057 + 0.3991 + 0.0149, time: 192.030053]
2023-06-08 21:27:10.880: epoch 62:	0.00627950  	0.10029996  	0.04726759  	0.03570980  	0.03611551  
2023-06-08 21:27:10.880: Found a better model.
2023-06-08 21:27:10.880: Save model to file as pretrain.
2023-06-08 21:30:30.399: [iter 63 : loss : 0.4198 = 0.0057 + 0.3991 + 0.0149, time: 193.944730]
2023-06-08 21:31:47.679: epoch 63:	0.00628396  	0.10033596  	0.04734072  	0.03579103  	0.03619171  
2023-06-08 21:31:47.679: Found a better model.
2023-06-08 21:31:47.679: Save model to file as pretrain.
2023-06-08 21:35:10.912: [iter 64 : loss : 0.4197 = 0.0057 + 0.3991 + 0.0149, time: 197.578824]
2023-06-08 21:36:21.694: epoch 64:	0.00627019  	0.10020287  	0.04730728  	0.03571973  	0.03613973  
2023-06-08 21:39:51.510: [iter 65 : loss : 0.4196 = 0.0056 + 0.3991 + 0.0149, time: 208.993357]
2023-06-08 21:41:13.854: epoch 65:	0.00627745  	0.10029213  	0.04735975  	0.03578117  	0.03621714  
2023-06-08 21:44:33.315: [iter 66 : loss : 0.4198 = 0.0057 + 0.3991 + 0.0149, time: 198.520006]
2023-06-08 21:45:44.322: epoch 66:	0.00629998  	0.10061931  	0.04752520  	0.03590718  	0.03633816  
2023-06-08 21:45:44.323: Found a better model.
2023-06-08 21:45:44.323: Save model to file as pretrain.
2023-06-08 21:49:06.169: [iter 67 : loss : 0.4197 = 0.0056 + 0.3991 + 0.0149, time: 196.184317]
2023-06-08 21:50:22.743: epoch 67:	0.00629774  	0.10058631  	0.04751599  	0.03592213  	0.03632961  
2023-06-08 21:53:39.192: [iter 68 : loss : 0.4196 = 0.0056 + 0.3991 + 0.0149, time: 195.613645]
2023-06-08 21:54:56.801: epoch 68:	0.00631580  	0.10093264  	0.04754535  	0.03588119  	0.03628717  
2023-06-08 21:54:56.801: Found a better model.
2023-06-08 21:54:56.801: Save model to file as pretrain.
2023-06-08 21:58:17.564: [iter 69 : loss : 0.4196 = 0.0055 + 0.3991 + 0.0149, time: 195.807555]
2023-06-08 21:59:38.233: epoch 69:	0.00631580  	0.10085800  	0.04758689  	0.03595433  	0.03637041  
2023-06-08 22:03:08.095: [iter 70 : loss : 0.4195 = 0.0055 + 0.3991 + 0.0149, time: 208.997391]
2023-06-08 22:04:29.826: epoch 70:	0.00631877  	0.10081930  	0.04759027  	0.03595578  	0.03637588  
2023-06-08 22:07:45.874: [iter 71 : loss : 0.4195 = 0.0055 + 0.3991 + 0.0149, time: 195.168660]
2023-06-08 22:09:03.216: epoch 71:	0.00632194  	0.10096288  	0.04761603  	0.03594953  	0.03638590  
2023-06-08 22:09:03.217: Found a better model.
2023-06-08 22:09:03.217: Save model to file as pretrain.
2023-06-08 22:12:39.743: [iter 72 : loss : 0.4195 = 0.0055 + 0.3991 + 0.0149, time: 211.172176]
2023-06-08 22:13:57.389: epoch 72:	0.00632920  	0.10111003  	0.04772865  	0.03609009  	0.03650413  
2023-06-08 22:13:57.389: Found a better model.
2023-06-08 22:13:57.389: Save model to file as pretrain.
2023-06-08 22:17:19.392: [iter 73 : loss : 0.4195 = 0.0054 + 0.3991 + 0.0149, time: 196.584012]
2023-06-08 22:18:40.160: epoch 73:	0.00633069  	0.10114688  	0.04768086  	0.03598192  	0.03638852  
2023-06-08 22:18:40.160: Found a better model.
2023-06-08 22:18:40.160: Save model to file as pretrain.
2023-06-08 22:21:58.665: [iter 74 : loss : 0.4194 = 0.0054 + 0.3991 + 0.0149, time: 192.985576]
2023-06-08 22:23:22.024: epoch 74:	0.00633665  	0.10122511  	0.04774100  	0.03601640  	0.03643700  
2023-06-08 22:23:22.024: Found a better model.
2023-06-08 22:23:22.024: Save model to file as pretrain.
2023-06-08 22:26:51.424: [iter 75 : loss : 0.4195 = 0.0055 + 0.3991 + 0.0149, time: 203.651821]
2023-06-08 22:28:14.524: epoch 75:	0.00633701  	0.10123245  	0.04777623  	0.03610221  	0.03652132  
2023-06-08 22:28:14.525: Found a better model.
2023-06-08 22:28:14.525: Save model to file as pretrain.
2023-06-08 22:31:37.852: [iter 76 : loss : 0.4193 = 0.0053 + 0.3991 + 0.0149, time: 197.764249]
2023-06-08 22:33:01.978: epoch 76:	0.00635004  	0.10140461  	0.04785629  	0.03615972  	0.03658692  
2023-06-08 22:33:01.978: Found a better model.
2023-06-08 22:33:01.978: Save model to file as pretrain.
2023-06-08 22:36:39.355: [iter 77 : loss : 0.4193 = 0.0053 + 0.3991 + 0.0149, time: 212.176731]
2023-06-08 22:38:01.847: epoch 77:	0.00634335  	0.10131881  	0.04791881  	0.03629598  	0.03671376  
2023-06-08 22:41:18.102: [iter 78 : loss : 0.4194 = 0.0054 + 0.3990 + 0.0149, time: 195.273349]
2023-06-08 22:42:29.900: epoch 78:	0.00635991  	0.10149376  	0.04796208  	0.03629104  	0.03672686  
2023-06-08 22:42:29.900: Found a better model.
2023-06-08 22:42:29.900: Save model to file as pretrain.
2023-06-08 22:46:06.637: [iter 79 : loss : 0.4193 = 0.0053 + 0.3991 + 0.0149, time: 211.275830]
2023-06-08 22:47:24.023: epoch 79:	0.00636699  	0.10170401  	0.04798608  	0.03624773  	0.03668560  
2023-06-08 22:47:24.024: Found a better model.
2023-06-08 22:47:24.025: Save model to file as pretrain.
2023-06-08 22:50:46.035: [iter 80 : loss : 0.4193 = 0.0053 + 0.3990 + 0.0149, time: 196.570032]
2023-06-08 22:52:02.366: epoch 80:	0.00635526  	0.10152177  	0.04798824  	0.03632285  	0.03675576  
2023-06-08 22:55:18.242: [iter 81 : loss : 0.4193 = 0.0053 + 0.3990 + 0.0149, time: 194.873906]
2023-06-08 22:56:34.984: epoch 81:	0.00636494  	0.10170264  	0.04801434  	0.03630801  	0.03673707  
2023-06-08 22:59:49.270: [iter 82 : loss : 0.4192 = 0.0052 + 0.3990 + 0.0149, time: 193.496107]
2023-06-08 23:01:06.756: epoch 82:	0.00635359  	0.10154365  	0.04799204  	0.03630723  	0.03674990  
2023-06-08 23:04:20.486: [iter 83 : loss : 0.4192 = 0.0052 + 0.3990 + 0.0149, time: 192.852315]
2023-06-08 23:05:43.841: epoch 83:	0.00635080  	0.10150085  	0.04804398  	0.03640827  	0.03682267  
2023-06-08 23:08:58.775: [iter 84 : loss : 0.4193 = 0.0053 + 0.3990 + 0.0149, time: 194.081568]
2023-06-08 23:10:10.332: epoch 84:	0.00637313  	0.10187188  	0.04820191  	0.03649047  	0.03692124  
2023-06-08 23:10:10.332: Found a better model.
2023-06-08 23:10:10.332: Save model to file as pretrain.
2023-06-08 23:13:21.298: [iter 85 : loss : 0.4192 = 0.0052 + 0.3991 + 0.0149, time: 185.782055]
2023-06-08 23:14:49.048: epoch 85:	0.00639230  	0.10210944  	0.04827457  	0.03654491  	0.03698280  
2023-06-08 23:14:49.048: Found a better model.
2023-06-08 23:14:49.048: Save model to file as pretrain.
2023-06-08 23:18:01.178: [iter 86 : loss : 0.4191 = 0.0051 + 0.3990 + 0.0149, time: 186.349989]
2023-06-08 23:19:08.009: epoch 86:	0.00640924  	0.10238472  	0.04837488  	0.03656903  	0.03700956  
2023-06-08 23:19:08.009: Found a better model.
2023-06-08 23:19:08.009: Save model to file as pretrain.
2023-06-08 23:22:16.965: [iter 87 : loss : 0.4192 = 0.0052 + 0.3990 + 0.0149, time: 183.464865]
2023-06-08 23:23:21.657: epoch 87:	0.00639212  	0.10206736  	0.04827267  	0.03653323  	0.03695430  
2023-06-08 23:26:30.376: [iter 88 : loss : 0.4192 = 0.0053 + 0.3990 + 0.0149, time: 188.074634]
2023-06-08 23:27:32.515: epoch 88:	0.00639566  	0.10208799  	0.04831470  	0.03658701  	0.03700758  
2023-06-08 23:30:45.250: [iter 89 : loss : 0.4192 = 0.0052 + 0.3990 + 0.0149, time: 192.103787]
2023-06-08 23:31:59.131: epoch 89:	0.00639212  	0.10205683  	0.04830611  	0.03659529  	0.03702098  
2023-06-08 23:35:13.335: [iter 90 : loss : 0.4192 = 0.0052 + 0.3990 + 0.0149, time: 193.307845]
2023-06-08 23:36:25.800: epoch 90:	0.00640291  	0.10223887  	0.04839390  	0.03665182  	0.03708282  
2023-06-08 23:39:42.731: [iter 91 : loss : 0.4191 = 0.0052 + 0.3990 + 0.0149, time: 196.013407]
2023-06-08 23:41:00.709: epoch 91:	0.00640552  	0.10233004  	0.04844532  	0.03668971  	0.03713693  
2023-06-08 23:44:14.254: [iter 92 : loss : 0.4191 = 0.0052 + 0.3990 + 0.0149, time: 192.640616]
2023-06-08 23:45:28.178: epoch 92:	0.00640217  	0.10216954  	0.04837529  	0.03663000  	0.03706730  
2023-06-08 23:48:42.638: [iter 93 : loss : 0.4191 = 0.0052 + 0.3990 + 0.0149, time: 193.660544]
2023-06-08 23:50:04.885: epoch 93:	0.00639583  	0.10207272  	0.04833700  	0.03660110  	0.03703064  
2023-06-08 23:53:20.718: [iter 94 : loss : 0.4191 = 0.0052 + 0.3990 + 0.0149, time: 194.869008]
2023-06-08 23:54:37.490: epoch 94:	0.00639304  	0.10206653  	0.04832638  	0.03657567  	0.03701793  
2023-06-08 23:57:53.569: [iter 95 : loss : 0.4191 = 0.0051 + 0.3990 + 0.0149, time: 195.223745]
2023-06-08 23:59:09.303: epoch 95:	0.00639956  	0.10227452  	0.04841809  	0.03663363  	0.03707525  
2023-06-09 00:02:23.449: [iter 96 : loss : 0.4190 = 0.0051 + 0.3990 + 0.0149, time: 193.179983]
2023-06-09 00:03:40.313: epoch 96:	0.00640645  	0.10240671  	0.04843488  	0.03661979  	0.03703815  
2023-06-09 00:03:40.314: Found a better model.
2023-06-09 00:03:40.314: Save model to file as pretrain.
2023-06-09 00:07:00.080: [iter 97 : loss : 0.4191 = 0.0051 + 0.3990 + 0.0149, time: 193.884598]
2023-06-09 00:08:11.022: epoch 97:	0.00641873  	0.10256192  	0.04852692  	0.03669961  	0.03712689  
2023-06-09 00:08:11.022: Found a better model.
2023-06-09 00:08:11.022: Save model to file as pretrain.
2023-06-09 00:11:49.432: [iter 98 : loss : 0.4190 = 0.0051 + 0.3990 + 0.0149, time: 212.675115]
2023-06-09 00:13:10.503: epoch 98:	0.00640775  	0.10236533  	0.04843837  	0.03664846  	0.03706554  
2023-06-09 00:16:29.876: [iter 99 : loss : 0.4190 = 0.0051 + 0.3990 + 0.0149, time: 198.477146]
2023-06-09 00:17:51.434: epoch 99:	0.00641427  	0.10250128  	0.04846422  	0.03662687  	0.03706682  
2023-06-09 00:21:21.978: [iter 100 : loss : 0.4190 = 0.0051 + 0.3990 + 0.0149, time: 209.677646]
2023-06-09 00:22:48.437: epoch 100:	0.00643232  	0.10276636  	0.04861311  	0.03680647  	0.03722997  
2023-06-09 00:22:48.437: Found a better model.
2023-06-09 00:22:48.437: Save model to file as pretrain.
2023-06-09 00:26:08.005: [iter 101 : loss : 0.4190 = 0.0051 + 0.3990 + 0.0149, time: 193.808647]
2023-06-09 00:27:28.469: epoch 101:	0.00643418  	0.10274171  	0.04864539  	0.03682727  	0.03726202  
2023-06-09 00:30:43.300: [iter 102 : loss : 0.4191 = 0.0051 + 0.3990 + 0.0149, time: 194.008657]
2023-06-09 00:32:00.166: epoch 102:	0.00644144  	0.10289825  	0.04867815  	0.03683852  	0.03726628  
2023-06-09 00:32:00.166: Found a better model.
2023-06-09 00:32:00.166: Save model to file as pretrain.
2023-06-09 00:35:28.262: [iter 103 : loss : 0.4190 = 0.0050 + 0.3990 + 0.0149, time: 202.173994]
2023-06-09 00:36:50.828: epoch 103:	0.00644070  	0.10293127  	0.04870258  	0.03686893  	0.03729108  
2023-06-09 00:36:50.828: Found a better model.
2023-06-09 00:36:50.829: Save model to file as pretrain.
2023-06-09 00:40:10.841: [iter 104 : loss : 0.4190 = 0.0051 + 0.3990 + 0.0149, time: 194.108715]
2023-06-09 00:41:28.520: epoch 104:	0.00645820  	0.10314476  	0.04871014  	0.03679605  	0.03722932  
2023-06-09 00:41:28.520: Found a better model.
2023-06-09 00:41:28.520: Save model to file as pretrain.
2023-06-09 00:45:08.168: [iter 105 : loss : 0.4189 = 0.0050 + 0.3990 + 0.0149, time: 213.625912]
2023-06-09 00:46:30.683: epoch 105:	0.00647290  	0.10347877  	0.04882382  	0.03685711  	0.03730008  
2023-06-09 00:46:30.683: Found a better model.
2023-06-09 00:46:30.683: Save model to file as pretrain.
2023-06-09 00:49:50.158: [iter 106 : loss : 0.4190 = 0.0051 + 0.3990 + 0.0149, time: 193.547773]
2023-06-09 00:51:11.280: epoch 106:	0.00646602  	0.10334408  	0.04880420  	0.03687298  	0.03731145  
2023-06-09 00:54:42.429: [iter 107 : loss : 0.4189 = 0.0051 + 0.3990 + 0.0149, time: 210.202121]
2023-06-09 00:56:04.166: epoch 107:	0.00646770  	0.10342279  	0.04881826  	0.03688144  	0.03732704  
2023-06-09 00:59:20.051: [iter 108 : loss : 0.4189 = 0.0050 + 0.3990 + 0.0149, time: 194.953872]
2023-06-09 01:00:42.939: epoch 108:	0.00647346  	0.10350396  	0.04885539  	0.03690412  	0.03735333  
2023-06-09 01:00:42.939: Found a better model.
2023-06-09 01:00:42.939: Save model to file as pretrain.
2023-06-09 01:04:13.773: [iter 109 : loss : 0.4189 = 0.0051 + 0.3990 + 0.0149, time: 205.231185]
2023-06-09 01:05:24.633: epoch 109:	0.00645038  	0.10323200  	0.04880482  	0.03688902  	0.03734082  
2023-06-09 01:08:41.509: [iter 110 : loss : 0.4189 = 0.0051 + 0.3990 + 0.0149, time: 195.942559]
2023-06-09 01:09:58.424: epoch 110:	0.00645727  	0.10320728  	0.04883613  	0.03693629  	0.03737916  
2023-06-09 01:13:12.071: [iter 111 : loss : 0.4189 = 0.0051 + 0.3990 + 0.0149, time: 192.777611]
2023-06-09 01:14:29.036: epoch 111:	0.00646806  	0.10341519  	0.04890119  	0.03695403  	0.03738702  
2023-06-09 01:17:46.112: [iter 112 : loss : 0.4189 = 0.0051 + 0.3990 + 0.0149, time: 196.264109]
2023-06-09 01:19:03.121: epoch 112:	0.00646490  	0.10336353  	0.04887807  	0.03695394  	0.03738795  
2023-06-09 01:22:18.394: [iter 113 : loss : 0.4189 = 0.0051 + 0.3990 + 0.0149, time: 194.531027]
2023-06-09 01:23:34.375: epoch 113:	0.00646863  	0.10345580  	0.04895445  	0.03705079  	0.03748544  
2023-06-09 01:26:49.866: [iter 114 : loss : 0.4188 = 0.0050 + 0.3990 + 0.0149, time: 194.548171]
2023-06-09 01:28:08.143: epoch 114:	0.00647868  	0.10361452  	0.04897198  	0.03703090  	0.03746595  
2023-06-09 01:28:08.143: Found a better model.
2023-06-09 01:28:08.143: Save model to file as pretrain.
2023-06-09 01:31:27.259: [iter 115 : loss : 0.4189 = 0.0050 + 0.3990 + 0.0149, time: 193.297731]
2023-06-09 01:32:37.507: epoch 115:	0.00648072  	0.10362337  	0.04890410  	0.03693343  	0.03736788  
2023-06-09 01:32:37.535: Found a better model.
2023-06-09 01:32:37.535: Save model to file as pretrain.
2023-06-09 01:35:56.929: [iter 116 : loss : 0.4189 = 0.0050 + 0.3990 + 0.0149, time: 193.761751]
2023-06-09 01:37:05.904: epoch 116:	0.00647588  	0.10350759  	0.04900910  	0.03712413  	0.03757167  
2023-06-09 01:40:20.749: [iter 117 : loss : 0.4189 = 0.0051 + 0.3989 + 0.0149, time: 194.021132]
2023-06-09 01:41:31.551: epoch 117:	0.00647905  	0.10355665  	0.04898005  	0.03704340  	0.03748529  
2023-06-09 01:44:50.939: [iter 118 : loss : 0.4188 = 0.0049 + 0.3990 + 0.0149, time: 198.571703]
2023-06-09 01:46:02.176: epoch 118:	0.00648203  	0.10362643  	0.04898580  	0.03701426  	0.03745582  
2023-06-09 01:46:02.176: Found a better model.
2023-06-09 01:46:02.176: Save model to file as pretrain.
2023-06-09 01:49:39.752: [iter 119 : loss : 0.4188 = 0.0050 + 0.3990 + 0.0149, time: 211.756577]
2023-06-09 01:50:56.700: epoch 119:	0.00648649  	0.10366460  	0.04901863  	0.03704872  	0.03749778  
2023-06-09 01:50:56.700: Found a better model.
2023-06-09 01:50:56.700: Save model to file as pretrain.
2023-06-09 01:54:33.608: [iter 120 : loss : 0.4188 = 0.0049 + 0.3989 + 0.0149, time: 211.887171]
2023-06-09 01:55:57.479: epoch 120:	0.00648575  	0.10371821  	0.04915392  	0.03726692  	0.03769739  
2023-06-09 01:55:57.480: Found a better model.
2023-06-09 01:55:57.480: Save model to file as pretrain.
2023-06-09 01:59:34.623: [iter 121 : loss : 0.4188 = 0.0050 + 0.3990 + 0.0149, time: 211.619877]
2023-06-09 02:00:57.986: epoch 121:	0.00650976  	0.10401750  	0.04922591  	0.03727888  	0.03772012  
2023-06-09 02:00:57.986: Found a better model.
2023-06-09 02:00:57.986: Save model to file as pretrain.
2023-06-09 02:04:35.168: [iter 122 : loss : 0.4188 = 0.0050 + 0.3990 + 0.0149, time: 211.755994]
2023-06-09 02:05:56.458: epoch 122:	0.00650492  	0.10386058  	0.04915187  	0.03723225  	0.03766387  
2023-06-09 02:09:21.228: [iter 123 : loss : 0.4187 = 0.0049 + 0.3989 + 0.0149, time: 203.762980]
2023-06-09 02:10:37.635: epoch 123:	0.00650474  	0.10395260  	0.04916000  	0.03721015  	0.03765389  
2023-06-09 02:13:52.850: [iter 124 : loss : 0.4189 = 0.0050 + 0.3990 + 0.0149, time: 194.297629]
2023-06-09 02:15:11.550: epoch 124:	0.00652391  	0.10426788  	0.04936414  	0.03737358  	0.03780108  
2023-06-09 02:15:11.551: Found a better model.
2023-06-09 02:15:11.555: Save model to file as pretrain.
2023-06-09 02:18:31.725: [iter 125 : loss : 0.4188 = 0.0050 + 0.3990 + 0.0149, time: 194.585350]
2023-06-09 02:19:48.442: epoch 125:	0.00651814  	0.10410851  	0.04926300  	0.03726855  	0.03770488  
2023-06-09 02:23:03.238: [iter 126 : loss : 0.4188 = 0.0050 + 0.3990 + 0.0149, time: 193.914803]
2023-06-09 02:24:18.689: epoch 126:	0.00652019  	0.10413624  	0.04932525  	0.03737203  	0.03781178  
2023-06-09 02:27:33.861: [iter 127 : loss : 0.4188 = 0.0050 + 0.3989 + 0.0149, time: 194.313404]
2023-06-09 02:28:50.668: epoch 127:	0.00652949  	0.10434265  	0.04940261  	0.03740777  	0.03784684  
2023-06-09 02:28:50.669: Found a better model.
2023-06-09 02:28:50.669: Save model to file as pretrain.
2023-06-09 02:32:11.149: [iter 128 : loss : 0.4188 = 0.0050 + 0.3989 + 0.0149, time: 194.754866]
2023-06-09 02:33:28.784: epoch 128:	0.00652558  	0.10428654  	0.04935622  	0.03735254  	0.03780978  
2023-06-09 02:36:42.442: [iter 129 : loss : 0.4189 = 0.0050 + 0.3990 + 0.0149, time: 192.705791]
2023-06-09 02:37:59.612: epoch 129:	0.00653135  	0.10440055  	0.04944920  	0.03746843  	0.03791302  
2023-06-09 02:37:59.612: Found a better model.
2023-06-09 02:37:59.612: Save model to file as pretrain.
2023-06-09 02:41:23.818: [iter 130 : loss : 0.4188 = 0.0049 + 0.3990 + 0.0149, time: 198.774659]
2023-06-09 02:42:34.731: epoch 130:	0.00654140  	0.10454702  	0.04950650  	0.03751146  	0.03795803  
2023-06-09 02:42:34.732: Found a better model.
2023-06-09 02:42:34.732: Save model to file as pretrain.
2023-06-09 02:45:56.505: [iter 131 : loss : 0.4188 = 0.0049 + 0.3990 + 0.0149, time: 196.001823]
2023-06-09 02:47:07.293: epoch 131:	0.00653378  	0.10444136  	0.04950782  	0.03754430  	0.03800490  
2023-06-09 02:50:21.773: [iter 132 : loss : 0.4187 = 0.0049 + 0.3989 + 0.0149, time: 193.687873]
2023-06-09 02:51:36.817: epoch 132:	0.00653731  	0.10449077  	0.04949639  	0.03752782  	0.03798131  
2023-06-09 02:54:50.345: [iter 133 : loss : 0.4187 = 0.0049 + 0.3990 + 0.0149, time: 192.727102]
2023-06-09 02:56:06.798: epoch 133:	0.00654438  	0.10464767  	0.04957773  	0.03758688  	0.03803739  
2023-06-09 02:56:06.799: Found a better model.
2023-06-09 02:56:06.799: Save model to file as pretrain.
2023-06-09 02:59:36.906: [iter 134 : loss : 0.4188 = 0.0050 + 0.3989 + 0.0149, time: 204.659213]
2023-06-09 03:00:46.676: epoch 134:	0.00653582  	0.10446051  	0.04954106  	0.03756939  	0.03801971  
2023-06-09 03:03:59.447: [iter 135 : loss : 0.4187 = 0.0049 + 0.3989 + 0.0149, time: 191.823717]
2023-06-09 03:05:10.735: epoch 135:	0.00654755  	0.10459949  	0.04956635  	0.03755724  	0.03801420  
2023-06-09 03:08:17.147: [iter 136 : loss : 0.4188 = 0.0050 + 0.3990 + 0.0149, time: 185.538894]
2023-06-09 03:09:26.476: epoch 136:	0.00654680  	0.10452795  	0.04948597  	0.03748113  	0.03794146  
2023-06-09 03:12:32.819: [iter 137 : loss : 0.4187 = 0.0049 + 0.3989 + 0.0149, time: 185.700705]
2023-06-09 03:13:42.609: epoch 137:	0.00655016  	0.10468651  	0.04962196  	0.03764024  	0.03808651  
2023-06-09 03:13:42.610: Found a better model.
2023-06-09 03:13:42.610: Save model to file as pretrain.
2023-06-09 03:16:51.512: [iter 138 : loss : 0.4186 = 0.0048 + 0.3989 + 0.0149, time: 183.291285]
2023-06-09 03:17:52.036: epoch 138:	0.00653862  	0.10441563  	0.04952069  	0.03756552  	0.03801579  
2023-06-09 03:20:56.044: [iter 139 : loss : 0.4186 = 0.0048 + 0.3989 + 0.0149, time: 183.363152]
2023-06-09 03:21:44.687: epoch 139:	0.00654922  	0.10456717  	0.04960852  	0.03764173  	0.03807527  
2023-06-09 03:24:49.745: [iter 140 : loss : 0.4187 = 0.0049 + 0.3989 + 0.0149, time: 184.425023]
2023-06-09 03:25:37.975: epoch 140:	0.00655853  	0.10476895  	0.04967560  	0.03765382  	0.03809160  
2023-06-09 03:25:37.975: Found a better model.
2023-06-09 03:25:37.975: Save model to file as pretrain.
2023-06-09 03:29:02.195: [iter 141 : loss : 0.4188 = 0.0050 + 0.3990 + 0.0149, time: 198.915082]
2023-06-09 03:30:11.149: epoch 141:	0.00655369  	0.10465848  	0.04969111  	0.03768679  	0.03813809  
2023-06-09 03:33:14.474: [iter 142 : loss : 0.4187 = 0.0048 + 0.3990 + 0.0149, time: 182.690110]
2023-06-09 03:34:24.319: epoch 142:	0.00657100  	0.10494253  	0.04977989  	0.03774438  	0.03818431  
2023-06-09 03:34:24.319: Found a better model.
2023-06-09 03:34:24.319: Save model to file as pretrain.
2023-06-09 03:37:41.525: [iter 143 : loss : 0.4186 = 0.0049 + 0.3989 + 0.0149, time: 191.604762]
2023-06-09 03:38:50.674: epoch 143:	0.00655853  	0.10480309  	0.04967561  	0.03761255  	0.03805788  
2023-06-09 03:41:57.858: [iter 144 : loss : 0.4187 = 0.0049 + 0.3989 + 0.0148, time: 186.557258]
2023-06-09 03:42:48.027: epoch 144:	0.00656542  	0.10494708  	0.04962163  	0.03750447  	0.03793606  
2023-06-09 03:42:48.027: Found a better model.
2023-06-09 03:42:48.027: Save model to file as pretrain.
2023-06-09 03:46:11.821: [iter 145 : loss : 0.4188 = 0.0049 + 0.3990 + 0.0149, time: 198.715363]
2023-06-09 03:47:21.220: epoch 145:	0.00655686  	0.10478094  	0.04959665  	0.03751436  	0.03795119  
2023-06-09 03:50:39.497: [iter 146 : loss : 0.4187 = 0.0049 + 0.3990 + 0.0148, time: 197.631017]
2023-06-09 03:51:48.674: epoch 146:	0.00657529  	0.10507515  	0.04974274  	0.03764170  	0.03807890  
2023-06-09 03:51:48.674: Found a better model.
2023-06-09 03:51:48.674: Save model to file as pretrain.
2023-06-09 03:55:12.048: [iter 147 : loss : 0.4186 = 0.0048 + 0.3989 + 0.0148, time: 197.965951]
2023-06-09 03:56:21.263: epoch 147:	0.00657845  	0.10513276  	0.04973140  	0.03759042  	0.03804089  
2023-06-09 03:56:21.263: Found a better model.
2023-06-09 03:56:21.263: Save model to file as pretrain.
2023-06-09 03:59:30.874: [iter 148 : loss : 0.4186 = 0.0048 + 0.3989 + 0.0149, time: 184.299310]
2023-06-09 04:00:20.231: epoch 148:	0.00657324  	0.10499635  	0.04968022  	0.03757245  	0.03800371  
2023-06-09 04:03:25.717: [iter 149 : loss : 0.4187 = 0.0049 + 0.3989 + 0.0149, time: 184.853911]
2023-06-09 04:04:25.991: epoch 149:	0.00657324  	0.10502260  	0.04967946  	0.03753516  	0.03796666  
2023-06-09 04:07:30.678: [iter 150 : loss : 0.4186 = 0.0048 + 0.3990 + 0.0148, time: 184.061031]
2023-06-09 04:08:20.009: epoch 150:	0.00659092  	0.10543735  	0.04985021  	0.03767737  	0.03812313  
2023-06-09 04:08:20.009: Found a better model.
2023-06-09 04:08:20.009: Save model to file as pretrain.
2023-06-09 04:11:43.678: [iter 151 : loss : 0.4186 = 0.0048 + 0.3989 + 0.0148, time: 198.062715]
2023-06-09 04:12:53.088: epoch 151:	0.00658906  	0.10528144  	0.04984928  	0.03771987  	0.03815942  
2023-06-09 04:15:58.538: [iter 152 : loss : 0.4186 = 0.0048 + 0.3990 + 0.0148, time: 184.812619]
2023-06-09 04:16:48.261: epoch 152:	0.00659017  	0.10530223  	0.04988244  	0.03778603  	0.03822483  
2023-06-09 04:20:06.662: [iter 153 : loss : 0.4186 = 0.0048 + 0.3989 + 0.0148, time: 197.734077]
2023-06-09 04:21:15.821: epoch 153:	0.00658962  	0.10533183  	0.04986174  	0.03773884  	0.03818296  
2023-06-09 04:24:21.090: [iter 154 : loss : 0.4187 = 0.0049 + 0.3990 + 0.0148, time: 184.634803]
2023-06-09 04:25:30.394: epoch 154:	0.00659688  	0.10547746  	0.04990102  	0.03772538  	0.03818246  
2023-06-09 04:25:30.394: Found a better model.
2023-06-09 04:25:30.394: Save model to file as pretrain.
2023-06-09 04:28:41.301: [iter 155 : loss : 0.4187 = 0.0049 + 0.3989 + 0.0148, time: 185.492673]
2023-06-09 04:29:31.457: epoch 155:	0.00660805  	0.10558543  	0.04996689  	0.03780168  	0.03825329  
2023-06-09 04:29:31.458: Found a better model.
2023-06-09 04:29:31.458: Save model to file as pretrain.
2023-06-09 04:32:41.528: [iter 156 : loss : 0.4186 = 0.0048 + 0.3989 + 0.0148, time: 184.650773]
2023-06-09 04:33:51.418: epoch 156:	0.00659297  	0.10539963  	0.04992911  	0.03782802  	0.03827225  
2023-06-09 04:36:58.477: [iter 157 : loss : 0.4187 = 0.0049 + 0.3989 + 0.0148, time: 186.415830]
2023-06-09 04:37:46.782: epoch 157:	0.00658962  	0.10532448  	0.04989021  	0.03779900  	0.03825013  
2023-06-09 04:40:49.949: [iter 158 : loss : 0.4187 = 0.0049 + 0.3990 + 0.0148, time: 182.519306]
2023-06-09 04:41:38.462: epoch 158:	0.00660228  	0.10554808  	0.04995582  	0.03782151  	0.03827880  
2023-06-09 04:44:44.136: [iter 159 : loss : 0.4186 = 0.0048 + 0.3989 + 0.0148, time: 185.038105]
2023-06-09 04:45:45.254: epoch 159:	0.00660060  	0.10554016  	0.04991881  	0.03777085  	0.03823021  
2023-06-09 04:48:49.657: [iter 160 : loss : 0.4186 = 0.0049 + 0.3989 + 0.0148, time: 183.771905]
2023-06-09 04:49:38.994: epoch 160:	0.00659762  	0.10544080  	0.04991479  	0.03778685  	0.03822490  
2023-06-09 04:52:55.911: [iter 161 : loss : 0.4187 = 0.0049 + 0.3989 + 0.0148, time: 196.265139]
2023-06-09 04:54:05.059: epoch 161:	0.00661810  	0.10580064  	0.05001961  	0.03783964  	0.03830187  
2023-06-09 04:54:05.059: Found a better model.
2023-06-09 04:54:05.059: Save model to file as pretrain.
2023-06-09 04:57:13.615: [iter 162 : loss : 0.4186 = 0.0049 + 0.3989 + 0.0148, time: 183.508285]
2023-06-09 04:58:13.632: epoch 162:	0.00660451  	0.10550025  	0.04997494  	0.03785143  	0.03829276  
2023-06-09 05:01:17.850: [iter 163 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 183.582475]
2023-06-09 05:02:17.713: epoch 163:	0.00660730  	0.10569947  	0.05000895  	0.03784597  	0.03830231  
2023-06-09 05:05:22.569: [iter 164 : loss : 0.4186 = 0.0049 + 0.3989 + 0.0148, time: 184.205497]
2023-06-09 05:06:23.124: epoch 164:	0.00661400  	0.10575365  	0.05004515  	0.03789654  	0.03834546  
2023-06-09 05:09:26.567: [iter 165 : loss : 0.4186 = 0.0049 + 0.3989 + 0.0148, time: 182.792653]
2023-06-09 05:10:28.800: epoch 165:	0.00660283  	0.10554680  	0.04999364  	0.03787211  	0.03832068  
2023-06-09 05:13:34.006: [iter 166 : loss : 0.4186 = 0.0049 + 0.3989 + 0.0148, time: 184.551737]
2023-06-09 05:14:23.904: epoch 166:	0.00660823  	0.10563572  	0.05002392  	0.03788713  	0.03835178  
2023-06-09 05:17:42.734: [iter 167 : loss : 0.4186 = 0.0048 + 0.3989 + 0.0148, time: 198.194680]
2023-06-09 05:18:43.028: epoch 167:	0.00661512  	0.10564308  	0.05003185  	0.03789064  	0.03834461  
2023-06-09 05:21:49.155: [iter 168 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 185.495956]
2023-06-09 05:22:58.730: epoch 168:	0.00660321  	0.10547529  	0.05006077  	0.03797616  	0.03844189  
2023-06-09 05:26:04.212: [iter 169 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 184.859686]
2023-06-09 05:27:13.543: epoch 169:	0.00661084  	0.10569537  	0.05008023  	0.03794871  	0.03840789  
2023-06-09 05:30:24.863: [iter 170 : loss : 0.4186 = 0.0048 + 0.3989 + 0.0148, time: 190.692859]
2023-06-09 05:31:34.450: epoch 170:	0.00661438  	0.10578014  	0.05007052  	0.03792154  	0.03838788  
2023-06-09 05:34:40.871: [iter 171 : loss : 0.4186 = 0.0048 + 0.3989 + 0.0148, time: 185.793243]
2023-06-09 05:35:50.946: epoch 171:	0.00660395  	0.10566977  	0.05006572  	0.03793827  	0.03840108  
2023-06-09 05:39:10.217: [iter 172 : loss : 0.4185 = 0.0047 + 0.3989 + 0.0148, time: 198.636410]
2023-06-09 05:40:19.530: epoch 172:	0.00661531  	0.10574663  	0.05006865  	0.03794035  	0.03840115  
2023-06-09 05:43:25.339: [iter 173 : loss : 0.4186 = 0.0049 + 0.3989 + 0.0148, time: 185.162228]
2023-06-09 05:44:34.285: epoch 173:	0.00661642  	0.10578171  	0.05010670  	0.03796681  	0.03842972  
2023-06-09 05:47:44.353: [iter 174 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 189.431784]
2023-06-09 05:48:54.357: epoch 174:	0.00661233  	0.10568225  	0.05013208  	0.03802830  	0.03848514  
2023-06-09 05:51:59.309: [iter 175 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 184.310942]
2023-06-09 05:52:49.304: epoch 175:	0.00662256  	0.10583328  	0.05020748  	0.03807220  	0.03854087  
2023-06-09 05:52:49.304: Found a better model.
2023-06-09 05:52:49.304: Save model to file as pretrain.
2023-06-09 05:56:01.740: [iter 176 : loss : 0.4186 = 0.0048 + 0.3989 + 0.0148, time: 189.316357]
2023-06-09 05:57:10.705: epoch 176:	0.00661437  	0.10576833  	0.05012899  	0.03797586  	0.03844133  
2023-06-09 06:00:16.665: [iter 177 : loss : 0.4186 = 0.0048 + 0.3989 + 0.0148, time: 185.308643]
2023-06-09 06:01:25.964: epoch 177:	0.00661549  	0.10578027  	0.05012571  	0.03798264  	0.03844022  
2023-06-09 06:04:31.636: [iter 178 : loss : 0.4186 = 0.0049 + 0.3989 + 0.0148, time: 185.032057]
2023-06-09 06:05:31.871: epoch 178:	0.00662499  	0.10594136  	0.05020791  	0.03804148  	0.03850723  
2023-06-09 06:05:31.871: Found a better model.
2023-06-09 06:05:31.871: Save model to file as pretrain.
2023-06-09 06:08:37.620: [iter 179 : loss : 0.4186 = 0.0048 + 0.3990 + 0.0148, time: 184.051468]
2023-06-09 06:09:38.238: epoch 179:	0.00662332  	0.10589869  	0.05019370  	0.03803545  	0.03849618  
2023-06-09 06:12:43.247: [iter 180 : loss : 0.4185 = 0.0048 + 0.3990 + 0.0148, time: 184.368621]
2023-06-09 06:13:44.073: epoch 180:	0.00661922  	0.10588413  	0.05008021  	0.03793533  	0.03837650  
2023-06-09 06:16:47.861: [iter 181 : loss : 0.4186 = 0.0048 + 0.3990 + 0.0148, time: 183.145669]
2023-06-09 06:17:48.673: epoch 181:	0.00662480  	0.10600419  	0.05015797  	0.03799752  	0.03844334  
2023-06-09 06:17:48.674: Found a better model.
2023-06-09 06:17:48.674: Save model to file as pretrain.
2023-06-09 06:20:54.694: [iter 182 : loss : 0.4185 = 0.0048 + 0.3990 + 0.0148, time: 184.346336]
2023-06-09 06:21:55.169: epoch 182:	0.00663094  	0.10603216  	0.05019539  	0.03798735  	0.03844202  
2023-06-09 06:21:55.169: Found a better model.
2023-06-09 06:21:55.169: Save model to file as pretrain.
2023-06-09 06:25:01.962: [iter 183 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 185.124988]
2023-06-09 06:26:11.358: epoch 183:	0.00662833  	0.10591426  	0.05008217  	0.03787463  	0.03833012  
2023-06-09 06:29:30.457: [iter 184 : loss : 0.4185 = 0.0047 + 0.3989 + 0.0148, time: 198.460580]
2023-06-09 06:30:40.500: epoch 184:	0.00663392  	0.10613061  	0.05020152  	0.03798038  	0.03843585  
2023-06-09 06:30:40.500: Found a better model.
2023-06-09 06:30:40.500: Save model to file as pretrain.
2023-06-09 06:33:54.065: [iter 185 : loss : 0.4185 = 0.0047 + 0.3990 + 0.0148, time: 191.330110]
2023-06-09 06:34:43.823: epoch 185:	0.00663038  	0.10599131  	0.05016394  	0.03795163  	0.03841332  
2023-06-09 06:37:50.310: [iter 186 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 185.856330]
2023-06-09 06:38:49.947: epoch 186:	0.00663243  	0.10604856  	0.05019549  	0.03798989  	0.03845412  
2023-06-09 06:41:54.005: [iter 187 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 183.425931]
2023-06-09 06:42:54.414: epoch 187:	0.00663466  	0.10608295  	0.05020478  	0.03796589  	0.03842924  
2023-06-09 06:46:00.206: [iter 188 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 185.156461]
2023-06-09 06:46:59.903: epoch 188:	0.00663466  	0.10598240  	0.05017015  	0.03794539  	0.03841547  
2023-06-09 06:50:06.001: [iter 189 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 185.458484]
2023-06-09 06:50:54.462: epoch 189:	0.00664546  	0.10626326  	0.05020338  	0.03790401  	0.03838044  
2023-06-09 06:50:54.462: Found a better model.
2023-06-09 06:50:54.462: Save model to file as pretrain.
2023-06-09 06:54:00.892: [iter 190 : loss : 0.4186 = 0.0048 + 0.3989 + 0.0148, time: 184.782067]
2023-06-09 06:55:01.620: epoch 190:	0.00663782  	0.10613243  	0.05017423  	0.03789887  	0.03837531  
2023-06-09 06:58:07.754: [iter 191 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 185.500546]
2023-06-09 06:59:07.517: epoch 191:	0.00663392  	0.10608208  	0.05020750  	0.03798281  	0.03845092  
2023-06-09 07:02:11.748: [iter 192 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 183.594067]
2023-06-09 07:03:11.376: epoch 192:	0.00664081  	0.10620575  	0.05024402  	0.03798218  	0.03845489  
2023-06-09 07:06:13.996: [iter 193 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 181.970374]
2023-06-09 07:07:14.799: epoch 193:	0.00664063  	0.10624311  	0.05021533  	0.03793759  	0.03839461  
2023-06-09 07:10:27.993: [iter 194 : loss : 0.4185 = 0.0047 + 0.3989 + 0.0148, time: 192.558131]
2023-06-09 07:11:16.213: epoch 194:	0.00664285  	0.10617678  	0.05020900  	0.03794383  	0.03841276  
2023-06-09 07:14:22.500: [iter 195 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 185.647899]
2023-06-09 07:15:10.727: epoch 195:	0.00663932  	0.10619843  	0.05022376  	0.03794586  	0.03841590  
2023-06-09 07:18:17.055: [iter 196 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 185.701901]
2023-06-09 07:19:04.935: epoch 196:	0.00664546  	0.10631758  	0.05021634  	0.03791647  	0.03838367  
2023-06-09 07:19:04.935: Found a better model.
2023-06-09 07:19:04.935: Save model to file as pretrain.
2023-06-09 07:22:10.425: [iter 197 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0148, time: 183.873419]
2023-06-09 07:23:19.866: epoch 197:	0.00665663  	0.10650556  	0.05037850  	0.03809374  	0.03856996  
2023-06-09 07:23:19.866: Found a better model.
2023-06-09 07:23:19.866: Save model to file as pretrain.
2023-06-09 07:26:28.541: [iter 198 : loss : 0.4185 = 0.0048 + 0.3990 + 0.0148, time: 186.996679]
2023-06-09 07:27:17.271: epoch 198:	0.00665402  	0.10647868  	0.05039550  	0.03813088  	0.03859848  
2023-06-09 07:30:23.205: [iter 199 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 185.300376]
2023-06-09 07:31:11.540: epoch 199:	0.00666128  	0.10653590  	0.05037740  	0.03806808  	0.03853780  
2023-06-09 07:31:11.541: Found a better model.
2023-06-09 07:31:11.541: Save model to file as pretrain.
2023-06-09 07:34:19.162: [iter 200 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0148, time: 186.017359]
2023-06-09 07:35:18.441: epoch 200:	0.00667245  	0.10665286  	0.05038577  	0.03804255  	0.03850957  
2023-06-09 07:35:18.441: Found a better model.
2023-06-09 07:35:18.442: Save model to file as pretrain.
2023-06-09 07:38:24.453: [iter 201 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 184.372724]
2023-06-09 07:39:13.687: epoch 201:	0.00666836  	0.10661827  	0.05038416  	0.03803390  	0.03851528  
2023-06-09 07:42:17.402: [iter 202 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 183.083472]
2023-06-09 07:43:05.956: epoch 202:	0.00667487  	0.10675374  	0.05038315  	0.03799994  	0.03848264  
2023-06-09 07:43:05.956: Found a better model.
2023-06-09 07:43:05.956: Save model to file as pretrain.
2023-06-09 07:46:26.307: [iter 203 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 198.751690]
2023-06-09 07:47:35.946: epoch 203:	0.00667469  	0.10678273  	0.05038933  	0.03799200  	0.03847063  
2023-06-09 07:47:35.946: Found a better model.
2023-06-09 07:47:35.947: Save model to file as pretrain.
2023-06-09 07:50:55.288: [iter 204 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0148, time: 197.701741]
2023-06-09 07:52:04.943: epoch 204:	0.00665904  	0.10654365  	0.05037070  	0.03803299  	0.03851025  
2023-06-09 07:55:07.065: [iter 205 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 181.468849]
2023-06-09 07:56:15.142: epoch 205:	0.00665700  	0.10652640  	0.05035798  	0.03804773  	0.03851839  
2023-06-09 07:59:20.448: [iter 206 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 184.632894]
2023-06-09 08:00:21.112: epoch 206:	0.00666296  	0.10665919  	0.05039319  	0.03804749  	0.03851993  
2023-06-09 08:03:24.798: [iter 207 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0148, time: 183.037692]
2023-06-09 08:04:34.216: epoch 207:	0.00667692  	0.10685307  	0.05044656  	0.03807801  	0.03854030  
2023-06-09 08:04:34.216: Found a better model.
2023-06-09 08:04:34.216: Save model to file as pretrain.
2023-06-09 08:07:42.125: [iter 208 : loss : 0.4184 = 0.0048 + 0.3989 + 0.0148, time: 186.225026]
2023-06-09 08:08:31.737: epoch 208:	0.00667487  	0.10674492  	0.05046962  	0.03811032  	0.03858567  
2023-06-09 08:11:36.808: [iter 209 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 184.418014]
2023-06-09 08:12:37.213: epoch 209:	0.00666762  	0.10676239  	0.05052862  	0.03821248  	0.03867785  
2023-06-09 08:15:40.849: [iter 210 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0148, time: 182.987612]
2023-06-09 08:16:41.062: epoch 210:	0.00667860  	0.10690221  	0.05049023  	0.03809972  	0.03855196  
2023-06-09 08:16:41.064: Found a better model.
2023-06-09 08:16:41.064: Save model to file as pretrain.
2023-06-09 08:19:46.403: [iter 211 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0148, time: 183.233750]
2023-06-09 08:20:55.850: epoch 211:	0.00669069  	0.10706556  	0.05050747  	0.03806315  	0.03852332  
2023-06-09 08:20:55.850: Found a better model.
2023-06-09 08:20:55.850: Save model to file as pretrain.
2023-06-09 08:24:08.786: [iter 212 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 191.167216]
2023-06-09 08:25:17.838: epoch 212:	0.00667059  	0.10682201  	0.05048561  	0.03810364  	0.03856501  
2023-06-09 08:28:22.845: [iter 213 : loss : 0.4184 = 0.0048 + 0.3989 + 0.0148, time: 184.346849]
2023-06-09 08:29:32.251: epoch 213:	0.00666352  	0.10664406  	0.05036637  	0.03802387  	0.03848724  
2023-06-09 08:32:50.781: [iter 214 : loss : 0.4184 = 0.0048 + 0.3989 + 0.0148, time: 197.899166]
2023-06-09 08:34:00.088: epoch 214:	0.00667785  	0.10688781  	0.05047391  	0.03808311  	0.03854082  
2023-06-09 08:37:05.099: [iter 215 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0148, time: 184.364289]
2023-06-09 08:38:14.929: epoch 215:	0.00667934  	0.10693697  	0.05053280  	0.03816674  	0.03861814  
2023-06-09 08:41:33.847: [iter 216 : loss : 0.4184 = 0.0048 + 0.3989 + 0.0148, time: 198.270359]
2023-06-09 08:42:43.084: epoch 216:	0.00667953  	0.10685488  	0.05049277  	0.03813848  	0.03859055  
2023-06-09 08:45:49.718: [iter 217 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 185.995717]
2023-06-09 08:46:49.348: epoch 217:	0.00666649  	0.10665661  	0.05045901  	0.03811895  	0.03858772  
2023-06-09 08:49:52.428: [iter 218 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 182.413849]
2023-06-09 08:50:52.797: epoch 218:	0.00667320  	0.10681190  	0.05048893  	0.03812082  	0.03858363  
2023-06-09 08:53:58.893: [iter 219 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0148, time: 185.438280]
2023-06-09 08:54:47.511: epoch 219:	0.00666835  	0.10671275  	0.05046623  	0.03811928  	0.03858384  
2023-06-09 08:57:53.696: [iter 220 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0148, time: 185.541015]
2023-06-09 08:59:03.131: epoch 220:	0.00666854  	0.10663175  	0.05043877  	0.03808149  	0.03853937  
2023-06-09 09:02:21.112: [iter 221 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0148, time: 197.346530]
2023-06-09 09:03:30.401: epoch 221:	0.00668027  	0.10684103  	0.05053793  	0.03816891  	0.03862855  
2023-06-09 09:06:35.296: [iter 222 : loss : 0.4184 = 0.0048 + 0.3989 + 0.0148, time: 184.270496]
2023-06-09 09:07:36.046: epoch 222:	0.00668362  	0.10686497  	0.05054239  	0.03814486  	0.03860736  
2023-06-09 09:10:42.202: [iter 223 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0148, time: 185.506558]
2023-06-09 09:11:30.985: epoch 223:	0.00667580  	0.10674935  	0.05063687  	0.03833805  	0.03880275  
2023-06-09 09:14:36.939: [iter 224 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 185.321453]
2023-06-09 09:15:25.430: epoch 224:	0.00666500  	0.10662714  	0.05047743  	0.03813998  	0.03859997  
2023-06-09 09:18:36.592: [iter 225 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 190.526567]
2023-06-09 09:19:25.400: epoch 225:	0.00667375  	0.10673968  	0.05059376  	0.03825966  	0.03873508  
2023-06-09 09:22:31.643: [iter 226 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0148, time: 185.603688]
2023-06-09 09:23:19.571: epoch 226:	0.00668361  	0.10690823  	0.05065717  	0.03829733  	0.03878103  
2023-06-09 09:26:25.353: [iter 227 : loss : 0.4185 = 0.0048 + 0.3989 + 0.0148, time: 185.150557]
2023-06-09 09:27:25.947: epoch 227:	0.00666425  	0.10660690  	0.05055268  	0.03825255  	0.03872215  
2023-06-09 09:30:31.312: [iter 228 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0148, time: 184.739249]
2023-06-09 09:31:19.938: epoch 228:	0.00668027  	0.10684829  	0.05060690  	0.03825413  	0.03873563  
2023-06-09 09:34:24.386: [iter 229 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0147, time: 183.816254]
2023-06-09 09:35:25.103: epoch 229:	0.00668455  	0.10680510  	0.05063860  	0.03829826  	0.03877188  
2023-06-09 09:38:29.064: [iter 230 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0148, time: 183.334544]
2023-06-09 09:39:30.277: epoch 230:	0.00669274  	0.10697741  	0.05072045  	0.03839556  	0.03885945  
2023-06-09 09:42:33.852: [iter 231 : loss : 0.4184 = 0.0047 + 0.3989 + 0.0148, time: 182.947632]
2023-06-09 09:43:34.105: epoch 231:	0.00666742  	0.10654894  	0.05055790  	0.03829497  	0.03874927  
2023-06-09 09:43:34.105: Early stopping is triggered at epoch: 231
2023-06-09 09:43:34.105: best_result@epoch 211:

2023-06-09 09:43:34.105: Loading from the saved model.
2023-06-09 09:44:34.415: 		0.00669069  	0.10706556  	0.05050747  	0.03806315  	0.03852332  
/home/Thesis/model/general_recommender/SGL.py:146: RuntimeWarning: divide by zero encountered in power
  d_inv = np.power(rowsum, -0.5).flatten()
