seed= 2021
load saved data...
Item degree grouping...
User degree grouping...
Data loading finished
Evaluate model with cpp
2023-06-07 21:10:49.337: Dataset name: ifashion
The number of users: 300000
The number of items: 81614
The number of ratings: 1607813
Average actions of users: 5.36
Average actions of items: 19.70
The sparsity of the dataset: 99.993433%
2023-06-07 21:10:49.337: 

NeuRec hyperparameters:
recommender=SGL
config_dir=./conf
gpu_id=0
gpu_mem=1.0
data.input.path=dataset
data.input.dataset=ifashion
data.column.format=UI
data.convert.separator=','
user_min=0
item_min=0
splitter=given
ratio=0.8
by_time=False
metric=["Precision", "Recall", "NDCG", "MAP", "MRR"]
topk=[20]
group_view=None
rec.evaluate.neg=0
test_batch_size=128
num_thread=8
start_testing_epoch=0
proj_path=./

SGL's hyperparameters:
seed=2021
aug_type=0
reg=1e-3
embed_size=64
n_layers=3
ssl_reg=0.02
ssl_ratio=0.4
ssl_temp=0.5
ssl_mode=both_side
ssl_loss_type=2
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=1024
num_negatives=1
init_method=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=20
pretrain=0
save_flag=1

Using debiased loss
2023-06-07 21:11:10.066: metrics:	Precision@20	Recall@20   	NDCG@20     	MAP@20      	MRR@20      
2023-06-07 21:12:03.756: 		0.00000558  	0.00008412  	0.00002601  	0.00001163  	0.00001163  
2023-06-07 21:15:04.434: [iter 1 : loss : 1.0078 = 0.6035 + 0.4038 + 0.0005, time: 180.018609]
2023-06-07 21:15:58.083: epoch 1:	0.00245387  	0.03951123  	0.01698997  	0.01201233  	0.01206543  
2023-06-07 21:15:58.092: Found a better model.
2023-06-07 21:15:58.092: Save model to file as pretrain.
2023-06-07 21:19:02.378: [iter 2 : loss : 0.6931 = 0.2655 + 0.4236 + 0.0040, time: 179.164145]
2023-06-07 21:19:54.942: epoch 2:	0.00288784  	0.04633290  	0.02027571  	0.01461256  	0.01469318  
2023-06-07 21:19:54.944: Found a better model.
2023-06-07 21:19:54.944: Save model to file as pretrain.
2023-06-07 21:23:12.258: [iter 3 : loss : 0.5943 = 0.1680 + 0.4201 + 0.0062, time: 192.189192]
2023-06-07 21:24:04.927: epoch 3:	0.00334784  	0.05368526  	0.02351024  	0.01690427  	0.01700790  
2023-06-07 21:24:04.927: Found a better model.
2023-06-07 21:24:04.928: Save model to file as pretrain.
2023-06-07 21:27:11.090: [iter 4 : loss : 0.5474 = 0.1242 + 0.4157 + 0.0076, time: 181.100049]
2023-06-07 21:28:00.095: epoch 4:	0.00372268  	0.05974721  	0.02644902  	0.01915340  	0.01927759  
2023-06-07 21:28:00.095: Found a better model.
2023-06-07 21:28:00.095: Save model to file as pretrain.
2023-06-07 21:31:19.809: [iter 5 : loss : 0.5183 = 0.0969 + 0.4127 + 0.0087, time: 194.626744]
2023-06-07 21:32:09.792: epoch 5:	0.00403402  	0.06480439  	0.02871854  	0.02079426  	0.02092951  
2023-06-07 21:32:09.792: Found a better model.
2023-06-07 21:32:09.792: Save model to file as pretrain.
2023-06-07 21:35:28.617: [iter 6 : loss : 0.4987 = 0.0785 + 0.4104 + 0.0097, time: 193.822664]
2023-06-07 21:36:26.409: epoch 6:	0.00429072  	0.06902511  	0.03079081  	0.02236745  	0.02251438  
2023-06-07 21:36:26.409: Found a better model.
2023-06-07 21:36:26.409: Save model to file as pretrain.
2023-06-07 21:39:33.797: [iter 7 : loss : 0.4842 = 0.0648 + 0.4088 + 0.0106, time: 182.292922]
2023-06-07 21:40:26.234: epoch 7:	0.00451057  	0.07265975  	0.03258239  	0.02374577  	0.02390449  
2023-06-07 21:40:26.235: Found a better model.
2023-06-07 21:40:26.235: Save model to file as pretrain.
2023-06-07 21:43:29.965: [iter 8 : loss : 0.4734 = 0.0545 + 0.4075 + 0.0114, time: 178.672872]
2023-06-07 21:44:23.639: epoch 8:	0.00468070  	0.07537869  	0.03393465  	0.02478586  	0.02496192  
2023-06-07 21:44:23.639: Found a better model.
2023-06-07 21:44:23.640: Save model to file as pretrain.
2023-06-07 21:47:27.866: [iter 9 : loss : 0.4651 = 0.0465 + 0.4064 + 0.0121, time: 179.224552]
2023-06-07 21:48:31.766: epoch 9:	0.00485830  	0.07825564  	0.03537717  	0.02592762  	0.02610519  
2023-06-07 21:48:31.766: Found a better model.
2023-06-07 21:48:31.766: Save model to file as pretrain.
2023-06-07 21:51:39.052: [iter 10 : loss : 0.4583 = 0.0400 + 0.4056 + 0.0127, time: 181.975996]
2023-06-07 21:52:43.713: epoch 10:	0.00497967  	0.08019173  	0.03638753  	0.02673959  	0.02693025  
2023-06-07 21:52:43.713: Found a better model.
2023-06-07 21:52:43.713: Save model to file as pretrain.
2023-06-07 21:55:50.486: [iter 11 : loss : 0.4529 = 0.0347 + 0.4049 + 0.0132, time: 181.992995]
2023-06-07 21:56:44.724: epoch 11:	0.00511202  	0.08238374  	0.03746953  	0.02756902  	0.02776344  
2023-06-07 21:56:44.724: Found a better model.
2023-06-07 21:56:44.724: Save model to file as pretrain.
2023-06-07 21:59:52.339: [iter 12 : loss : 0.4485 = 0.0304 + 0.4043 + 0.0137, time: 182.361400]
2023-06-07 22:00:55.302: epoch 12:	0.00524549  	0.08440123  	0.03844631  	0.02830916  	0.02852662  
2023-06-07 22:00:55.302: Found a better model.
2023-06-07 22:00:55.302: Save model to file as pretrain.
2023-06-07 22:04:03.508: [iter 13 : loss : 0.4449 = 0.0270 + 0.4038 + 0.0142, time: 183.007864]
2023-06-07 22:05:06.477: epoch 13:	0.00534452  	0.08598472  	0.03925496  	0.02895050  	0.02918731  
2023-06-07 22:05:06.477: Found a better model.
2023-06-07 22:05:06.477: Save model to file as pretrain.
2023-06-07 22:08:28.861: [iter 14 : loss : 0.4419 = 0.0241 + 0.4033 + 0.0145, time: 197.280710]
2023-06-07 22:09:31.690: epoch 14:	0.00545192  	0.08769856  	0.04010247  	0.02963232  	0.02989171  
2023-06-07 22:09:31.690: Found a better model.
2023-06-07 22:09:31.690: Save model to file as pretrain.
2023-06-07 22:12:40.190: [iter 15 : loss : 0.4395 = 0.0218 + 0.4029 + 0.0148, time: 183.448625]
2023-06-07 22:13:29.525: epoch 15:	0.00550925  	0.08851642  	0.04058222  	0.03002797  	0.03031212  
2023-06-07 22:13:29.525: Found a better model.
2023-06-07 22:13:29.525: Save model to file as pretrain.
2023-06-07 22:16:37.891: [iter 16 : loss : 0.4370 = 0.0193 + 0.4026 + 0.0151, time: 183.590540]
2023-06-07 22:17:41.620: epoch 16:	0.00559413  	0.08990008  	0.04121374  	0.03047351  	0.03077259  
2023-06-07 22:17:41.620: Found a better model.
2023-06-07 22:17:41.620: Save model to file as pretrain.
2023-06-07 22:20:48.178: [iter 17 : loss : 0.4353 = 0.0177 + 0.4023 + 0.0152, time: 181.663322]
2023-06-07 22:21:50.456: epoch 17:	0.00563695  	0.09053417  	0.04165559  	0.03088299  	0.03118626  
2023-06-07 22:21:50.457: Found a better model.
2023-06-07 22:21:50.457: Save model to file as pretrain.
2023-06-07 22:24:57.893: [iter 18 : loss : 0.4336 = 0.0161 + 0.4021 + 0.0154, time: 182.276452]
2023-06-07 22:26:01.184: epoch 18:	0.00567659  	0.09116065  	0.04205355  	0.03124328  	0.03154122  
2023-06-07 22:26:01.185: Found a better model.
2023-06-07 22:26:01.185: Save model to file as pretrain.
2023-06-07 22:29:10.912: [iter 19 : loss : 0.4322 = 0.0149 + 0.4018 + 0.0155, time: 184.572587]
2023-06-07 22:30:00.565: epoch 19:	0.00572164  	0.09188737  	0.04246905  	0.03159740  	0.03190698  
2023-06-07 22:30:00.565: Found a better model.
2023-06-07 22:30:00.565: Save model to file as pretrain.
2023-06-07 22:33:10.606: [iter 20 : loss : 0.4314 = 0.0142 + 0.4016 + 0.0155, time: 184.793386]
2023-06-07 22:34:10.181: epoch 20:	0.00577209  	0.09263026  	0.04294796  	0.03205318  	0.03236956  
2023-06-07 22:34:10.181: Found a better model.
2023-06-07 22:34:10.181: Save model to file as pretrain.
2023-06-07 22:37:19.333: [iter 21 : loss : 0.4300 = 0.0130 + 0.4015 + 0.0156, time: 184.146074]
2023-06-07 22:38:09.340: epoch 21:	0.00579051  	0.09287927  	0.04315202  	0.03221533  	0.03255056  
2023-06-07 22:38:09.340: Found a better model.
2023-06-07 22:38:09.340: Save model to file as pretrain.
2023-06-07 22:41:17.188: [iter 22 : loss : 0.4292 = 0.0123 + 0.4013 + 0.0156, time: 182.739536]
2023-06-07 22:42:19.893: epoch 22:	0.00581006  	0.09313627  	0.04339666  	0.03248350  	0.03280950  
2023-06-07 22:42:19.893: Found a better model.
2023-06-07 22:42:19.893: Save model to file as pretrain.
2023-06-07 22:45:28.778: [iter 23 : loss : 0.4284 = 0.0117 + 0.4011 + 0.0156, time: 183.804136]
2023-06-07 22:46:32.361: epoch 23:	0.00585139  	0.09372381  	0.04372831  	0.03278945  	0.03310290  
2023-06-07 22:46:32.361: Found a better model.
2023-06-07 22:46:32.361: Save model to file as pretrain.
2023-06-07 22:49:44.084: [iter 24 : loss : 0.4276 = 0.0110 + 0.4010 + 0.0156, time: 186.773242]
2023-06-07 22:50:33.186: epoch 24:	0.00587986  	0.09407001  	0.04396243  	0.03295971  	0.03329766  
2023-06-07 22:50:33.186: Found a better model.
2023-06-07 22:50:33.186: Save model to file as pretrain.
2023-06-07 22:53:42.334: [iter 25 : loss : 0.4270 = 0.0105 + 0.4009 + 0.0155, time: 184.179274]
2023-06-07 22:54:52.075: epoch 25:	0.00590443  	0.09459860  	0.04423621  	0.03323439  	0.03355891  
2023-06-07 22:54:52.075: Found a better model.
2023-06-07 22:54:52.075: Save model to file as pretrain.
2023-06-07 22:58:01.657: [iter 26 : loss : 0.4264 = 0.0101 + 0.4008 + 0.0155, time: 184.500585]
2023-06-07 22:59:04.677: epoch 26:	0.00593385  	0.09495147  	0.04448529  	0.03344334  	0.03377113  
2023-06-07 22:59:04.677: Found a better model.
2023-06-07 22:59:04.677: Save model to file as pretrain.
2023-06-07 23:02:12.175: [iter 27 : loss : 0.4257 = 0.0096 + 0.4007 + 0.0155, time: 182.355011]
2023-06-07 23:03:02.397: epoch 27:	0.00594315  	0.09501038  	0.04456770  	0.03353221  	0.03387870  
2023-06-07 23:03:02.397: Found a better model.
2023-06-07 23:03:02.397: Save model to file as pretrain.
2023-06-07 23:06:10.486: [iter 28 : loss : 0.4252 = 0.0092 + 0.4006 + 0.0154, time: 183.091370]
2023-06-07 23:07:02.387: epoch 28:	0.00595916  	0.09536511  	0.04473860  	0.03366977  	0.03403014  
2023-06-07 23:07:02.387: Found a better model.
2023-06-07 23:07:02.387: Save model to file as pretrain.
2023-06-07 23:10:09.846: [iter 29 : loss : 0.4248 = 0.0089 + 0.4005 + 0.0154, time: 182.239418]
2023-06-07 23:11:10.809: epoch 29:	0.00598001  	0.09568358  	0.04494693  	0.03386147  	0.03422078  
2023-06-07 23:11:10.809: Found a better model.
2023-06-07 23:11:10.809: Save model to file as pretrain.
2023-06-07 23:14:33.820: [iter 30 : loss : 0.4245 = 0.0088 + 0.4004 + 0.0153, time: 197.795193]
2023-06-07 23:15:37.242: epoch 30:	0.00598280  	0.09572048  	0.04499330  	0.03389146  	0.03423657  
2023-06-07 23:15:37.242: Found a better model.
2023-06-07 23:15:37.242: Save model to file as pretrain.
2023-06-07 23:18:45.704: [iter 31 : loss : 0.4242 = 0.0086 + 0.4004 + 0.0153, time: 183.438453]
2023-06-07 23:19:48.814: epoch 31:	0.00600570  	0.09603910  	0.04516724  	0.03407478  	0.03441745  
2023-06-07 23:19:48.814: Found a better model.
2023-06-07 23:19:48.814: Save model to file as pretrain.
2023-06-07 23:22:55.582: [iter 32 : loss : 0.4237 = 0.0082 + 0.4003 + 0.0153, time: 181.649950]
2023-06-07 23:23:58.085: epoch 32:	0.00601872  	0.09615135  	0.04527259  	0.03418905  	0.03454480  
2023-06-07 23:23:58.086: Found a better model.
2023-06-07 23:23:58.086: Save model to file as pretrain.
2023-06-07 23:27:06.211: [iter 33 : loss : 0.4234 = 0.0080 + 0.4002 + 0.0152, time: 183.173331]
2023-06-07 23:27:56.414: epoch 33:	0.00604758  	0.09666076  	0.04548829  	0.03434551  	0.03471288  
2023-06-07 23:27:56.414: Found a better model.
2023-06-07 23:27:56.414: Save model to file as pretrain.
2023-06-07 23:31:02.958: [iter 34 : loss : 0.4233 = 0.0079 + 0.4002 + 0.0152, time: 181.388048]
2023-06-07 23:32:05.757: epoch 34:	0.00605372  	0.09675890  	0.04560620  	0.03448442  	0.03483504  
2023-06-07 23:32:05.757: Found a better model.
2023-06-07 23:32:05.757: Save model to file as pretrain.
2023-06-07 23:35:28.952: [iter 35 : loss : 0.4230 = 0.0077 + 0.4001 + 0.0151, time: 198.168452]
2023-06-07 23:36:29.860: epoch 35:	0.00607531  	0.09704594  	0.04580022  	0.03468216  	0.03504512  
2023-06-07 23:36:29.860: Found a better model.
2023-06-07 23:36:29.860: Save model to file as pretrain.
2023-06-07 23:39:41.532: [iter 36 : loss : 0.4227 = 0.0075 + 0.4001 + 0.0151, time: 186.665981]
2023-06-07 23:40:43.149: epoch 36:	0.00609113  	0.09721529  	0.04591630  	0.03476898  	0.03516173  
2023-06-07 23:40:43.149: Found a better model.
2023-06-07 23:40:43.149: Save model to file as pretrain.
2023-06-07 23:44:04.717: [iter 37 : loss : 0.4224 = 0.0073 + 0.4000 + 0.0151, time: 196.455119]
2023-06-07 23:44:56.485: epoch 37:	0.00609132  	0.09731834  	0.04597641  	0.03482052  	0.03520611  
2023-06-07 23:44:56.486: Found a better model.
2023-06-07 23:44:56.486: Save model to file as pretrain.
2023-06-07 23:48:04.379: [iter 38 : loss : 0.4222 = 0.0072 + 0.4000 + 0.0151, time: 182.894765]
2023-06-07 23:48:56.295: epoch 38:	0.00611980  	0.09774560  	0.04605497  	0.03481360  	0.03519042  
2023-06-07 23:48:56.295: Found a better model.
2023-06-07 23:48:56.295: Save model to file as pretrain.
2023-06-07 23:52:06.042: [iter 39 : loss : 0.4221 = 0.0071 + 0.4000 + 0.0151, time: 184.648799]
2023-06-07 23:53:07.788: epoch 39:	0.00610752  	0.09750665  	0.04606052  	0.03486612  	0.03525160  
2023-06-07 23:56:12.145: [iter 40 : loss : 0.4221 = 0.0071 + 0.3999 + 0.0150, time: 183.712466]
2023-06-07 23:57:14.442: epoch 40:	0.00613581  	0.09804621  	0.04620463  	0.03497294  	0.03535462  
2023-06-07 23:57:14.442: Found a better model.
2023-06-07 23:57:14.442: Save model to file as pretrain.
2023-06-08 00:00:25.136: [iter 41 : loss : 0.4219 = 0.0070 + 0.3999 + 0.0150, time: 185.556497]
2023-06-08 00:01:28.130: epoch 41:	0.00613245  	0.09792787  	0.04630454  	0.03510857  	0.03550602  
2023-06-08 00:04:32.887: [iter 42 : loss : 0.4217 = 0.0068 + 0.3999 + 0.0150, time: 184.114822]
2023-06-08 00:05:33.646: epoch 42:	0.00613692  	0.09802154  	0.04631157  	0.03508285  	0.03549290  
2023-06-08 00:08:37.599: [iter 43 : loss : 0.4215 = 0.0067 + 0.3998 + 0.0150, time: 183.311901]
2023-06-08 00:09:27.790: epoch 43:	0.00614884  	0.09820957  	0.04641805  	0.03514007  	0.03555924  
2023-06-08 00:09:27.790: Found a better model.
2023-06-08 00:09:27.790: Save model to file as pretrain.
2023-06-08 00:12:37.830: [iter 44 : loss : 0.4214 = 0.0067 + 0.3998 + 0.0150, time: 185.247157]
2023-06-08 00:13:40.173: epoch 44:	0.00616391  	0.09837648  	0.04650127  	0.03522442  	0.03562443  
2023-06-08 00:13:40.173: Found a better model.
2023-06-08 00:13:40.173: Save model to file as pretrain.
2023-06-08 00:16:48.091: [iter 45 : loss : 0.4212 = 0.0065 + 0.3998 + 0.0150, time: 182.973016]
2023-06-08 00:17:38.754: epoch 45:	0.00616354  	0.09831005  	0.04654470  	0.03526836  	0.03568516  
2023-06-08 00:20:44.379: [iter 46 : loss : 0.4212 = 0.0065 + 0.3997 + 0.0150, time: 184.983882]
2023-06-08 00:21:32.858: epoch 46:	0.00616913  	0.09850332  	0.04665681  	0.03538450  	0.03580288  
2023-06-08 00:21:32.858: Found a better model.
2023-06-08 00:21:32.858: Save model to file as pretrain.
2023-06-08 00:24:43.624: [iter 47 : loss : 0.4212 = 0.0065 + 0.3997 + 0.0150, time: 185.772217]
2023-06-08 00:25:35.198: epoch 47:	0.00617750  	0.09862537  	0.04665576  	0.03535628  	0.03575780  
2023-06-08 00:25:35.199: Found a better model.
2023-06-08 00:25:35.199: Save model to file as pretrain.
2023-06-08 00:28:44.629: [iter 48 : loss : 0.4209 = 0.0062 + 0.3997 + 0.0150, time: 184.430020]
2023-06-08 00:29:49.147: epoch 48:	0.00617881  	0.09865364  	0.04665549  	0.03532765  	0.03573911  
2023-06-08 00:29:49.148: Found a better model.
2023-06-08 00:29:49.148: Save model to file as pretrain.
2023-06-08 00:33:06.456: [iter 49 : loss : 0.4209 = 0.0063 + 0.3997 + 0.0150, time: 192.034756]
2023-06-08 00:33:56.763: epoch 49:	0.00618793  	0.09885391  	0.04672372  	0.03538705  	0.03578438  
2023-06-08 00:33:56.763: Found a better model.
2023-06-08 00:33:56.763: Save model to file as pretrain.
2023-06-08 00:37:06.012: [iter 50 : loss : 0.4208 = 0.0062 + 0.3997 + 0.0150, time: 184.098967]
2023-06-08 00:38:08.365: epoch 50:	0.00618830  	0.09884237  	0.04667760  	0.03531563  	0.03571724  
2023-06-08 00:41:13.107: [iter 51 : loss : 0.4207 = 0.0061 + 0.3997 + 0.0149, time: 184.104618]
2023-06-08 00:42:01.382: epoch 51:	0.00619779  	0.09894302  	0.04677160  	0.03539675  	0.03581667  
2023-06-08 00:42:01.382: Found a better model.
2023-06-08 00:42:01.382: Save model to file as pretrain.
2023-06-08 00:45:09.070: [iter 52 : loss : 0.4207 = 0.0061 + 0.3997 + 0.0149, time: 182.637219]
2023-06-08 00:46:11.915: epoch 52:	0.00619612  	0.09893234  	0.04679511  	0.03543591  	0.03585016  
2023-06-08 00:49:17.504: [iter 53 : loss : 0.4206 = 0.0061 + 0.3996 + 0.0149, time: 184.948074]
2023-06-08 00:50:06.880: epoch 53:	0.00621566  	0.09926394  	0.04694097  	0.03553253  	0.03596848  
2023-06-08 00:50:06.880: Found a better model.
2023-06-08 00:50:06.880: Save model to file as pretrain.
2023-06-08 00:53:30.718: [iter 54 : loss : 0.4206 = 0.0060 + 0.3996 + 0.0150, time: 198.774075]
2023-06-08 00:54:32.608: epoch 54:	0.00622534  	0.09945492  	0.04692636  	0.03548675  	0.03590287  
2023-06-08 00:54:32.609: Found a better model.
2023-06-08 00:54:32.609: Save model to file as pretrain.
2023-06-08 00:57:41.864: [iter 55 : loss : 0.4206 = 0.0061 + 0.3996 + 0.0149, time: 184.369753]
2023-06-08 00:58:44.156: epoch 55:	0.00620840  	0.09921357  	0.04691723  	0.03555635  	0.03597227  
2023-06-08 01:01:49.849: [iter 56 : loss : 0.4206 = 0.0061 + 0.3996 + 0.0149, time: 185.074272]
2023-06-08 01:02:39.792: epoch 56:	0.00622608  	0.09937248  	0.04701889  	0.03562460  	0.03603774  
2023-06-08 01:05:43.002: [iter 57 : loss : 0.4203 = 0.0058 + 0.3996 + 0.0149, time: 182.578138]
2023-06-08 01:06:31.604: epoch 57:	0.00622925  	0.09951200  	0.04709482  	0.03570325  	0.03611429  
2023-06-08 01:06:31.604: Found a better model.
2023-06-08 01:06:31.604: Save model to file as pretrain.
2023-06-08 01:09:41.358: [iter 58 : loss : 0.4204 = 0.0058 + 0.3996 + 0.0149, time: 184.835687]
2023-06-08 01:10:42.058: epoch 58:	0.00622813  	0.09937114  	0.04710835  	0.03573703  	0.03612484  
2023-06-08 01:14:00.735: [iter 59 : loss : 0.4202 = 0.0058 + 0.3995 + 0.0149, time: 198.015356]
2023-06-08 01:15:01.002: epoch 59:	0.00625419  	0.09985444  	0.04724093  	0.03575815  	0.03616054  
2023-06-08 01:15:01.002: Found a better model.
2023-06-08 01:15:01.002: Save model to file as pretrain.
2023-06-08 01:18:10.609: [iter 60 : loss : 0.4202 = 0.0057 + 0.3995 + 0.0149, time: 184.466801]
2023-06-08 01:19:13.099: epoch 60:	0.00624396  	0.09979722  	0.04719331  	0.03575837  	0.03614911  
2023-06-08 01:22:17.145: [iter 61 : loss : 0.4202 = 0.0058 + 0.3995 + 0.0149, time: 183.414030]
2023-06-08 01:23:20.127: epoch 61:	0.00624898  	0.09986825  	0.04726791  	0.03583249  	0.03622427  
2023-06-08 01:23:20.127: Found a better model.
2023-06-08 01:23:20.127: Save model to file as pretrain.
2023-06-08 01:26:29.461: [iter 62 : loss : 0.4201 = 0.0057 + 0.3995 + 0.0149, time: 184.412628]
2023-06-08 01:27:32.082: epoch 62:	0.00625381  	0.09994067  	0.04731695  	0.03585170  	0.03625111  
2023-06-08 01:27:32.083: Found a better model.
2023-06-08 01:27:32.083: Save model to file as pretrain.
2023-06-08 01:30:40.849: [iter 63 : loss : 0.4201 = 0.0057 + 0.3995 + 0.0149, time: 183.801112]
2023-06-08 01:31:43.810: epoch 63:	0.00626033  	0.10002296  	0.04738674  	0.03591671  	0.03632752  
2023-06-08 01:31:43.810: Found a better model.
2023-06-08 01:31:43.810: Save model to file as pretrain.
2023-06-08 01:34:53.674: [iter 64 : loss : 0.4201 = 0.0057 + 0.3995 + 0.0149, time: 184.989155]
2023-06-08 01:35:57.369: epoch 64:	0.00626610  	0.10011879  	0.04735184  	0.03581421  	0.03622782  
2023-06-08 01:35:57.369: Found a better model.
2023-06-08 01:35:57.369: Save model to file as pretrain.
2023-06-08 01:39:05.552: [iter 65 : loss : 0.4200 = 0.0056 + 0.3995 + 0.0149, time: 183.239220]
2023-06-08 01:40:08.674: epoch 65:	0.00628044  	0.10035157  	0.04751977  	0.03601970  	0.03643196  
2023-06-08 01:40:08.674: Found a better model.
2023-06-08 01:40:08.674: Save model to file as pretrain.
2023-06-08 01:43:31.542: [iter 66 : loss : 0.4201 = 0.0057 + 0.3995 + 0.0149, time: 197.988934]
2023-06-08 01:44:31.507: epoch 66:	0.00629142  	0.10052852  	0.04761133  	0.03608475  	0.03649686  
2023-06-08 01:44:31.518: Found a better model.
2023-06-08 01:44:31.518: Save model to file as pretrain.
2023-06-08 01:47:39.980: [iter 67 : loss : 0.4200 = 0.0056 + 0.3995 + 0.0149, time: 183.562945]
2023-06-08 01:48:43.580: epoch 67:	0.00629179  	0.10053910  	0.04759629  	0.03605708  	0.03647561  
2023-06-08 01:48:43.580: Found a better model.
2023-06-08 01:48:43.580: Save model to file as pretrain.
2023-06-08 01:51:53.266: [iter 68 : loss : 0.4200 = 0.0056 + 0.3995 + 0.0149, time: 184.502183]
2023-06-08 01:52:55.759: epoch 68:	0.00630650  	0.10080574  	0.04768152  	0.03609180  	0.03649685  
2023-06-08 01:52:55.759: Found a better model.
2023-06-08 01:52:55.759: Save model to file as pretrain.
2023-06-08 01:56:05.557: [iter 69 : loss : 0.4200 = 0.0055 + 0.3995 + 0.0149, time: 184.590773]
2023-06-08 01:57:07.585: epoch 69:	0.00629701  	0.10063541  	0.04769060  	0.03618924  	0.03659687  
2023-06-08 02:00:12.637: [iter 70 : loss : 0.4199 = 0.0055 + 0.3995 + 0.0149, time: 184.414699]
2023-06-08 02:01:14.699: epoch 70:	0.00630743  	0.10080519  	0.04776334  	0.03621380  	0.03662061  
2023-06-08 02:04:18.919: [iter 71 : loss : 0.4199 = 0.0055 + 0.3995 + 0.0149, time: 183.571432]
2023-06-08 02:05:09.053: epoch 71:	0.00631172  	0.10096199  	0.04781561  	0.03625786  	0.03663431  
2023-06-08 02:05:09.054: Found a better model.
2023-06-08 02:05:09.054: Save model to file as pretrain.
2023-06-08 02:08:18.098: [iter 72 : loss : 0.4199 = 0.0055 + 0.3995 + 0.0149, time: 184.000353]
2023-06-08 02:09:19.314: epoch 72:	0.00630837  	0.10084565  	0.04786563  	0.03633686  	0.03672508  
2023-06-08 02:12:33.222: [iter 73 : loss : 0.4198 = 0.0054 + 0.3995 + 0.0149, time: 193.262657]
2023-06-08 02:13:36.299: epoch 73:	0.00632958  	0.10113212  	0.04793106  	0.03632625  	0.03672495  
2023-06-08 02:13:36.299: Found a better model.
2023-06-08 02:13:36.299: Save model to file as pretrain.
2023-06-08 02:16:43.655: [iter 74 : loss : 0.4198 = 0.0054 + 0.3995 + 0.0149, time: 182.294505]
2023-06-08 02:17:46.127: epoch 74:	0.00634745  	0.10153617  	0.04804816  	0.03638753  	0.03679601  
2023-06-08 02:17:46.127: Found a better model.
2023-06-08 02:17:46.127: Save model to file as pretrain.
2023-06-08 02:20:54.490: [iter 75 : loss : 0.4198 = 0.0054 + 0.3995 + 0.0149, time: 183.281021]
2023-06-08 02:21:58.250: epoch 75:	0.00634708  	0.10149287  	0.04803937  	0.03639492  	0.03680153  
2023-06-08 02:25:17.456: [iter 76 : loss : 0.4197 = 0.0054 + 0.3994 + 0.0149, time: 198.557102]
2023-06-08 02:26:16.754: epoch 76:	0.00636029  	0.10176872  	0.04810068  	0.03637430  	0.03678135  
2023-06-08 02:26:16.754: Found a better model.
2023-06-08 02:26:16.754: Save model to file as pretrain.
2023-06-08 02:29:25.808: [iter 77 : loss : 0.4197 = 0.0053 + 0.3994 + 0.0149, time: 184.059332]
2023-06-08 02:30:28.062: epoch 77:	0.00635657  	0.10164735  	0.04814407  	0.03648017  	0.03689018  
2023-06-08 02:33:32.704: [iter 78 : loss : 0.4197 = 0.0053 + 0.3994 + 0.0149, time: 183.998002]
2023-06-08 02:34:32.662: epoch 78:	0.00636252  	0.10167718  	0.04816857  	0.03648674  	0.03689365  
2023-06-08 02:37:36.225: [iter 79 : loss : 0.4197 = 0.0054 + 0.3994 + 0.0149, time: 182.901896]
2023-06-08 02:38:26.741: epoch 79:	0.00636699  	0.10183284  	0.04813538  	0.03646172  	0.03685397  
2023-06-08 02:38:26.741: Found a better model.
2023-06-08 02:38:26.741: Save model to file as pretrain.
2023-06-08 02:41:34.866: [iter 80 : loss : 0.4196 = 0.0053 + 0.3994 + 0.0149, time: 183.000098]
2023-06-08 02:42:37.960: epoch 80:	0.00636755  	0.10190792  	0.04820220  	0.03653798  	0.03693099  
2023-06-08 02:42:37.960: Found a better model.
2023-06-08 02:42:37.960: Save model to file as pretrain.
2023-06-08 02:45:46.143: [iter 81 : loss : 0.4196 = 0.0053 + 0.3994 + 0.0149, time: 183.008006]
2023-06-08 02:46:39.585: epoch 81:	0.00636812  	0.10192078  	0.04814937  	0.03646393  	0.03685090  
2023-06-08 02:46:39.585: Found a better model.
2023-06-08 02:46:39.585: Save model to file as pretrain.
2023-06-08 02:49:46.415: [iter 82 : loss : 0.4196 = 0.0052 + 0.3994 + 0.0149, time: 182.145738]
2023-06-08 02:50:49.641: epoch 82:	0.00637184  	0.10202619  	0.04817250  	0.03646679  	0.03685788  
2023-06-08 02:50:49.641: Found a better model.
2023-06-08 02:50:49.641: Save model to file as pretrain.
2023-06-08 02:53:58.153: [iter 83 : loss : 0.4195 = 0.0052 + 0.3994 + 0.0149, time: 183.429459]
2023-06-08 02:54:47.747: epoch 83:	0.00637612  	0.10211598  	0.04824579  	0.03649761  	0.03689905  
2023-06-08 02:54:47.747: Found a better model.
2023-06-08 02:54:47.747: Save model to file as pretrain.
2023-06-08 02:57:57.179: [iter 84 : loss : 0.4196 = 0.0053 + 0.3994 + 0.0149, time: 184.516786]
2023-06-08 02:58:46.673: epoch 84:	0.00639306  	0.10236998  	0.04835470  	0.03656799  	0.03697481  
2023-06-08 02:58:46.673: Found a better model.
2023-06-08 02:58:46.673: Save model to file as pretrain.
2023-06-08 03:01:54.596: [iter 85 : loss : 0.4196 = 0.0052 + 0.3994 + 0.0149, time: 183.042277]
2023-06-08 03:02:42.868: epoch 85:	0.00639138  	0.10226927  	0.04833613  	0.03657955  	0.03698823  
2023-06-08 03:05:46.644: [iter 86 : loss : 0.4195 = 0.0051 + 0.3994 + 0.0149, time: 183.133909]
2023-06-08 03:06:36.071: epoch 86:	0.00640088  	0.10249743  	0.04843988  	0.03664529  	0.03705748  
2023-06-08 03:06:36.071: Found a better model.
2023-06-08 03:06:36.071: Save model to file as pretrain.
2023-06-08 03:09:44.680: [iter 87 : loss : 0.4196 = 0.0052 + 0.3994 + 0.0149, time: 183.617032]
2023-06-08 03:10:46.874: epoch 87:	0.00640068  	0.10248077  	0.04838268  	0.03656032  	0.03696989  
2023-06-08 03:13:49.585: [iter 88 : loss : 0.4195 = 0.0052 + 0.3994 + 0.0149, time: 182.058405]
2023-06-08 03:14:52.285: epoch 88:	0.00640571  	0.10254297  	0.04841200  	0.03659245  	0.03700182  
2023-06-08 03:14:52.286: Found a better model.
2023-06-08 03:14:52.286: Save model to file as pretrain.
2023-06-08 03:18:01.582: [iter 89 : loss : 0.4195 = 0.0052 + 0.3994 + 0.0149, time: 184.159952]
2023-06-08 03:19:06.770: epoch 89:	0.00639324  	0.10227191  	0.04840707  	0.03664492  	0.03705816  
2023-06-08 03:22:12.120: [iter 90 : loss : 0.4195 = 0.0052 + 0.3994 + 0.0149, time: 184.689659]
2023-06-08 03:23:03.723: epoch 90:	0.00640962  	0.10254829  	0.04852251  	0.03672588  	0.03714443  
2023-06-08 03:23:03.724: Found a better model.
2023-06-08 03:23:03.724: Save model to file as pretrain.
2023-06-08 03:26:27.128: [iter 91 : loss : 0.4194 = 0.0051 + 0.3994 + 0.0149, time: 198.373028]
2023-06-08 03:27:36.009: epoch 91:	0.00643401  	0.10304862  	0.04865972  	0.03675326  	0.03717602  
2023-06-08 03:27:36.009: Found a better model.
2023-06-08 03:27:36.009: Save model to file as pretrain.
2023-06-08 03:30:45.394: [iter 92 : loss : 0.4195 = 0.0052 + 0.3994 + 0.0149, time: 184.402346]
2023-06-08 03:31:50.559: epoch 92:	0.00642637  	0.10278256  	0.04853811  	0.03666815  	0.03709095  
2023-06-08 03:34:56.666: [iter 93 : loss : 0.4195 = 0.0052 + 0.3994 + 0.0149, time: 185.458171]
2023-06-08 03:35:46.494: epoch 93:	0.00641483  	0.10262837  	0.04848549  	0.03666577  	0.03707948  
2023-06-08 03:38:50.821: [iter 94 : loss : 0.4195 = 0.0052 + 0.3994 + 0.0149, time: 183.683436]
2023-06-08 03:39:43.325: epoch 94:	0.00643829  	0.10306881  	0.04866280  	0.03676071  	0.03718535  
2023-06-08 03:39:43.325: Found a better model.
2023-06-08 03:39:43.325: Save model to file as pretrain.
2023-06-08 03:42:53.279: [iter 95 : loss : 0.4194 = 0.0051 + 0.3994 + 0.0149, time: 184.873739]
2023-06-08 03:43:42.502: epoch 95:	0.00643456  	0.10301191  	0.04864634  	0.03672374  	0.03713632  
2023-06-08 03:46:48.447: [iter 96 : loss : 0.4194 = 0.0051 + 0.3994 + 0.0149, time: 185.298378]
2023-06-08 03:47:38.807: epoch 96:	0.00642711  	0.10284695  	0.04860508  	0.03669747  	0.03710235  
2023-06-08 03:50:44.945: [iter 97 : loss : 0.4194 = 0.0051 + 0.3994 + 0.0149, time: 185.508423]
2023-06-08 03:51:34.379: epoch 97:	0.00643922  	0.10306174  	0.04873328  	0.03683054  	0.03724791  
2023-06-08 03:54:38.713: [iter 98 : loss : 0.4194 = 0.0051 + 0.3994 + 0.0149, time: 183.692112]
2023-06-08 03:55:27.971: epoch 98:	0.00644294  	0.10311186  	0.04871621  	0.03677676  	0.03718445  
2023-06-08 03:55:27.971: Found a better model.
2023-06-08 03:55:27.971: Save model to file as pretrain.
2023-06-08 03:58:37.519: [iter 99 : loss : 0.4194 = 0.0051 + 0.3994 + 0.0149, time: 184.752791]
2023-06-08 03:59:27.603: epoch 99:	0.00643977  	0.10302645  	0.04875899  	0.03687629  	0.03729784  
2023-06-08 04:02:32.974: [iter 100 : loss : 0.4194 = 0.0051 + 0.3994 + 0.0149, time: 184.725072]
2023-06-08 04:03:23.896: epoch 100:	0.00644331  	0.10303238  	0.04889793  	0.03707022  	0.03748653  
2023-06-08 04:06:29.188: [iter 101 : loss : 0.4194 = 0.0051 + 0.3994 + 0.0149, time: 184.652228]
2023-06-08 04:07:19.686: epoch 101:	0.00645280  	0.10330422  	0.04892804  	0.03704473  	0.03745353  
2023-06-08 04:07:19.686: Found a better model.
2023-06-08 04:07:19.686: Save model to file as pretrain.
2023-06-08 04:10:43.271: [iter 102 : loss : 0.4195 = 0.0052 + 0.3994 + 0.0149, time: 198.604222]
2023-06-08 04:11:46.147: epoch 102:	0.00646732  	0.10351053  	0.04897650  	0.03702907  	0.03744606  
2023-06-08 04:11:46.147: Found a better model.
2023-06-08 04:11:46.147: Save model to file as pretrain.
2023-06-08 04:14:54.902: [iter 103 : loss : 0.4194 = 0.0051 + 0.3994 + 0.0149, time: 183.556420]
2023-06-08 04:15:55.630: epoch 103:	0.00646359  	0.10338805  	0.04887168  	0.03692826  	0.03735523  
2023-06-08 04:18:59.572: [iter 104 : loss : 0.4193 = 0.0051 + 0.3994 + 0.0149, time: 183.309590]
2023-06-08 04:19:51.784: epoch 104:	0.00646881  	0.10350295  	0.04889212  	0.03690577  	0.03733786  
2023-06-08 04:22:57.291: [iter 105 : loss : 0.4192 = 0.0049 + 0.3994 + 0.0149, time: 184.853476]
2023-06-08 04:23:50.444: epoch 105:	0.00647662  	0.10369549  	0.04891057  	0.03688918  	0.03731224  
2023-06-08 04:23:50.445: Found a better model.
2023-06-08 04:23:50.445: Save model to file as pretrain.
2023-06-08 04:26:58.320: [iter 106 : loss : 0.4193 = 0.0051 + 0.3994 + 0.0149, time: 183.143555]
2023-06-08 04:27:47.426: epoch 106:	0.00647142  	0.10352998  	0.04889289  	0.03691215  	0.03732640  
2023-06-08 04:30:50.284: [iter 107 : loss : 0.4193 = 0.0050 + 0.3993 + 0.0149, time: 182.213136]
2023-06-08 04:31:40.130: epoch 107:	0.00647905  	0.10369190  	0.04897137  	0.03699304  	0.03739916  
2023-06-08 04:34:58.876: [iter 108 : loss : 0.4193 = 0.0050 + 0.3994 + 0.0149, time: 198.089829]
2023-06-08 04:35:48.373: epoch 108:	0.00648669  	0.10381253  	0.04892927  	0.03688043  	0.03728974  
2023-06-08 04:35:48.373: Found a better model.
2023-06-08 04:35:48.373: Save model to file as pretrain.
2023-06-08 04:38:56.324: [iter 109 : loss : 0.4193 = 0.0050 + 0.3994 + 0.0149, time: 182.902849]
2023-06-08 04:39:58.828: epoch 109:	0.00648277  	0.10374911  	0.04900620  	0.03700440  	0.03741255  
2023-06-08 04:43:02.922: [iter 110 : loss : 0.4193 = 0.0051 + 0.3993 + 0.0149, time: 183.451815]
2023-06-08 04:43:53.776: epoch 110:	0.00646974  	0.10355180  	0.04902080  	0.03708225  	0.03748542  
2023-06-08 04:46:57.687: [iter 111 : loss : 0.4193 = 0.0051 + 0.3993 + 0.0149, time: 183.270503]
2023-06-08 04:47:47.608: epoch 111:	0.00647384  	0.10357664  	0.04906803  	0.03712439  	0.03753762  
2023-06-08 04:50:53.115: [iter 112 : loss : 0.4193 = 0.0050 + 0.3994 + 0.0149, time: 184.864843]
2023-06-08 04:51:43.629: epoch 112:	0.00647124  	0.10358967  	0.04899805  	0.03704235  	0.03744144  
2023-06-08 04:54:46.541: [iter 113 : loss : 0.4192 = 0.0050 + 0.3993 + 0.0149, time: 182.269269]
2023-06-08 04:55:35.987: epoch 113:	0.00648277  	0.10377342  	0.04912900  	0.03715537  	0.03758410  
2023-06-08 04:58:41.298: [iter 114 : loss : 0.4192 = 0.0049 + 0.3993 + 0.0149, time: 184.673164]
2023-06-08 04:59:31.031: epoch 114:	0.00648091  	0.10370696  	0.04909097  	0.03714456  	0.03755611  
2023-06-08 05:02:35.326: [iter 115 : loss : 0.4192 = 0.0049 + 0.3994 + 0.0149, time: 183.657465]
2023-06-08 05:03:26.134: epoch 115:	0.00648054  	0.10371339  	0.04906266  	0.03710413  	0.03751678  
2023-06-08 05:06:30.935: [iter 116 : loss : 0.4193 = 0.0050 + 0.3993 + 0.0149, time: 184.150324]
2023-06-08 05:07:18.991: epoch 116:	0.00649636  	0.10390826  	0.04917537  	0.03720543  	0.03762820  
2023-06-08 05:07:18.991: Found a better model.
2023-06-08 05:07:18.991: Save model to file as pretrain.
2023-06-08 05:10:28.607: [iter 117 : loss : 0.4193 = 0.0051 + 0.3993 + 0.0149, time: 184.917145]
2023-06-08 05:11:38.000: epoch 117:	0.00649990  	0.10384545  	0.04917209  	0.03721197  	0.03764625  
2023-06-08 05:14:56.412: [iter 118 : loss : 0.4192 = 0.0049 + 0.3994 + 0.0149, time: 197.771071]
2023-06-08 05:16:05.767: epoch 118:	0.00649729  	0.10390220  	0.04918515  	0.03720753  	0.03763766  
2023-06-08 05:19:10.378: [iter 119 : loss : 0.4192 = 0.0050 + 0.3993 + 0.0149, time: 183.976176]
2023-06-08 05:20:19.090: epoch 119:	0.00650678  	0.10401380  	0.04930545  	0.03736567  	0.03780482  
2023-06-08 05:20:19.090: Found a better model.
2023-06-08 05:20:19.090: Save model to file as pretrain.
2023-06-08 05:23:27.166: [iter 120 : loss : 0.4191 = 0.0049 + 0.3993 + 0.0149, time: 183.024975]
2023-06-08 05:24:29.850: epoch 120:	0.00650064  	0.10403361  	0.04933704  	0.03737322  	0.03779700  
2023-06-08 05:24:29.850: Found a better model.
2023-06-08 05:24:29.850: Save model to file as pretrain.
2023-06-08 05:27:52.306: [iter 121 : loss : 0.4192 = 0.0050 + 0.3993 + 0.0149, time: 197.512535]
2023-06-08 05:28:54.217: epoch 121:	0.00651795  	0.10430835  	0.04932519  	0.03731869  	0.03773880  
2023-06-08 05:28:54.218: Found a better model.
2023-06-08 05:28:54.218: Save model to file as pretrain.
2023-06-08 05:32:04.519: [iter 122 : loss : 0.4191 = 0.0049 + 0.3993 + 0.0149, time: 185.258934]
2023-06-08 05:33:07.166: epoch 122:	0.00650883  	0.10411326  	0.04927048  	0.03727087  	0.03769182  
2023-06-08 05:36:11.110: [iter 123 : loss : 0.4191 = 0.0049 + 0.3993 + 0.0149, time: 183.290190]
2023-06-08 05:37:15.099: epoch 123:	0.00652112  	0.10435645  	0.04933392  	0.03729665  	0.03772270  
2023-06-08 05:37:15.100: Found a better model.
2023-06-08 05:37:15.100: Save model to file as pretrain.
2023-06-08 05:40:32.127: [iter 124 : loss : 0.4193 = 0.0051 + 0.3993 + 0.0149, time: 191.984459]
2023-06-08 05:41:35.076: epoch 124:	0.00653508  	0.10451283  	0.04952997  	0.03750481  	0.03791913  
2023-06-08 05:41:35.076: Found a better model.
2023-06-08 05:41:35.077: Save model to file as pretrain.
2023-06-08 05:44:42.454: [iter 125 : loss : 0.4192 = 0.0050 + 0.3993 + 0.0149, time: 182.599133]
2023-06-08 05:45:45.019: epoch 125:	0.00653117  	0.10454986  	0.04950049  	0.03746213  	0.03788142  
2023-06-08 05:45:45.019: Found a better model.
2023-06-08 05:45:45.019: Save model to file as pretrain.
2023-06-08 05:48:53.552: [iter 126 : loss : 0.4193 = 0.0050 + 0.3994 + 0.0149, time: 183.351560]
2023-06-08 05:49:41.958: epoch 126:	0.00652670  	0.10446081  	0.04951638  	0.03751959  	0.03793963  
2023-06-08 05:52:45.807: [iter 127 : loss : 0.4191 = 0.0049 + 0.3993 + 0.0149, time: 183.209323]
2023-06-08 05:53:46.030: epoch 127:	0.00653005  	0.10451746  	0.04951334  	0.03749412  	0.03792420  
2023-06-08 05:56:52.147: [iter 128 : loss : 0.4192 = 0.0050 + 0.3993 + 0.0149, time: 185.468567]
2023-06-08 05:57:40.985: epoch 128:	0.00653117  	0.10451162  	0.04953060  	0.03751611  	0.03795674  
2023-06-08 06:00:45.921: [iter 129 : loss : 0.4193 = 0.0051 + 0.3993 + 0.0149, time: 184.299443]
2023-06-08 06:01:35.127: epoch 129:	0.00652689  	0.10451231  	0.04956925  	0.03756329  	0.03798969  
2023-06-08 06:04:40.019: [iter 130 : loss : 0.4192 = 0.0049 + 0.3993 + 0.0149, time: 184.249211]
2023-06-08 06:05:32.594: epoch 130:	0.00653042  	0.10452994  	0.04952131  	0.03751169  	0.03793333  
2023-06-08 06:08:38.281: [iter 131 : loss : 0.4192 = 0.0050 + 0.3993 + 0.0149, time: 185.016631]
2023-06-08 06:09:27.782: epoch 131:	0.00652820  	0.10452566  	0.04957556  	0.03758605  	0.03801039  
2023-06-08 06:12:32.128: [iter 132 : loss : 0.4191 = 0.0049 + 0.3993 + 0.0149, time: 183.697405]
2023-06-08 06:13:22.063: epoch 132:	0.00654513  	0.10480484  	0.04959013  	0.03750359  	0.03792896  
2023-06-08 06:13:22.071: Found a better model.
2023-06-08 06:13:22.071: Save model to file as pretrain.
2023-06-08 06:16:31.085: [iter 133 : loss : 0.4191 = 0.0049 + 0.3993 + 0.0149, time: 184.171442]
2023-06-08 06:17:34.263: epoch 133:	0.00654272  	0.10476653  	0.04962486  	0.03758668  	0.03800967  
2023-06-08 06:20:39.454: [iter 134 : loss : 0.4191 = 0.0050 + 0.3993 + 0.0149, time: 184.525057]
2023-06-08 06:21:29.901: epoch 134:	0.00653694  	0.10465892  	0.04961789  	0.03756144  	0.03797921  
2023-06-08 06:24:34.188: [iter 135 : loss : 0.4191 = 0.0049 + 0.3993 + 0.0149, time: 183.651455]
2023-06-08 06:25:37.003: epoch 135:	0.00655537  	0.10500083  	0.04975143  	0.03767562  	0.03810182  
2023-06-08 06:25:37.003: Found a better model.
2023-06-08 06:25:37.003: Save model to file as pretrain.
2023-06-08 06:28:45.976: [iter 136 : loss : 0.4191 = 0.0049 + 0.3993 + 0.0149, time: 183.998141]
2023-06-08 06:29:48.900: epoch 136:	0.00656356  	0.10509478  	0.04977114  	0.03766307  	0.03810414  
2023-06-08 06:29:48.900: Found a better model.
2023-06-08 06:29:48.900: Save model to file as pretrain.
2023-06-08 06:32:58.482: [iter 137 : loss : 0.4191 = 0.0049 + 0.3993 + 0.0149, time: 184.523044]
2023-06-08 06:33:48.985: epoch 137:	0.00656505  	0.10522244  	0.04982635  	0.03767520  	0.03812722  
2023-06-08 06:33:48.986: Found a better model.
2023-06-08 06:33:48.986: Save model to file as pretrain.
2023-06-08 06:36:57.389: [iter 138 : loss : 0.4190 = 0.0049 + 0.3993 + 0.0149, time: 183.363163]
2023-06-08 06:37:57.741: epoch 138:	0.00657882  	0.10544039  	0.04980733  	0.03760660  	0.03805030  
2023-06-08 06:37:57.742: Found a better model.
2023-06-08 06:37:57.742: Save model to file as pretrain.
2023-06-08 06:41:06.475: [iter 139 : loss : 0.4190 = 0.0048 + 0.3993 + 0.0149, time: 183.622656]
2023-06-08 06:42:06.254: epoch 139:	0.00657175  	0.10536064  	0.04976477  	0.03755311  	0.03798356  
2023-06-08 06:45:12.214: [iter 140 : loss : 0.4191 = 0.0049 + 0.3993 + 0.0149, time: 185.310596]
2023-06-08 06:46:02.629: epoch 140:	0.00657808  	0.10538997  	0.04982971  	0.03763358  	0.03806547  
2023-06-08 06:49:21.784: [iter 141 : loss : 0.4191 = 0.0050 + 0.3993 + 0.0148, time: 198.500194]
2023-06-08 06:50:13.328: epoch 141:	0.00658273  	0.10548919  	0.04981301  	0.03758599  	0.03803661  
2023-06-08 06:50:13.328: Found a better model.
2023-06-08 06:50:13.328: Save model to file as pretrain.
2023-06-08 06:53:28.166: [iter 142 : loss : 0.4190 = 0.0048 + 0.3993 + 0.0149, time: 189.709564]
2023-06-08 06:54:16.505: epoch 142:	0.00657789  	0.10539306  	0.04980685  	0.03760578  	0.03805449  
2023-06-08 06:57:21.052: [iter 143 : loss : 0.4190 = 0.0049 + 0.3993 + 0.0148, time: 183.905242]
2023-06-08 06:58:10.524: epoch 143:	0.00656803  	0.10519926  	0.04973261  	0.03755114  	0.03800559  
2023-06-08 07:01:16.448: [iter 144 : loss : 0.4191 = 0.0049 + 0.3993 + 0.0148, time: 185.278455]
2023-06-08 07:02:06.557: epoch 144:	0.00658106  	0.10542708  	0.04975573  	0.03751356  	0.03795508  
2023-06-08 07:05:13.341: [iter 145 : loss : 0.4191 = 0.0050 + 0.3993 + 0.0149, time: 186.159063]
2023-06-08 07:06:16.200: epoch 145:	0.00657436  	0.10528181  	0.04975668  	0.03755452  	0.03800198  
2023-06-08 07:09:22.410: [iter 146 : loss : 0.4191 = 0.0049 + 0.3993 + 0.0148, time: 185.575589]
2023-06-08 07:10:25.353: epoch 146:	0.00659037  	0.10554970  	0.04985370  	0.03761013  	0.03807846  
2023-06-08 07:10:25.353: Found a better model.
2023-06-08 07:10:25.353: Save model to file as pretrain.
2023-06-08 07:13:35.418: [iter 147 : loss : 0.4190 = 0.0048 + 0.3993 + 0.0148, time: 184.910142]
2023-06-08 07:14:38.604: epoch 147:	0.00659521  	0.10559870  	0.04988629  	0.03767064  	0.03811273  
2023-06-08 07:14:38.605: Found a better model.
2023-06-08 07:14:38.605: Save model to file as pretrain.
2023-06-08 07:17:46.867: [iter 148 : loss : 0.4190 = 0.0049 + 0.3993 + 0.0148, time: 183.126213]
2023-06-08 07:18:36.432: epoch 148:	0.00658553  	0.10549636  	0.04978220  	0.03753665  	0.03798595  
2023-06-08 07:21:41.674: [iter 149 : loss : 0.4191 = 0.0049 + 0.3993 + 0.0149, time: 184.595399]
2023-06-08 07:22:30.620: epoch 149:	0.00658478  	0.10541017  	0.04980608  	0.03755340  	0.03801177  
2023-06-08 07:25:36.246: [iter 150 : loss : 0.4190 = 0.0048 + 0.3994 + 0.0148, time: 184.984672]
2023-06-08 07:26:24.904: epoch 150:	0.00657342  	0.10534529  	0.04985696  	0.03766895  	0.03809806  
2023-06-08 07:29:30.962: [iter 151 : loss : 0.4190 = 0.0048 + 0.3993 + 0.0148, time: 185.427139]
2023-06-08 07:30:18.396: epoch 151:	0.00659483  	0.10568361  	0.04997236  	0.03773462  	0.03816871  
2023-06-08 07:30:18.396: Found a better model.
2023-06-08 07:30:18.396: Save model to file as pretrain.
2023-06-08 07:33:27.754: [iter 152 : loss : 0.4190 = 0.0048 + 0.3993 + 0.0148, time: 184.348777]
2023-06-08 07:34:29.961: epoch 152:	0.00659055  	0.10554898  	0.04990079  	0.03768034  	0.03811660  
2023-06-08 07:37:34.777: [iter 153 : loss : 0.4190 = 0.0048 + 0.3993 + 0.0148, time: 184.174217]
2023-06-08 07:38:42.887: epoch 153:	0.00659241  	0.10554615  	0.04993358  	0.03773737  	0.03816356  
2023-06-08 07:41:48.371: [iter 154 : loss : 0.4190 = 0.0049 + 0.3993 + 0.0148, time: 184.843757]
2023-06-08 07:42:37.602: epoch 154:	0.00660432  	0.10579810  	0.04991492  	0.03762197  	0.03805411  
2023-06-08 07:42:37.602: Found a better model.
2023-06-08 07:42:37.602: Save model to file as pretrain.
2023-06-08 07:45:48.483: [iter 155 : loss : 0.4190 = 0.0049 + 0.3993 + 0.0148, time: 185.842417]
2023-06-08 07:46:51.063: epoch 155:	0.00662051  	0.10596832  	0.04997704  	0.03763580  	0.03807976  
2023-06-08 07:46:51.063: Found a better model.
2023-06-08 07:46:51.063: Save model to file as pretrain.
2023-06-08 07:50:01.060: [iter 156 : loss : 0.4189 = 0.0048 + 0.3993 + 0.0148, time: 184.868643]
2023-06-08 07:50:50.931: epoch 156:	0.00659836  	0.10558769  	0.04988644  	0.03761102  	0.03804237  
2023-06-08 07:53:56.266: [iter 157 : loss : 0.4190 = 0.0049 + 0.3993 + 0.0148, time: 184.685967]
2023-06-08 07:54:47.395: epoch 157:	0.00661475  	0.10587952  	0.05000352  	0.03770557  	0.03814085  
2023-06-08 07:57:52.341: [iter 158 : loss : 0.4190 = 0.0048 + 0.3993 + 0.0148, time: 184.303104]
2023-06-08 07:58:40.945: epoch 158:	0.00660283  	0.10559836  	0.04994205  	0.03769981  	0.03813772  
2023-06-08 08:01:47.343: [iter 159 : loss : 0.4189 = 0.0048 + 0.3993 + 0.0148, time: 185.743740]
2023-06-08 08:02:47.377: epoch 159:	0.00660172  	0.10557490  	0.04991061  	0.03766571  	0.03810776  
2023-06-08 08:05:53.308: [iter 160 : loss : 0.4190 = 0.0048 + 0.3993 + 0.0148, time: 185.272808]
2023-06-08 08:06:54.032: epoch 160:	0.00660190  	0.10558085  	0.04988826  	0.03764199  	0.03807296  
2023-06-08 08:09:58.266: [iter 161 : loss : 0.4190 = 0.0049 + 0.3993 + 0.0148, time: 183.600634]
2023-06-08 08:10:48.521: epoch 161:	0.00661716  	0.10580222  	0.05000674  	0.03774173  	0.03819674  
2023-06-08 08:13:54.903: [iter 162 : loss : 0.4190 = 0.0049 + 0.3993 + 0.0148, time: 185.708628]
2023-06-08 08:14:44.997: epoch 162:	0.00661456  	0.10580295  	0.05000342  	0.03773346  	0.03817572  
2023-06-08 08:17:48.502: [iter 163 : loss : 0.4189 = 0.0048 + 0.3993 + 0.0148, time: 182.847909]
2023-06-08 08:18:38.031: epoch 163:	0.00661587  	0.10584866  	0.05002104  	0.03774944  	0.03818623  
2023-06-08 08:21:43.929: [iter 164 : loss : 0.4190 = 0.0048 + 0.3993 + 0.0148, time: 185.241113]
2023-06-08 08:22:33.922: epoch 164:	0.00664100  	0.10625133  	0.05014550  	0.03782766  	0.03826349  
2023-06-08 08:22:33.922: Found a better model.
2023-06-08 08:22:33.922: Save model to file as pretrain.
2023-06-08 08:25:42.930: [iter 165 : loss : 0.4190 = 0.0049 + 0.3993 + 0.0148, time: 183.885946]
2023-06-08 08:26:45.043: epoch 165:	0.00662406  	0.10591266  	0.05009626  	0.03782301  	0.03827398  
2023-06-08 08:29:55.374: [iter 166 : loss : 0.4190 = 0.0049 + 0.3993 + 0.0148, time: 189.682241]
2023-06-08 08:30:45.150: epoch 166:	0.00664100  	0.10617017  	0.05014976  	0.03782171  	0.03827348  
2023-06-08 08:33:51.385: [iter 167 : loss : 0.4190 = 0.0048 + 0.3993 + 0.0148, time: 185.584463]
2023-06-08 08:34:40.182: epoch 167:	0.00663243  	0.10605599  	0.05007869  	0.03776740  	0.03821752  
2023-06-08 08:37:46.964: [iter 168 : loss : 0.4189 = 0.0048 + 0.3993 + 0.0148, time: 186.145170]
2023-06-08 08:38:47.921: epoch 168:	0.00662964  	0.10610843  	0.05016571  	0.03788479  	0.03835076  
2023-06-08 08:41:50.122: [iter 169 : loss : 0.4189 = 0.0048 + 0.3993 + 0.0148, time: 181.568008]
2023-06-08 08:42:50.060: epoch 169:	0.00663745  	0.10617007  	0.05018118  	0.03789361  	0.03835628  
2023-06-08 08:45:56.723: [iter 170 : loss : 0.4190 = 0.0049 + 0.3993 + 0.0148, time: 186.016406]
2023-06-08 08:46:55.783: epoch 170:	0.00666166  	0.10655235  	0.05030454  	0.03793429  	0.03840617  
2023-06-08 08:46:55.783: Found a better model.
2023-06-08 08:46:55.783: Save model to file as pretrain.
2023-06-08 08:50:07.231: [iter 171 : loss : 0.4189 = 0.0048 + 0.3993 + 0.0148, time: 186.138349]
2023-06-08 08:50:58.235: epoch 171:	0.00664211  	0.10623084  	0.05022812  	0.03793745  	0.03838199  
2023-06-08 08:54:05.616: [iter 172 : loss : 0.4189 = 0.0048 + 0.3993 + 0.0148, time: 186.735251]
2023-06-08 08:54:58.293: epoch 172:	0.00663988  	0.10625526  	0.05026218  	0.03799378  	0.03845348  
2023-06-08 08:58:05.870: [iter 173 : loss : 0.4190 = 0.0049 + 0.3993 + 0.0148, time: 186.917771]
2023-06-08 08:58:55.195: epoch 173:	0.00663839  	0.10614199  	0.05022556  	0.03799321  	0.03843265  
2023-06-08 09:02:02.047: [iter 174 : loss : 0.4189 = 0.0048 + 0.3993 + 0.0148, time: 186.222852]
2023-06-08 09:02:50.624: epoch 174:	0.00664286  	0.10626974  	0.05032817  	0.03807490  	0.03851501  
2023-06-08 09:05:55.478: [iter 175 : loss : 0.4189 = 0.0048 + 0.3993 + 0.0148, time: 184.221210]
2023-06-08 09:06:44.564: epoch 175:	0.00664583  	0.10631644  	0.05033388  	0.03806484  	0.03851041  
2023-06-08 09:09:51.568: [iter 176 : loss : 0.4189 = 0.0048 + 0.3993 + 0.0148, time: 186.361161]
2023-06-08 09:10:39.801: epoch 176:	0.00664360  	0.10629183  	0.05027848  	0.03798693  	0.03843807  
2023-06-08 09:13:46.663: [iter 177 : loss : 0.4189 = 0.0048 + 0.3993 + 0.0148, time: 186.219388]
2023-06-08 09:14:35.727: epoch 177:	0.00663578  	0.10610944  	0.05032131  	0.03809172  	0.03853463  
2023-06-08 09:17:39.955: [iter 178 : loss : 0.4190 = 0.0049 + 0.3993 + 0.0148, time: 183.606011]
2023-06-08 09:18:30.314: epoch 178:	0.00663615  	0.10609189  	0.05034503  	0.03812796  	0.03857194  
2023-06-08 09:21:36.287: [iter 179 : loss : 0.4190 = 0.0049 + 0.3993 + 0.0148, time: 185.330423]
2023-06-08 09:22:25.204: epoch 179:	0.00663578  	0.10615178  	0.05047630  	0.03830236  	0.03874602  
2023-06-08 09:25:30.621: [iter 180 : loss : 0.4189 = 0.0048 + 0.3993 + 0.0148, time: 184.765986]
2023-06-08 09:26:30.895: epoch 180:	0.00665793  	0.10652298  	0.05042499  	0.03810689  	0.03853915  
2023-06-08 09:29:34.837: [iter 181 : loss : 0.4190 = 0.0048 + 0.3993 + 0.0148, time: 183.284284]
2023-06-08 09:30:34.848: epoch 181:	0.00665774  	0.10649222  	0.05036864  	0.03803843  	0.03848632  
2023-06-08 09:33:40.327: [iter 182 : loss : 0.4189 = 0.0048 + 0.3993 + 0.0148, time: 184.829662]
2023-06-08 09:34:40.408: epoch 182:	0.00666482  	0.10658430  	0.05041093  	0.03806994  	0.03851532  
2023-06-08 09:34:40.409: Found a better model.
2023-06-08 09:34:40.409: Save model to file as pretrain.
2023-06-08 09:37:51.462: [iter 183 : loss : 0.4189 = 0.0048 + 0.3993 + 0.0148, time: 186.094400]
2023-06-08 09:38:41.263: epoch 183:	0.00665068  	0.10635802  	0.05040828  	0.03813481  	0.03859232  
2023-06-08 09:42:00.015: [iter 184 : loss : 0.4189 = 0.0048 + 0.3993 + 0.0148, time: 198.116316]
2023-06-08 09:43:09.938: epoch 184:	0.00664789  	0.10630032  	0.05037902  	0.03813351  	0.03858484  
2023-06-08 09:46:13.148: [iter 185 : loss : 0.4189 = 0.0048 + 0.3993 + 0.0148, time: 182.545867]
2023-06-08 09:47:22.364: epoch 185:	0.00665160  	0.10630811  	0.05035496  	0.03805724  	0.03851680  
2023-06-08 09:50:27.747: [iter 186 : loss : 0.4188 = 0.0048 + 0.3993 + 0.0148, time: 184.729016]
2023-06-08 09:51:36.996: epoch 186:	0.00665793  	0.10650776  	0.05049334  	0.03822568  	0.03869115  
2023-06-08 09:54:55.247: [iter 187 : loss : 0.4189 = 0.0048 + 0.3993 + 0.0148, time: 197.611018]
2023-06-08 09:56:05.193: epoch 187:	0.00665719  	0.10645533  	0.05047446  	0.03817485  	0.03863480  
2023-06-08 09:59:08.262: [iter 188 : loss : 0.4189 = 0.0048 + 0.3993 + 0.0148, time: 182.421041]
2023-06-08 09:59:57.758: epoch 188:	0.00665347  	0.10655367  	0.05054187  	0.03829151  	0.03875136  
2023-06-08 10:03:04.642: [iter 189 : loss : 0.4189 = 0.0048 + 0.3993 + 0.0148, time: 186.242455]
2023-06-08 10:04:05.247: epoch 189:	0.00666259  	0.10671032  	0.05057218  	0.03827592  	0.03872410  
2023-06-08 10:04:05.248: Found a better model.
2023-06-08 10:04:05.248: Save model to file as pretrain.
2023-06-08 10:07:16.764: [iter 190 : loss : 0.4189 = 0.0048 + 0.3993 + 0.0148, time: 186.688892]
2023-06-08 10:08:19.448: epoch 190:	0.00664808  	0.10646133  	0.05058836  	0.03835640  	0.03882069  
2023-06-08 10:11:24.297: [iter 191 : loss : 0.4189 = 0.0048 + 0.3993 + 0.0148, time: 184.180878]
2023-06-08 10:12:27.053: epoch 191:	0.00665459  	0.10649101  	0.05055601  	0.03830589  	0.03877806  
2023-06-08 10:15:31.851: [iter 192 : loss : 0.4189 = 0.0048 + 0.3993 + 0.0148, time: 184.144354]
2023-06-08 10:16:31.021: epoch 192:	0.00664379  	0.10641661  	0.05055600  	0.03831508  	0.03877252  
2023-06-08 10:19:37.488: [iter 193 : loss : 0.4189 = 0.0048 + 0.3993 + 0.0148, time: 185.812948]
2023-06-08 10:20:28.890: epoch 193:	0.00666836  	0.10672553  	0.05057219  	0.03826598  	0.03871187  
2023-06-08 10:20:28.890: Found a better model.
2023-06-08 10:20:28.890: Save model to file as pretrain.
2023-06-08 10:23:40.053: [iter 194 : loss : 0.4189 = 0.0048 + 0.3993 + 0.0148, time: 185.967446]
2023-06-08 10:24:29.470: epoch 194:	0.00665496  	0.10656033  	0.05057023  	0.03831258  	0.03876814  
2023-06-08 10:27:34.882: [iter 195 : loss : 0.4188 = 0.0047 + 0.3993 + 0.0148, time: 184.760326]
2023-06-08 10:28:24.058: epoch 195:	0.00665086  	0.10649741  	0.05056944  	0.03831427  	0.03878595  
2023-06-08 10:31:29.025: [iter 196 : loss : 0.4189 = 0.0048 + 0.3993 + 0.0148, time: 184.312807]
2023-06-08 10:32:18.213: epoch 196:	0.00666762  	0.10678808  	0.05062936  	0.03833152  	0.03879702  
2023-06-08 10:32:18.213: Found a better model.
2023-06-08 10:32:18.213: Save model to file as pretrain.
2023-06-08 10:35:29.917: [iter 197 : loss : 0.4188 = 0.0048 + 0.3993 + 0.0148, time: 186.656450]
2023-06-08 10:36:19.341: epoch 197:	0.00666334  	0.10666147  	0.05059246  	0.03829323  	0.03875918  
2023-06-08 10:39:28.688: [iter 198 : loss : 0.4189 = 0.0047 + 0.3993 + 0.0148, time: 188.702235]
2023-06-08 10:40:19.588: epoch 198:	0.00666501  	0.10673536  	0.05061224  	0.03831713  	0.03877509  
2023-06-08 10:43:25.699: [iter 199 : loss : 0.4188 = 0.0047 + 0.3993 + 0.0148, time: 185.454142]
2023-06-08 10:44:15.454: epoch 199:	0.00666110  	0.10667592  	0.05062756  	0.03835451  	0.03880597  
2023-06-08 10:47:23.984: [iter 200 : loss : 0.4188 = 0.0048 + 0.3993 + 0.0148, time: 187.839370]
2023-06-08 10:48:13.851: epoch 200:	0.00665068  	0.10654721  	0.05054764  	0.03829850  	0.03874910  
2023-06-08 10:51:22.027: [iter 201 : loss : 0.4189 = 0.0048 + 0.3993 + 0.0148, time: 187.535935]
2023-06-08 10:52:25.528: epoch 201:	0.00665291  	0.10663719  	0.05059244  	0.03831195  	0.03875703  
2023-06-08 10:55:31.911: [iter 202 : loss : 0.4189 = 0.0048 + 0.3993 + 0.0148, time: 185.741453]
2023-06-08 10:56:21.252: epoch 202:	0.00666985  	0.10680340  	0.05062307  	0.03829308  	0.03875428  
2023-06-08 10:56:21.253: Found a better model.
2023-06-08 10:56:21.253: Save model to file as pretrain.
2023-06-08 10:59:33.156: [iter 203 : loss : 0.4188 = 0.0047 + 0.3993 + 0.0148, time: 186.679798]
2023-06-08 11:00:23.407: epoch 203:	0.00667748  	0.10687870  	0.05057884  	0.03819760  	0.03865556  
2023-06-08 11:00:23.407: Found a better model.
2023-06-08 11:00:23.408: Save model to file as pretrain.
2023-06-08 11:03:33.317: [iter 204 : loss : 0.4189 = 0.0048 + 0.3993 + 0.0148, time: 184.903913]
2023-06-08 11:04:36.621: epoch 204:	0.00665719  	0.10662384  	0.05050834  	0.03818294  	0.03863962  
2023-06-08 11:07:42.847: [iter 205 : loss : 0.4189 = 0.0048 + 0.3993 + 0.0148, time: 185.594104]
2023-06-08 11:08:33.267: epoch 205:	0.00667897  	0.10686010  	0.05056191  	0.03819823  	0.03865963  
2023-06-08 11:11:41.176: [iter 206 : loss : 0.4189 = 0.0048 + 0.3993 + 0.0148, time: 187.271619]
2023-06-08 11:12:31.770: epoch 206:	0.00665886  	0.10658068  	0.05044835  	0.03811752  	0.03856113  
2023-06-08 11:15:36.704: [iter 207 : loss : 0.4188 = 0.0047 + 0.3993 + 0.0148, time: 184.296443]
2023-06-08 11:16:40.749: epoch 207:	0.00664994  	0.10644721  	0.05042521  	0.03812726  	0.03858433  
2023-06-08 11:19:46.748: [iter 208 : loss : 0.4188 = 0.0047 + 0.3993 + 0.0148, time: 185.352124]
2023-06-08 11:20:39.789: epoch 208:	0.00664770  	0.10637800  	0.05045890  	0.03818810  	0.03864055  
2023-06-08 11:23:47.156: [iter 209 : loss : 0.4188 = 0.0048 + 0.3993 + 0.0148, time: 186.618214]
2023-06-08 11:24:49.397: epoch 209:	0.00666297  	0.10672848  	0.05058317  	0.03828492  	0.03871595  
2023-06-08 11:27:56.012: [iter 210 : loss : 0.4188 = 0.0047 + 0.3993 + 0.0148, time: 185.985338]
2023-06-08 11:28:58.247: epoch 210:	0.00666743  	0.10677323  	0.05062321  	0.03827943  	0.03872836  
2023-06-08 11:32:01.921: [iter 211 : loss : 0.4188 = 0.0048 + 0.3993 + 0.0148, time: 183.022337]
2023-06-08 11:32:53.594: epoch 211:	0.00667190  	0.10682255  	0.05065832  	0.03833376  	0.03878307  
2023-06-08 11:36:01.639: [iter 212 : loss : 0.4189 = 0.0048 + 0.3993 + 0.0148, time: 187.397703]
2023-06-08 11:36:52.041: epoch 212:	0.00666352  	0.10673473  	0.05060458  	0.03826448  	0.03870769  
2023-06-08 11:40:00.024: [iter 213 : loss : 0.4188 = 0.0048 + 0.3993 + 0.0148, time: 187.329193]
2023-06-08 11:40:55.145: epoch 213:	0.00666594  	0.10677683  	0.05057372  	0.03822395  	0.03866862  
2023-06-08 11:44:01.790: [iter 214 : loss : 0.4188 = 0.0048 + 0.3993 + 0.0148, time: 185.963135]
2023-06-08 11:45:05.374: epoch 214:	0.00667134  	0.10690445  	0.05064693  	0.03830497  	0.03874597  
2023-06-08 11:45:05.374: Found a better model.
2023-06-08 11:45:05.375: Save model to file as pretrain.
2023-06-08 11:48:24.403: [iter 215 : loss : 0.4188 = 0.0047 + 0.3993 + 0.0148, time: 193.665446]
2023-06-08 11:49:29.591: epoch 215:	0.00668493  	0.10706596  	0.05067542  	0.03830009  	0.03874709  
2023-06-08 11:49:29.591: Found a better model.
2023-06-08 11:49:29.591: Save model to file as pretrain.
2023-06-08 11:52:54.016: [iter 216 : loss : 0.4188 = 0.0048 + 0.3993 + 0.0148, time: 198.982828]
2023-06-08 11:53:47.334: epoch 216:	0.00667264  	0.10683291  	0.05058906  	0.03823991  	0.03868591  
2023-06-08 11:56:54.330: [iter 217 : loss : 0.4188 = 0.0048 + 0.3993 + 0.0148, time: 186.356005]
2023-06-08 11:57:43.839: epoch 217:	0.00667748  	0.10689814  	0.05055437  	0.03818819  	0.03863200  
2023-06-08 12:00:51.921: [iter 218 : loss : 0.4189 = 0.0048 + 0.3993 + 0.0148, time: 187.420941]
2023-06-08 12:01:40.634: epoch 218:	0.00666575  	0.10659197  	0.05048592  	0.03815442  	0.03859994  
2023-06-08 12:04:49.151: [iter 219 : loss : 0.4188 = 0.0047 + 0.3993 + 0.0148, time: 187.848292]
2023-06-08 12:05:41.718: epoch 219:	0.00665812  	0.10653219  	0.05048682  	0.03819373  	0.03864124  
2023-06-08 12:08:49.843: [iter 220 : loss : 0.4188 = 0.0047 + 0.3993 + 0.0148, time: 187.483359]
2023-06-08 12:09:50.544: epoch 220:	0.00664770  	0.10640359  	0.05043507  	0.03814230  	0.03858255  
2023-06-08 12:12:56.997: [iter 221 : loss : 0.4188 = 0.0047 + 0.3993 + 0.0148, time: 185.805733]
2023-06-08 12:13:46.166: epoch 221:	0.00668046  	0.10700855  	0.05059320  	0.03819698  	0.03864150  
2023-06-08 12:16:52.715: [iter 222 : loss : 0.4188 = 0.0048 + 0.3993 + 0.0148, time: 185.915113]
2023-06-08 12:17:40.797: epoch 222:	0.00666668  	0.10671850  	0.05056335  	0.03822711  	0.03866047  
2023-06-08 12:20:48.924: [iter 223 : loss : 0.4187 = 0.0047 + 0.3993 + 0.0148, time: 187.487042]
2023-06-08 12:21:38.682: epoch 223:	0.00669758  	0.10719781  	0.05071247  	0.03829705  	0.03873542  
2023-06-08 12:21:38.682: Found a better model.
2023-06-08 12:21:38.682: Save model to file as pretrain.
2023-06-08 12:24:49.482: [iter 224 : loss : 0.4188 = 0.0048 + 0.3993 + 0.0148, time: 185.742743]
2023-06-08 12:25:42.218: epoch 224:	0.00669293  	0.10713317  	0.05060559  	0.03814681  	0.03858527  
2023-06-08 12:28:50.212: [iter 225 : loss : 0.4189 = 0.0048 + 0.3993 + 0.0148, time: 187.353573]
2023-06-08 12:29:53.437: epoch 225:	0.00669032  	0.10706475  	0.05063256  	0.03821633  	0.03865413  
2023-06-08 12:33:00.781: [iter 226 : loss : 0.4188 = 0.0047 + 0.3993 + 0.0148, time: 186.699536]
2023-06-08 12:33:50.656: epoch 226:	0.00669498  	0.10715704  	0.05065635  	0.03820362  	0.03866294  
2023-06-08 12:36:54.225: [iter 227 : loss : 0.4188 = 0.0047 + 0.3993 + 0.0148, time: 182.937600]
2023-06-08 12:37:44.158: epoch 227:	0.00667916  	0.10688091  	0.05059331  	0.03822983  	0.03866377  
2023-06-08 12:40:48.443: [iter 228 : loss : 0.4187 = 0.0047 + 0.3993 + 0.0148, time: 183.643763]
2023-06-08 12:41:39.762: epoch 228:	0.00668176  	0.10688736  	0.05063621  	0.03826278  	0.03872086  
2023-06-08 12:44:47.552: [iter 229 : loss : 0.4188 = 0.0047 + 0.3993 + 0.0147, time: 187.156329]
2023-06-08 12:45:38.504: epoch 229:	0.00668920  	0.10706881  	0.05072011  	0.03832007  	0.03877627  
2023-06-08 12:48:45.522: [iter 230 : loss : 0.4188 = 0.0047 + 0.3993 + 0.0148, time: 186.389548]
2023-06-08 12:49:35.526: epoch 230:	0.00668213  	0.10697913  	0.05068681  	0.03833201  	0.03879275  
2023-06-08 12:52:40.931: [iter 231 : loss : 0.4188 = 0.0047 + 0.3993 + 0.0148, time: 184.767142]
2023-06-08 12:53:32.262: epoch 231:	0.00669572  	0.10723169  	0.05068893  	0.03827678  	0.03871970  
2023-06-08 12:53:32.262: Found a better model.
2023-06-08 12:53:32.262: Save model to file as pretrain.
2023-06-08 12:56:45.466: [iter 232 : loss : 0.4188 = 0.0047 + 0.3993 + 0.0148, time: 188.039751]
2023-06-08 12:57:46.740: epoch 232:	0.00669014  	0.10707618  	0.05069410  	0.03829838  	0.03875217  
2023-06-08 13:00:51.888: [iter 233 : loss : 0.4187 = 0.0047 + 0.3993 + 0.0148, time: 184.511493]
2023-06-08 13:01:51.876: epoch 233:	0.00670726  	0.10727848  	0.05067526  	0.03819042  	0.03865743  
2023-06-08 13:01:51.876: Found a better model.
2023-06-08 13:01:51.876: Save model to file as pretrain.
2023-06-08 13:05:03.820: [iter 234 : loss : 0.4187 = 0.0047 + 0.3993 + 0.0148, time: 187.061920]
2023-06-08 13:06:07.411: epoch 234:	0.00670372  	0.10731707  	0.05075918  	0.03830414  	0.03876600  
2023-06-08 13:06:07.411: Found a better model.
2023-06-08 13:06:07.411: Save model to file as pretrain.
2023-06-08 13:09:17.524: [iter 235 : loss : 0.4188 = 0.0048 + 0.3993 + 0.0148, time: 184.777876]
2023-06-08 13:10:21.288: epoch 235:	0.00668586  	0.10705191  	0.05070061  	0.03830548  	0.03875570  
2023-06-08 13:13:27.171: [iter 236 : loss : 0.4188 = 0.0047 + 0.3993 + 0.0148, time: 185.230148]
2023-06-08 13:14:30.361: epoch 236:	0.00668679  	0.10707362  	0.05070926  	0.03832483  	0.03877096  
2023-06-08 13:17:37.541: [iter 237 : loss : 0.4188 = 0.0047 + 0.3993 + 0.0148, time: 186.539549]
2023-06-08 13:18:40.172: epoch 237:	0.00669144  	0.10714343  	0.05072068  	0.03833732  	0.03879225  
2023-06-08 13:21:54.507: [iter 238 : loss : 0.4188 = 0.0047 + 0.3993 + 0.0148, time: 193.688660]
2023-06-08 13:22:56.013: epoch 238:	0.00669516  	0.10717419  	0.05071913  	0.03829212  	0.03874489  
2023-06-08 13:26:16.181: [iter 239 : loss : 0.4188 = 0.0047 + 0.3993 + 0.0148, time: 199.503806]
2023-06-08 13:27:18.999: epoch 239:	0.00670503  	0.10730930  	0.05069364  	0.03822594  	0.03868873  
2023-06-08 13:30:23.996: [iter 240 : loss : 0.4188 = 0.0047 + 0.3993 + 0.0147, time: 184.359697]
2023-06-08 13:31:17.433: epoch 240:	0.00668940  	0.10707037  	0.05071880  	0.03833315  	0.03878079  
2023-06-08 13:34:24.365: [iter 241 : loss : 0.4188 = 0.0048 + 0.3993 + 0.0147, time: 186.268895]
2023-06-08 13:35:15.340: epoch 241:	0.00669405  	0.10712302  	0.05071083  	0.03830099  	0.03875469  
2023-06-08 13:38:23.086: [iter 242 : loss : 0.4187 = 0.0047 + 0.3993 + 0.0147, time: 187.093442]
2023-06-08 13:39:16.233: epoch 242:	0.00669014  	0.10710321  	0.05068130  	0.03831381  	0.03877378  
2023-06-08 13:42:21.671: [iter 243 : loss : 0.4188 = 0.0047 + 0.3993 + 0.0148, time: 184.783263]
2023-06-08 13:43:25.566: epoch 243:	0.00668102  	0.10701834  	0.05068665  	0.03833601  	0.03878976  
2023-06-08 13:46:33.872: [iter 244 : loss : 0.4187 = 0.0047 + 0.3993 + 0.0147, time: 187.629548]
2023-06-08 13:47:26.214: epoch 244:	0.00667600  	0.10691782  	0.05061112  	0.03824785  	0.03869519  
2023-06-08 13:50:32.883: [iter 245 : loss : 0.4187 = 0.0047 + 0.3993 + 0.0147, time: 186.025854]
2023-06-08 13:51:24.325: epoch 245:	0.00668829  	0.10718250  	0.05060004  	0.03815428  	0.03859553  
2023-06-08 13:54:30.609: [iter 246 : loss : 0.4188 = 0.0048 + 0.3993 + 0.0148, time: 185.639876]
2023-06-08 13:55:21.129: epoch 246:	0.00671378  	0.10759489  	0.05076662  	0.03825038  	0.03870161  
2023-06-08 13:55:21.130: Found a better model.
2023-06-08 13:55:21.130: Save model to file as pretrain.
2023-06-08 13:58:34.493: [iter 247 : loss : 0.4188 = 0.0048 + 0.3993 + 0.0148, time: 188.499325]
2023-06-08 13:59:39.956: epoch 247:	0.00672477  	0.10779121  	0.05082032  	0.03828197  	0.03873700  
2023-06-08 13:59:39.956: Found a better model.
2023-06-08 13:59:39.956: Save model to file as pretrain.
2023-06-08 14:02:52.134: [iter 248 : loss : 0.4187 = 0.0047 + 0.3993 + 0.0147, time: 187.076887]
2023-06-08 14:04:02.273: epoch 248:	0.00671862  	0.10765234  	0.05085604  	0.03833520  	0.03878766  
2023-06-08 14:07:06.346: [iter 249 : loss : 0.4187 = 0.0047 + 0.3993 + 0.0147, time: 183.426006]
2023-06-08 14:08:38.872: epoch 249:	0.00670931  	0.10752843  	0.05080095  	0.03829303  	0.03874946  
2023-06-08 14:11:44.751: [iter 250 : loss : 0.4187 = 0.0047 + 0.3993 + 0.0147, time: 185.222498]
2023-06-08 14:13:03.196: epoch 250:	0.00672495  	0.10772771  	0.05082382  	0.03828821  	0.03874154  
2023-06-08 14:16:09.569: [iter 251 : loss : 0.4188 = 0.0047 + 0.3993 + 0.0147, time: 185.730585]
2023-06-08 14:17:27.140: epoch 251:	0.00672290  	0.10769993  	0.05085624  	0.03834181  	0.03878207  
2023-06-08 14:20:32.942: [iter 252 : loss : 0.4188 = 0.0047 + 0.3993 + 0.0147, time: 185.148920]
2023-06-08 14:21:44.274: epoch 252:	0.00672439  	0.10767765  	0.05094977  	0.03848309  	0.03892290  
2023-06-08 14:24:48.894: [iter 253 : loss : 0.4188 = 0.0048 + 0.3993 + 0.0147, time: 183.969375]
2023-06-08 14:25:49.476: epoch 253:	0.00671415  	0.10758862  	0.05095936  	0.03852526  	0.03897756  
2023-06-08 14:28:56.467: [iter 254 : loss : 0.4187 = 0.0047 + 0.3993 + 0.0147, time: 186.341854]
2023-06-08 14:29:59.441: epoch 254:	0.00673482  	0.10787493  	0.05104881  	0.03857678  	0.03904172  
2023-06-08 14:29:59.441: Found a better model.
2023-06-08 14:29:59.441: Save model to file as pretrain.
2023-06-08 14:33:09.697: [iter 255 : loss : 0.4187 = 0.0047 + 0.3993 + 0.0147, time: 185.379596]
2023-06-08 14:34:20.734: epoch 255:	0.00672793  	0.10771326  	0.05097602  	0.03851720  	0.03897414  
2023-06-08 14:37:26.119: [iter 256 : loss : 0.4188 = 0.0047 + 0.3993 + 0.0147, time: 184.735309]
2023-06-08 14:38:37.098: epoch 256:	0.00671546  	0.10756160  	0.05088484  	0.03842467  	0.03888933  
2023-06-08 14:41:44.242: [iter 257 : loss : 0.4187 = 0.0047 + 0.3993 + 0.0147, time: 186.480027]
2023-06-08 14:42:48.061: epoch 257:	0.00672551  	0.10770760  	0.05106882  	0.03863914  	0.03910567  
2023-06-08 14:45:54.767: [iter 258 : loss : 0.4187 = 0.0047 + 0.3993 + 0.0147, time: 186.063696]
2023-06-08 14:47:01.674: epoch 258:	0.00672328  	0.10772932  	0.05099953  	0.03854519  	0.03899923  
2023-06-08 14:50:08.795: [iter 259 : loss : 0.4187 = 0.0047 + 0.3993 + 0.0147, time: 186.465823]
2023-06-08 14:51:19.413: epoch 259:	0.00673352  	0.10784943  	0.05108827  	0.03865620  	0.03912318  
2023-06-08 14:54:33.567: [iter 260 : loss : 0.4187 = 0.0047 + 0.3993 + 0.0147, time: 193.508669]
2023-06-08 14:55:43.729: epoch 260:	0.00673444  	0.10787070  	0.05102263  	0.03852570  	0.03898336  
2023-06-08 14:58:49.403: [iter 261 : loss : 0.4187 = 0.0047 + 0.3993 + 0.0147, time: 185.003886]
2023-06-08 15:00:01.680: epoch 261:	0.00674319  	0.10798638  	0.05095841  	0.03840793  	0.03885215  
2023-06-08 15:00:01.681: Found a better model.
2023-06-08 15:00:01.681: Save model to file as pretrain.
2023-06-08 15:03:09.594: [iter 262 : loss : 0.4185 = 0.0046 + 0.3993 + 0.0147, time: 182.512669]
2023-06-08 15:04:19.686: epoch 262:	0.00673035  	0.10774105  	0.05094493  	0.03843750  	0.03888802  
2023-06-08 15:07:25.502: [iter 263 : loss : 0.4187 = 0.0047 + 0.3993 + 0.0147, time: 185.152147]
2023-06-08 15:08:42.350: epoch 263:	0.00672626  	0.10759375  	0.05091599  	0.03842995  	0.03888812  
2023-06-08 15:11:51.853: [iter 264 : loss : 0.4187 = 0.0047 + 0.3993 + 0.0147, time: 188.776431]
2023-06-08 15:13:03.122: epoch 264:	0.00673985  	0.10788511  	0.05092023  	0.03836592  	0.03881913  
2023-06-08 15:16:08.977: [iter 265 : loss : 0.4186 = 0.0046 + 0.3993 + 0.0147, time: 185.159441]
2023-06-08 15:17:34.456: epoch 265:	0.00674078  	0.10794328  	0.05095099  	0.03837617  	0.03882817  
2023-06-08 15:20:47.203: [iter 266 : loss : 0.4188 = 0.0047 + 0.3993 + 0.0147, time: 192.111926]
2023-06-08 15:21:49.752: epoch 266:	0.00673557  	0.10798444  	0.05093125  	0.03835138  	0.03880057  
2023-06-08 15:24:55.461: [iter 267 : loss : 0.4188 = 0.0047 + 0.3993 + 0.0147, time: 185.073078]
2023-06-08 15:25:58.259: epoch 267:	0.00674934  	0.10805190  	0.05099151  	0.03840876  	0.03885177  
2023-06-08 15:25:58.259: Found a better model.
2023-06-08 15:25:58.259: Save model to file as pretrain.
2023-06-08 15:29:11.071: [iter 268 : loss : 0.4186 = 0.0046 + 0.3993 + 0.0147, time: 187.640835]
2023-06-08 15:30:11.880: epoch 268:	0.00674785  	0.10807765  	0.05105561  	0.03852438  	0.03897742  
2023-06-08 15:30:11.880: Found a better model.
2023-06-08 15:30:11.880: Save model to file as pretrain.
2023-06-08 15:33:21.839: [iter 269 : loss : 0.4187 = 0.0047 + 0.3993 + 0.0147, time: 184.726379]
2023-06-08 15:34:25.958: epoch 269:	0.00674096  	0.10793077  	0.05096052  	0.03843737  	0.03887913  
2023-06-08 15:37:45.604: [iter 270 : loss : 0.4187 = 0.0047 + 0.3993 + 0.0147, time: 198.988006]
2023-06-08 15:38:48.540: epoch 270:	0.00672868  	0.10769746  	0.05099117  	0.03852626  	0.03898312  
2023-06-08 15:41:54.181: [iter 271 : loss : 0.4187 = 0.0047 + 0.3993 + 0.0147, time: 184.991833]
2023-06-08 15:42:46.356: epoch 271:	0.00673743  	0.10782155  	0.05106400  	0.03862038  	0.03908190  
2023-06-08 15:45:53.732: [iter 272 : loss : 0.4187 = 0.0047 + 0.3993 + 0.0147, time: 186.724594]
2023-06-08 15:46:45.132: epoch 272:	0.00673538  	0.10773468  	0.05103575  	0.03858547  	0.03903909  
2023-06-08 15:49:50.563: [iter 273 : loss : 0.4188 = 0.0048 + 0.3993 + 0.0147, time: 184.796475]
2023-06-08 15:50:41.538: epoch 273:	0.00671043  	0.10745501  	0.05094068  	0.03853930  	0.03900750  
2023-06-08 15:53:47.138: [iter 274 : loss : 0.4187 = 0.0047 + 0.3993 + 0.0147, time: 184.947533]
2023-06-08 15:54:43.727: epoch 274:	0.00671229  	0.10744578  	0.05101275  	0.03863985  	0.03912002  
2023-06-08 15:58:04.614: [iter 275 : loss : 0.4188 = 0.0048 + 0.3993 + 0.0147, time: 200.230089]
2023-06-08 15:58:54.712: epoch 275:	0.00671080  	0.10744486  	0.05100968  	0.03864143  	0.03911150  
2023-06-08 16:01:59.880: [iter 276 : loss : 0.4187 = 0.0047 + 0.3993 + 0.0147, time: 184.521182]
2023-06-08 16:02:49.478: epoch 276:	0.00671509  	0.10743411  	0.05101455  	0.03864475  	0.03911700  
2023-06-08 16:05:58.139: [iter 277 : loss : 0.4186 = 0.0046 + 0.3993 + 0.0147, time: 188.016008]
2023-06-08 16:06:48.462: epoch 277:	0.00671639  	0.10749997  	0.05106381  	0.03867472  	0.03914226  
2023-06-08 16:09:54.453: [iter 278 : loss : 0.4188 = 0.0047 + 0.3993 + 0.0147, time: 185.347903]
2023-06-08 16:10:45.707: epoch 278:	0.00674040  	0.10784733  	0.05109239  	0.03862651  	0.03908492  
2023-06-08 16:13:50.273: [iter 279 : loss : 0.4187 = 0.0047 + 0.3993 + 0.0147, time: 183.923232]
2023-06-08 16:14:41.477: epoch 279:	0.00672700  	0.10762733  	0.05101959  	0.03858869  	0.03906410  
2023-06-08 16:17:50.822: [iter 280 : loss : 0.4187 = 0.0047 + 0.3993 + 0.0147, time: 188.700738]
2023-06-08 16:18:41.816: epoch 280:	0.00672067  	0.10753818  	0.05103128  	0.03862785  	0.03909750  
2023-06-08 16:21:49.205: [iter 281 : loss : 0.4187 = 0.0047 + 0.3993 + 0.0147, time: 186.733231]
2023-06-08 16:22:40.802: epoch 281:	0.00673091  	0.10774166  	0.05108569  	0.03867424  	0.03913366  
2023-06-08 16:25:48.940: [iter 282 : loss : 0.4186 = 0.0046 + 0.3993 + 0.0147, time: 187.493928]
2023-06-08 16:26:41.984: epoch 282:	0.00671714  	0.10753950  	0.05096646  	0.03856737  	0.03903260  
2023-06-08 16:29:48.099: [iter 283 : loss : 0.4187 = 0.0047 + 0.3993 + 0.0147, time: 185.466087]
2023-06-08 16:30:36.501: epoch 283:	0.00671509  	0.10741992  	0.05093370  	0.03855841  	0.03900598  
2023-06-08 16:33:44.062: [iter 284 : loss : 0.4187 = 0.0047 + 0.3993 + 0.0147, time: 186.918598]
2023-06-08 16:34:33.947: epoch 284:	0.00671862  	0.10753097  	0.05093480  	0.03851873  	0.03896721  
2023-06-08 16:37:40.273: [iter 285 : loss : 0.4187 = 0.0047 + 0.3993 + 0.0147, time: 185.684228]
2023-06-08 16:38:31.237: epoch 285:	0.00671826  	0.10747033  	0.05100644  	0.03864092  	0.03909291  
2023-06-08 16:41:35.909: [iter 286 : loss : 0.4187 = 0.0047 + 0.3993 + 0.0147, time: 184.039938]
2023-06-08 16:42:25.550: epoch 286:	0.00672644  	0.10773671  	0.05103697  	0.03859724  	0.03906056  
2023-06-08 16:45:31.495: [iter 287 : loss : 0.4187 = 0.0047 + 0.3993 + 0.0147, time: 185.308909]
2023-06-08 16:46:20.378: epoch 287:	0.00672569  	0.10766793  	0.05108272  	0.03868971  	0.03914105  
2023-06-08 16:49:23.932: [iter 288 : loss : 0.4187 = 0.0048 + 0.3993 + 0.0147, time: 182.911186]
2023-06-08 16:50:12.819: epoch 288:	0.00673035  	0.10775109  	0.05113341  	0.03875734  	0.03922347  
2023-06-08 16:50:12.819: Early stopping is triggered at epoch: 288
2023-06-08 16:50:12.820: best_result@epoch 268:

2023-06-08 16:50:12.820: Loading from the saved model.
2023-06-08 16:51:03.038: 		0.00674785  	0.10807765  	0.05105563  	0.03852440  	0.03897744  
/home/Thesis/model/general_recommender/SGL.py:146: RuntimeWarning: divide by zero encountered in power
  d_inv = np.power(rowsum, -0.5).flatten()
